X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:00,506 --> 00:00:09,516 A:middle
[ Silence ]

2
00:00:10,016 --> 00:00:16,000 A:middle
[ Applause ]

3
00:00:16,366 --> 00:00:17,086 A:middle
>> Hi everyone.

4
00:00:17,086 --> 00:00:18,016 A:middle
Thanks for coming today.

5
00:00:18,456 --> 00:00:19,586 A:middle
My name is David Eldred.

6
00:00:19,586 --> 00:00:22,056 A:middle
This is session 513
and we're going to talk

7
00:00:22,056 --> 00:00:25,156 A:middle
about Video Encoders
and Decoders today.

8
00:00:25,866 --> 00:00:26,296 A:middle
All right.

9
00:00:26,716 --> 00:00:28,916 A:middle
We want to make sure that
no matter what you're doing

10
00:00:28,916 --> 00:00:31,216 A:middle
with the video in your
application, you have access

11
00:00:31,596 --> 00:00:33,416 A:middle
to hardware encoders
and decoders.

12
00:00:34,256 --> 00:00:36,136 A:middle
This will help users.

13
00:00:36,136 --> 00:00:38,596 A:middle
This will improve user
experience in a number of ways.

14
00:00:39,426 --> 00:00:41,196 A:middle
Obviously, they'll
get better performance

15
00:00:41,196 --> 00:00:46,176 A:middle
and they will be far more
efficient, but most importantly,

16
00:00:46,176 --> 00:00:47,616 A:middle
this will extend battery life.

17
00:00:48,236 --> 00:00:53,456 A:middle
Users will really appreciate it
if their OS X, their portables

18
00:00:53,736 --> 00:00:56,616 A:middle
as well as their iOS devices
have improved battery life.

19
00:00:57,356 --> 00:01:00,486 A:middle
And as an added bonus, people
with portables will love it

20

21
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

22
00:00:57,356 --> 00:01:00,486 A:middle
And as an added bonus, people
with portables will love it

23
00:01:00,486 --> 00:01:02,096 A:middle
if their fans don't kick

24
00:01:02,096 --> 00:01:03,916 A:middle
in every time they're
doing video processing.

25
00:01:05,256 --> 00:01:09,366 A:middle
So today, we're going
to break this --

26
00:01:09,366 --> 00:01:11,396 A:middle
first, we're going to break this
down into a few case studies.

27
00:01:11,396 --> 00:01:13,806 A:middle
We're going to look at
some common user scenarios.

28
00:01:14,546 --> 00:01:16,696 A:middle
The first scenario we're going
to talk about is the case

29
00:01:16,696 --> 00:01:19,706 A:middle
where you have a stream of H.264
data coming in over the network

30
00:01:20,056 --> 00:01:21,406 A:middle
and you want to display
that inside

31
00:01:21,406 --> 00:01:22,766 A:middle
of a layer in your application.

32
00:01:23,356 --> 00:01:25,556 A:middle
The next one we're going
to talk about is the case

33
00:01:25,556 --> 00:01:28,746 A:middle
where you have a stream of H.264
data coming in over the network,

34
00:01:29,016 --> 00:01:30,186 A:middle
but you don't just
want to display

35
00:01:30,186 --> 00:01:33,026 A:middle
that in your application, but
you actually want to get access

36
00:01:33,026 --> 00:01:34,736 A:middle
to those decoded
CV pixel buffers.

37
00:01:36,646 --> 00:01:39,686 A:middle
Next, we'll be talking
about when the case

38
00:01:39,686 --> 00:01:42,596 A:middle
where you have a sequence of
images coming in from the camera

39
00:01:42,596 --> 00:01:44,086 A:middle
or someplace else and you'd

40
00:01:44,086 --> 00:01:46,316 A:middle
like to compress those
directly into a movie file.

41
00:01:48,086 --> 00:01:51,826 A:middle
And accompanying that, there's
the case where you have a stream

42
00:01:51,826 --> 00:01:54,326 A:middle
of images coming in from
the camera or someplace else

43
00:01:54,906 --> 00:01:57,186 A:middle
and you'd like to compress
those but get direct access

44
00:01:57,186 --> 00:01:58,726 A:middle
to those compressed
sample buffers

45
00:01:59,066 --> 00:02:00,616 A:middle
so that you can send
them out over the network

46

47
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

48
00:01:59,066 --> 00:02:00,616 A:middle
so that you can send
them out over the network

49
00:02:00,996 --> 00:02:02,356 A:middle
or do whatever you
like with them.

50
00:02:03,336 --> 00:02:05,906 A:middle
And then finally, we're
going to give you an intro

51
00:02:05,906 --> 00:02:07,486 A:middle
to our new multi-pass APIs

52
00:02:07,486 --> 00:02:11,136 A:middle
that we're introducing
in iOS8 and Yosemite.

53
00:02:11,446 --> 00:02:15,836 A:middle
All right, let's
do a quick overview

54
00:02:15,836 --> 00:02:17,166 A:middle
of our media interface stack.

55
00:02:17,406 --> 00:02:19,976 A:middle
You've seen stuff like
this earlier this week,

56
00:02:20,026 --> 00:02:23,796 A:middle
but we'll do it once more, and
there's a little focus on video

57
00:02:23,796 --> 00:02:27,296 A:middle
in my view of this, because
we're talking about video.

58
00:02:28,116 --> 00:02:30,496 A:middle
So at the top we have AVKit.

59
00:02:30,496 --> 00:02:35,196 A:middle
AVKit provides very easy-to-use
high level view level interfaces

60
00:02:35,196 --> 00:02:36,056 A:middle
for dealing with media.

61
00:02:37,496 --> 00:02:39,316 A:middle
Below that, we have
AVFoundation.

62
00:02:39,686 --> 00:02:42,226 A:middle
AVFoundation provides an
easy-to-use objective C

63
00:02:42,226 --> 00:02:45,026 A:middle
interface for a wide
range of media tasks.

64
00:02:46,186 --> 00:02:48,726 A:middle
And below that, we
have Video Toolbox.

65
00:02:49,076 --> 00:02:51,796 A:middle
Video Toolbox has been
there on OS X for a while,

66
00:02:51,796 --> 00:02:55,006 A:middle
but now it's finally
populated with headers on iOS.

67
00:02:55,676 --> 00:02:57,996 A:middle
This provides direct
access to encoders

68
00:02:57,996 --> 00:02:58,646 A:middle
and decoders [applause].

69

70
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

71
00:03:01,306 --> 00:03:05,926 A:middle
And below that we have
Core Media Core Video.

72
00:03:06,246 --> 00:03:09,226 A:middle
These frameworks provide
many of the necessary types

73
00:03:09,226 --> 00:03:10,246 A:middle
that you'll see throughout
the --

74
00:03:10,346 --> 00:03:14,236 A:middle
in the interfaces in
the rest of the stack.

75
00:03:15,076 --> 00:03:18,326 A:middle
So today, we're going
to focus on AVFoundation

76
00:03:18,326 --> 00:03:19,456 A:middle
and the Video Toolbox.

77
00:03:19,896 --> 00:03:22,596 A:middle
In AVFoundation, we'll be
looking at some interfaces

78
00:03:22,596 --> 00:03:25,616 A:middle
that allow you to decode
video directly into a layer

79
00:03:25,616 --> 00:03:30,676 A:middle
in your application or compress
frames directly into a file.

80
00:03:30,676 --> 00:03:34,156 A:middle
And the Video Toolbox we'll
be looking at these interfaces

81
00:03:34,156 --> 00:03:37,216 A:middle
to give you more direct access
to encoders and decoders

82
00:03:37,756 --> 00:03:40,186 A:middle
so you can decompress
directly to CV pixel buffers

83
00:03:40,186 --> 00:03:42,836 A:middle
or compress directly
to CM sample buffers.

84
00:03:44,376 --> 00:03:48,676 A:middle
So a quick note on
using these frameworks.

85
00:03:48,676 --> 00:03:50,896 A:middle
A lot of people think they have
to dive down to the lowest level

86
00:03:50,896 --> 00:03:52,286 A:middle
and use the Video
Toolbox in order

87
00:03:52,286 --> 00:03:56,026 A:middle
to get hardware acceleration,
but that's really not true.

88
00:03:57,366 --> 00:03:59,806 A:middle
On iOS, AVKit, AVFoundation

89
00:03:59,806 --> 00:04:02,666 A:middle
and Video Toolbox will
all use hardware codec.

90

91
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

92
00:03:59,806 --> 00:04:02,666 A:middle
and Video Toolbox will
all use hardware codec.

93
00:04:04,046 --> 00:04:07,236 A:middle
On OS X, AVKit and AVFoundation
will use hardware codec

94
00:04:07,236 --> 00:04:09,596 A:middle
when they're available on
the system and when you --

95
00:04:09,756 --> 00:04:10,876 A:middle
when it's appropriate.

96
00:04:11,706 --> 00:04:14,146 A:middle
And Video Toolbox will
use hardware codec

97
00:04:14,296 --> 00:04:17,976 A:middle
when it's available on system
and when you request it.

98
00:04:19,026 --> 00:04:19,375 A:middle
All right.

99
00:04:20,646 --> 00:04:23,056 A:middle
So before we dive into
more stuff, we're going --

100
00:04:23,206 --> 00:04:25,866 A:middle
I'm going to do a quick look
at this cast of characters.

101
00:04:25,866 --> 00:04:27,126 A:middle
These are some of
the common types

102
00:04:27,126 --> 00:04:29,486 A:middle
that you'll encounter
in these interfaces.

103
00:04:31,606 --> 00:04:33,436 A:middle
First off, there's
CVPixelBuffer.

104
00:04:33,816 --> 00:04:39,476 A:middle
CVPixelBuffer contains a block
of image data and wrapping

105
00:04:39,476 --> 00:04:42,906 A:middle
that buffer of data is the
CVPixelBuffer wrapping.

106
00:04:43,286 --> 00:04:45,656 A:middle
And the CVPixelBuffer
wrapping tells you how

107
00:04:45,656 --> 00:04:46,716 A:middle
to access that data.

108
00:04:46,816 --> 00:04:49,506 A:middle
It's got the dimensions,
the width and the height.

109
00:04:49,506 --> 00:04:52,166 A:middle
It's got the pixel format,
everything you need in order

110
00:04:52,166 --> 00:04:55,916 A:middle
to correctly interpret
the pixel data.

111
00:04:56,636 --> 00:04:58,436 A:middle
Next, we've got the
CVPixelBufferPool.

112
00:04:58,436 --> 00:05:00,306 A:middle
The CVPixelBufferPool allows you

113

114
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

115
00:04:58,436 --> 00:05:00,306 A:middle
The CVPixelBufferPool allows you

116
00:05:00,306 --> 00:05:03,136 A:middle
to efficiently recycle
CVPixelBuffer back ends.

117
00:05:03,826 --> 00:05:07,496 A:middle
Those data buffers can be very
expensive to constantly allocate

118
00:05:07,496 --> 00:05:08,266 A:middle
and de-allocate,

119
00:05:08,356 --> 00:05:11,996 A:middle
so PixelBufferPool allows
you to recycle them.

120
00:05:12,766 --> 00:05:15,726 A:middle
The way a PixelBufferPool works
is you allocate a CVPixelBuffer

121
00:05:15,726 --> 00:05:18,946 A:middle
from the pool and the
CVPixelBuffer is a ref

122
00:05:18,946 --> 00:05:19,656 A:middle
counted object.

123
00:05:19,976 --> 00:05:22,116 A:middle
When everyone releases
that CVPixelBuffer,

124
00:05:22,436 --> 00:05:25,016 A:middle
the data back end goes back
into the pool and it's available

125
00:05:25,016 --> 00:05:30,266 A:middle
for reuse next time you allocate
a PixelBuffer from that pool.

126
00:05:31,266 --> 00:05:34,336 A:middle
Next thing is
pixelBufferAttributes.

127
00:05:34,456 --> 00:05:36,636 A:middle
This isn't actually a type
like the rest of the things

128
00:05:36,636 --> 00:05:40,576 A:middle
in this list, but it's a
common object you'll see listed

129
00:05:40,576 --> 00:05:41,446 A:middle
in our interfaces.

130
00:05:41,446 --> 00:05:42,526 A:middle
You'll see requests

131
00:05:42,526 --> 00:05:44,266 A:middle
for pixelBufferAttributes
dictionaries.

132
00:05:44,996 --> 00:05:47,336 A:middle
pixelBufferAttributes are a
CF dictionary containing a set

133
00:05:47,336 --> 00:05:50,106 A:middle
of requirements for
either a CVPixelBuffer

134
00:05:50,106 --> 00:05:51,136 A:middle
or a PixelBufferPool.

135
00:05:52,646 --> 00:05:56,096 A:middle
This includes the -- this
can include several things.

136
00:05:56,096 --> 00:05:57,206 A:middle
This can include dimensions

137
00:05:57,206 --> 00:05:58,906 A:middle
that you're requesting,
the width and height.

138
00:05:59,436 --> 00:06:02,076 A:middle
This can include a specific
pixel format or a list

139

140
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

141
00:05:59,436 --> 00:06:02,076 A:middle
This can include a specific
pixel format or a list

142
00:06:02,076 --> 00:06:04,886 A:middle
of pixel formats that
you'd like to receive.

143
00:06:05,926 --> 00:06:09,586 A:middle
And you can include specific
compatibility flags requesting

144
00:06:09,586 --> 00:06:12,636 A:middle
compatibility with specific
display technologies

145
00:06:12,636 --> 00:06:16,336 A:middle
such as OpenGL, OpenGL
ES or Core Animation.

146
00:06:19,316 --> 00:06:19,696 A:middle
All right.

147
00:06:19,696 --> 00:06:20,996 A:middle
Next, we've got CMTime.

148
00:06:21,626 --> 00:06:24,716 A:middle
CMTime is the basic
description of time

149
00:06:24,716 --> 00:06:26,006 A:middle
that you'll see in
your interfaces.

150
00:06:26,506 --> 00:06:29,716 A:middle
This is a rational
representation of a time value.

151
00:06:29,716 --> 00:06:33,656 A:middle
It contains a 64 byte time
value that's the numerator,

152
00:06:34,216 --> 00:06:36,676 A:middle
and a 32 byte time scale,
which is the denominator.

153
00:06:37,326 --> 00:06:39,096 A:middle
We use the sort of
rational representation

154
00:06:39,096 --> 00:06:41,966 A:middle
so that these time values can
be passed throughout your media

155
00:06:41,966 --> 00:06:46,816 A:middle
pipeline and you won't have to
do any sort of rounding on them.

156
00:06:47,436 --> 00:06:47,886 A:middle
All right.

157
00:06:48,406 --> 00:06:50,446 A:middle
Next, CMVideoFormatDescription.

158
00:06:50,746 --> 00:06:52,516 A:middle
You'll see this in a
bunch of our interfaces,

159
00:06:52,576 --> 00:06:55,626 A:middle
and a CMVideoFormatDescription
is basically a description

160
00:06:55,626 --> 00:06:56,276 A:middle
of video data.

161
00:06:56,866 --> 00:06:58,346 A:middle
This contains the dimensions.

162
00:06:58,786 --> 00:07:03,446 A:middle
This includes the pixel format
and there's a set of extensions

163

164
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

165
00:06:58,786 --> 00:07:03,446 A:middle
This includes the pixel format
and there's a set of extensions

166
00:07:03,446 --> 00:07:07,546 A:middle
that go along with the
CMVideoFormatDescription.

167
00:07:07,936 --> 00:07:11,186 A:middle
These extensions can
include information to --

168
00:07:11,866 --> 00:07:15,696 A:middle
information used for
displaying that video data just

169
00:07:15,696 --> 00:07:16,896 A:middle
as pixel aspect ratio,

170
00:07:17,356 --> 00:07:19,546 A:middle
and it can include
color space information.

171
00:07:19,866 --> 00:07:24,766 A:middle
And in the case of H.264 data,
the parameter sets are included

172
00:07:24,766 --> 00:07:26,746 A:middle
in these extensions
and we'll talk

173
00:07:26,746 --> 00:07:29,536 A:middle
about that more a
little bit later.

174
00:07:30,536 --> 00:07:32,116 A:middle
All right, next is
CMBlockBuffer.

175
00:07:32,626 --> 00:07:37,076 A:middle
CMBlockBuffer is the basic way
that we wrap arbitrary blocks

176
00:07:37,076 --> 00:07:38,096 A:middle
of data in core media.

177
00:07:39,096 --> 00:07:41,506 A:middle
In general, when you
encounter video data,

178
00:07:41,646 --> 00:07:43,586 A:middle
compressed video
data in our pipeline,

179
00:07:43,586 --> 00:07:45,346 A:middle
it will be wrapped
in a CMBlockBuffer.

180
00:07:45,916 --> 00:07:50,286 A:middle
All right, now we
have CMSampleBuffer.

181
00:07:50,596 --> 00:07:53,776 A:middle
You'll see CMSampleBuffer show
up a lot in our interfaces.

182
00:07:54,266 --> 00:07:55,726 A:middle
These wrap samples of data.

183
00:07:56,056 --> 00:07:58,356 A:middle
In the case of video,

184
00:07:58,446 --> 00:08:02,006 A:middle
CMSampleBuffer's can wrap
either compressed video frames

185

186
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

187
00:07:58,446 --> 00:08:02,006 A:middle
CMSampleBuffer's can wrap
either compressed video frames

188
00:08:02,006 --> 00:08:05,536 A:middle
or uncompressed video frames
and CMSampleBuffer's build

189
00:08:05,536 --> 00:08:07,366 A:middle
on several of the types that
we've talked about here.

190
00:08:08,226 --> 00:08:09,796 A:middle
They contain a CMTime.

191
00:08:09,916 --> 00:08:12,056 A:middle
This is the presentation
time for the sample.

192
00:08:12,646 --> 00:08:15,706 A:middle
They contain a
CMVideoFormatDescription.

193
00:08:15,816 --> 00:08:18,446 A:middle
This describes the data
inside of the CMSampleBuffer.

194
00:08:19,826 --> 00:08:21,746 A:middle
And finally, in the case
of compressed video,

195
00:08:21,746 --> 00:08:23,236 A:middle
they contain a CMBlockBuffer

196
00:08:23,236 --> 00:08:25,586 A:middle
and the CMBlockBuffer has
the compressed video data.

197
00:08:26,446 --> 00:08:29,346 A:middle
And if it's an uncompressed
image in the CMSampleBuffer,

198
00:08:29,846 --> 00:08:32,426 A:middle
the uncompressed image
may be in a CVPixelBuffer

199
00:08:32,816 --> 00:08:34,385 A:middle
or it may be in a CMBlockBuffer.

200
00:08:34,956 --> 00:08:37,056 A:middle
All right.

201
00:08:37,056 --> 00:08:38,346 A:middle
Next, we've got CMClock.

202
00:08:39,576 --> 00:08:43,385 A:middle
CMClock is the core media
wrapper around a source of time

203
00:08:43,936 --> 00:08:46,636 A:middle
and like the clock on a
wall, there's no clocks

204
00:08:46,636 --> 00:08:48,426 A:middle
on the wall here, but
like a clock on the wall,

205
00:08:48,896 --> 00:08:52,226 A:middle
time is always moving and it's
always increasing on a CMClock.

206
00:08:53,506 --> 00:08:55,246 A:middle
One of the common clocks

207
00:08:55,246 --> 00:08:57,556 A:middle
that you'll see used
is the HostTimeClock.

208
00:08:58,026 --> 00:09:03,546 A:middle
So CMClockgetHostTimeClock will
return a clock which is based

209

210
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

211
00:08:58,026 --> 00:09:03,546 A:middle
So CMClockgetHostTimeClock will
return a clock which is based

212
00:09:03,696 --> 00:09:06,016 A:middle
on mach absolute time.

213
00:09:08,096 --> 00:09:10,516 A:middle
So CMClocks are hard to control.

214
00:09:10,516 --> 00:09:12,156 A:middle
You can't really control them.

215
00:09:12,466 --> 00:09:14,526 A:middle
As I mentioned, they're
always moving

216
00:09:14,896 --> 00:09:16,306 A:middle
and always at a constant rate.

217
00:09:16,896 --> 00:09:20,606 A:middle
So CMTimebase provides a more
controlled view onto a CMClock.

218
00:09:22,156 --> 00:09:25,606 A:middle
So if we go ahead and
create a CMClock based --

219
00:09:25,826 --> 00:09:27,956 A:middle
CMTimebase based on
the host time clock,

220
00:09:28,346 --> 00:09:31,196 A:middle
we could then set the time to
time zero on our time base.

221
00:09:32,966 --> 00:09:37,606 A:middle
Now, time zero on our time
base maps to the current time

222
00:09:37,656 --> 00:09:42,006 A:middle
on the CMClock, and you
can control the rate

223
00:09:42,096 --> 00:09:43,246 A:middle
of your time base.

224
00:09:43,346 --> 00:09:46,206 A:middle
So if you were then to go and
set your time base rate to one,

225
00:09:46,376 --> 00:09:48,866 A:middle
time will begin advancing on
your time base at the same rate

226
00:09:48,916 --> 00:09:50,596 A:middle
at which the clock is advancing.

227
00:09:51,036 --> 00:09:54,916 A:middle
And CMTimebases can be
created based on CMClocks

228
00:09:54,916 --> 00:09:57,216 A:middle
or they can be created
based on other CMTimebases.

229
00:09:58,836 --> 00:09:59,736 A:middle
All right.

230

231
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

232
00:10:00,576 --> 00:10:02,376 A:middle
Let's hop into our
first use case.

233
00:10:02,936 --> 00:10:05,156 A:middle
This is the case where you
have a stream of data coming

234
00:10:05,156 --> 00:10:08,746 A:middle
in over the network and
since its video data coming

235
00:10:08,746 --> 00:10:10,986 A:middle
over the network, we can
safely assume it's a cat video,

236
00:10:12,246 --> 00:10:16,916 A:middle
and so we've got
AVSampleBufferDisplayLayer,

237
00:10:16,916 --> 00:10:21,086 A:middle
which takes -- which can take
a sequence of compressed frames

238
00:10:21,476 --> 00:10:23,566 A:middle
and display it in a layer
inside of your application.

239
00:10:24,666 --> 00:10:26,846 A:middle
AVSampleBufferDisplayLayer
shipped

240
00:10:27,016 --> 00:10:29,906 A:middle
in Mavericks, and
it's new in iOS8.

241
00:10:31,026 --> 00:10:33,806 A:middle
So let's take a look inside
AVSampleBufferDisplayLayer.

242
00:10:34,846 --> 00:10:39,256 A:middle
As I mentioned, it takes a
sequence of compressed frames

243
00:10:39,256 --> 00:10:41,706 A:middle
as input and these need
to be in CMSampleBuffers.

244
00:10:42,796 --> 00:10:44,776 A:middle
Internally, it's going
to have a video decoder

245
00:10:45,656 --> 00:10:49,006 A:middle
and it will decode the
frames into CVPixelBuffers

246
00:10:49,006 --> 00:10:51,806 A:middle
and it will have a sequence
of CVPixelBuffers queued up

247
00:10:51,876 --> 00:10:53,996 A:middle
and ready to display
in your application

248
00:10:53,996 --> 00:10:54,976 A:middle
at the appropriate time.

249
00:10:55,546 --> 00:11:00,966 A:middle
But, I mentioned we were getting
our data off of the network.

250

251
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

252
00:10:55,546 --> 00:11:00,966 A:middle
But, I mentioned we were getting
our data off of the network.

253
00:11:01,186 --> 00:11:03,646 A:middle
A lot of times, when
you're getting a stream

254
00:11:03,646 --> 00:11:06,176 A:middle
of compressed video off the
network, it's going to be

255
00:11:06,176 --> 00:11:07,746 A:middle
in the form of an
elementary stream.

256
00:11:08,886 --> 00:11:10,686 A:middle
And I mentioned that CMSample --

257
00:11:10,796 --> 00:11:14,566 A:middle
AVSampleBufferDisplayLayer wants
CMSampleBuffers as its input.

258
00:11:15,836 --> 00:11:18,256 A:middle
Well, there's a little bit of
work that has to happen here

259
00:11:18,256 --> 00:11:20,036 A:middle
to convert your elementary
screen data

260
00:11:20,036 --> 00:11:21,276 A:middle
into CMSampleBuffers.

261
00:11:21,276 --> 00:11:23,766 A:middle
So let's talk about this.

262
00:11:23,766 --> 00:11:28,176 A:middle
H.264 defines a couple
of ways of packaging --

263
00:11:28,176 --> 00:11:33,226 A:middle
the H.264 spec defines a couple
of ways of packaging H.264 data.

264
00:11:33,226 --> 00:11:34,386 A:middle
The first one I'm going to refer

265
00:11:34,386 --> 00:11:35,996 A:middle
to is Elementary
Stream packaging.

266
00:11:36,506 --> 00:11:38,986 A:middle
This is used in elementary
streams, transport streams,

267
00:11:38,986 --> 00:11:41,966 A:middle
a lot of things with
streams in their name.

268
00:11:41,966 --> 00:11:43,596 A:middle
Next, is MPEG-4 packaging.

269
00:11:44,056 --> 00:11:47,596 A:middle
This is used in movie
files and MP4 files.

270
00:11:48,786 --> 00:11:52,516 A:middle
And in our interfaces that deal
with CMSampleBuffers, core media

271
00:11:52,516 --> 00:11:56,376 A:middle
and AVFoundation exclusively
want the data packaged

272
00:11:56,616 --> 00:11:58,656 A:middle
in MPEG-4 packaging.

273

274
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

275
00:12:00,006 --> 00:12:03,496 A:middle
So let's look closer
at an H.264 stream.

276
00:12:04,066 --> 00:12:08,336 A:middle
An H.264 stream consists
of a sequence of blocks

277
00:12:08,336 --> 00:12:10,356 A:middle
of data packaged in NAL Units.

278
00:12:10,836 --> 00:12:13,546 A:middle
These NAL Units can
contain several --

279
00:12:13,996 --> 00:12:15,566 A:middle
so this is the network
abstraction layer,

280
00:12:16,126 --> 00:12:18,416 A:middle
and these are Network
Abstraction Layer units.

281
00:12:19,266 --> 00:12:20,956 A:middle
These can contain a
few different things.

282
00:12:21,436 --> 00:12:23,446 A:middle
First off, they can
contain sample data.

283
00:12:25,846 --> 00:12:30,976 A:middle
So you could have a single
frame of video could be packaged

284
00:12:30,976 --> 00:12:36,016 A:middle
in one NAL Unit or a frame
of video could be spread

285
00:12:36,016 --> 00:12:37,386 A:middle
across several NAL Units.

286
00:12:38,286 --> 00:12:43,116 A:middle
The other thing that NAL Units
can contain is parameter sets.

287
00:12:43,446 --> 00:12:45,686 A:middle
The parameter sets, the
Sequence Parameter Set

288
00:12:45,686 --> 00:12:49,416 A:middle
and Picture Parameter
Set are chunks of data

289
00:12:49,416 --> 00:12:51,856 A:middle
of which the decoder holds
on to and these apply

290
00:12:51,856 --> 00:12:55,916 A:middle
to all subsequent frames; well,

291
00:12:55,916 --> 00:12:57,316 A:middle
until a new parameter
set arrives.

292
00:12:59,226 --> 00:13:01,536 A:middle
So let's look at
Elementary Stream packaging.

293

294
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

295
00:12:59,226 --> 00:13:01,536 A:middle
So let's look at
Elementary Stream packaging.

296
00:13:01,976 --> 00:13:04,786 A:middle
Elementary Stream packaging,
in Elementary Stream packaging,

297
00:13:05,126 --> 00:13:06,366 A:middle
the parameter sets are included

298
00:13:06,366 --> 00:13:08,206 A:middle
in NAL Units right
inside the stream.

299
00:13:08,396 --> 00:13:10,296 A:middle
This is great if you're
doing sequential playback.

300
00:13:10,866 --> 00:13:13,196 A:middle
You read in your parameter
sets and they apply

301
00:13:13,196 --> 00:13:16,156 A:middle
to all subsequent frames until
a new frame or sets arrive.

302
00:13:17,556 --> 00:13:21,036 A:middle
MPEG-4 packaging has the NAL
Units pulled out and it's

303
00:13:21,036 --> 00:13:24,616 A:middle
in a separate block of data,
and this block of data is stored

304
00:13:24,616 --> 00:13:26,236 A:middle
in the CMVideoFormatDescription.

305
00:13:26,786 --> 00:13:27,586 A:middle
So as I mentioned,

306
00:13:27,666 --> 00:13:32,346 A:middle
each CMSampleBuffer references
this CMVideoFormatDescription.

307
00:13:32,476 --> 00:13:35,666 A:middle
That means each frame
of data has access

308
00:13:35,756 --> 00:13:37,146 A:middle
to the parameter sets.

309
00:13:38,106 --> 00:13:40,826 A:middle
This sort of packaging
is superior

310
00:13:40,826 --> 00:13:42,246 A:middle
for random access in a file.

311
00:13:42,306 --> 00:13:44,836 A:middle
It allows you to jump anywhere

312
00:13:44,836 --> 00:13:47,106 A:middle
and begin decoding
at an I frame.

313
00:13:49,066 --> 00:13:50,356 A:middle
So what do you have to do

314
00:13:50,356 --> 00:13:52,076 A:middle
if you have an Elementary
Stream coming in?

315
00:13:52,986 --> 00:13:55,046 A:middle
Well, we've got --
you've got a couple --

316
00:13:55,276 --> 00:13:58,276 A:middle
you've got your parameter sets
and NAL Units and you're going

317
00:13:58,276 --> 00:14:01,276 A:middle
to have to package those in
a CMVideoFormatDescription.

318

319
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

320
00:13:58,276 --> 00:14:01,276 A:middle
to have to package those in
a CMVideoFormatDescription.

321
00:14:02,086 --> 00:14:05,096 A:middle
Well, we provide a handy
utility that does this for you;

322
00:14:05,246 --> 00:14:07,976 A:middle
CMVideoFormatDescription
CreatefromH264ParameterSets.

323
00:14:08,516 --> 00:14:12,956 A:middle
[ Applause ]

324
00:14:13,456 --> 00:14:17,396 A:middle
All right, so the next
difference that we're going

325
00:14:17,396 --> 00:14:19,536 A:middle
to talk about between
an Elementary Stream

326
00:14:19,536 --> 00:14:23,306 A:middle
and MPEG-4 packaging
is in NAL Unit headers.

327
00:14:24,086 --> 00:14:25,286 A:middle
So each NAL Unit

328
00:14:25,286 --> 00:14:27,736 A:middle
in an Elementary
Stream will have a three

329
00:14:27,736 --> 00:14:33,166 A:middle
or four bytes start code as the
header and in MPEG-4 packaging,

330
00:14:33,256 --> 00:14:34,786 A:middle
we have a length code.

331
00:14:35,456 --> 00:14:37,616 A:middle
So for each NAL Unit in your
stream, they're going --

332
00:14:38,156 --> 00:14:41,026 A:middle
you have to strip
off that start code

333
00:14:41,026 --> 00:14:42,426 A:middle
and replace it with
a length code.

334
00:14:42,766 --> 00:14:44,066 A:middle
That's the length
of the NAL Unit.

335
00:14:45,256 --> 00:14:46,126 A:middle
It's not that hard.

336
00:14:48,096 --> 00:14:50,226 A:middle
So let's talk about
building a CMSampleBuffer

337
00:14:50,876 --> 00:14:52,626 A:middle
from your Elementary Stream.

338
00:14:52,916 --> 00:14:55,096 A:middle
First thing you're going to
have to do is take your NAL Unit

339
00:14:55,476 --> 00:15:00,496 A:middle
or NAL Units and replace the
start code with a length code.

340

341
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

342
00:14:55,476 --> 00:15:00,496 A:middle
or NAL Units and replace the
start code with a length code.

343
00:15:02,436 --> 00:15:05,986 A:middle
And you'll wrap that NAL
Unit in a CMBlockBuffer.

344
00:15:06,646 --> 00:15:09,776 A:middle
One note here, for simplicity,
I'm showing a single NAL Unit

345
00:15:09,776 --> 00:15:12,326 A:middle
but if you have a frame that
consists of several NAL Units,

346
00:15:12,716 --> 00:15:14,506 A:middle
you need to include
all of the NAL Units

347
00:15:14,506 --> 00:15:15,746 A:middle
in your CMSampleBuffer.

348
00:15:16,876 --> 00:15:18,486 A:middle
So you have a CMBlockBuffer.

349
00:15:18,786 --> 00:15:20,306 A:middle
You have your
CMVideoFormatDescription

350
00:15:20,306 --> 00:15:21,556 A:middle
that you created
from your initial --

351
00:15:21,626 --> 00:15:25,286 A:middle
from your parameter sets,
and throw in a CMTime value,

352
00:15:25,286 --> 00:15:27,016 A:middle
that's the presentation
time of your frame,

353
00:15:27,646 --> 00:15:29,876 A:middle
and you have everything
you need in order

354
00:15:29,876 --> 00:15:33,696 A:middle
to create CMSampleBuffer
using CMSampleBufferCreate.

355
00:15:34,536 --> 00:15:38,256 A:middle
All right, let's talk

356
00:15:38,256 --> 00:15:40,336 A:middle
about AVSampleBufferDisplayLayer
in time.

357
00:15:41,086 --> 00:15:41,936 A:middle
So as we saw,

358
00:15:41,936 --> 00:15:44,826 A:middle
all CMSampleBuffers have an
associated presentation time

359
00:15:44,826 --> 00:15:48,176 A:middle
stamp, and our video
decoder's going to be spitting

360
00:15:48,176 --> 00:15:52,226 A:middle
out CVPixelBuffers each with
an associated presentation

361
00:15:52,226 --> 00:15:52,796 A:middle
time stamp.

362
00:15:53,646 --> 00:15:55,556 A:middle
Well, how does it know when
to display these frames?

363
00:15:56,516 --> 00:15:59,286 A:middle
By default, it will be driven
off of the host time clock.

364

365
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

366
00:16:00,466 --> 00:16:02,426 A:middle
Well, that can be a
little bit hard to manager.

367
00:16:02,426 --> 00:16:05,266 A:middle
The host time clock isn't
really under your control.

368
00:16:06,126 --> 00:16:08,796 A:middle
So we allow you to
replace the host time clock

369
00:16:08,796 --> 00:16:10,936 A:middle
with your own time base.

370
00:16:11,816 --> 00:16:14,826 A:middle
To do this you set the time --
you know in the example here,

371
00:16:15,026 --> 00:16:18,566 A:middle
we're creating a time base
based on the host time clock

372
00:16:18,986 --> 00:16:21,096 A:middle
and we're setting that
as the control time base

373
00:16:21,096 --> 00:16:22,716 A:middle
on our
AVSampleBufferDisplayLayer.

374
00:16:24,056 --> 00:16:26,016 A:middle
Here, we're setting the
time base time to five,

375
00:16:26,056 --> 00:16:29,146 A:middle
which would mean our frame
whose time stamp is five will be

376
00:16:29,146 --> 00:16:31,916 A:middle
displayed in our layer,
and then we go ahead

377
00:16:31,916 --> 00:16:33,676 A:middle
and set the time
base rate to one,

378
00:16:34,046 --> 00:16:36,266 A:middle
and now our time base begins
moving at the same rate

379
00:16:36,266 --> 00:16:38,936 A:middle
as the host time clock,

380
00:16:39,476 --> 00:16:42,186 A:middle
and subsequent frames
will be displayed

381
00:16:42,186 --> 00:16:44,616 A:middle
at the appropriate time.

382
00:16:45,636 --> 00:16:46,466 A:middle
All right.

383
00:16:47,706 --> 00:16:50,956 A:middle
So providing the
CMSampleBuffers,

384
00:16:50,956 --> 00:16:52,426 A:middle
the SampleBufferDisplayLayer,

385
00:16:52,626 --> 00:16:54,826 A:middle
there's really two
major scenarios

386
00:16:54,826 --> 00:16:55,746 A:middle
that can describe this.

387
00:16:56,446 --> 00:16:58,226 A:middle
First off, there's
the periodic source.

388
00:16:58,486 --> 00:16:59,966 A:middle
This is the case where
you're getting frames

389
00:16:59,966 --> 00:17:03,026 A:middle
in at basically the same rate
at which they're being displayed

390

391
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

392
00:16:59,966 --> 00:17:03,026 A:middle
in at basically the same rate
at which they're being displayed

393
00:17:03,026 --> 00:17:05,556 A:middle
in the
AVSampleBufferDisplayLayer.

394
00:17:06,086 --> 00:17:08,336 A:middle
This would be the case
for a live streaming app

395
00:17:08,896 --> 00:17:12,195 A:middle
or live streaming
app with low latency

396
00:17:12,195 --> 00:17:14,066 A:middle
or video conferencing scenario.

397
00:17:15,175 --> 00:17:17,626 A:middle
The next case is the
unconstrained source.

398
00:17:18,056 --> 00:17:22,215 A:middle
This is the case where you have
a large set of CMSampleBuffers

399
00:17:22,215 --> 00:17:23,576 A:middle
at your disposal ready to feed

400
00:17:23,576 --> 00:17:26,415 A:middle
into the
AVSampleBufferDisplayLayer

401
00:17:26,756 --> 00:17:27,445 A:middle
at one time.

402
00:17:28,756 --> 00:17:31,076 A:middle
This would be the case
if you have a large cache

403
00:17:31,076 --> 00:17:32,446 A:middle
of buffered network data

404
00:17:32,816 --> 00:17:35,136 A:middle
or if you're reading the
CMSampleBuffers from a file.

405
00:17:35,926 --> 00:17:38,246 A:middle
All right, let's talk
about the first case.

406
00:17:39,066 --> 00:17:40,066 A:middle
This is really simple.

407
00:17:40,166 --> 00:17:41,366 A:middle
Frames are coming
in at the same rate

408
00:17:41,366 --> 00:17:42,456 A:middle
at which they're
being displayed.

409
00:17:42,786 --> 00:17:45,306 A:middle
You can go ahead and just
enqueue the sample buffers

410
00:17:45,446 --> 00:17:47,446 A:middle
with your
AVSampleBufferDisplayLayer

411
00:17:47,446 --> 00:17:48,206 A:middle
as they arrive.

412
00:17:50,166 --> 00:17:52,096 A:middle
You use the enqueueSampleBuffer
column.

413
00:17:52,576 --> 00:17:53,756 A:middle
All right.

414
00:17:53,756 --> 00:17:56,006 A:middle
The unconstrained source is a
little bit more complicated.

415
00:17:56,206 --> 00:17:59,056 A:middle
You don't want to just shove
all of those CMSampleBuffers

416
00:17:59,056 --> 00:18:00,446 A:middle
into the
AVSampleBufferDisplayLayer

417

418
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

419
00:17:59,056 --> 00:18:00,446 A:middle
into the
AVSampleBufferDisplayLayer

420
00:18:00,446 --> 00:18:00,836 A:middle
at once.

421
00:18:01,456 --> 00:18:02,956 A:middle
No one will be happy with that.

422
00:18:03,706 --> 00:18:05,136 A:middle
What you want to do,

423
00:18:05,226 --> 00:18:10,416 A:middle
the AVSampleBufferDisplayLayer
can tell you when its buffers,

424
00:18:10,996 --> 00:18:13,196 A:middle
internal buffers are low
and it needs more data

425
00:18:13,776 --> 00:18:15,806 A:middle
and you can ask it when
it has enough data.

426
00:18:16,856 --> 00:18:20,946 A:middle
The way you do this is
using the requestMediaData

427
00:18:20,946 --> 00:18:22,076 A:middle
WhenReadyOnQueue.

428
00:18:23,236 --> 00:18:26,716 A:middle
You provide a block
in this interface

429
00:18:27,136 --> 00:18:31,156 A:middle
and AVSampleBufferDisplayLayer
will call your block every time

430
00:18:31,216 --> 00:18:34,346 A:middle
its internal queue's are
low and it needs more data.

431
00:18:36,576 --> 00:18:38,646 A:middle
Inside of that block,
you can go ahead

432
00:18:38,646 --> 00:18:43,096 A:middle
and loop while you're asking
whether it has enough data.

433
00:18:43,206 --> 00:18:45,816 A:middle
You use isReadyForMoreMediaData
column.

434
00:18:46,296 --> 00:18:49,166 A:middle
If it returns true, that means
it wants for SampleBuffers,

435
00:18:49,306 --> 00:18:51,126 A:middle
so you keep on feeding
SampleBuffers in.

436
00:18:51,316 --> 00:18:53,246 A:middle
As soon as it returns false,

437
00:18:53,246 --> 00:18:55,226 A:middle
that means it has
enough and you can stop.

438
00:18:56,226 --> 00:18:58,656 A:middle
So it's a pretty
simple loop to write.

439

440
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

441
00:19:00,276 --> 00:19:01,456 A:middle
All right.

442
00:19:02,476 --> 00:19:04,466 A:middle
Let's do a quick
summary of what we talked

443
00:19:04,466 --> 00:19:06,106 A:middle
about with
AVSampleBufferDisplayLayer.

444
00:19:06,226 --> 00:19:08,356 A:middle
At this point, you
should be able

445
00:19:08,356 --> 00:19:10,426 A:middle
to create an
AVSampleBufferDisplayLayer.

446
00:19:11,716 --> 00:19:14,396 A:middle
You've learned how to
convert your Elementary Stream

447
00:19:14,616 --> 00:19:17,676 A:middle
to H.264 data into
CMSampleBuffers

448
00:19:17,726 --> 00:19:20,376 A:middle
that will happily
be decompressed

449
00:19:20,376 --> 00:19:21,926 A:middle
by your
AVSampleBufferDisplayLayer.

450
00:19:23,886 --> 00:19:26,006 A:middle
We've talked about a
couple of scenarios

451
00:19:26,286 --> 00:19:28,796 A:middle
about how you would provide
these CMSampleBuffers

452
00:19:28,836 --> 00:19:31,406 A:middle
to your layer,
AVSampleBufferDisplayLayer.

453
00:19:31,786 --> 00:19:34,386 A:middle
And finally, we talked about
using a custom time base

454
00:19:34,386 --> 00:19:35,966 A:middle
with the
AVSampleBufferDisplayLayer.

455
00:19:36,596 --> 00:19:37,626 A:middle
All right.

456
00:19:38,476 --> 00:19:40,116 A:middle
So let's dive into
our second case.

457
00:19:40,436 --> 00:19:43,296 A:middle
This is the case where you have
a stream of H.264 data coming

458
00:19:43,296 --> 00:19:44,946 A:middle
in over the network,
but you don't want

459
00:19:44,946 --> 00:19:46,296 A:middle
to just display it
in your application.

460
00:19:46,296 --> 00:19:48,066 A:middle
You want to actually
decode those frames

461
00:19:48,066 --> 00:19:50,766 A:middle
and get the decompressed
pixel buffers.

462
00:19:52,416 --> 00:19:55,666 A:middle
So what we had

463
00:19:55,666 --> 00:19:57,886 A:middle
in AVSampleBufferDisplayLayer
contains a lot

464
00:19:57,886 --> 00:19:58,756 A:middle
of the pieces we need.

465
00:19:59,656 --> 00:20:01,886 A:middle
But instead of accessing
the video decoder

466

467
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

468
00:19:59,656 --> 00:20:01,886 A:middle
But instead of accessing
the video decoder

469
00:20:01,886 --> 00:20:03,646 A:middle
through the
AVSampleBufferDisplayLayer,

470
00:20:04,166 --> 00:20:06,616 A:middle
we'll access it through
the VTDecompressionSession.

471
00:20:07,386 --> 00:20:10,126 A:middle
Like the
AVSampleBufferDisplayLayer,

472
00:20:10,236 --> 00:20:13,836 A:middle
VTDecompressionSession wants
CMSampleBuffers as its input.

473
00:20:15,946 --> 00:20:18,196 A:middle
And it will decode
the CMSampleBuffers

474
00:20:18,196 --> 00:20:20,796 A:middle
to CVPixelBuffers
and receive those

475
00:20:20,796 --> 00:20:22,866 A:middle
in the output callback
that you implement.

476
00:20:24,166 --> 00:20:26,766 A:middle
So in order to create a
VTDecompressionSession,

477
00:20:26,766 --> 00:20:27,796 A:middle
you'll need a few things.

478
00:20:28,626 --> 00:20:30,376 A:middle
First, you need to
provide a description

479
00:20:30,376 --> 00:20:32,506 A:middle
of the source buffers that
you'll be decompressing.

480
00:20:33,386 --> 00:20:35,256 A:middle
This is a
CMVideoFormatDescription.

481
00:20:35,306 --> 00:20:39,426 A:middle
If you're decompressing from an
Elementary Stream you've created

482
00:20:39,426 --> 00:20:40,576 A:middle
this from your parameter sets,

483
00:20:41,006 --> 00:20:43,046 A:middle
if you just have a
CMSampleBuffer that you want

484
00:20:43,046 --> 00:20:46,026 A:middle
to decompress you can pull it
right off the CMSampleBuffer.

485
00:20:47,916 --> 00:20:49,726 A:middle
Next, you need to
describe your requirements

486
00:20:49,726 --> 00:20:51,306 A:middle
for your output pixel buffers.

487
00:20:51,986 --> 00:20:55,086 A:middle
You use a pixelBufferAttributes
dictionary for this.

488
00:20:56,696 --> 00:20:57,706 A:middle
And finally, you need

489
00:20:57,706 --> 00:21:00,406 A:middle
to implement a
VTDecompressionOutputCallback.

490

491
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

492
00:20:57,706 --> 00:21:00,406 A:middle
to implement a
VTDecompressionOutputCallback.

493
00:21:01,226 --> 00:21:02,346 A:middle
All right.

494
00:21:02,566 --> 00:21:04,446 A:middle
Let's talk about
describing your requirements

495
00:21:04,446 --> 00:21:06,286 A:middle
for the Output PixelBuffers.

496
00:21:07,006 --> 00:21:08,906 A:middle
Here, you need to create
a PixelBufferAttributes

497
00:21:08,906 --> 00:21:09,426 A:middle
dictionary.

498
00:21:09,926 --> 00:21:12,726 A:middle
So let's look at a
scenario where we want

499
00:21:12,886 --> 00:21:14,936 A:middle
to use the Output CVPixelBuffers

500
00:21:14,936 --> 00:21:16,886 A:middle
in an open GLS ES
render pipeline.

501
00:21:18,406 --> 00:21:20,336 A:middle
Really, the only
requirement here that we have

502
00:21:20,336 --> 00:21:21,796 A:middle
for our Output PixelBuffers is

503
00:21:21,796 --> 00:21:23,746 A:middle
that they be OpenGL
ES compatible.

504
00:21:24,416 --> 00:21:28,336 A:middle
So we can go ahead and
just create a CF dictionary

505
00:21:28,336 --> 00:21:32,016 A:middle
or NS dictionary specifying
the kCVPixelBufferOpen

506
00:21:32,016 --> 00:21:37,976 A:middle
GLESCompatibilityKey
and set it to true.

507
00:21:38,826 --> 00:21:40,826 A:middle
So it can be very tempting

508
00:21:41,046 --> 00:21:42,926 A:middle
to when you're creating
these PixelBufferAttributes

509
00:21:42,926 --> 00:21:44,636 A:middle
dictionaries to be
very specific.

510
00:21:45,226 --> 00:21:47,256 A:middle
That way, there's no
surprises about what you get

511
00:21:47,256 --> 00:21:48,786 A:middle
out of the
VTDecompressionSession,

512
00:21:49,126 --> 00:21:50,326 A:middle
but there's some pitfalls here.

513
00:21:50,966 --> 00:21:52,506 A:middle
So let's look at this case

514
00:21:52,506 --> 00:21:56,446 A:middle
where we had kCVPixelBufferOpen
GLESCompatibilityKey set

515
00:21:56,446 --> 00:21:56,876 A:middle
to true.

516
00:21:58,126 --> 00:22:00,936 A:middle
Here, our decompression
session, the decoder inside

517

518
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

519
00:21:58,126 --> 00:22:00,936 A:middle
Here, our decompression
session, the decoder inside

520
00:22:00,936 --> 00:22:03,256 A:middle
of our decompression session is
going to be decoding the frames

521
00:22:03,256 --> 00:22:05,736 A:middle
and outputting YUV
CVPixelBuffers.

522
00:22:06,966 --> 00:22:10,736 A:middle
In the VTDecompressionSession
will then ask is this --

523
00:22:11,146 --> 00:22:14,006 A:middle
well, it'll ask itself, is
this PixelBuffer compatible

524
00:22:14,006 --> 00:22:16,066 A:middle
with those requested attributes.

525
00:22:16,696 --> 00:22:17,686 A:middle
And the answer is yes.

526
00:22:17,876 --> 00:22:21,016 A:middle
That YUV frame is OpenGL ES
compatible so it can return

527
00:22:21,016 --> 00:22:22,336 A:middle
that directly to your callback.

528
00:22:23,596 --> 00:22:28,796 A:middle
But let's say you were
possessed to add BGRA request

529
00:22:28,896 --> 00:22:30,536 A:middle
to your PixelBufferAttributes.

530
00:22:31,446 --> 00:22:35,086 A:middle
So just like before,
the decoder inside

531
00:22:35,086 --> 00:22:38,066 A:middle
of our VTDecompressionSession
will decode to a YUV format

532
00:22:38,066 --> 00:22:42,336 A:middle
and will ask whether this
CVPixelBuffer is compatible

533
00:22:42,336 --> 00:22:44,186 A:middle
with the requested
output requirements.

534
00:22:44,986 --> 00:22:48,626 A:middle
And it is OpenGL ES compatible,
but it's certainly not BGRA.

535
00:22:49,716 --> 00:22:52,616 A:middle
So it will need to do an
extra buffer copy to convert

536
00:22:52,616 --> 00:22:54,446 A:middle
that YUV data to BGRA data.

537
00:22:56,616 --> 00:22:59,056 A:middle
So extra buffer copies are bad.

538
00:22:59,296 --> 00:23:02,856 A:middle
They decrease efficiency
and they can lead

539

540
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

541
00:22:59,296 --> 00:23:02,856 A:middle
They decrease efficiency
and they can lead

542
00:23:02,986 --> 00:23:04,686 A:middle
to decreased battery life.

543
00:23:05,086 --> 00:23:08,456 A:middle
So the moral story here is
be it -- don't over specify.

544
00:23:09,796 --> 00:23:12,776 A:middle
All right, so let's talk
about your Output Callback.

545
00:23:14,276 --> 00:23:15,956 A:middle
So the Output Callback is

546
00:23:15,956 --> 00:23:18,576 A:middle
where you'll receive the
decoded CVPixelBuffers

547
00:23:19,736 --> 00:23:23,196 A:middle
and CVPixelBuffers don't
have a built in time stamp,

548
00:23:23,196 --> 00:23:25,496 A:middle
so you'll receive the
presentation time stamp

549
00:23:26,356 --> 00:23:27,726 A:middle
for that PixelBuffer here.

550
00:23:28,876 --> 00:23:32,426 A:middle
And if there are errors or the
frame is dropped for any reason,

551
00:23:32,426 --> 00:23:34,556 A:middle
you'll receive that information
in the Output Callback.

552
00:23:34,696 --> 00:23:35,866 A:middle
And it's important to note

553
00:23:35,866 --> 00:23:38,786 A:middle
that the Output Callback will
be called for every single frame

554
00:23:38,786 --> 00:23:41,786 A:middle
that you push into the
VTDecompressionSession even

555
00:23:41,786 --> 00:23:43,556 A:middle
if there's an error,
even if it's dropped.

556
00:23:45,556 --> 00:23:48,386 A:middle
All right, let's talk
about providing frames

557
00:23:48,436 --> 00:23:50,106 A:middle
to your VTDecompressionSession.

558
00:23:50,746 --> 00:23:53,666 A:middle
To do that, you call
VTDecompression

559
00:23:53,666 --> 00:23:54,896 A:middle
SessionDecodeFrame.

560
00:23:56,336 --> 00:23:58,236 A:middle
Just like
AVSampleBufferDisplayLayer,

561
00:23:58,526 --> 00:24:03,306 A:middle
you need to provide these as
CMSampleBuffers, and you need

562

563
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

564
00:23:58,526 --> 00:24:03,306 A:middle
you need to provide these as
CMSampleBuffers, and you need

565
00:24:03,306 --> 00:24:05,196 A:middle
to provide these
frames in decode order.

566
00:24:07,726 --> 00:24:08,906 A:middle
And by default,

567
00:24:08,906 --> 00:24:11,256 A:middle
VTDecompressionSession
DecodeFrame will

568
00:24:11,256 --> 00:24:12,416 A:middle
operate synchronously.

569
00:24:12,736 --> 00:24:15,906 A:middle
This means that your Output
Callback will be called before

570
00:24:15,906 --> 00:24:18,976 A:middle
VTDecompression
SessionDecodeFrame returns.

571
00:24:20,526 --> 00:24:22,746 A:middle
If you want a synchronous
operation, you can pass

572
00:24:22,746 --> 00:24:25,556 A:middle
in the flag requesting
EnableASynchronous

573
00:24:25,586 --> 00:24:26,346 A:middle
Decompression.

574
00:24:26,896 --> 00:24:32,256 A:middle
All right, let's talk about
Asynchronous Decompression then.

575
00:24:32,256 --> 00:24:33,546 A:middle
With ASynchronousDecompression,

576
00:24:33,856 --> 00:24:34,346 A:middle
the call

577
00:24:34,346 --> 00:24:37,696 A:middle
to VTDecompressionSession
DecodeFrame returns as soon

578
00:24:37,696 --> 00:24:40,196 A:middle
as it hands the frame
off to the decoder.

579
00:24:40,656 --> 00:24:44,726 A:middle
But decoders often have limited
pipelines for decoding frames.

580
00:24:45,446 --> 00:24:48,566 A:middle
So when the decoders
internal pipeline is full,

581
00:24:48,566 --> 00:24:51,966 A:middle
the call to VTDecompression
SessionDecodeFrame will block

582
00:24:52,306 --> 00:24:54,656 A:middle
until space opens up in
the decoders pipeline.

583
00:24:56,246 --> 00:24:57,756 A:middle
We call this decoder
back pressure.

584
00:24:58,896 --> 00:25:01,996 A:middle
So what this means is that
even though you're calling

585

586
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

587
00:24:58,896 --> 00:25:01,996 A:middle
So what this means is that
even though you're calling

588
00:25:02,086 --> 00:25:04,186 A:middle
VTDecompressionSession
DecodeFrame

589
00:25:04,186 --> 00:25:06,096 A:middle
and requesting Asynchronous
Decompression,

590
00:25:06,356 --> 00:25:09,316 A:middle
we will be doing the
decompression asynchronously

591
00:25:09,396 --> 00:25:14,336 A:middle
but the call can still block in
some cases, so be aware of that.

592
00:25:14,336 --> 00:25:15,796 A:middle
You're doing
ASynchronousDecompression

593
00:25:15,796 --> 00:25:19,546 A:middle
but the call can block, so don't
perform UI tasks on that thread.

594
00:25:20,766 --> 00:25:24,616 A:middle
All right, if you find yourself
in a situation where you want

595
00:25:24,616 --> 00:25:26,746 A:middle
to ensure that all asynchronous
frames have been cleared

596
00:25:26,746 --> 00:25:31,416 A:middle
out of the decoder, you can call
VTDecompressionSession and wait

597
00:25:31,416 --> 00:25:32,496 A:middle
for asynchronous frames.

598
00:25:32,996 --> 00:25:35,666 A:middle
This call will not return until
all frames have been omitted

599
00:25:35,666 --> 00:25:36,996 A:middle
from the decompression session.

600
00:25:39,876 --> 00:25:43,956 A:middle
So sometimes, we'll be decode
in a sequence of video frames.

601
00:25:44,466 --> 00:25:46,956 A:middle
There will be a change in
the CMVideoFormatDescription,

602
00:25:47,156 --> 00:25:50,086 A:middle
so let's look at the case
where we had a sequence

603
00:25:50,086 --> 00:25:51,666 A:middle
of an Elementary Stream

604
00:25:51,666 --> 00:25:53,946 A:middle
and we created the
first format description

605
00:25:53,946 --> 00:25:56,186 A:middle
out of the first parameter
sets that we encountered.

606
00:25:56,386 --> 00:25:58,166 A:middle
So now we have format
description one

607
00:25:58,306 --> 00:25:59,946 A:middle
with our first SPS and PPS.

608
00:25:59,946 --> 00:26:04,126 A:middle
We can go ahead and create
our VTDecompressionSession

609

610
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

611
00:25:59,946 --> 00:26:04,126 A:middle
We can go ahead and create
our VTDecompressionSession

612
00:26:04,126 --> 00:26:07,856 A:middle
with that format description and
decode all the subsequent frames

613
00:26:08,036 --> 00:26:10,706 A:middle
with that format description
attached to the CMSampleBuffer

614
00:26:11,956 --> 00:26:16,826 A:middle
until we encounter a new
SPS and PPS in the stream.

615
00:26:17,886 --> 00:26:20,266 A:middle
Then, we need to create
a new format description

616
00:26:20,266 --> 00:26:24,496 A:middle
with the new SPS and PPS
and we have to make sure

617
00:26:24,496 --> 00:26:26,726 A:middle
that the decompression
session can switch

618
00:26:26,726 --> 00:26:28,186 A:middle
between these format
descriptions.

619
00:26:29,316 --> 00:26:32,966 A:middle
So to do that, you call
VTDecompressionSession

620
00:26:32,966 --> 00:26:34,596 A:middle
CanAcceptFormatDescription.

621
00:26:35,296 --> 00:26:37,926 A:middle
This will ensure -- ask the
decoder whether it's able

622
00:26:37,926 --> 00:26:39,856 A:middle
to transition from
FormatDescription one

623
00:26:39,856 --> 00:26:42,826 A:middle
to FormatDescription two.

624
00:26:43,366 --> 00:26:46,116 A:middle
If the answer is true, yes,

625
00:26:46,116 --> 00:26:49,776 A:middle
it can handle the new
accepted FormatDescription.

626
00:26:50,146 --> 00:26:52,226 A:middle
That means you can
pass subsequent samples

627
00:26:52,226 --> 00:26:54,346 A:middle
with that new FormatDescription
attached to them

628
00:26:54,946 --> 00:26:57,806 A:middle
into the Decompression Session
and everything will work fine.

629
00:26:58,186 --> 00:27:02,066 A:middle
If it returns false that
means the decompressor cannot

630

631
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

632
00:26:58,186 --> 00:27:02,066 A:middle
If it returns false that
means the decompressor cannot

633
00:27:02,066 --> 00:27:04,696 A:middle
transition from that
first format description

634
00:27:04,946 --> 00:27:07,236 A:middle
to the second format
description, and you'll need

635
00:27:07,236 --> 00:27:09,236 A:middle
to create a new
VTDecompressionSession

636
00:27:09,966 --> 00:27:13,566 A:middle
and be sure and pass the
new frames into that one.

637
00:27:14,326 --> 00:27:17,266 A:middle
And be sure to release that
old VTDecompressionSession

638
00:27:17,796 --> 00:27:20,256 A:middle
when you're no longer using it.

639
00:27:20,816 --> 00:27:21,296 A:middle
All right.

640
00:27:21,976 --> 00:27:23,076 A:middle
Quick summary of what we talked

641
00:27:23,076 --> 00:27:24,746 A:middle
about with the
VTDecompressionSession.

642
00:27:25,586 --> 00:27:30,166 A:middle
We talked creating the
VTDecompressionSession and how

643
00:27:30,166 --> 00:27:31,446 A:middle
to make optimal decisions

644
00:27:31,446 --> 00:27:35,356 A:middle
when creating the
PixelBufferAttributes dictionary

645
00:27:36,326 --> 00:27:38,996 A:middle
for specifying your
output requirements.

646
00:27:39,616 --> 00:27:43,046 A:middle
We talked about running your
decompression session both

647
00:27:43,046 --> 00:27:46,426 A:middle
synchronously and
asynchronously and we talked

648
00:27:46,426 --> 00:27:49,106 A:middle
about handing changes in
CMVideo FormatDescription.

649
00:27:50,846 --> 00:27:53,886 A:middle
So with that, let's
hop into case three.

650
00:27:54,446 --> 00:27:59,686 A:middle
This is the case where you
have a stream of CVPixelBuffers

651
00:27:59,686 --> 00:28:02,566 A:middle
or frames coming in from a
camera or another source,

652

653
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

654
00:27:59,686 --> 00:28:02,566 A:middle
or frames coming in from a
camera or another source,

655
00:28:03,296 --> 00:28:05,786 A:middle
and you want to compress those
directly into a movie file.

656
00:28:07,136 --> 00:28:10,216 A:middle
Well, for this, you may be
familiar with this already.

657
00:28:10,326 --> 00:28:11,726 A:middle
We have AVAssetWriter.

658
00:28:13,306 --> 00:28:16,626 A:middle
AVAssetWriter has an encoder
internally, and it's going

659
00:28:16,626 --> 00:28:19,196 A:middle
to be encoding those
frames into CMSampleBuffers

660
00:28:20,046 --> 00:28:22,086 A:middle
and it's got some
file writing smarts,

661
00:28:22,196 --> 00:28:25,066 A:middle
so it can write these
optimally into a movie file.

662
00:28:25,896 --> 00:28:30,056 A:middle
We're not actually going
to talk more at this point

663
00:28:30,056 --> 00:28:34,326 A:middle
about AVAssetWriter, but
it's an important concept

664
00:28:34,326 --> 00:28:36,396 A:middle
and an important thing to bring
up in the context of this talk,

665
00:28:36,596 --> 00:28:39,446 A:middle
so if you want more information
on the AVAssetWriter,

666
00:28:39,546 --> 00:28:45,506 A:middle
you can go back to WWDC 2013
and the talk Moving to AVKit

667
00:28:45,506 --> 00:28:48,086 A:middle
and AVFoundation or 2011,

668
00:28:48,766 --> 00:28:50,736 A:middle
Working with Media
and AVFoundation.

669
00:28:51,756 --> 00:28:53,856 A:middle
All right.

670
00:28:54,236 --> 00:28:56,086 A:middle
Let's just hop straight
into case four.

671
00:28:56,466 --> 00:28:59,886 A:middle
This is the case where you
have that stream of data coming

672
00:28:59,886 --> 00:29:03,156 A:middle
in from your camera and
you want to compress it,

673

674
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

675
00:28:59,886 --> 00:29:03,156 A:middle
in from your camera and
you want to compress it,

676
00:29:03,156 --> 00:29:04,906 A:middle
but you don't want to
write into a movie file.

677
00:29:05,046 --> 00:29:07,656 A:middle
You want direct access to
those compresses SampleBuffers.

678
00:29:08,896 --> 00:29:11,486 A:middle
So we want to approach
our video encoder

679
00:29:11,986 --> 00:29:14,446 A:middle
through a VTCompressionSession
rather

680
00:29:14,446 --> 00:29:15,706 A:middle
than through the AVAssetWriter.

681
00:29:17,316 --> 00:29:18,976 A:middle
So just like AVAssetWriter,

682
00:29:18,976 --> 00:29:21,946 A:middle
VTCompressionSession takes
CVPixelBuffers as its input,

683
00:29:22,726 --> 00:29:25,586 A:middle
and it's going to compress those
and return CMSampleBuffers,

684
00:29:25,876 --> 00:29:27,336 A:middle
and we can go ahead and send

685
00:29:27,716 --> 00:29:29,376 A:middle
that compressed data
out over the network.

686
00:29:30,736 --> 00:29:34,156 A:middle
So to create a
VTCompressionSession,

687
00:29:34,156 --> 00:29:36,826 A:middle
you'll need a few things,
and this is really simple.

688
00:29:37,206 --> 00:29:39,296 A:middle
You just need to specify
the dimensions you want

689
00:29:39,296 --> 00:29:40,516 A:middle
for your compressed output.

690
00:29:41,616 --> 00:29:44,816 A:middle
You need to tell us what format
you want to compress to such

691
00:29:44,816 --> 00:29:51,826 A:middle
as kCMVideoCodecTypeH.264 and
you can optionally provide a set

692
00:29:51,826 --> 00:29:54,316 A:middle
of PixelBufferAttributes
describing your source

693
00:29:54,476 --> 00:29:56,326 A:middle
CVPixelBuffers that
you'll be sending

694
00:29:56,326 --> 00:29:56,976 A:middle
to the VTCompressionSession.

695
00:29:57,106 --> 00:29:59,966 A:middle
And finally, you need

696
00:29:59,966 --> 00:30:02,346 A:middle
to implement a
VTCompressionOutput Callback.

697

698
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

699
00:29:59,966 --> 00:30:02,346 A:middle
to implement a
VTCompressionOutput Callback.

700
00:30:04,386 --> 00:30:07,336 A:middle
So you've created a
VTCompressionSession.

701
00:30:07,626 --> 00:30:09,356 A:middle
Now you want to configure it.

702
00:30:10,386 --> 00:30:12,476 A:middle
You configure a
VTCompressionSession using

703
00:30:12,476 --> 00:30:14,166 A:middle
VTSession SetProperty.

704
00:30:14,666 --> 00:30:17,316 A:middle
In fact, you can
have a whole sequence

705
00:30:17,316 --> 00:30:19,516 A:middle
of VTSessionSetProperty calls.

706
00:30:19,596 --> 00:30:24,076 A:middle
So I'm going to go through a
few common properties here and

707
00:30:24,676 --> 00:30:26,226 A:middle
but this is not an
exhaustive list.

708
00:30:26,876 --> 00:30:29,216 A:middle
The first one I'm going to
mention is AllowFrameReordering.

709
00:30:29,216 --> 00:30:33,816 A:middle
By default, H.264 encoder will
allow frames to be reordered.

710
00:30:34,286 --> 00:30:36,826 A:middle
That means the presentation
time stamp that you pass them

711
00:30:36,826 --> 00:30:41,116 A:middle
in will not necessarily
equal the decode order

712
00:30:41,376 --> 00:30:42,576 A:middle
in which they're admitted.

713
00:30:43,446 --> 00:30:46,926 A:middle
If you want to disable this
behavior, you can pass false

714
00:30:47,266 --> 00:30:48,456 A:middle
to allow frame reordering.

715
00:30:50,426 --> 00:30:51,936 A:middle
Next one, average byte rate.

716
00:30:52,386 --> 00:30:54,916 A:middle
This is how you set a target
byte rate for the compressor.

717
00:30:56,186 --> 00:31:03,416 A:middle
H.264EntropyMode; using this,
you can specify CALV compression

718

719
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

720
00:30:56,186 --> 00:31:03,416 A:middle
H.264EntropyMode; using this,
you can specify CALV compression

721
00:31:03,416 --> 00:31:06,616 A:middle
or KVTH compression
for your H.264 encoder.

722
00:31:07,436 --> 00:31:10,306 A:middle
All right, and then there's
the RealTime property.

723
00:31:10,956 --> 00:31:13,396 A:middle
The RealTime property allows
you to tell the encoder

724
00:31:13,396 --> 00:31:16,786 A:middle
that this is a real time
encoding operation such as

725
00:31:16,786 --> 00:31:22,166 A:middle
in a live streaming case,
conferencing case as opposed

726
00:31:22,166 --> 00:31:26,636 A:middle
to more of a background activity
like a transcode operation.

727
00:31:27,426 --> 00:31:30,256 A:middle
And the final one I'm going

728
00:31:30,256 --> 00:31:32,276 A:middle
to mention here is
the ProfileLevelKey.

729
00:31:32,756 --> 00:31:35,726 A:middle
This allows you to specify
specific profiles and levels

730
00:31:35,826 --> 00:31:39,236 A:middle
or specific profiles and allow
us to choose the correct level.

731
00:31:39,816 --> 00:31:43,366 A:middle
And this is definitely
not an exhaustive list.

732
00:31:43,456 --> 00:31:48,006 A:middle
There's a lot of these options
available, so go ahead and look

733
00:31:48,006 --> 00:31:52,316 A:middle
in VTCompressionProperties.H
and see what we have for you.

734
00:31:52,316 --> 00:31:57,006 A:middle
All right, let's talk about
providing CVPixelBuffers

735
00:31:57,006 --> 00:31:58,376 A:middle
to your VTCompressionSession.

736
00:31:59,406 --> 00:32:01,576 A:middle
Use
VTCompressionSessionEncodeFrame

737

738
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

739
00:31:59,406 --> 00:32:01,576 A:middle
Use
VTCompressionSessionEncodeFrame

740
00:32:01,576 --> 00:32:07,556 A:middle
to do this, and you'll need
to provide CVPixelBuffers

741
00:32:08,106 --> 00:32:10,066 A:middle
and as I've mentioned,

742
00:32:10,066 --> 00:32:14,076 A:middle
CVPixelBuffers don't have a
presentation timestamp built

743
00:32:14,076 --> 00:32:16,286 A:middle
into them, so as a
separate parameter,

744
00:32:16,286 --> 00:32:18,096 A:middle
you'll provide the
presentation timestamp.

745
00:32:19,626 --> 00:32:23,576 A:middle
You need to feed the frames
in in presentation order.

746
00:32:25,996 --> 00:32:30,746 A:middle
And it's one more note about
the presentation order, they --

747
00:32:31,106 --> 00:32:33,496 A:middle
the presentation timestamps
must be increasing.

748
00:32:33,926 --> 00:32:36,236 A:middle
No duplicate presentation
timestamps,

749
00:32:36,576 --> 00:32:38,066 A:middle
no timestamps that go backwards.

750
00:32:39,736 --> 00:32:42,146 A:middle
And so compression sessions,

751
00:32:42,326 --> 00:32:45,866 A:middle
compressions operations usually
require a window or frames

752
00:32:45,866 --> 00:32:49,046 A:middle
that they'll operate on, so
your output may be delayed.

753
00:32:49,756 --> 00:32:52,916 A:middle
So you may not receive
a compressed frame

754
00:32:52,916 --> 00:32:54,716 A:middle
in your Output Callback
until a certain number

755
00:32:54,716 --> 00:32:56,556 A:middle
of frames have been
pushed into the encoder.

756
00:32:57,116 --> 00:32:59,476 A:middle
All right.

757
00:32:59,476 --> 00:33:01,946 A:middle
And finally, if you've
reached the end of the frames

758

759
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

760
00:32:59,476 --> 00:33:01,946 A:middle
And finally, if you've
reached the end of the frames

761
00:33:01,946 --> 00:33:04,196 A:middle
that you're passing to the
compression session and you want

762
00:33:04,876 --> 00:33:07,606 A:middle
to have it emit all of the
frames that it's received

763
00:33:07,606 --> 00:33:10,106 A:middle
so far, you can use
VTCompressionSession

764
00:33:10,106 --> 00:33:11,096 A:middle
CompleteFrames.

765
00:33:11,436 --> 00:33:12,956 A:middle
All pending frames
will be omitted.

766
00:33:14,896 --> 00:33:15,376 A:middle
All right.

767
00:33:15,706 --> 00:33:17,336 A:middle
Let's talk about
your Output Callback.

768
00:33:19,296 --> 00:33:20,426 A:middle
So your Output Callback is

769
00:33:20,426 --> 00:33:23,276 A:middle
where you'll receive your
output CMSampleBuffers.

770
00:33:23,426 --> 00:33:25,126 A:middle
These contain the
compressed frames.

771
00:33:25,976 --> 00:33:29,476 A:middle
If there were any errors or
dropped frames, you'll receive

772
00:33:29,476 --> 00:33:30,526 A:middle
that information here.

773
00:33:31,466 --> 00:33:34,786 A:middle
And final thing, frames will
be omitted in decode order.

774
00:33:35,006 --> 00:33:37,436 A:middle
So you provided frames to
the VTCompressionSession

775
00:33:37,436 --> 00:33:38,446 A:middle
in presentation order

776
00:33:38,856 --> 00:33:40,716 A:middle
and they'll be omitted
in decode order.

777
00:33:41,456 --> 00:33:44,486 A:middle
All right.

778
00:33:45,176 --> 00:33:48,136 A:middle
Well, so you've compressed
a bunch of frames.

779
00:33:48,306 --> 00:33:51,516 A:middle
They're now compressed
in CMSampleBuffers,

780
00:33:51,516 --> 00:33:54,876 A:middle
which means that they're
using MPEG-4 packaging.

781
00:33:55,646 --> 00:33:57,696 A:middle
And you want to send that
out over the network,

782
00:33:58,036 --> 00:34:01,576 A:middle
which means you may
need to switch these

783

784
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

785
00:33:58,036 --> 00:34:01,576 A:middle
which means you may
need to switch these

786
00:34:01,576 --> 00:34:03,416 A:middle
over to Elementary
Stream packaging.

787
00:34:04,346 --> 00:34:05,866 A:middle
Well, once again,
you're going to have

788
00:34:05,866 --> 00:34:08,025 A:middle
to do a little bit of work.

789
00:34:09,096 --> 00:34:12,196 A:middle
So we talked about the
parameter sets before.

790
00:34:13,025 --> 00:34:16,626 A:middle
So the parameters sets will
in your MPEG-4 package,

791
00:34:16,626 --> 00:34:20,315 A:middle
H.264 will be in the
CMVideoFormatDescription.

792
00:34:21,076 --> 00:34:22,335 A:middle
So the first thing
you're going to have

793
00:34:22,335 --> 00:34:25,866 A:middle
to do is extract those
parameter sets and package them

794
00:34:25,866 --> 00:34:27,766 A:middle
as NAL Units to send
out over the network.

795
00:34:29,716 --> 00:34:33,686 A:middle
Well, we provide a handy
utility for that too.

796
00:34:34,186 --> 00:34:38,176 A:middle
CMVideoFormatDescription
GetH.264ParameterSetAtIndex.

797
00:34:39,696 --> 00:34:44,686 A:middle
All right, and the next thing
you need to do is the opposite

798
00:34:44,686 --> 00:34:46,795 A:middle
of what we did with
AVSampleBufferDisplayLayer.

799
00:34:47,616 --> 00:34:51,666 A:middle
Our NAL Units are all going
to have length headers

800
00:34:52,585 --> 00:34:53,636 A:middle
and you're going to need

801
00:34:53,636 --> 00:34:56,835 A:middle
to convert those length
headers into start codes.

802
00:34:58,816 --> 00:35:00,966 A:middle
So as you extract each NAL Unit

803

804
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

805
00:34:58,816 --> 00:35:00,966 A:middle
So as you extract each NAL Unit

806
00:35:00,966 --> 00:35:03,576 A:middle
from the compressed data
inside the CMSampleBuffer,

807
00:35:04,206 --> 00:35:06,106 A:middle
convert those headers
on the NAL Units.

808
00:35:07,736 --> 00:35:08,236 A:middle
All right.

809
00:35:08,536 --> 00:35:10,136 A:middle
Quick summary of what we talked

810
00:35:10,136 --> 00:35:11,776 A:middle
about with the
VTCompressionSession.

811
00:35:12,636 --> 00:35:15,026 A:middle
We talked about creating
the VTCompressionSession.

812
00:35:16,216 --> 00:35:17,086 A:middle
We've talked about how

813
00:35:17,086 --> 00:35:19,766 A:middle
to configure it using the
VTSessionSetProperty column.

814
00:35:21,886 --> 00:35:24,676 A:middle
And we talked about how you
would provide CVPixelBuffers

815
00:35:24,676 --> 00:35:25,996 A:middle
to the compression session.

816
00:35:27,816 --> 00:35:31,316 A:middle
And finally, we talked about
converting those CMSampleBuffers

817
00:35:31,316 --> 00:35:34,736 A:middle
into an H.264 Elementary
Stream packaging.

818
00:35:35,796 --> 00:35:36,436 A:middle
All right.

819
00:35:36,436 --> 00:35:39,126 A:middle
And with that, I'd like
to hand things off to Eric

820
00:35:39,126 --> 00:35:40,546 A:middle
so he can talk about Multi-Pass.

821
00:35:40,996 --> 00:35:43,806 A:middle
>> Good morning everyone.

822
00:35:43,996 --> 00:35:45,326 A:middle
My name is Eric Turnquist.

823
00:35:45,326 --> 00:35:47,486 A:middle
I'm the Core Media Engineer,
and today, I want to talk to you

824
00:35:47,486 --> 00:35:48,636 A:middle
about Multi-Pass Encoding.

825
00:35:49,606 --> 00:35:53,096 A:middle
So as a media engineer, we often
deal with two opposing forces;

826
00:35:53,326 --> 00:35:54,936 A:middle
quality versus bit rate.

827
00:35:55,536 --> 00:35:58,256 A:middle
So quality is how pristine
the image is, and we all know

828
00:35:58,256 --> 00:36:01,076 A:middle
and we've seen great quality
video and we really don't

829

830
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

831
00:35:58,256 --> 00:36:01,076 A:middle
and we've seen great quality
video and we really don't

832
00:36:01,076 --> 00:36:02,596 A:middle
like seeing bad quality video.

833
00:36:03,476 --> 00:36:05,436 A:middle
Bit rate is how much
data per time is

834
00:36:05,436 --> 00:36:06,536 A:middle
in the output media file.

835
00:36:07,076 --> 00:36:08,956 A:middle
So let's say we're
preparing some content.

836
00:36:10,636 --> 00:36:13,436 A:middle
If you're like me, you go
for high quality first.

837
00:36:13,776 --> 00:36:15,116 A:middle
So great, we have high quality.

838
00:36:16,076 --> 00:36:17,996 A:middle
Now in this case, what
happens with the bit rate?

839
00:36:18,806 --> 00:36:21,476 A:middle
Well unfortunately, if you have
high quality, you also tend

840
00:36:21,476 --> 00:36:22,436 A:middle
to have a high bit rate.

841
00:36:22,436 --> 00:36:25,116 A:middle
Now that's okay,
but not what we want

842
00:36:25,116 --> 00:36:27,486 A:middle
if we're streaming this content
or storing it on a server.

843
00:36:28,606 --> 00:36:30,446 A:middle
So in that case we
want to a low bit rate

844
00:36:30,756 --> 00:36:33,046 A:middle
but the quality isn't
going to stay this high.

845
00:36:33,826 --> 00:36:35,916 A:middle
Unfortunately, that's also
going to go down as well.

846
00:36:37,086 --> 00:36:39,936 A:middle
So we've all seen this as
block encoder artifacts

847
00:36:39,936 --> 00:36:41,846 A:middle
or an output image that
doesn't really even look

848
00:36:41,846 --> 00:36:42,626 A:middle
like the source.

849
00:36:42,716 --> 00:36:43,586 A:middle
We don't want this either.

850
00:36:44,246 --> 00:36:45,786 A:middle
Ideally, we want
something like this;

851
00:36:46,126 --> 00:36:47,856 A:middle
high quality and low bit rate.

852
00:36:48,426 --> 00:36:51,236 A:middle
In order to achieve that goal,
we've added Multi-Pass Encoding

853
00:36:51,236 --> 00:36:53,166 A:middle
to AVFoundation and
Video Toolbox.

854
00:36:53,706 --> 00:37:02,266 A:middle
Yeah, so first off, what
is Multi-Pass Encoding?

855

856
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

857
00:36:53,706 --> 00:37:02,266 A:middle
Yeah, so first off, what
is Multi-Pass Encoding?

858
00:37:02,716 --> 00:37:05,786 A:middle
Well, let's do a review of what
Single-Pass Encoding is first.

859
00:37:05,786 --> 00:37:07,956 A:middle
So this is what David covered
in his portion of the talk.

860
00:37:09,146 --> 00:37:11,306 A:middle
With Single-Pass Encoding,
you have frames coming in,

861
00:37:11,456 --> 00:37:13,186 A:middle
going into the encoder
and being admitted.

862
00:37:13,466 --> 00:37:14,926 A:middle
In this case, we're
going to a movie file.

863
00:37:16,206 --> 00:37:18,996 A:middle
Then once you're done appending
all the samples, we're finished,

864
00:37:20,356 --> 00:37:21,966 A:middle
and we're left with
our output movie file.

865
00:37:22,246 --> 00:37:22,826 A:middle
Simple enough.

866
00:37:24,066 --> 00:37:25,616 A:middle
Let's see how Multi-Pass
differs.

867
00:37:25,796 --> 00:37:27,746 A:middle
So you have uncompressed
frames coming in going

868
00:37:27,746 --> 00:37:29,826 A:middle
into the compression
session, being admitted

869
00:37:29,826 --> 00:37:30,946 A:middle
as compressed samples.

870
00:37:30,946 --> 00:37:32,566 A:middle
Now we're going to change
things up a little bit.

871
00:37:33,206 --> 00:37:35,126 A:middle
So we're going to have
our frame database.

872
00:37:35,446 --> 00:37:37,076 A:middle
This will store the
compressed samples

873
00:37:37,076 --> 00:37:39,766 A:middle
and allow us random access in
replacement, which is important

874
00:37:39,766 --> 00:37:42,726 A:middle
for Multi-Pass, and we're going
to have our encoder database.

875
00:37:43,226 --> 00:37:44,976 A:middle
This will store frame analysis.

876
00:37:46,876 --> 00:37:49,066 A:middle
So we're done appending
for one pass

877
00:37:49,066 --> 00:37:52,036 A:middle
and the encoder will decide I
think I can actually do better

878
00:37:52,036 --> 00:37:54,266 A:middle
in another pass, so I can tweak
the parameters a little bit

879
00:37:54,266 --> 00:37:55,156 A:middle
to get better quality.

880
00:37:57,536 --> 00:37:59,896 A:middle
It will request some
samples and you'll go through

881
00:37:59,896 --> 00:38:01,736 A:middle
and send those samples
again to the encoder,

882

883
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

884
00:37:59,896 --> 00:38:01,736 A:middle
and send those samples
again to the encoder,

885
00:38:02,306 --> 00:38:06,596 A:middle
and then it may decide I'm
done or I'm actually --

886
00:38:06,596 --> 00:38:07,766 A:middle
or I want more passes.

887
00:38:07,766 --> 00:38:09,466 A:middle
In this case, let's
assume that we're finished.

888
00:38:11,016 --> 00:38:13,326 A:middle
So we no longer need
the encoder database

889
00:38:13,326 --> 00:38:14,896 A:middle
or the compression
session, but we're left

890
00:38:14,896 --> 00:38:17,246 A:middle
with this Frame Database
and we want a movie file,

891
00:38:17,546 --> 00:38:18,606 A:middle
so we need one more step.

892
00:38:19,856 --> 00:38:22,326 A:middle
There's a final copy
from the Frame Database

893
00:38:22,326 --> 00:38:25,356 A:middle
to the output movie
file and that's it.

894
00:38:25,356 --> 00:38:28,576 A:middle
We have a Multi-Pass encoded
video track on a movie file.

895
00:38:29,986 --> 00:38:32,466 A:middle
Cool. Let's go over
some encoder features.

896
00:38:33,556 --> 00:38:36,826 A:middle
So my first point is I want to
make a note of is David said

897
00:38:36,826 --> 00:38:38,716 A:middle
that Single-Pass is
hardware accelerated

898
00:38:39,056 --> 00:38:41,166 A:middle
and Multi-Pass is also
hardware accelerated,

899
00:38:41,366 --> 00:38:43,296 A:middle
so you're not losing any
hardware acceleration there.

900
00:38:46,536 --> 00:38:49,486 A:middle
Second point is that Multi-Pass
has knowledge of the future.

901
00:38:50,046 --> 00:38:52,446 A:middle
Now it's not some crazy time
traveling video encoder.

902
00:38:53,016 --> 00:38:55,226 A:middle
Bonus points whoever filed
that enhancement request.

903
00:38:55,766 --> 00:38:59,696 A:middle
It allows or is able to
see your entire content.

904

905
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

906
00:39:00,216 --> 00:39:03,196 A:middle
So in Single-Pass, as frames
come in, the encoder has

907
00:39:03,226 --> 00:39:05,166 A:middle
to make assumptions about
what might come next.

908
00:39:05,786 --> 00:39:07,996 A:middle
In Multi-Pass, it's already
seen all your content

909
00:39:07,996 --> 00:39:09,626 A:middle
so it can make much
better decisions there.

910
00:39:11,996 --> 00:39:14,456 A:middle
Third, it can change
decision that it's made.

911
00:39:14,716 --> 00:39:18,406 A:middle
So in Single-Pass, as soon as
the frame is emitted, that's it.

912
00:39:18,406 --> 00:39:20,066 A:middle
It can't -- it can
no longer change.

913
00:39:20,806 --> 00:39:23,986 A:middle
It can no longer change its
mind about what it's emitted.

914
00:39:24,986 --> 00:39:27,966 A:middle
In Multi-Pass, because the frame
database supports replacement,

915
00:39:28,316 --> 00:39:30,686 A:middle
each pass you can go through
and change its mind about how

916
00:39:30,686 --> 00:39:32,006 A:middle
to achieve optimal quality.

917
00:39:32,566 --> 00:39:35,046 A:middle
And as a result of this,

918
00:39:35,046 --> 00:39:37,476 A:middle
you really get optimal
quality per bit, so it's sort

919
00:39:37,476 --> 00:39:40,906 A:middle
of like having a very awesome
custom encoder for your content.

920
00:39:41,916 --> 00:39:45,246 A:middle
So that's how Multi-Pass
works and some more features.

921
00:39:45,296 --> 00:39:46,736 A:middle
Let's talk about new APIs.

922
00:39:47,966 --> 00:39:49,976 A:middle
So first off, let's
talk about AVFoundation.

923
00:39:50,636 --> 00:39:54,646 A:middle
In AVFoundation, we have a new
AVAssetExport Session property.

924
00:39:55,046 --> 00:39:57,366 A:middle
We have new pass descriptions
for AVAssetWriterInput

925
00:39:57,766 --> 00:39:59,696 A:middle
and we have reuse on
AVAssetReaderOutput.

926

927
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

928
00:40:00,596 --> 00:40:02,276 A:middle
So first, let's go
over an overview

929
00:40:02,276 --> 00:40:03,586 A:middle
of AVAssetExport Session.

930
00:40:04,766 --> 00:40:07,296 A:middle
In AVAsset ExportSession,
you're going from a source file,

931
00:40:07,836 --> 00:40:10,556 A:middle
decoding them then
performing some operation

932
00:40:10,556 --> 00:40:12,856 A:middle
on those uncompressed
buffers, something like scaling

933
00:40:12,856 --> 00:40:15,236 A:middle
or color conversion,
and you're encoding them

934
00:40:15,236 --> 00:40:16,496 A:middle
and writing them
to a movie file.

935
00:40:17,036 --> 00:40:19,476 A:middle
So in this case, what does
AVAsset ExportSession provide?

936
00:40:20,376 --> 00:40:21,726 A:middle
Well, it does all this for you.

937
00:40:21,896 --> 00:40:26,456 A:middle
It's the easiest way to
transcode media on iOS and OS X.

938
00:40:26,686 --> 00:40:27,906 A:middle
So let's see what
we've added here.

939
00:40:29,246 --> 00:40:31,696 A:middle
So in AVAssetExportSession
multiple passes are taken care

940
00:40:31,696 --> 00:40:33,156 A:middle
of for you automatically.

941
00:40:33,236 --> 00:40:34,836 A:middle
There's no work you have to do

942
00:40:34,836 --> 00:40:36,546 A:middle
to send the samples
between passes.

943
00:40:37,066 --> 00:40:39,926 A:middle
And also, it falls
back to Single-Pass

944
00:40:39,926 --> 00:40:41,206 A:middle
if Multi-Pass isn't supported.

945
00:40:41,586 --> 00:40:44,156 A:middle
So if you choose a
preset that uses a codec

946
00:40:44,156 --> 00:40:46,256 A:middle
where Multi-Pass isn't
supported, don't worry,

947
00:40:46,296 --> 00:40:47,296 A:middle
it'll use Single-Pass.

948
00:40:48,566 --> 00:40:50,536 A:middle
And we have one new
property, Set SDS

949
00:40:50,536 --> 00:40:53,196 A:middle
and you're automatically opted
into Multi-Task, and that's it.

950
00:40:53,666 --> 00:40:56,426 A:middle
So for a large majority of
you, this is all you need.

951
00:40:57,616 --> 00:40:59,466 A:middle
Next, let's talk
about AVSWriter.

952

953
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

954
00:41:00,356 --> 00:41:03,136 A:middle
So AVSWriter, you're coming
from uncompressed samples.

955
00:41:03,136 --> 00:41:05,126 A:middle
You want to compress them and
write them to a movie file.

956
00:41:06,356 --> 00:41:09,486 A:middle
You might be coming from an
OpenGL or OpenGL ES context.

957
00:41:09,826 --> 00:41:11,766 A:middle
In this case, what
does AVSWriter provide?

958
00:41:13,106 --> 00:41:15,686 A:middle
Well, it wraps this portion
going from the encoder

959
00:41:15,846 --> 00:41:17,186 A:middle
to the output movie file.

960
00:41:19,686 --> 00:41:23,406 A:middle
Another use case, it's
similar to AVSExportSession

961
00:41:23,446 --> 00:41:25,276 A:middle
where you're going from
a source movie file

962
00:41:25,346 --> 00:41:26,836 A:middle
to a destination app movie file

963
00:41:26,836 --> 00:41:28,636 A:middle
and modifying the
buffers in some way.

964
00:41:29,536 --> 00:41:32,116 A:middle
Well in this case, you're
going to use an AVSReaderOutput

965
00:41:32,116 --> 00:41:33,486 A:middle
and an AVSWriterInput.

966
00:41:33,486 --> 00:41:36,156 A:middle
You're responsible for sending
samples from one to the other.

967
00:41:36,686 --> 00:41:42,356 A:middle
Let's go over a new
AVSWriterInput APIs.

968
00:41:42,486 --> 00:41:45,566 A:middle
So like AVAssetExportSession,
you need to enable Multi-Pass,

969
00:41:46,036 --> 00:41:48,226 A:middle
so set SDS and you're
automatically opted in.

970
00:41:48,806 --> 00:41:52,356 A:middle
Then after you're done
appending samples,

971
00:41:52,726 --> 00:41:54,636 A:middle
you need to mark the
current pass as finished.

972
00:41:55,366 --> 00:41:56,326 A:middle
So what does this do?

973
00:41:56,676 --> 00:41:58,456 A:middle
Well, this triggers
the encoder analysis.

974
00:41:58,696 --> 00:42:01,756 A:middle
The encoder needs to decide if I
need to perform multiple passes

975

976
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

977
00:41:58,696 --> 00:42:01,756 A:middle
The encoder needs to decide if I
need to perform multiple passes

978
00:42:02,296 --> 00:42:04,916 A:middle
and if so, what time ranges.

979
00:42:05,026 --> 00:42:07,936 A:middle
So the encoder might say I want
to see the entire sequence again

980
00:42:08,156 --> 00:42:10,086 A:middle
or I want to see
subsets of the sequence.

981
00:42:11,126 --> 00:42:12,316 A:middle
So how does the encoder talk

982
00:42:12,316 --> 00:42:15,876 A:middle
about what time ranges it
wants for the next pass?

983
00:42:16,196 --> 00:42:18,576 A:middle
Well, that's through
AVSWriterInput PassDescription.

984
00:42:19,016 --> 00:42:21,826 A:middle
So in this case, we have
time from zero to three,

985
00:42:22,006 --> 00:42:25,596 A:middle
but not the sample at time
three, and samples from five

986
00:42:25,596 --> 00:42:27,606 A:middle
to seven, but not the
sample at time seven.

987
00:42:28,376 --> 00:42:32,136 A:middle
So a pass description is the
encoder's request for media

988
00:42:32,136 --> 00:42:35,686 A:middle
in the next pass, and it may
contain the entire sequence

989
00:42:35,756 --> 00:42:37,156 A:middle
or subsets of the sequence.

990
00:42:37,536 --> 00:42:41,316 A:middle
On a pass description, you
can query the time ranges

991
00:42:41,316 --> 00:42:44,046 A:middle
that the encoder has requested
by calling sourceTimeRanges.

992
00:42:47,616 --> 00:42:50,526 A:middle
All right, let's talk
about how AVSWriter uses

993
00:42:50,526 --> 00:42:51,496 A:middle
pass descriptions.

994
00:42:52,896 --> 00:42:55,626 A:middle
So when you trigger the encoder
analysis, the encoder needs

995
00:42:55,626 --> 00:42:57,836 A:middle
to reply with what
decisions it's made.

996
00:42:57,926 --> 00:43:01,396 A:middle
So you provide a block on this
method to allow the encoder

997

998
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

999
00:42:57,926 --> 00:43:01,396 A:middle
So you provide a block on this
method to allow the encoder

1000
00:43:01,396 --> 00:43:02,926 A:middle
to give you that answer.

1001
00:43:03,226 --> 00:43:05,396 A:middle
So this block is called when
the encoder makes a decision

1002
00:43:05,396 --> 00:43:07,796 A:middle
about the next pass.

1003
00:43:08,076 --> 00:43:10,396 A:middle
In that block, you can get
the new pass description,

1004
00:43:10,396 --> 00:43:11,256 A:middle
the encoder's decision

1005
00:43:11,256 --> 00:43:13,216 A:middle
about what content it
wants for the next pass.

1006
00:43:13,506 --> 00:43:15,026 A:middle
Let's see how that
works all in a sample.

1007
00:43:15,586 --> 00:43:18,606 A:middle
So here's our sample.

1008
00:43:19,286 --> 00:43:21,116 A:middle
We have our block
callback that your provide.

1009
00:43:23,036 --> 00:43:25,676 A:middle
Inside that callback you call
current pass description.

1010
00:43:25,676 --> 00:43:27,876 A:middle
This asks the encoder
what time ranges it wants

1011
00:43:27,876 --> 00:43:30,726 A:middle
for the next pass.

1012
00:43:30,846 --> 00:43:33,626 A:middle
If the pass is none nil,
meaning the encoder wants data

1013
00:43:33,626 --> 00:43:36,566 A:middle
for another pass, you
reconfigure your source.

1014
00:43:36,656 --> 00:43:38,966 A:middle
So this is where the
source will send samples

1015
00:43:39,316 --> 00:43:43,686 A:middle
to the AVSWriterInput, and then
you prepare the AVSWriterInput

1016
00:43:43,736 --> 00:43:44,766 A:middle
for the next pass.

1017
00:43:44,856 --> 00:43:45,516 A:middle
You're already familiar

1018
00:43:45,516 --> 00:43:47,666 A:middle
with requestMediaDataWhen
ReadyOnQueue.

1019
00:43:48,276 --> 00:43:53,036 A:middle
If the pass is nil, that means
the encoder has finished passes.

1020
00:43:53,366 --> 00:43:53,916 A:middle
Then you're done.

1021
00:43:53,986 --> 00:43:55,616 A:middle
You can mark your
input as finished.

1022
00:43:56,136 --> 00:44:00,686 A:middle
All right, let's say you're
going from a source media file.

1023

1024
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1025
00:43:56,136 --> 00:44:00,686 A:middle
All right, let's say you're
going from a source media file.

1026
00:44:00,686 --> 00:44:01,996 A:middle
That was in our second example.

1027
00:44:02,486 --> 00:44:05,036 A:middle
So we have new APIs
for AVSReaderOutput.

1028
00:44:05,696 --> 00:44:07,726 A:middle
You can prepare your
source for Multi-Pass

1029
00:44:07,726 --> 00:44:10,246 A:middle
by saying supportsRandomAccess
equals yes.

1030
00:44:10,816 --> 00:44:14,276 A:middle
Then when the encoder
wants new time ranges,

1031
00:44:14,276 --> 00:44:16,296 A:middle
you need to reconfigure
your AVSReaderOutput

1032
00:44:16,376 --> 00:44:17,676 A:middle
to deliver those time ranges.

1033
00:44:18,126 --> 00:44:20,106 A:middle
So that's
resetForReadingTimeRanges

1034
00:44:20,106 --> 00:44:21,696 A:middle
with an NSArray of time ranges.

1035
00:44:23,056 --> 00:44:25,226 A:middle
Finally, when all
passes have completed you

1036
00:44:25,226 --> 00:44:26,826 A:middle
callMarkConfigurationAsFinal.

1037
00:44:27,256 --> 00:44:30,016 A:middle
This allows the AVSReaderOutput
to transition

1038
00:44:30,016 --> 00:44:34,006 A:middle
to its completed state so it
can start tearing itself down.

1039
00:44:34,036 --> 00:44:36,026 A:middle
Right. Now there's a couple
short cuts you can use

1040
00:44:36,026 --> 00:44:38,696 A:middle
if you're using AVSReader
and AVSWriter

1041
00:44:38,696 --> 00:44:39,796 A:middle
in combination together.

1042
00:44:41,256 --> 00:44:44,076 A:middle
So you can enable
AVSReaderOutput

1043
00:44:44,076 --> 00:44:46,766 A:middle
if the AVSWriterInput
supports Multi-Pass.

1044
00:44:47,086 --> 00:44:49,086 A:middle
So if the encoder
supports Multi-Pass,

1045
00:44:49,696 --> 00:44:51,836 A:middle
we need to support random
access on the source.

1046
00:44:52,366 --> 00:44:56,776 A:middle
Then you can reconfigure your
source to deliver samples

1047
00:44:56,776 --> 00:44:58,236 A:middle
for the AVSWriterInput.

1048
00:44:58,496 --> 00:45:01,266 A:middle
So with your readerOutput
call resetForReadingTimeRanges

1049

1050
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1051
00:44:58,496 --> 00:45:01,266 A:middle
So with your readerOutput
call resetForReadingTimeRanges

1052
00:45:01,476 --> 00:45:03,276 A:middle
with the pass description's
time ranges.

1053
00:45:03,746 --> 00:45:06,026 A:middle
Let's go over that
in the sample.

1054
00:45:07,046 --> 00:45:09,266 A:middle
So instead of delivering
for an arbitrary source,

1055
00:45:09,266 --> 00:45:11,706 A:middle
we now want to deliver for
our AVS at ReaderOuput.

1056
00:45:11,706 --> 00:45:13,576 A:middle
So we call
resetForReadingTimeRanges

1057
00:45:13,576 --> 00:45:16,206 A:middle
with the pass description
source time ranges.

1058
00:45:20,976 --> 00:45:24,416 A:middle
Great. So that's the new API
and AVFoundation for Multi-Pass.

1059
00:45:24,416 --> 00:45:26,196 A:middle
Let's talk next about
Video Toolbox.

1060
00:45:27,146 --> 00:45:30,336 A:middle
So in Video Toolbox, our encoder
frame analysis data base,

1061
00:45:30,836 --> 00:45:33,746 A:middle
we like to call this
our VTMultiPassStorage.

1062
00:45:34,776 --> 00:45:37,266 A:middle
We also have additions
to VTCompressionSession,

1063
00:45:37,266 --> 00:45:39,166 A:middle
which David introduced in
his portion of the talk,

1064
00:45:39,776 --> 00:45:43,866 A:middle
and decompressed database, or
as we call it, the VTFrameSilo.

1065
00:45:44,306 --> 00:45:46,576 A:middle
So let's go over
the architecture,

1066
00:45:47,426 --> 00:45:50,176 A:middle
but this time replacing
the frame database

1067
00:45:50,176 --> 00:45:51,406 A:middle
and the encoder database

1068
00:45:51,406 --> 00:45:53,296 A:middle
with the objects
that we actually use.

1069
00:45:54,066 --> 00:45:55,996 A:middle
So in this case, we
have our VTFrameSilo

1070
00:45:55,996 --> 00:45:57,676 A:middle
and our VTMultiPassStorage.

1071
00:45:59,766 --> 00:46:00,826 A:middle
We're done with this pass.

1072

1073
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1074
00:45:59,766 --> 00:46:00,826 A:middle
We're done with this pass.

1075
00:46:00,826 --> 00:46:02,596 A:middle
The encoder wants to
see samples again.

1076
00:46:04,276 --> 00:46:06,606 A:middle
We're sending in those
samples that it requests.

1077
00:46:09,556 --> 00:46:12,856 A:middle
Then we're finished and we can
tear down the VTMultiPassStorage

1078
00:46:12,856 --> 00:46:19,006 A:middle
and the compression session and
we're left with our FrameSilo.

1079
00:46:19,066 --> 00:46:20,646 A:middle
So this is where we
need to perform the copy

1080
00:46:20,646 --> 00:46:22,566 A:middle
from the FrameSilo to
the output movie file.

1081
00:46:23,096 --> 00:46:26,966 A:middle
Great, we have our
output movie file.

1082
00:46:28,276 --> 00:46:31,476 A:middle
So first off, let's go over
what the VTMultiPassStorage is.

1083
00:46:31,476 --> 00:46:33,256 A:middle
So this is the encoder analysis.

1084
00:46:33,476 --> 00:46:35,276 A:middle
This is a pretty simple API.

1085
00:46:35,416 --> 00:46:37,036 A:middle
First you create the storage

1086
00:46:38,296 --> 00:46:40,606 A:middle
and then you close the
file once you're finished.

1087
00:46:40,876 --> 00:46:43,996 A:middle
So that's all the API
that you need to use.

1088
00:46:44,406 --> 00:46:46,566 A:middle
The data that's stored in
this is private to the encoder

1089
00:46:46,566 --> 00:46:48,486 A:middle
and you don't have
to worry about it.

1090
00:46:49,626 --> 00:46:52,256 A:middle
Next, let's talk about additions
to VTCompressionSession.

1091
00:46:53,906 --> 00:46:56,336 A:middle
So first, you need to tell
the VTCompressionSession

1092
00:46:56,336 --> 00:46:59,426 A:middle
and the encoder about
your VTMultiPassStorage.

1093
00:46:59,546 --> 00:47:01,796 A:middle
So you can do that by
setting a property.

1094

1095
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1096
00:46:59,546 --> 00:47:01,796 A:middle
So you can do that by
setting a property.

1097
00:47:02,246 --> 00:47:04,386 A:middle
This will tell the
encoder to use MultiPass

1098
00:47:04,386 --> 00:47:08,036 A:middle
and use this VTMultiPassStorage
for its frame analysis.

1099
00:47:08,506 --> 00:47:12,706 A:middle
Next, we've added a couple
functions for MultiPass.

1100
00:47:13,856 --> 00:47:18,506 A:middle
So you call begin pass before
you've appended any frames then

1101
00:47:18,506 --> 00:47:19,946 A:middle
after you're done
appending frames

1102
00:47:19,946 --> 00:47:21,776 A:middle
for that pass, you
call end pass.

1103
00:47:22,456 --> 00:47:24,386 A:middle
End pass also asks the encoder

1104
00:47:24,386 --> 00:47:25,796 A:middle
if another pass can
be performed.

1105
00:47:27,816 --> 00:47:30,156 A:middle
So if another -- if the
encoder wants another pass

1106
00:47:30,156 --> 00:47:32,446 A:middle
to be performed then you need
to ask it what time ranges

1107
00:47:32,446 --> 00:47:34,156 A:middle
of samples it wants
for the next pass.

1108
00:47:34,746 --> 00:47:37,006 A:middle
That's called
VTCompressionSession

1109
00:47:37,006 --> 00:47:39,436 A:middle
GetTimeRangesFor NextPass
and you're given a count

1110
00:47:39,436 --> 00:47:40,816 A:middle
and a C array of time ranges.

1111
00:47:41,046 --> 00:47:44,776 A:middle
Now let's talk about
the VTFrameSilo.

1112
00:47:44,776 --> 00:47:46,716 A:middle
So this is the compressed
frame store.

1113
00:47:48,416 --> 00:47:52,776 A:middle
So like the other objects you
created, and then you want

1114
00:47:52,776 --> 00:47:55,566 A:middle
to add samples to
this VTFrameSilo.

1115
00:47:57,226 --> 00:47:59,796 A:middle
So frames will automatically
be replaced

1116
00:47:59,796 --> 00:48:01,996 A:middle
if they have the same
presentation timestamp

1117

1118
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1119
00:47:59,796 --> 00:48:01,996 A:middle
if they have the same
presentation timestamp

1120
00:48:01,996 --> 00:48:05,036 A:middle
and how this data is stored
is abstracted away from you

1121
00:48:05,036 --> 00:48:06,446 A:middle
and you don't need
to worry about it.

1122
00:48:06,446 --> 00:48:09,766 A:middle
It's a convenient
database for you to use.

1123
00:48:09,886 --> 00:48:12,656 A:middle
Then you can prepare the
VTFrameSilo for the next pass.

1124
00:48:12,736 --> 00:48:16,826 A:middle
This optimizes the
storage for the next pass.

1125
00:48:19,756 --> 00:48:23,146 A:middle
Finally, let's talk about
the copy from the VTFrameSilo

1126
00:48:23,286 --> 00:48:24,456 A:middle
to the output movie file.

1127
00:48:25,766 --> 00:48:28,976 A:middle
So you can retrieve samples
for a given time range.

1128
00:48:29,286 --> 00:48:32,086 A:middle
This allows you to get a
sample in a block callback

1129
00:48:32,086 --> 00:48:34,496 A:middle
that you provide and add it
to your output movie file.

1130
00:48:35,156 --> 00:48:38,166 A:middle
Right, that's the new
Video Toolbox APIs.

1131
00:48:38,356 --> 00:48:40,456 A:middle
So I want to close with
a couple considerations.

1132
00:48:41,756 --> 00:48:44,256 A:middle
So we've talked about
how MultiPass works

1133
00:48:44,256 --> 00:48:47,546 A:middle
and what APIs you can use in
AVFoundation and Video Toolbox,

1134
00:48:47,826 --> 00:48:49,556 A:middle
but we need to talk
about your use cases

1135
00:48:49,556 --> 00:48:51,976 A:middle
and your priority in your app.

1136
00:48:52,226 --> 00:48:54,236 A:middle
So if you're performing
real time encoding,

1137
00:48:55,396 --> 00:48:56,856 A:middle
you should be using Single-Pass.

1138
00:48:57,066 --> 00:48:59,256 A:middle
Real time encoding has
very specific deadlines

1139
00:48:59,256 --> 00:49:01,046 A:middle
of how much compression can take

1140

1141
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1142
00:48:59,256 --> 00:49:01,046 A:middle
of how much compression can take

1143
00:49:01,456 --> 00:49:04,486 A:middle
and Multi-Pass will perform
more passes over the time range,

1144
00:49:04,516 --> 00:49:06,176 A:middle
so use Single-Pass
in these cases.

1145
00:49:08,996 --> 00:49:11,416 A:middle
If you're concerned about
using the minimum amount

1146
00:49:11,416 --> 00:49:14,696 A:middle
of power during encoding,
use Single-Pass.

1147
00:49:15,076 --> 00:49:17,286 A:middle
Multiple passes will
take more power

1148
00:49:17,286 --> 00:49:19,406 A:middle
and as will the encoder
analysis.

1149
00:49:20,756 --> 00:49:23,186 A:middle
If you're concerned with
using the minimum amount

1150
00:49:23,186 --> 00:49:25,046 A:middle
of temporary storage
during the encode

1151
00:49:25,046 --> 00:49:28,466 A:middle
or transcode operation,
use Single-Pass.

1152
00:49:28,636 --> 00:49:30,046 A:middle
The encoder analysis storage

1153
00:49:30,046 --> 00:49:32,126 A:middle
and the frame database
will use more storage

1154
00:49:32,126 --> 00:49:33,206 A:middle
than the output medial file.

1155
00:49:34,856 --> 00:49:37,906 A:middle
However, if you're concerned
about having the best quality

1156
00:49:37,906 --> 00:49:40,876 A:middle
for your content,
Multi-Pass is a great option.

1157
00:49:41,496 --> 00:49:45,386 A:middle
If you want to be as close to
the target bit rate you set

1158
00:49:45,386 --> 00:49:47,566 A:middle
on the VTCompressionSession
or AssetWriter

1159
00:49:47,566 --> 00:49:50,346 A:middle
as possible, use Multi-Pass.

1160
00:49:50,346 --> 00:49:54,176 A:middle
Multi-Pass can see all of the
portions of your source media

1161
00:49:54,176 --> 00:49:56,496 A:middle
and so it can allocate bits
only where it needs to.

1162
00:49:56,596 --> 00:49:57,926 A:middle
It's very smart in this sense.

1163

1164
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1165
00:50:00,676 --> 00:50:04,046 A:middle
If it's okay to take longer
in your app, so if it's okay

1166
00:50:04,046 --> 00:50:06,426 A:middle
for the encoder transfer
operation to take longer

1167
00:50:06,426 --> 00:50:09,586 A:middle
for better quality,
Multi-Pass is a good option.

1168
00:50:10,136 --> 00:50:13,176 A:middle
But the biggest takeaway
is that in your app,

1169
00:50:13,566 --> 00:50:14,636 A:middle
you need to experiment.

1170
00:50:14,636 --> 00:50:17,816 A:middle
So you need to think about
your use cases and your users

1171
00:50:17,816 --> 00:50:19,846 A:middle
and if they're willing to wait
longer for better quality.

1172
00:50:20,286 --> 00:50:24,896 A:middle
Next, let's talk about content.

1173
00:50:27,376 --> 00:50:29,576 A:middle
So if you, if your
app has low quality

1174
00:50:29,576 --> 00:50:32,856 A:middle
or low complexity content, think
of this like a title sequence

1175
00:50:32,856 --> 00:50:34,416 A:middle
or a static image sequence.

1176
00:50:36,676 --> 00:50:38,786 A:middle
Both Single-Pass and
Multi-Pass are going

1177
00:50:38,786 --> 00:50:40,416 A:middle
to both give you
great quality here,

1178
00:50:40,706 --> 00:50:42,516 A:middle
but Multi-Pass won't give
you much better quality

1179
00:50:42,516 --> 00:50:43,256 A:middle
than Single-Pass.

1180
00:50:43,256 --> 00:50:44,766 A:middle
These are both pretty
easy to encode.

1181
00:50:46,136 --> 00:50:48,516 A:middle
Next, let's talk about
high complexity content.

1182
00:50:48,646 --> 00:50:51,376 A:middle
So think of this as classic
encoder stress tests;

1183
00:50:51,376 --> 00:50:53,066 A:middle
water, fire, explosions.

1184
00:50:53,656 --> 00:50:56,856 A:middle
We all love to do
this, but Single-Pass

1185
00:50:57,086 --> 00:50:59,376 A:middle
and Multi-Pass are
both going to do well,

1186
00:50:59,376 --> 00:51:01,916 A:middle
but Multi-Pass probably won't
do much better than Single-Pass.

1187

1188
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1189
00:50:59,376 --> 00:51:01,916 A:middle
but Multi-Pass probably won't
do much better than Single-Pass.

1190
00:51:01,916 --> 00:51:04,566 A:middle
These are -- this kind of
content is hard for encoders

1191
00:51:08,406 --> 00:51:10,346 A:middle
to encode -- or is
Multi-Pass a better decision?

1192
00:51:11,396 --> 00:51:13,666 A:middle
Well, that's in varying
complexity, so think of this

1193
00:51:13,666 --> 00:51:16,036 A:middle
as a feature-length
movie or a documentary

1194
00:51:16,036 --> 00:51:18,276 A:middle
in Final Cut Pro or
an iMovie Trailer.

1195
00:51:18,636 --> 00:51:21,816 A:middle
Might have low complexity
regions, a title sequence,

1196
00:51:21,816 --> 00:51:23,326 A:middle
high complexity transitions.

1197
00:51:23,786 --> 00:51:25,716 A:middle
Because there's a lot of
different kinds of content,

1198
00:51:25,876 --> 00:51:28,056 A:middle
Multi-Pass is able to
analyze those sections

1199
00:51:28,056 --> 00:51:30,446 A:middle
and really give you the
best quality per bit.

1200
00:51:30,956 --> 00:51:34,146 A:middle
But again, the message
is with your content,

1201
00:51:34,786 --> 00:51:35,846 A:middle
you need to experiment.

1202
00:51:35,966 --> 00:51:38,106 A:middle
So you know your content
and you should know

1203
00:51:38,106 --> 00:51:41,046 A:middle
if Multi-Pass will give you a
good benefit in these cases.

1204
00:51:41,586 --> 00:51:45,586 A:middle
So let's go over what
we've talked about today.

1205
00:51:45,586 --> 00:51:48,446 A:middle
AVFoundation provides powerful
APIs to operate on media,

1206
00:51:48,516 --> 00:51:51,506 A:middle
and for most of you, these are
the APIs you will be using.

1207
00:51:52,136 --> 00:51:55,336 A:middle
And when you need
the extra power,

1208
00:51:55,426 --> 00:51:58,626 A:middle
Video Toolbox APIs provide
you direct media access.

1209
00:51:58,626 --> 00:52:01,456 A:middle
If you fall into one of the use
cases that David talked about,

1210

1211
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1212
00:51:58,626 --> 00:52:01,456 A:middle
If you fall into one of the use
cases that David talked about,

1213
00:52:01,526 --> 00:52:04,926 A:middle
this is a good way
to use Video Toolbox.

1214
00:52:06,696 --> 00:52:09,596 A:middle
Finally, Multi-Pass can
provide substantial quality

1215
00:52:09,596 --> 00:52:11,976 A:middle
improvements, but you need
to think about your app,

1216
00:52:12,206 --> 00:52:15,466 A:middle
your use cases and your
users before you enable it.

1217
00:52:16,796 --> 00:52:19,886 A:middle
So for more information,
here's our Evangelism email.

1218
00:52:20,076 --> 00:52:21,686 A:middle
You have AVFoundation
Documentation

1219
00:52:21,686 --> 00:52:22,636 A:middle
and a programming guide.

1220
00:52:23,056 --> 00:52:25,516 A:middle
We can answer your questions
on the developer forums.

1221
00:52:26,296 --> 00:52:28,336 A:middle
For those of you that
are watching online,

1222
00:52:28,336 --> 00:52:29,906 A:middle
a lot of these talks
have already happened.

1223
00:52:29,906 --> 00:52:32,196 A:middle
If you're here live, so these
are the talks you might be

1224
00:52:32,196 --> 00:52:32,836 A:middle
interested in.

1225
00:52:33,156 --> 00:52:34,926 A:middle
Thanks everyone and have
a good rest of your day.

1226
00:52:35,516 --> 00:52:42,300 A:middle
[ Applause ]

1227
