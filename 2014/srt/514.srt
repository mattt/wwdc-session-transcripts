X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:12,046 --> 00:00:13,986 A:middle
>> My name is David Hayward
and welcome to our first

2
00:00:13,986 --> 00:00:16,206 A:middle
of two discussions
about Core Image.

3
00:00:16,206 --> 00:00:18,036 A:middle
And we'll be talking
today about what's new

4
00:00:18,036 --> 00:00:23,356 A:middle
in Core Image on
both iOS and OS X.

5
00:00:23,356 --> 00:00:24,736 A:middle
So what is Core Image?

6
00:00:25,126 --> 00:00:28,626 A:middle
Core Image is a fast,
easy, flexible framework

7
00:00:28,626 --> 00:00:29,946 A:middle
for doing image processing.

8
00:00:30,466 --> 00:00:31,726 A:middle
And it supports all

9
00:00:31,726 --> 00:00:35,476 A:middle
of our supported devices
on both iOS and OS X.

10
00:00:35,886 --> 00:00:39,996 A:middle
It's also used by several of our
key applications such as photos

11
00:00:40,966 --> 00:00:42,906 A:middle
on both platforms
and it allows you

12
00:00:42,906 --> 00:00:44,736 A:middle
to get very good
performance results

13
00:00:44,736 --> 00:00:46,466 A:middle
and very flexible output.

14
00:00:46,956 --> 00:00:49,906 A:middle
For those of you who may
be new to Core Image,

15
00:00:49,966 --> 00:00:51,856 A:middle
I just want to take a few
slides to talk about some

16
00:00:51,856 --> 00:00:53,786 A:middle
of the key concepts because
those will be relevant

17
00:00:53,786 --> 00:00:55,216 A:middle
for the rest of the
discussion today.

18
00:00:56,766 --> 00:00:59,736 A:middle
So first off, filters --
Core Image filters allow you

19
00:00:59,736 --> 00:01:03,036 A:middle
to perform per-pixel
operations on an image.

20

21
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

22
00:00:59,736 --> 00:01:03,036 A:middle
to perform per-pixel
operations on an image.

23
00:01:03,516 --> 00:01:06,736 A:middle
In a simple example, you have
an original image and you want

24
00:01:06,736 --> 00:01:08,726 A:middle
to apply a sepia
tone filter to it.

25
00:01:09,056 --> 00:01:10,326 A:middle
And you'll get a
resulting image.

26
00:01:11,026 --> 00:01:13,196 A:middle
Obviously, that's fun
but where things start

27
00:01:13,196 --> 00:01:15,756 A:middle
to get interesting is where
you combine multiple filters

28
00:01:15,756 --> 00:01:18,586 A:middle
in either chains
or complex graphs.

29
00:01:18,666 --> 00:01:21,676 A:middle
And here an example, you can see
a very interesting result you

30
00:01:21,676 --> 00:01:24,166 A:middle
can get by just chaining
three filters together,

31
00:01:24,226 --> 00:01:26,846 A:middle
sepia tone plus a hue
rotation to turn it

32
00:01:26,846 --> 00:01:29,556 A:middle
into a blue tone
image plus a contrast

33
00:01:29,556 --> 00:01:30,886 A:middle
to make it more dramatic.

34
00:01:32,316 --> 00:01:35,246 A:middle
One thing to keep in mind is
these intermediate images are

35
00:01:35,246 --> 00:01:36,606 A:middle
actually lightweight objects.

36
00:01:36,936 --> 00:01:39,396 A:middle
So there need not necessarily
even be memory associated

37
00:01:39,396 --> 00:01:41,816 A:middle
with these of any
significant amount.

38
00:01:43,216 --> 00:01:44,476 A:middle
Another thing that's
important to keep

39
00:01:44,476 --> 00:01:49,086 A:middle
in mind is each filter may have
one or more kernels associated.

40
00:01:49,086 --> 00:01:51,626 A:middle
So these kernels are
the actual algorithm

41
00:01:51,626 --> 00:01:53,606 A:middle
that implements each
filter's effect.

42
00:01:54,676 --> 00:01:55,616 A:middle
And one of the great things

43
00:01:55,616 --> 00:01:58,436 A:middle
about Core Image is we
can take these kernels

44
00:01:58,706 --> 00:02:01,656 A:middle
and concatenate them into
programs and this allows us

45

46
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

47
00:01:58,706 --> 00:02:01,656 A:middle
and concatenate them into
programs and this allows us

48
00:02:01,656 --> 00:02:04,896 A:middle
at runtime to minimize the
amount of intermediate results

49
00:02:04,996 --> 00:02:07,516 A:middle
and with some great
compiler technology,

50
00:02:07,906 --> 00:02:11,406 A:middle
both at the image processing and
at the low-level compiler level,

51
00:02:11,576 --> 00:02:13,616 A:middle
we're able to get the
best possible performance

52
00:02:13,746 --> 00:02:14,996 A:middle
out of a complex graph.

53
00:02:15,496 --> 00:02:18,586 A:middle
So that's the basics in
terms of how it works.

54
00:02:18,886 --> 00:02:21,136 A:middle
These are the four key
object types that you need

55
00:02:21,136 --> 00:02:23,116 A:middle
to be familiar with if you
want to use Core Image.

56
00:02:23,696 --> 00:02:26,286 A:middle
The first which we'll be talking
about a lot today is CIKernel.

57
00:02:26,836 --> 00:02:28,956 A:middle
And this represents a
program that's written in CI's

58
00:02:28,956 --> 00:02:30,936 A:middle
or Core Image's Kernel language.

59
00:02:31,876 --> 00:02:36,056 A:middle
Second object type is a
CIFilter and this is an object

60
00:02:36,056 --> 00:02:38,536 A:middle
that has mutable
input parameters

61
00:02:38,536 --> 00:02:40,956 A:middle
and those parameters
can be images or numbers

62
00:02:40,956 --> 00:02:42,846 A:middle
or vectors or other types.

63
00:02:43,016 --> 00:02:46,166 A:middle
And it also allows you to
use one or more kernels

64
00:02:46,456 --> 00:02:49,286 A:middle
to create a new image based on
the current state of the output

65
00:02:49,286 --> 00:02:51,156 A:middle
or of the input parameters.

66
00:02:52,826 --> 00:02:56,556 A:middle
Third key type is a CIImage
and this is an immutable object

67
00:02:56,556 --> 00:02:59,416 A:middle
that represents the
recipe to produce an image.

68

69
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

70
00:03:00,036 --> 00:03:03,246 A:middle
Just the act of creating an
image does not necessarily do

71
00:03:03,246 --> 00:03:03,966 A:middle
any real work.

72
00:03:04,226 --> 00:03:06,596 A:middle
The actual work occurs
when you render a CIImage

73
00:03:06,596 --> 00:03:08,896 A:middle
into a CIContext and
that's the object

74
00:03:08,896 --> 00:03:10,316 A:middle
through which you
render results.

75
00:03:11,296 --> 00:03:12,896 A:middle
So those are the basics.

76
00:03:13,476 --> 00:03:15,476 A:middle
What I want to talk
about today is what's new

77
00:03:15,476 --> 00:03:17,656 A:middle
in Core Image this year and
we have a lot to talk about.

78
00:03:18,096 --> 00:03:20,276 A:middle
We have a bunch of new
things that are on iOS.

79
00:03:20,386 --> 00:03:23,276 A:middle
For example, we have our
most requested feature

80
00:03:23,386 --> 00:03:24,886 A:middle
which is Custom CIKernels.

81
00:03:25,456 --> 00:03:28,236 A:middle
We also like to talk about
how you can do Photo Editing

82
00:03:28,236 --> 00:03:29,546 A:middle
Extensions using Core Image

83
00:03:29,936 --> 00:03:33,226 A:middle
and also how we can now
support large images on iOS.

84
00:03:33,386 --> 00:03:36,696 A:middle
We also made some improvements
to how the GPU render is used.

85
00:03:38,086 --> 00:03:40,026 A:middle
We also have some
API modernization.

86
00:03:40,566 --> 00:03:42,166 A:middle
We have some new
built-in filters.

87
00:03:42,506 --> 00:03:45,406 A:middle
We have some new CIDetectors
and then lastly, we will talk

88
00:03:45,406 --> 00:03:50,006 A:middle
about some new things that
we have on the Mac OS X side,

89
00:03:50,356 --> 00:03:52,946 A:middle
improve RAW support and
how to use a second GPU.

90
00:03:54,716 --> 00:03:56,926 A:middle
So first and most interesting,

91
00:03:56,926 --> 00:03:59,236 A:middle
I think is Custom
CIKernels on iOS.

92
00:03:59,236 --> 00:04:01,466 A:middle
As I mentioned, this has been
our top requested feature.

93

94
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

95
00:03:59,236 --> 00:04:01,466 A:middle
As I mentioned, this has been
our top requested feature.

96
00:04:02,146 --> 00:04:06,146 A:middle
Core Image already has 115
great built-in filters on iOS.

97
00:04:06,536 --> 00:04:08,346 A:middle
But now you can easily
create your own.

98
00:04:08,686 --> 00:04:11,246 A:middle
So this is a terrific
feature for developers.

99
00:04:12,076 --> 00:04:14,656 A:middle
When you're writing
CIKernels on iOS,

100
00:04:14,656 --> 00:04:16,346 A:middle
you can use the same
CIKernel language

101
00:04:16,346 --> 00:04:18,336 A:middle
that you use today on OS X.

102
00:04:18,926 --> 00:04:20,185 A:middle
There are a few extensions

103
00:04:20,245 --> 00:04:23,526 A:middle
which allow making
typical kernels even easier

104
00:04:23,706 --> 00:04:25,486 A:middle
and we'll talk about
that in much more detail

105
00:04:25,486 --> 00:04:26,596 A:middle
in our next presentation.

106
00:04:27,856 --> 00:04:30,076 A:middle
Where can your CIKernels live?

107
00:04:30,456 --> 00:04:32,056 A:middle
Well, they can live
in your application.

108
00:04:32,386 --> 00:04:35,016 A:middle
The kernel code can
either be a text resource

109
00:04:35,116 --> 00:04:36,966 A:middle
or it can just be an
NSString, if you'd like.

110
00:04:37,476 --> 00:04:41,356 A:middle
The kernel is wrapped
up in CIFilter subclass

111
00:04:41,356 --> 00:04:43,496 A:middle
that you provide that
applies to kernels

112
00:04:43,496 --> 00:04:44,636 A:middle
to produce an output image.

113
00:04:45,996 --> 00:04:48,246 A:middle
Another great place for
your Custom CIKernels

114
00:04:48,246 --> 00:04:50,426 A:middle
to go is inside an
App Extension.

115
00:04:50,426 --> 00:04:53,986 A:middle
For example, Photo Editing
Extensions can use CIKernels

116
00:04:53,986 --> 00:04:56,116 A:middle
and CIFilter subclasses
very effectively.

117
00:04:56,636 --> 00:05:00,486 A:middle
And you can use them to modify
either photos or videos.

118

119
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

120
00:04:56,636 --> 00:05:00,486 A:middle
And you can use them to modify
either photos or videos.

121
00:05:02,736 --> 00:05:05,396 A:middle
So again, we'll be talking
our next presentation

122
00:05:05,576 --> 00:05:09,376 A:middle
in much more detail about
how to use CIKernels on iOS

123
00:05:09,406 --> 00:05:11,076 A:middle
but let me just give
you a little teaser now

124
00:05:11,176 --> 00:05:12,276 A:middle
of how simple it is.

125
00:05:12,766 --> 00:05:14,836 A:middle
Here we have in just
basically two lines of code,

126
00:05:15,316 --> 00:05:17,216 A:middle
how to use a Custom CIKernel.

127
00:05:17,606 --> 00:05:22,036 A:middle
We create an NSString which has
some CI Core Image source code

128
00:05:22,036 --> 00:05:22,276 A:middle
in it.

129
00:05:22,646 --> 00:05:24,766 A:middle
This is a very simple kernel

130
00:05:24,766 --> 00:05:27,546 A:middle
that takes a pixel
value and inverts it.

131
00:05:27,896 --> 00:05:30,486 A:middle
You'll notice it's actually
subtracting it not from 1

132
00:05:30,486 --> 00:05:31,576 A:middle
but from the alpha value.

133
00:05:31,576 --> 00:05:34,746 A:middle
That's the correct way to invert
if you've got premultiplied data

134
00:05:34,856 --> 00:05:36,766 A:middle
which is what Core
Image receives.

135
00:05:37,766 --> 00:05:40,166 A:middle
Once you have the program
written then all you need

136
00:05:40,166 --> 00:05:42,716 A:middle
to do is create a
CIKernel object

137
00:05:42,716 --> 00:05:45,416 A:middle
from the string and
then apply it.

138
00:05:45,776 --> 00:05:47,456 A:middle
You can specify two things.

139
00:05:47,456 --> 00:05:51,366 A:middle
One is the resulting
extent of the produced image

140
00:05:51,786 --> 00:05:55,816 A:middle
and also the arguments that
will be passed to that kernel.

141
00:05:56,286 --> 00:05:58,836 A:middle
In this particular example,
there is only a single argument

142
00:05:58,836 --> 00:06:02,196 A:middle
which is the input image and
so as a result, our arguments

143

144
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

145
00:05:58,836 --> 00:06:02,196 A:middle
which is the input image and
so as a result, our arguments

146
00:06:02,336 --> 00:06:06,686 A:middle
down below is just an array
with a single image in it.

147
00:06:07,636 --> 00:06:10,636 A:middle
So to give you a little bit
of idea of what that looks

148
00:06:10,636 --> 00:06:12,156 A:middle
like in practice, I
have a quick demo.

149
00:06:12,546 --> 00:06:14,556 A:middle
This is a fun example
that we wrote.

150
00:06:15,496 --> 00:06:18,016 A:middle
And it's kind of an
example of something

151
00:06:18,016 --> 00:06:20,776 A:middle
that you wouldn't necessarily
have as a built-in filter.

152
00:06:22,296 --> 00:06:22,716 A:middle
Let's see.

153
00:06:23,846 --> 00:06:27,216 A:middle
But it would be fun for
a presentation like this.

154
00:06:27,296 --> 00:06:30,016 A:middle
So we have an application
called Core Image Funhouse

155
00:06:30,596 --> 00:06:33,656 A:middle
and this allows you to explore
all the built-in filters

156
00:06:33,936 --> 00:06:37,276 A:middle
and also allows you to see
some sample code for how

157
00:06:37,416 --> 00:06:38,676 A:middle
to write Custom CIKernels.

158
00:06:39,226 --> 00:06:40,786 A:middle
So the image starts out as gray.

159
00:06:41,346 --> 00:06:44,116 A:middle
The first thing we need to do is
provide an image to start with.

160
00:06:44,376 --> 00:06:46,936 A:middle
And we're going to say that we
want the video feed to come in.

161
00:06:47,456 --> 00:06:51,146 A:middle
And then I'm going to add
a filter and you can see,

162
00:06:51,146 --> 00:06:53,056 A:middle
we're seeing a list
of all the filters

163
00:06:53,056 --> 00:06:54,556 A:middle
that are part of Core Image.

164
00:06:55,066 --> 00:06:58,416 A:middle
And we created one down
here called WWDC 2014

165
00:06:59,056 --> 00:07:01,366 A:middle
and I hope you can see this
so that I can kind of wave

166

167
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

168
00:06:59,056 --> 00:07:01,366 A:middle
and I hope you can see this
so that I can kind of wave

169
00:07:01,366 --> 00:07:03,316 A:middle
in front of the camera.

170
00:07:03,316 --> 00:07:07,706 A:middle
What we're doing here is
actually algorithmically taking

171
00:07:07,706 --> 00:07:10,426 A:middle
the luminance from the
video feed and then using

172
00:07:10,426 --> 00:07:11,736 A:middle
that to control the size

173
00:07:11,736 --> 00:07:15,856 A:middle
of the geometrically
generated rounded rectangle.

174
00:07:16,376 --> 00:07:20,676 A:middle
And we can change the size
of that larger or smaller

175
00:07:21,776 --> 00:07:24,446 A:middle
or we can change the amount
of the rounded radius here.

176
00:07:24,846 --> 00:07:28,686 A:middle
It's actually a little easier
to see that it's a video feed

177
00:07:28,686 --> 00:07:34,076 A:middle
when it's smaller but it looks
more cool when it's bigger.

178
00:07:34,206 --> 00:07:38,086 A:middle
So and we're getting about
30 frames per second on that

179
00:07:38,086 --> 00:07:40,816 A:middle
which is probably the frame
rate of the camera right now.

180
00:07:41,406 --> 00:07:44,956 A:middle
So that's our short example and
we'll have that code available

181
00:07:45,236 --> 00:07:46,426 A:middle
for download at some point soon.

182
00:07:47,646 --> 00:07:50,326 A:middle
So again, that's Custom
CIKernels and please come

183
00:07:50,326 --> 00:07:53,366 A:middle
to our second session to see
all you can learn about that.

184
00:07:54,296 --> 00:07:55,516 A:middle
The next thing I'd like to talk

185
00:07:55,516 --> 00:07:59,176 A:middle
about briefly is the Photo
Editing Extensions on iOS.

186
00:07:59,236 --> 00:08:02,206 A:middle
There are whole talks on
that this year at WWDC.

187

188
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

189
00:07:59,236 --> 00:08:02,206 A:middle
There are whole talks on
that this year at WWDC.

190
00:08:02,446 --> 00:08:05,256 A:middle
I'd like to talk a little
bit about how that works

191
00:08:05,346 --> 00:08:06,706 A:middle
in relationship to Core Image.

192
00:08:07,326 --> 00:08:08,956 A:middle
So here's just a
little short video run

193
00:08:08,956 --> 00:08:11,156 A:middle
through of how this
works in practice.

194
00:08:11,946 --> 00:08:14,586 A:middle
What we have is an image
the user wanted to edit.

195
00:08:14,876 --> 00:08:16,996 A:middle
They brought up a
list of extensions.

196
00:08:16,996 --> 00:08:18,186 A:middle
We picked the Core Image one

197
00:08:18,966 --> 00:08:22,196 A:middle
and this particular Core Image
based extension has two sliders.

198
00:08:22,196 --> 00:08:25,396 A:middle
One is the amount of sepia
tone which we can slide

199
00:08:25,806 --> 00:08:27,526 A:middle
and we're getting
very good frame rates

200
00:08:27,526 --> 00:08:29,516 A:middle
to the screen as we do this.

201
00:08:30,046 --> 00:08:33,866 A:middle
And then the second slider
is a vignette amount.

202
00:08:34,126 --> 00:08:36,056 A:middle
So it starts out with
a large radius and then

203
00:08:36,056 --> 00:08:38,066 A:middle
as you bring the radius
smaller, you get more

204
00:08:38,306 --> 00:08:41,926 A:middle
of the vignette effect
as you bring it down.

205
00:08:42,116 --> 00:08:44,246 A:middle
And all of this is
happening right now

206
00:08:44,246 --> 00:08:45,596 A:middle
on a display-sized image.

207
00:08:45,916 --> 00:08:48,236 A:middle
Later on, when you
hit Save, it's applied

208
00:08:48,236 --> 00:08:51,206 A:middle
on a full-sized image which
is the 12 megapixel image

209
00:08:51,206 --> 00:08:51,736 A:middle
in this case.

210
00:08:52,266 --> 00:08:54,276 A:middle
And it goes back into your
library with your edits.

211
00:08:54,956 --> 00:08:56,436 A:middle
So that's how it
looks in practice.

212
00:08:56,746 --> 00:08:59,206 A:middle
I'm not going to go into too
much detail on how to code this

213
00:08:59,276 --> 00:09:01,166 A:middle
but I'll give you
some good advice here.

214

215
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

216
00:08:59,276 --> 00:09:01,166 A:middle
but I'll give you
some good advice here.

217
00:09:01,796 --> 00:09:05,106 A:middle
First off, you can start to
create a Photo Editing Extension

218
00:09:05,106 --> 00:09:06,916 A:middle
by going into the
templates in Xcode.

219
00:09:07,516 --> 00:09:09,956 A:middle
We'll also provide some
sample code as well

220
00:09:09,956 --> 00:09:11,216 A:middle
so that'll be a good
starting point.

221
00:09:11,766 --> 00:09:13,316 A:middle
But as I said, I
wanted to talk a bit

222
00:09:13,316 --> 00:09:15,426 A:middle
about how you can use
Core Image effectively

223
00:09:15,726 --> 00:09:17,366 A:middle
within Photo Editing Extensions.

224
00:09:18,316 --> 00:09:20,106 A:middle
There's basically three steps.

225
00:09:20,196 --> 00:09:22,916 A:middle
The first step is when your
extension is initialized,

226
00:09:23,446 --> 00:09:26,486 A:middle
what you want to do is you want
to ask the editing input object

227
00:09:26,486 --> 00:09:28,466 A:middle
for a display-sized image.

228
00:09:29,046 --> 00:09:31,256 A:middle
Initially, that is a UI
image object and from

229
00:09:31,256 --> 00:09:34,446 A:middle
that you can create a CGImage
and then from that CIImage.

230
00:09:34,446 --> 00:09:36,496 A:middle
That sounds like
a couple of steps

231
00:09:36,496 --> 00:09:39,226 A:middle
but it's actually those are
just lightweight wrappers.

232
00:09:39,896 --> 00:09:41,876 A:middle
Once you've created that
CIImage, we're going to store

233
00:09:41,876 --> 00:09:44,516 A:middle
that in a property
for our delegate.

234
00:09:45,206 --> 00:09:47,756 A:middle
The other thing, it's a good
time to do at that time is

235
00:09:47,756 --> 00:09:49,756 A:middle
to create your view that you're
going to be rendering into.

236
00:09:49,756 --> 00:09:53,736 A:middle
We recommend using a GLKView
and also create a CIContext

237
00:09:53,736 --> 00:09:56,116 A:middle
that is associated
with that view.

238
00:09:56,116 --> 00:09:58,466 A:middle
And it's good to store that
away in the property as well.

239

240
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

241
00:10:00,326 --> 00:10:04,516 A:middle
Step two is what you do every
time the user makes an edit

242
00:10:04,516 --> 00:10:07,316 A:middle
in your extension so every
time the slider moves.

243
00:10:07,866 --> 00:10:09,136 A:middle
And this is very simple.

244
00:10:09,236 --> 00:10:12,166 A:middle
What you do is you recall
the display-sized CIImage

245
00:10:12,166 --> 00:10:13,386 A:middle
that we created in step one.

246
00:10:14,146 --> 00:10:16,096 A:middle
We apply the filters
that correspond

247
00:10:16,096 --> 00:10:17,836 A:middle
to those slider adjustments.

248
00:10:17,886 --> 00:10:21,696 A:middle
So in that previous example,
it was the sepia tone filter

249
00:10:21,696 --> 00:10:23,276 A:middle
and the vignette effect filter.

250
00:10:24,076 --> 00:10:25,416 A:middle
And then once you've
chained those together,

251
00:10:25,416 --> 00:10:26,856 A:middle
you get the output
image from that.

252
00:10:27,466 --> 00:10:29,876 A:middle
And then you're going to
draw that using the CIContext

253
00:10:29,876 --> 00:10:31,776 A:middle
that we also created
in step one.

254
00:10:32,326 --> 00:10:34,566 A:middle
And Step three is what happens

255
00:10:34,566 --> 00:10:36,086 A:middle
when the user clicks
the Done button.

256
00:10:36,086 --> 00:10:38,826 A:middle
And this is slightly
different because in this case,

257
00:10:38,826 --> 00:10:40,956 A:middle
you want to apply the effect
on the full-sized image.

258
00:10:41,516 --> 00:10:44,826 A:middle
So what we have here is we can
ask the editing input object

259
00:10:44,826 --> 00:10:46,676 A:middle
for its fullSizeImageURL.

260
00:10:46,876 --> 00:10:48,836 A:middle
From that, we create a CIImage

261
00:10:49,376 --> 00:10:51,196 A:middle
and we apply the
filters to this as well.

262
00:10:51,606 --> 00:10:54,386 A:middle
Now, for the most part, this is
the same as we did in step two.

263
00:10:54,676 --> 00:10:57,696 A:middle
Some parameters however such as
radiuses may need to be scaled

264
00:10:58,176 --> 00:11:00,116 A:middle
in accordance to the fact
that you're now working

265

266
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

267
00:10:58,176 --> 00:11:00,116 A:middle
in accordance to the fact
that you're now working

268
00:11:00,116 --> 00:11:01,076 A:middle
on a full-sized image.

269
00:11:02,106 --> 00:11:04,266 A:middle
Once you have chained
together your filters,

270
00:11:04,266 --> 00:11:06,486 A:middle
you ask the output
image and then you --

271
00:11:06,936 --> 00:11:10,526 A:middle
the way this API works is you
return the CGImage so you can do

272
00:11:10,526 --> 00:11:11,926 A:middle
that very easily
with Core Image.

273
00:11:12,286 --> 00:11:16,606 A:middle
You ask a CIContext to create a
CGImage and this will work even

274
00:11:16,606 --> 00:11:18,166 A:middle
on the full-sized image.

275
00:11:19,876 --> 00:11:22,446 A:middle
So that brings me to the
next subject I want to talk

276
00:11:22,446 --> 00:11:25,426 A:middle
about today which is working
on large images on iOS.

277
00:11:25,556 --> 00:11:28,646 A:middle
So we've made some great
improvements here in addition

278
00:11:28,646 --> 00:11:31,436 A:middle
to the supporting kernels, this
is I think our second key thing

279
00:11:31,436 --> 00:11:33,026 A:middle
that we've added
this year on iOS.

280
00:11:34,456 --> 00:11:38,116 A:middle
So now you can -- we have
full support for images

281
00:11:38,116 --> 00:11:40,096 A:middle
that are larger than
the GPU texture limits.

282
00:11:40,716 --> 00:11:43,716 A:middle
And this means that input
images can now be larger than 4K

283
00:11:44,186 --> 00:11:46,966 A:middle
and output renders
can be larger than 4K.

284
00:11:47,436 --> 00:11:50,336 A:middle
We refer to this as large
images but in practice,

285
00:11:50,386 --> 00:11:52,506 A:middle
4K images are not
that large these days.

286
00:11:52,506 --> 00:11:56,076 A:middle
Many of our devices'
cameras are bigger than that.

287
00:11:56,466 --> 00:11:58,256 A:middle
So this is actually a
really critical feature

288
00:11:58,256 --> 00:11:59,916 A:middle
to support this size
image as well.

289

290
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

291
00:12:00,956 --> 00:12:03,516 A:middle
The way we achieve
this automatically is

292
00:12:03,516 --> 00:12:05,656 A:middle
that we have automatic
tiling support in Core Image.

293
00:12:06,196 --> 00:12:08,486 A:middle
And this among other
things leverages some great

294
00:12:08,486 --> 00:12:11,496 A:middle
improvements that were made
in ImageIO and they're JPEG

295
00:12:11,496 --> 00:12:14,096 A:middle
to improve how the
decoder and encoder works.

296
00:12:14,876 --> 00:12:17,056 A:middle
And also, there's
some great features

297
00:12:17,056 --> 00:12:20,346 A:middle
in the Core Image language
that allows supporting

298
00:12:20,346 --> 00:12:21,416 A:middle
of large image as well.

299
00:12:22,176 --> 00:12:24,516 A:middle
So let me talk about that last
item in a little bit of detail.

300
00:12:25,276 --> 00:12:28,006 A:middle
So the CIKernel language
allows your kernels

301
00:12:28,006 --> 00:12:30,016 A:middle
to just work automatically
regardless

302
00:12:30,016 --> 00:12:33,416 A:middle
of whether tiling happens
or at what size it happens.

303
00:12:33,846 --> 00:12:34,876 A:middle
So this is a great feature

304
00:12:34,876 --> 00:12:38,226 A:middle
that makes writing
CIKernels very flexible.

305
00:12:39,306 --> 00:12:43,286 A:middle
The way this is achieved is by
two key extensions that we have

306
00:12:43,286 --> 00:12:45,086 A:middle
in our language and
these are available both

307
00:12:45,086 --> 00:12:47,466 A:middle
on OS X and on iOS now.

308
00:12:48,096 --> 00:12:50,886 A:middle
The first is a function called
desk coordinate or deskCoord

309
00:12:51,566 --> 00:12:53,216 A:middle
and that allows Core Image

310
00:12:53,516 --> 00:12:55,486 A:middle
to support tiled
output automatically.

311
00:12:56,286 --> 00:12:59,176 A:middle
It basically allows your kernel
to see the desk coordinate

312
00:12:59,456 --> 00:13:02,136 A:middle
in the native images space even
though we may only be rendering

313

314
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

315
00:12:59,456 --> 00:13:02,136 A:middle
in the native images space even
though we may only be rendering

316
00:13:02,136 --> 00:13:03,866 A:middle
a given tile at a time.

317
00:13:05,026 --> 00:13:08,656 A:middle
Similarly, there's a function
called samplerTransform

318
00:13:08,956 --> 00:13:11,356 A:middle
and that allows Core
Image to support tiling

319
00:13:11,356 --> 00:13:13,776 A:middle
of large input images
automatically.

320
00:13:14,456 --> 00:13:17,616 A:middle
So this is the two key things
about the CIKernel language

321
00:13:17,616 --> 00:13:20,186 A:middle
that we'll talk about
in much more detail

322
00:13:20,186 --> 00:13:21,246 A:middle
in our second presentation.

323
00:13:23,736 --> 00:13:27,466 A:middle
So another great thing about our
large image support is how we

324
00:13:27,466 --> 00:13:30,486 A:middle
work together with CGImageRef

325
00:13:30,556 --> 00:13:32,686 A:middle
and how we get some
great improvements

326
00:13:32,686 --> 00:13:35,106 A:middle
on iOS 8 by being lazy.

327
00:13:36,066 --> 00:13:37,656 A:middle
So one thing to keep in mind is

328
00:13:37,656 --> 00:13:39,686 A:middle
if you have a small
input CGImage

329
00:13:39,716 --> 00:13:44,096 A:middle
that you create a CIImage from,
then this image is fully decoded

330
00:13:44,096 --> 00:13:46,926 A:middle
at the time you call
CIImage initWith CGImage.

331
00:13:48,026 --> 00:13:50,356 A:middle
And that's actually usually
the right thing to do

332
00:13:50,356 --> 00:13:53,176 A:middle
for small images
because you may be using

333
00:13:53,176 --> 00:13:55,076 A:middle
that image multiple
times and you want

334
00:13:55,076 --> 00:14:00,896 A:middle
to take the performance impact
of decoding the JPEG once early.

335

336
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

337
00:13:55,076 --> 00:14:00,896 A:middle
to take the performance impact
of decoding the JPEG once early.

338
00:14:01,976 --> 00:14:05,156 A:middle
However, for large images,
that's not a good strategy

339
00:14:05,246 --> 00:14:08,106 A:middle
because you don't want to
require all of that memory

340
00:14:08,656 --> 00:14:10,496 A:middle
to be -- for that JPEG

341
00:14:10,496 --> 00:14:12,346 A:middle
to be compressed unless
you know you need it.

342
00:14:13,156 --> 00:14:17,566 A:middle
So if you have a large
input CGImage, that image,

343
00:14:18,026 --> 00:14:21,516 A:middle
that JPEG image behind that
CGImage is decoded only

344
00:14:21,516 --> 00:14:24,596 A:middle
as needed when you
call CIContext render.

345
00:14:25,186 --> 00:14:29,966 A:middle
So that's a very
important detail.

346
00:14:30,216 --> 00:14:33,466 A:middle
Similarly, when you're
producing a CGImage as an output

347
00:14:33,466 --> 00:14:38,556 A:middle
of CIImage, when you call
CIContext createCGImage,

348
00:14:38,556 --> 00:14:42,706 A:middle
if the output CGImage is small,
then the image is fully rendered

349
00:14:42,706 --> 00:14:43,956 A:middle
when CGImage is called.

350
00:14:44,746 --> 00:14:47,856 A:middle
However, if you're producing
a large CGImage as an output

351
00:14:48,286 --> 00:14:51,376 A:middle
such as an example of
the photo extensions,

352
00:14:51,816 --> 00:14:54,536 A:middle
the image is only
rendered as needed

353
00:14:54,536 --> 00:14:56,166 A:middle
when the CGImage is rendered.

354
00:14:57,286 --> 00:15:00,596 A:middle
This is also important because
a very common situation is you

355

356
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

357
00:14:57,286 --> 00:15:00,596 A:middle
This is also important because
a very common situation is you

358
00:15:00,596 --> 00:15:04,106 A:middle
pass the CGImage, the
CGImage DestinationFinalize

359
00:15:04,356 --> 00:15:08,106 A:middle
to encode it back as a JPEG.

360
00:15:08,316 --> 00:15:12,406 A:middle
So what all this means is that
if you have a very large JPEG,

361
00:15:12,856 --> 00:15:16,706 A:middle
you can take that large JPEG,
decode it, apply a filter to it

362
00:15:16,856 --> 00:15:20,196 A:middle
and re-encode it back into
a JPEG with minimal memory

363
00:15:20,596 --> 00:15:22,786 A:middle
and great performance
and this is a huge win

364
00:15:23,146 --> 00:15:24,496 A:middle
for Core Image on iOS.

365
00:15:25,036 --> 00:15:26,316 A:middle
So let's take a quick example.

366
00:15:26,636 --> 00:15:31,016 A:middle
You're applying a sepia tone
effect to a 4K by 6K JPEG,

367
00:15:31,886 --> 00:15:33,726 A:middle
so 100 megabytes of image.

368
00:15:33,896 --> 00:15:38,606 A:middle
That on iOS 7 took 17 seconds
to decode, apply the filter

369
00:15:38,606 --> 00:15:39,876 A:middle
and re-encode it as a JPEG.

370
00:15:40,666 --> 00:15:42,316 A:middle
On iOS 8, that's 1 second.

371
00:15:43,516 --> 00:15:46,756 A:middle
[ Applause ]

372
00:15:47,256 --> 00:15:50,316 A:middle
And just as important on iOS
is the memory high water mark

373
00:15:50,396 --> 00:15:52,786 A:middle
because that can really
force your application

374
00:15:52,786 --> 00:15:54,366 A:middle
into an unhappy place.

375
00:15:54,506 --> 00:15:58,016 A:middle
And our high water mark
on iOS 7 was 200 megabytes

376
00:15:58,016 --> 00:15:58,736 A:middle
which makes sense.

377
00:15:58,736 --> 00:16:01,696 A:middle
We have a source image that was
fully decompressed and we need

378

379
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

380
00:15:58,736 --> 00:16:01,696 A:middle
We have a source image that was
fully decompressed and we need

381
00:16:01,696 --> 00:16:03,956 A:middle
to produce a whole new image
which is the same size.

382
00:16:04,836 --> 00:16:06,286 A:middle
However because we
now have tiling,

383
00:16:06,286 --> 00:16:09,576 A:middle
our high water mark
is now 25 megabytes.

384
00:16:10,516 --> 00:16:15,026 A:middle
[ Applause ]

385
00:16:15,526 --> 00:16:19,456 A:middle
And just to summarize, on iOS
7, we worked on the full image

386
00:16:19,456 --> 00:16:21,786 A:middle
at a time and because it
was large, we often had

387
00:16:21,786 --> 00:16:22,916 A:middle
to use a CPU renderer.

388
00:16:23,566 --> 00:16:27,286 A:middle
On iOS 8, we have automatic
tiling and as a result,

389
00:16:27,286 --> 00:16:29,856 A:middle
we can use the GPU
which is a huge win.

390
00:16:31,516 --> 00:16:34,436 A:middle
So we've also made
some other improvements

391
00:16:34,436 --> 00:16:36,386 A:middle
to how GPU rendering
works with Core Image

392
00:16:36,386 --> 00:16:38,666 A:middle
on iOS which are important.

393
00:16:39,906 --> 00:16:42,146 A:middle
So your application
sometimes needs

394
00:16:42,146 --> 00:16:43,136 A:middle
to render in the background.

395
00:16:43,426 --> 00:16:46,006 A:middle
Often either when the app is
just transitioning to background

396
00:16:46,006 --> 00:16:48,266 A:middle
or when it's fully in
the background state.

397
00:16:48,666 --> 00:16:50,276 A:middle
On iOS 7, that is supported.

398
00:16:50,626 --> 00:16:53,946 A:middle
However all background renders
used the slower Core Image CPU

399
00:16:53,946 --> 00:16:54,566 A:middle
Rendering path.

400
00:16:55,606 --> 00:16:58,196 A:middle
On iOS 8, we have an improvement
in this regard which is

401
00:16:58,196 --> 00:17:00,106 A:middle
that renders that occur
within a short time

402

403
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

404
00:16:58,196 --> 00:17:00,106 A:middle
that renders that occur
within a short time

405
00:17:00,106 --> 00:17:03,836 A:middle
of switching the background will
now use the faster GPU renderer.

406
00:17:04,846 --> 00:17:07,996 A:middle
Now, it is serviced with a lower
GPU priority and the advantage

407
00:17:07,996 --> 00:17:10,306 A:middle
to that is that any
foreground renderers that happen

408
00:17:10,306 --> 00:17:11,736 A:middle
at that time will not be --

409
00:17:11,876 --> 00:17:13,266 A:middle
have any performance impact

410
00:17:13,685 --> 00:17:16,636 A:middle
because Core Image will be
using a lower priority renderer.

411
00:17:17,306 --> 00:17:18,636 A:middle
So this is another
great advantage.

412
00:17:19,806 --> 00:17:23,066 A:middle
There are some restrictions
on this GPU usage.

413
00:17:23,326 --> 00:17:27,076 A:middle
It is not allowed if you use
CIContext drawImage inRect

414
00:17:27,076 --> 00:17:29,956 A:middle
fromRect because in that case,
Core Image needs to render

415
00:17:29,956 --> 00:17:32,476 A:middle
into the client's
[inaudible] context.

416
00:17:32,826 --> 00:17:36,316 A:middle
However, any of the other render
methods calling createCGImage

417
00:17:36,316 --> 00:17:37,916 A:middle
or render toCVPixelBuffer

418
00:17:38,166 --> 00:17:43,506 A:middle
or render toBitmap will
all work in this way.

419
00:17:44,116 --> 00:17:47,676 A:middle
Another great improvement we
have is oftentimes you want

420
00:17:47,826 --> 00:17:50,246 A:middle
to do rendering in the
foreground when your app is

421
00:17:50,246 --> 00:17:52,146 A:middle
in the foreground but do it

422
00:17:52,196 --> 00:17:54,766 A:middle
from a secondary thread
in a polite manner.

423
00:17:55,246 --> 00:17:58,336 A:middle
So if your application
is showing one thing

424
00:17:58,336 --> 00:17:59,146 A:middle
and then doing something

425
00:17:59,146 --> 00:18:02,906 A:middle
on a secondary thread
using Core Image, on iOS 7,

426

427
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

428
00:17:59,146 --> 00:18:02,906 A:middle
on a secondary thread
using Core Image, on iOS 7,

429
00:18:02,906 --> 00:18:05,826 A:middle
that required care
in order to avoid --

430
00:18:06,116 --> 00:18:10,386 A:middle
in order for the secondary
thread to avoid causing glitches

431
00:18:10,386 --> 00:18:11,266 A:middle
for the foreground thread.

432
00:18:12,106 --> 00:18:14,486 A:middle
And of course, the only
sure-fire way to avoid that was

433
00:18:14,486 --> 00:18:16,866 A:middle
to use Core Image's
slower CPU renderer.

434
00:18:17,486 --> 00:18:19,926 A:middle
On iOS 8, we have a new feature

435
00:18:20,226 --> 00:18:24,246 A:middle
which is the secondary thread
can now render into a context

436
00:18:24,246 --> 00:18:26,396 A:middle
that has had this
new option specified

437
00:18:26,436 --> 00:18:29,396 A:middle
which is CIContext
PriorityRequestLow.

438
00:18:30,256 --> 00:18:33,436 A:middle
And the idea now is that
context renders using

439
00:18:33,546 --> 00:18:37,486 A:middle
that context will not
interrupt any foreground higher

440
00:18:37,486 --> 00:18:38,426 A:middle
priority renders.

441
00:18:38,786 --> 00:18:40,486 A:middle
So this is also great
for your application.

442
00:18:41,246 --> 00:18:43,956 A:middle
So this brings me to
some final thoughts

443
00:18:43,956 --> 00:18:46,226 A:middle
on Core Image's CPU rendering.

444
00:18:46,956 --> 00:18:50,156 A:middle
Basically, there were three key
reasons why an app would need

445
00:18:50,156 --> 00:18:52,866 A:middle
to use the CPU renderer
on iOS 7.

446
00:18:52,866 --> 00:18:56,006 A:middle
For example, the CPU
renderer was used

447
00:18:56,006 --> 00:18:59,856 A:middle
when GPU texture
limits were exceeded.

448

449
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

450
00:19:00,226 --> 00:19:04,066 A:middle
Well, starting on iOS 8, that's
no longer a limit in Core Image

451
00:19:04,066 --> 00:19:05,266 A:middle
so that's not a reason anymore.

452
00:19:06,086 --> 00:19:09,656 A:middle
Similarly, the application might
have needed to render briefly

453
00:19:09,656 --> 00:19:13,556 A:middle
when in the background, that's
also been improved in iOS 8.

454
00:19:14,756 --> 00:19:17,256 A:middle
And lastly, if your
application wanted to render

455
00:19:17,256 --> 00:19:19,516 A:middle
from a secondary thread
when in the foreground,

456
00:19:20,606 --> 00:19:22,606 A:middle
you might have used the
CPU renderer and now

457
00:19:22,606 --> 00:19:25,596 A:middle
that is no longer a limitation.

458
00:19:25,906 --> 00:19:28,476 A:middle
So we have some great
ways to keep us

459
00:19:28,476 --> 00:19:31,786 A:middle
on Core Image's much
faster GPU rendering path.

460
00:19:33,336 --> 00:19:36,396 A:middle
The next subject I want to
talk about this afternoon is

461
00:19:36,396 --> 00:19:38,326 A:middle
about some API modernizations

462
00:19:38,326 --> 00:19:41,286 A:middle
that have been made
both on OS X and on iOS.

463
00:19:41,856 --> 00:19:45,546 A:middle
These are small conveniences
but they add up in total.

464
00:19:45,816 --> 00:19:48,286 A:middle
First off, Core Image
filter subclasses

465
00:19:48,286 --> 00:19:51,156 A:middle
on OS X can now use
properties instead of ivars.

466
00:19:51,856 --> 00:19:54,026 A:middle
One thing to be aware of is

467
00:19:54,026 --> 00:19:57,976 A:middle
that Core Image filter
subclasses do not need

468
00:19:57,976 --> 00:20:02,956 A:middle
to release the object associated
with input ivars or properties.

469

470
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

471
00:19:57,976 --> 00:20:02,956 A:middle
to release the object associated
with input ivars or properties.

472
00:20:03,156 --> 00:20:05,886 A:middle
So it's a little bit nonstandard
as a class in that regard.

473
00:20:07,136 --> 00:20:09,876 A:middle
By supporting properties,
that means that code that used

474
00:20:09,876 --> 00:20:12,656 A:middle
to look like this where you
have output image equals filter

475
00:20:12,986 --> 00:20:18,296 A:middle
valueForKey kCIOutputImageKey
can now be a little cleaner

476
00:20:18,296 --> 00:20:21,516 A:middle
and just look like outImage
equals filter.outputImage.

477
00:20:23,856 --> 00:20:26,986 A:middle
We also have a convenience
method if you want

478
00:20:26,986 --> 00:20:29,086 A:middle
to create a filter
and also set a bunch

479
00:20:29,086 --> 00:20:30,756 A:middle
of parameters all
in one fell swoop.

480
00:20:31,356 --> 00:20:34,086 A:middle
This can be now done by
saying filter, filterWithName

481
00:20:34,446 --> 00:20:37,936 A:middle
and then you could specify some
parameters at the same time.

482
00:20:38,576 --> 00:20:40,576 A:middle
And in those parameters
are a dictionary

483
00:20:40,576 --> 00:20:44,186 A:middle
where you can specify all the
inputs in one convenient manner.

484
00:20:45,876 --> 00:20:47,956 A:middle
There's an even slightly
simpler case

485
00:20:47,956 --> 00:20:50,736 A:middle
which is very commonly
usable where one

486
00:20:50,736 --> 00:20:53,006 A:middle
of your inputs is an input
image and you just want

487
00:20:53,006 --> 00:20:54,696 A:middle
to get the output of a filter.

488
00:20:55,056 --> 00:20:58,266 A:middle
So this means you can apply a
filter to an image with a set

489
00:20:58,266 --> 00:21:00,486 A:middle
of parameters without even
creating a filter object.

490

491
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

492
00:20:58,266 --> 00:21:00,486 A:middle
of parameters without even
creating a filter object.

493
00:21:03,616 --> 00:21:05,546 A:middle
Lastly, one of the
common questions we get

494
00:21:05,546 --> 00:21:08,566 A:middle
from developers is, "How do
I correctly orient my image

495
00:21:08,566 --> 00:21:11,026 A:middle
so the orientation is
correctly upright?"

496
00:21:11,756 --> 00:21:15,286 A:middle
And the standard TIFF
specification has a set

497
00:21:15,286 --> 00:21:18,476 A:middle
of 8 possible values that tell
how the image should be flipped

498
00:21:18,476 --> 00:21:22,446 A:middle
or rotated and we've provided
a code snippet in the past

499
00:21:22,446 --> 00:21:25,626 A:middle
for that but much easier
is that we provided an API

500
00:21:25,626 --> 00:21:28,616 A:middle
for that now in iOS 8 and OS X.

501
00:21:28,976 --> 00:21:31,536 A:middle
So the simplest way
of calling it is

502
00:21:31,536 --> 00:21:34,266 A:middle
to say
imageByApplyingOrientation

503
00:21:34,766 --> 00:21:36,476 A:middle
and that gives you
back a new image.

504
00:21:36,906 --> 00:21:39,786 A:middle
And again, you're specifying
an integer orientation value.

505
00:21:40,326 --> 00:21:44,376 A:middle
As an alternative to doing the
same thing, we also have an API

506
00:21:44,376 --> 00:21:47,526 A:middle
that allows you to get
back the fine transform

507
00:21:47,526 --> 00:21:48,486 A:middle
that is equivalent to that.

508
00:21:49,296 --> 00:21:52,886 A:middle
And the reason why that's useful
is usually orienting your image

509
00:21:52,886 --> 00:21:57,066 A:middle
upright is only the
first of several affines

510
00:21:57,066 --> 00:21:58,486 A:middle
that you may apply
to your image.

511
00:21:58,486 --> 00:22:00,666 A:middle
You may also be scaling
it to fit or panning it.

512

513
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

514
00:21:58,486 --> 00:22:00,666 A:middle
You may also be scaling
it to fit or panning it.

515
00:22:01,236 --> 00:22:05,376 A:middle
And so by getting this affine
matrix and concatenating

516
00:22:05,376 --> 00:22:06,706 A:middle
with any other affine matrix,

517
00:22:06,706 --> 00:22:08,616 A:middle
you can get a little better
performance out of Core Image.

518
00:22:12,156 --> 00:22:15,366 A:middle
So we've also made some
modernizations on OS X

519
00:22:15,366 --> 00:22:16,646 A:middle
with regard to color spaces.

520
00:22:17,146 --> 00:22:20,876 A:middle
The default RGB color space
is now sRGB which is great

521
00:22:20,876 --> 00:22:24,176 A:middle
because it matches with
the default RGB color space

522
00:22:24,176 --> 00:22:25,096 A:middle
that we have on iOS.

523
00:22:25,296 --> 00:22:29,376 A:middle
It also matches what most
modern applications expect

524
00:22:29,376 --> 00:22:31,326 A:middle
for untagged images.

525
00:22:33,106 --> 00:22:37,676 A:middle
Similarly, our default working
space has also changed on OS X.

526
00:22:37,806 --> 00:22:43,176 A:middle
It is now a linearized version
of the Rec.709 chromaticities

527
00:22:43,566 --> 00:22:45,676 A:middle
and again, this matches
the default we have

528
00:22:45,676 --> 00:22:47,686 A:middle
for our working space on iOS

529
00:22:47,866 --> 00:22:50,526 A:middle
and has a great performance
advantage which means

530
00:22:50,526 --> 00:22:52,046 A:middle
that in most typical scenarios

531
00:22:52,046 --> 00:22:55,286 A:middle
where you have sRGB
content going into a filter

532
00:22:55,286 --> 00:22:58,226 A:middle
in its working space and then
going back to sRGB output,

533
00:22:58,546 --> 00:23:00,226 A:middle
no matrix math is needed at all

534

535
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

536
00:22:58,546 --> 00:23:00,226 A:middle
no matrix math is needed at all

537
00:23:00,616 --> 00:23:02,256 A:middle
so this is a great,
great advantage.

538
00:23:02,496 --> 00:23:06,676 A:middle
Next subject, I'd like to talk

539
00:23:06,676 --> 00:23:10,506 A:middle
about today is some new
built-in Core Image filters.

540
00:23:11,836 --> 00:23:14,546 A:middle
So we have several I'd
like to talk about.

541
00:23:14,546 --> 00:23:18,756 A:middle
One is new to iOS 8 is
we've added CIAreaHistogram

542
00:23:18,756 --> 00:23:20,576 A:middle
and CIHistogramDisplayFilter.

543
00:23:21,196 --> 00:23:22,576 A:middle
The first filter,

544
00:23:22,576 --> 00:23:26,756 A:middle
CIAreaHistogram takes an
input image and the rectangle

545
00:23:26,756 --> 00:23:28,536 A:middle
that you want to generate
the histogram of it

546
00:23:28,966 --> 00:23:32,736 A:middle
and it'll produce an output
image that's typically 256

547
00:23:32,736 --> 00:23:33,856 A:middle
by 1 pixels.

548
00:23:34,386 --> 00:23:36,566 A:middle
So that image is useful
if you want to render

549
00:23:36,566 --> 00:23:37,826 A:middle
and get the pixel
values out of it

550
00:23:37,826 --> 00:23:41,296 A:middle
because that'll give you your
histogram data very efficiently.

551
00:23:42,196 --> 00:23:43,826 A:middle
However, oftentimes
you also want

552
00:23:43,826 --> 00:23:45,746 A:middle
to display this histogram
to the user.

553
00:23:46,146 --> 00:23:49,556 A:middle
So we have a second filter which
is CIHistogramDisplayFilter.

554
00:23:49,876 --> 00:23:53,286 A:middle
And it takes as an input
this 256 by 1 pixel image

555
00:23:53,696 --> 00:23:56,296 A:middle
and it produces a
pretty graph with red,

556
00:23:56,296 --> 00:23:57,856 A:middle
green and blue graphs
in it just like this.

557
00:23:58,956 --> 00:24:00,596 A:middle
It's very easy to use
in your application.

558

559
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

560
00:23:58,956 --> 00:24:00,596 A:middle
It's very easy to use
in your application.

561
00:24:00,596 --> 00:24:02,066 A:middle
You just chain together
these two filters.

562
00:24:03,696 --> 00:24:06,676 A:middle
This is another great filter
that I'm really pleased with.

563
00:24:06,676 --> 00:24:10,166 A:middle
This is -- we've always had
filters for doing Gaussian blurs

564
00:24:10,166 --> 00:24:13,236 A:middle
on an image but we have a new
filter called MaskVariableBlur.

565
00:24:13,686 --> 00:24:16,016 A:middle
And the idea is you want
to apply a blur to an image

566
00:24:16,016 --> 00:24:17,976 A:middle
but you want to apply a
different amount of blur

567
00:24:17,976 --> 00:24:19,106 A:middle
at different locations.

568
00:24:19,276 --> 00:24:22,166 A:middle
So the way this filter works is
you start with an input image

569
00:24:22,716 --> 00:24:24,586 A:middle
and you provide a masked image.

570
00:24:24,896 --> 00:24:27,386 A:middle
In this example, we
have the mask is white

571
00:24:27,476 --> 00:24:31,846 A:middle
in the lower left-hand
corner, black in the center

572
00:24:32,086 --> 00:24:35,156 A:middle
and then white again the
upper right-hand corner.

573
00:24:35,656 --> 00:24:38,096 A:middle
And what this means when
we combine these two images

574
00:24:38,096 --> 00:24:41,146 A:middle
with masked variable blur
is we get a resulting image

575
00:24:41,506 --> 00:24:46,036 A:middle
that is defocused at the corners
and then gradually transitions

576
00:24:46,036 --> 00:24:47,596 A:middle
to a nice sharp image
in the center.

577
00:24:48,516 --> 00:24:51,216 A:middle
This is not just done with
blends but it's actually done

578
00:24:51,216 --> 00:24:53,716 A:middle
with variable radius blurs
which is quite a trick.

579
00:24:54,506 --> 00:24:56,726 A:middle
So there's a couple of
different ways you can use this.

580
00:24:56,726 --> 00:24:58,726 A:middle
You can use this to
achieve a sort of fake depth

581
00:24:58,726 --> 00:25:00,896 A:middle
of field effect where
the top and bottom

582

583
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

584
00:24:58,726 --> 00:25:00,896 A:middle
of field effect where
the top and bottom

585
00:25:00,896 --> 00:25:03,056 A:middle
of your image might be blurry
and the center may be sharp.

586
00:25:03,676 --> 00:25:07,836 A:middle
Or you can actually hand create
a masked image with a person

587
00:25:07,836 --> 00:25:10,396 A:middle
in the foreground and then
nicely blur the background

588
00:25:10,396 --> 00:25:11,416 A:middle
with a nice bokeh.

589
00:25:12,926 --> 00:25:15,466 A:middle
So I hope to see lots
of fun examples of that.

590
00:25:16,416 --> 00:25:19,926 A:middle
This is another fun one we added
which is AccordionfoldTransition

591
00:25:19,926 --> 00:25:22,346 A:middle
and this is something
we did for the mail team

592
00:25:22,346 --> 00:25:24,486 A:middle
but we've also provided
it as a public filter.

593
00:25:24,846 --> 00:25:27,896 A:middle
You provide two images, a
before and an after and a couple

594
00:25:27,896 --> 00:25:30,316 A:middle
of parameters like how many
folds and how many pixels

595
00:25:30,316 --> 00:25:31,616 A:middle
at the bottom are shared.

596
00:25:32,296 --> 00:25:34,996 A:middle
And what this filter looks
like in practice is this.

597
00:25:35,896 --> 00:25:37,596 A:middle
And if you actually
look carefully,

598
00:25:37,866 --> 00:25:39,986 A:middle
that's the actual entire
kernel for this filter.

599
00:25:41,596 --> 00:25:46,606 A:middle
So it's a nice bit of trickery.

600
00:25:47,236 --> 00:25:50,666 A:middle
Another filter we've
added, in prior releases,

601
00:25:50,666 --> 00:25:53,256 A:middle
we've had filters for
generating QR codes.

602
00:25:53,916 --> 00:25:58,076 A:middle
We've added a new one for
generating code 128 barcodes

603
00:25:58,396 --> 00:25:59,936 A:middle
and it works in a
similar fashion.

604
00:25:59,936 --> 00:26:03,846 A:middle
You specify an input message
as NSData and in this case,

605

606
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

607
00:25:59,936 --> 00:26:03,846 A:middle
You specify an input message
as NSData and in this case,

608
00:26:03,846 --> 00:26:06,256 A:middle
there's an additional parameter
which says how many pixels

609
00:26:06,256 --> 00:26:07,316 A:middle
of quiet space you want

610
00:26:08,326 --> 00:26:10,276 A:middle
and it'll produce
an image like this.

611
00:26:10,796 --> 00:26:13,226 A:middle
We've also added another
one for Aztec codes.

612
00:26:13,626 --> 00:26:15,546 A:middle
Again the same kind
of idea for the API,

613
00:26:15,666 --> 00:26:17,666 A:middle
you just specify
the input message

614
00:26:18,056 --> 00:26:19,806 A:middle
and for this particular
generator,

615
00:26:19,806 --> 00:26:21,606 A:middle
it has an input correction level

616
00:26:21,606 --> 00:26:26,876 A:middle
which tells how many error
correction bits it will have.

617
00:26:26,916 --> 00:26:31,596 A:middle
Another new filter which is also
fun is CIPerspectiveCorrection.

618
00:26:32,066 --> 00:26:34,176 A:middle
And the idea behind this
is you have an input image

619
00:26:34,176 --> 00:26:38,156 A:middle
and you specify 4 points and
it will create a new image

620
00:26:38,216 --> 00:26:41,606 A:middle
that is cropped and undistorted
preserving the original

621
00:26:41,636 --> 00:26:45,126 A:middle
and intended aspect ratio
so this is again very nice

622
00:26:45,126 --> 00:26:52,166 A:middle
for capturing parts of an
image and distorting them.

623
00:26:52,646 --> 00:26:55,726 A:middle
We've added a handful of
new blend filters, linear,

624
00:26:55,726 --> 00:26:58,136 A:middle
dodge and burn, pin
lights, subtract, divide.

625
00:26:58,826 --> 00:27:03,206 A:middle
Also just to be aware, we've
made a fix to SoftLightBlendMode

626

627
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

628
00:26:58,826 --> 00:27:03,206 A:middle
Also just to be aware, we've
made a fix to SoftLightBlendMode

629
00:27:03,206 --> 00:27:06,606 A:middle
so it better matches the spec.

630
00:27:06,606 --> 00:27:09,456 A:middle
And then there's a few other new
ones we've added that are new

631
00:27:09,456 --> 00:27:12,276 A:middle
on iOS such as GlassDistortion,

632
00:27:12,276 --> 00:27:14,736 A:middle
StretchCrop for anamorphic
correction,

633
00:27:15,066 --> 00:27:16,846 A:middle
Droste which is a great demo

634
00:27:16,846 --> 00:27:20,966 A:middle
from our conference show two
years ago, and then who knows,

635
00:27:20,966 --> 00:27:22,756 A:middle
if we have some more time,
we'll get a few more in.

636
00:27:23,136 --> 00:27:26,676 A:middle
But what that brings us to today
is over 115 built-in filters

637
00:27:26,676 --> 00:27:29,666 A:middle
on iOS and of course, that
really is an infinite number now

638
00:27:29,666 --> 00:27:31,986 A:middle
that you guys can create
your own custom filters.

639
00:27:32,386 --> 00:27:34,516 A:middle
So we're excited to see
all sorts of new things.

640
00:27:35,916 --> 00:27:37,516 A:middle
Another area we've
made some improvements

641
00:27:37,516 --> 00:27:39,966 A:middle
in Core Image is CIDetectors.

642
00:27:40,186 --> 00:27:41,926 A:middle
So what is a CIDetector?

643
00:27:41,926 --> 00:27:44,666 A:middle
Well, CIDetector is an
abstract class that allows you

644
00:27:44,666 --> 00:27:46,276 A:middle
to help find things
within an image.

645
00:27:47,106 --> 00:27:51,606 A:middle
And prior to iOS 8, we had just
one type which was TypeFace.

646
00:27:52,186 --> 00:27:53,216 A:middle
But we've added two more.

647
00:27:53,306 --> 00:27:55,796 A:middle
So we now have
CIDetectorTypeRectangle

648
00:27:55,846 --> 00:27:57,886 A:middle
and CIDetectorTypeQRCode.

649
00:27:59,126 --> 00:28:00,986 A:middle
So how does this work?

650

651
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

652
00:27:59,126 --> 00:28:00,986 A:middle
So how does this work?

653
00:28:00,986 --> 00:28:03,686 A:middle
Well, creating a detector is
largely the same regardless

654
00:28:03,686 --> 00:28:05,206 A:middle
of what type of detector
you are creating.

655
00:28:05,596 --> 00:28:08,566 A:middle
Here we have an example of
creating a detector of TypeFace

656
00:28:08,696 --> 00:28:10,736 A:middle
where we say detector,
detector of TypeFace

657
00:28:10,736 --> 00:28:12,536 A:middle
and we can also specify
some options.

658
00:28:13,146 --> 00:28:14,926 A:middle
There are a couple of
options that are very useful

659
00:28:14,926 --> 00:28:16,076 A:middle
for all the detectors.

660
00:28:16,076 --> 00:28:19,856 A:middle
One is you could say whether
you want to have high accuracy

661
00:28:19,856 --> 00:28:23,126 A:middle
or low accuracy which depending
on your need might allow you

662
00:28:23,126 --> 00:28:25,416 A:middle
to trade off performance
versus precision.

663
00:28:26,606 --> 00:28:29,646 A:middle
Also, you can tell a detector
what the smallest feature

664
00:28:29,646 --> 00:28:33,296 A:middle
to detect is and that also can
greatly improve performance.

665
00:28:33,826 --> 00:28:37,996 A:middle
And of course, now that we've
added these new detectors,

666
00:28:38,286 --> 00:28:40,066 A:middle
you can just use
DetectorTypeRectangle

667
00:28:40,776 --> 00:28:42,286 A:middle
or DetectorTypeQRCode as well.

668
00:28:44,256 --> 00:28:48,036 A:middle
So just as a reminder, so when
you're using the FaceDetector,

669
00:28:48,686 --> 00:28:51,116 A:middle
there's a couple of options
that you want to pass

670
00:28:51,116 --> 00:28:53,346 A:middle
in when you're asking for the
actual features in an image.

671
00:28:53,766 --> 00:28:56,476 A:middle
One is you can specify what the
orientation of the image is.

672
00:28:56,716 --> 00:28:58,986 A:middle
That's important because
the FaceDetector looks

673
00:28:58,986 --> 00:28:59,946 A:middle
for upright faces.

674

675
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

676
00:29:00,746 --> 00:29:02,736 A:middle
Also you can specify
options to say I want to look

677
00:29:02,736 --> 00:29:06,456 A:middle
for eye blinks or smiles
and that's specified

678
00:29:06,456 --> 00:29:07,566 A:middle
in the same options dictionary.

679
00:29:07,566 --> 00:29:10,946 A:middle
And let me show you
a little bit of code

680
00:29:10,946 --> 00:29:14,016 A:middle
about how we can now use this
detector to create a sort

681
00:29:14,016 --> 00:29:16,276 A:middle
of augmented reality
example here.

682
00:29:16,636 --> 00:29:18,396 A:middle
And the idea we wanted
for this little bit

683
00:29:18,396 --> 00:29:20,806 A:middle
of a sample code is we wanted
to start with the input image,

684
00:29:20,806 --> 00:29:24,246 A:middle
find the faces in it
and then put squares

685
00:29:24,246 --> 00:29:25,996 A:middle
over the image where
we find them.

686
00:29:25,996 --> 00:29:28,646 A:middle
And so this is a little
clever bit of sample code.

687
00:29:28,646 --> 00:29:32,536 A:middle
First off, for each face that
we detect in the features array,

688
00:29:33,266 --> 00:29:35,626 A:middle
we're going to check to see if
the eyes were closed or not.

689
00:29:36,346 --> 00:29:38,486 A:middle
Then we're going to
create a CIImage WithColor.

690
00:29:39,216 --> 00:29:41,746 A:middle
And we're going to have
a different color based

691
00:29:41,746 --> 00:29:43,546 A:middle
on whether the eyes
are closed or not

692
00:29:43,546 --> 00:29:45,536 A:middle
or whether face is
smiling or not.

693
00:29:46,096 --> 00:29:48,796 A:middle
Now that API actually
returns an infinite image

694
00:29:49,766 --> 00:29:53,156 A:middle
so what we then need to do is
to crop that image to the bounds

695
00:29:53,156 --> 00:29:54,366 A:middle
of the feature that
was detected.

696
00:29:55,406 --> 00:29:59,826 A:middle
We then take that cropped
image color and we composite

697
00:29:59,826 --> 00:30:01,676 A:middle
over the previous
resulting image.

698

699
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

700
00:29:59,826 --> 00:30:01,676 A:middle
over the previous
resulting image.

701
00:30:02,156 --> 00:30:04,106 A:middle
And this is also a new
API that we've provided.

702
00:30:04,106 --> 00:30:07,456 A:middle
It's basically convenience
API that's equivalent

703
00:30:07,456 --> 00:30:10,296 A:middle
to using the Core Image source
over compositing filter.

704
00:30:10,776 --> 00:30:12,866 A:middle
And this is what it
looks like in practice.

705
00:30:12,866 --> 00:30:14,326 A:middle
Here's a little sample
video we shot

706
00:30:14,326 --> 00:30:18,516 A:middle
where we are detecting
the faces in real time

707
00:30:18,516 --> 00:30:22,316 A:middle
and then coloring them based
on whether the face is smiling

708
00:30:22,316 --> 00:30:23,696 A:middle
or blinking or combinations.

709
00:30:24,116 --> 00:30:26,626 A:middle
And we're getting about
25 frames per second.

710
00:30:27,136 --> 00:30:32,096 A:middle
We could do something similar
also for rectangle features.

711
00:30:32,096 --> 00:30:36,426 A:middle
So the idea behind rectangle
features is we understand

712
00:30:36,426 --> 00:30:40,446 A:middle
that in a lot of cases,
the first step in looking

713
00:30:40,486 --> 00:30:43,116 A:middle
in an image for something
interesting is to look

714
00:30:43,116 --> 00:30:44,256 A:middle
for something like a rectangle.

715
00:30:44,386 --> 00:30:47,006 A:middle
For example, if you're looking
for a sign or if you're looking

716
00:30:47,006 --> 00:30:49,886 A:middle
for a business card or if you're
looking for a piece of paper,

717
00:30:50,116 --> 00:30:52,846 A:middle
oftentimes looking for the
rectangle first is a great place

718
00:30:52,846 --> 00:30:53,246 A:middle
to start.

719
00:30:53,576 --> 00:30:56,676 A:middle
So we've created a generic
rectangle detector object

720
00:30:57,236 --> 00:31:00,176 A:middle
and it takes one
option parameter

721

722
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

723
00:30:57,236 --> 00:31:00,176 A:middle
and it takes one
option parameter

724
00:31:00,176 --> 00:31:02,356 A:middle
which is the aspect ratio
that we want to search for.

725
00:31:03,086 --> 00:31:05,496 A:middle
And again, you can
ask the detector

726
00:31:05,496 --> 00:31:07,236 A:middle
to return the features array.

727
00:31:07,796 --> 00:31:09,706 A:middle
Now right now, it just
returns one rectangle

728
00:31:09,706 --> 00:31:11,056 A:middle
but that may change
in the future.

729
00:31:12,066 --> 00:31:14,476 A:middle
So here again, we wanted
to do a little sample here,

730
00:31:14,476 --> 00:31:16,666 A:middle
a little bit fancier
because we want to,

731
00:31:16,666 --> 00:31:19,336 A:middle
instead of just doing
the bounding box overlay,

732
00:31:19,646 --> 00:31:21,316 A:middle
we want to make it a
little bit prettier.

733
00:31:21,746 --> 00:31:24,546 A:middle
So again, we're looping over
all the features in the image.

734
00:31:25,366 --> 00:31:29,736 A:middle
We're creating a CIImage
WithColor which is infinite.

735
00:31:30,626 --> 00:31:33,846 A:middle
But we're going to take that
infinite color image and run it

736
00:31:33,846 --> 00:31:36,286 A:middle
through the
CIPerspectiveTransform

737
00:31:36,416 --> 00:31:37,796 A:middle
WithExtent filter.

738
00:31:38,366 --> 00:31:40,456 A:middle
And that filter does two things.

739
00:31:40,456 --> 00:31:42,196 A:middle
First of all, you
specify an extent

740
00:31:42,576 --> 00:31:45,586 A:middle
which in this case
we're specifying 0011

741
00:31:45,936 --> 00:31:48,396 A:middle
so now effectively, we
have a unit square image.

742
00:31:49,246 --> 00:31:51,816 A:middle
And then the other parameters,
take that unit square

743
00:31:51,816 --> 00:31:56,456 A:middle
and stretch it to the top-left,
top-right, bottom-left,

744
00:31:56,526 --> 00:31:57,656 A:middle
bottom-right coordinates.

745
00:31:58,226 --> 00:32:00,156 A:middle
And then we overlay that
on the previous result.

746

747
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

748
00:31:58,226 --> 00:32:00,156 A:middle
And then we overlay that
on the previous result.

749
00:32:00,866 --> 00:32:02,556 A:middle
And here's what that
looks like in practice.

750
00:32:02,596 --> 00:32:06,176 A:middle
So this is the nameplate from
my office and we are taking,

751
00:32:06,326 --> 00:32:10,326 A:middle
running it through the Detector,
getting the detected rectangle

752
00:32:10,326 --> 00:32:12,676 A:middle
and then producing this
overlay tinted red image.

753
00:32:15,496 --> 00:32:18,676 A:middle
Lastly, we can do the
same thing with QR Codes.

754
00:32:19,036 --> 00:32:20,776 A:middle
The code here is
exactly the same.

755
00:32:21,196 --> 00:32:22,046 A:middle
The only difference is

756
00:32:22,046 --> 00:32:24,826 A:middle
that we're using the QR
Code feature instead.

757
00:32:25,486 --> 00:32:28,066 A:middle
This example, you could
have also gotten the message

758
00:32:28,066 --> 00:32:29,666 A:middle
from the QR Code
but in this case,

759
00:32:29,666 --> 00:32:31,336 A:middle
I'm just going to do an overlay.

760
00:32:32,016 --> 00:32:35,426 A:middle
So all I needed to do was
use the coordinates and again

761
00:32:35,426 --> 00:32:38,736 A:middle
as you see in the example,
we can detect this QR Code

762
00:32:38,736 --> 00:32:43,896 A:middle
and do an overlay in real time.

763
00:32:44,116 --> 00:32:46,946 A:middle
So that's the bulk of
my conversation there.

764
00:32:46,946 --> 00:32:49,936 A:middle
The last thing I want to
talk about is improvements

765
00:32:49,936 --> 00:32:53,086 A:middle
that we've made to
RAW support on OS X.

766
00:32:53,086 --> 00:32:55,766 A:middle
So let me talk a little
bit about our RAW support.

767
00:32:57,176 --> 00:33:00,066 A:middle
So I'll talk about our
history, the fundamentals

768

769
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

770
00:32:57,176 --> 00:33:00,066 A:middle
So I'll talk about our
history, the fundamentals

771
00:33:00,066 --> 00:33:03,616 A:middle
of RAW image processing,
some architectural overview

772
00:33:03,876 --> 00:33:05,836 A:middle
and how you can use this
great filter we have called

773
00:33:05,836 --> 00:33:06,766 A:middle
the CIRAWFilter.

774
00:33:07,846 --> 00:33:11,436 A:middle
So history first, so Apple
has been supporting RAW

775
00:33:11,436 --> 00:33:14,926 A:middle
since back in April of 2005.

776
00:33:15,096 --> 00:33:17,446 A:middle
Over those years, we have been
continuously adding support

777
00:33:17,446 --> 00:33:19,066 A:middle
for cameras and improving
the quality.

778
00:33:19,556 --> 00:33:22,696 A:middle
We have about 350
cameras supported today

779
00:33:22,696 --> 00:33:26,606 A:middle
and that's not including
all the DNG possibilities.

780
00:33:26,826 --> 00:33:30,486 A:middle
And one of the improvements
we've made in OS X this year is

781
00:33:30,486 --> 00:33:33,256 A:middle
that we support the latest
version of DNG specification

782
00:33:33,586 --> 00:33:34,966 A:middle
so that greatly improves
the number

783
00:33:34,966 --> 00:33:36,226 A:middle
of images that we can support.

784
00:33:36,706 --> 00:33:40,306 A:middle
And the other thing that's
wonderful about our support is

785
00:33:40,306 --> 00:33:42,476 A:middle
that it's provided to the
entire operating system

786
00:33:42,636 --> 00:33:45,126 A:middle
which means everything
from NSImages

787
00:33:45,126 --> 00:33:47,776 A:middle
to CGImages will
automatically support RAW files.

788
00:33:48,486 --> 00:33:52,316 A:middle
System services like Spotlight
and Quick Look support,

789
00:33:52,716 --> 00:33:56,456 A:middle
these key applications
like Preview, Finder,

790
00:33:56,456 --> 00:33:57,796 A:middle
even Mail support RAW.

791
00:33:58,456 --> 00:34:02,066 A:middle
Our photo applications
Aperture, iPhoto and Photos.

792

793
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

794
00:33:58,456 --> 00:34:02,066 A:middle
Our photo applications
Aperture, iPhoto and Photos.

795
00:34:03,346 --> 00:34:06,176 A:middle
Also all third-party
app can also get this

796
00:34:06,176 --> 00:34:07,766 A:middle
for very little effort.

797
00:34:10,096 --> 00:34:12,446 A:middle
So what is involved in
processing a RAW image?

798
00:34:12,446 --> 00:34:16,596 A:middle
And this is why, you know, this
subject is actually very dear

799
00:34:16,596 --> 00:34:18,556 A:middle
to my heart because
it involves a lot

800
00:34:18,556 --> 00:34:19,946 A:middle
of very advanced
image processing

801
00:34:19,946 --> 00:34:20,976 A:middle
to produce a RAW file.

802
00:34:21,755 --> 00:34:22,936 A:middle
So you start off with the fact

803
00:34:22,936 --> 00:34:26,156 A:middle
that RAW files contain only
a minimally processed data

804
00:34:26,266 --> 00:34:27,786 A:middle
from the camera sensor image.

805
00:34:28,065 --> 00:34:32,676 A:middle
And in fact, the image is
actually missing typically 66%

806
00:34:32,676 --> 00:34:35,326 A:middle
of the actual data because
at each pixel location,

807
00:34:35,326 --> 00:34:37,406 A:middle
you only have a red or
a green or a blue value.

808
00:34:38,045 --> 00:34:40,966 A:middle
And that means to produce a
final image, we actually have

809
00:34:41,466 --> 00:34:45,696 A:middle
to make up good values for
those missing 60% of your data.

810
00:34:46,396 --> 00:34:49,235 A:middle
And that requires a lot of
advanced image processing

811
00:34:49,235 --> 00:34:52,266 A:middle
to produce a beautiful
image at the end.

812
00:34:52,545 --> 00:34:54,226 A:middle
There are several
steps in this process.

813
00:34:54,676 --> 00:34:57,196 A:middle
They involve extracting
critical metadata from the file,

814
00:34:57,316 --> 00:35:00,376 A:middle
decoding the raw sensor,
de-mosaic deconstruction

815

816
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

817
00:34:57,316 --> 00:35:00,376 A:middle
decoding the raw sensor,
de-mosaic deconstruction

818
00:35:00,376 --> 00:35:02,456 A:middle
which is a hugely complex task,

819
00:35:02,936 --> 00:35:04,996 A:middle
lens correction,
noise reduction.

820
00:35:05,366 --> 00:35:06,966 A:middle
And then there's a set
of operations that are

821
00:35:06,966 --> 00:35:10,626 A:middle
in the color domain such as
mapping scene-referred color

822
00:35:10,626 --> 00:35:14,176 A:middle
values to output-referred
and then adjusting exposure

823
00:35:14,176 --> 00:35:17,506 A:middle
and temperature and tint
and then adding contrast

824
00:35:17,506 --> 00:35:19,036 A:middle
and saturation to taste.

825
00:35:19,436 --> 00:35:22,236 A:middle
So it's a lot of steps and
we've made some significant

826
00:35:22,236 --> 00:35:26,736 A:middle
improvements to several
of these in OS X Yosemite.

827
00:35:27,076 --> 00:35:29,266 A:middle
So we've benefitted
for lens correction,

828
00:35:29,266 --> 00:35:31,506 A:middle
a great new noise reduction
which we'll show in a minute

829
00:35:32,006 --> 00:35:33,996 A:middle
and also some improvements
to color as well.

830
00:35:36,076 --> 00:35:39,926 A:middle
So as I said before,
APIs like NSImage

831
00:35:39,926 --> 00:35:42,486 A:middle
and CGImage will get
RAW support for free.

832
00:35:43,236 --> 00:35:47,236 A:middle
And that's because our support
provides that default rendering

833
00:35:47,786 --> 00:35:50,566 A:middle
which is processed according
to all of our parameters

834
00:35:50,796 --> 00:35:53,186 A:middle
and whatever our
latest algorithm is.

835
00:35:55,096 --> 00:35:59,186 A:middle
However, we have this API
which is called the CIRAWFilter

836
00:35:59,506 --> 00:36:01,666 A:middle
which gives your
application much more control.

837

838
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

839
00:35:59,506 --> 00:36:01,666 A:middle
which gives your
application much more control.

840
00:36:01,666 --> 00:36:06,746 A:middle
And it allows you to get a
CIImage with extended range,

841
00:36:06,746 --> 00:36:10,146 A:middle
floating point precision
and also

842
00:36:10,146 --> 00:36:13,086 A:middle
on that object are
easy-to-use controls

843
00:36:13,086 --> 00:36:16,196 A:middle
to control how our RAW
imaging results are processed.

844
00:36:16,806 --> 00:36:18,866 A:middle
And it gives you fast
interactive performance all

845
00:36:18,866 --> 00:36:19,336 A:middle
in the GPU.

846
00:36:19,736 --> 00:36:22,056 A:middle
So it's some great stuff that
you can use in your application.

847
00:36:23,756 --> 00:36:26,456 A:middle
So this is sort of how it
works as a flow diagram.

848
00:36:26,736 --> 00:36:29,986 A:middle
You start out with a file
and that can be passed either

849
00:36:29,986 --> 00:36:32,196 A:middle
as a file URL or NSData.

850
00:36:32,616 --> 00:36:35,976 A:middle
And that's passed as an input
to create the CIRAWFilter.

851
00:36:37,066 --> 00:36:40,166 A:middle
Also it can be specified on
that RAW filter are several

852
00:36:40,166 --> 00:36:41,896 A:middle
of our processing parameters.

853
00:36:42,686 --> 00:36:46,526 A:middle
Once you've set those correctly,
you can get a CIImage output

854
00:36:47,056 --> 00:36:49,646 A:middle
which you can then
display on the screen.

855
00:36:49,946 --> 00:36:52,266 A:middle
And by default, it'll look just
like our default rendering.

856
00:36:53,316 --> 00:36:55,826 A:middle
However, the great thing
about the CIRAWFilter is

857
00:36:55,826 --> 00:36:57,276 A:middle
that once the user
has seen those

858
00:36:57,546 --> 00:36:59,316 A:middle
and if your application
has controls,

859
00:36:59,706 --> 00:37:05,096 A:middle
you can alter those values, send
them back into the CIRAWFilter

860

861
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

862
00:36:59,706 --> 00:37:05,096 A:middle
you can alter those values, send
them back into the CIRAWFilter

863
00:37:05,546 --> 00:37:09,376 A:middle
where it can be re-displayed
all in real time.

864
00:37:09,906 --> 00:37:13,996 A:middle
Another great feature we have on
this is we actually have a place

865
00:37:13,996 --> 00:37:16,896 A:middle
where you can insert a
custom CIFilter in the middle

866
00:37:16,896 --> 00:37:20,666 A:middle
of our RAW filter processing
before we've done anything

867
00:37:20,666 --> 00:37:23,126 A:middle
to change the data
from a linear space.

868
00:37:23,126 --> 00:37:24,776 A:middle
So this is very useful
if you want

869
00:37:24,776 --> 00:37:26,396 A:middle
to do certain types
of image processing.

870
00:37:26,396 --> 00:37:28,616 A:middle
Now of course, you
can also apply filters

871
00:37:28,616 --> 00:37:32,846 A:middle
after the CIRAWFilter but this
is a great set of functionality

872
00:37:32,846 --> 00:37:33,936 A:middle
for certain use cases.

873
00:37:35,276 --> 00:37:37,546 A:middle
And lastly, it doesn't
have to go to the display.

874
00:37:37,546 --> 00:37:40,706 A:middle
You can also take the CIImage,
create a CGImage from that

875
00:37:41,206 --> 00:37:44,136 A:middle
and produce a new CG, a
file on disk from that.

876
00:37:44,566 --> 00:37:47,476 A:middle
And this is an example

877
00:37:47,476 --> 00:37:49,566 A:middle
of how little code it
takes to use this filter.

878
00:37:50,256 --> 00:37:51,846 A:middle
Basically, we start
out with a URL.

879
00:37:52,176 --> 00:37:55,776 A:middle
We create a CIFilter
filterWithImageURL

880
00:37:55,776 --> 00:37:57,346 A:middle
and that'll return
to CIRAWFilter.

881
00:37:58,336 --> 00:38:00,266 A:middle
In this particular
example, we want to get

882

883
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

884
00:37:58,336 --> 00:38:00,266 A:middle
In this particular
example, we want to get

885
00:38:00,266 --> 00:38:02,286 A:middle
from that filter what
our default value

886
00:38:02,286 --> 00:38:03,986 A:middle
for the luminance
noise reduction was

887
00:38:04,286 --> 00:38:05,396 A:middle
that returns to us as an object.

888
00:38:06,046 --> 00:38:08,866 A:middle
We can then make slight changes
to that like say for example,

889
00:38:08,866 --> 00:38:11,876 A:middle
you want all of your images to
be slightly more noise-reduced.

890
00:38:12,126 --> 00:38:14,216 A:middle
You can take that
value, add a bit to it

891
00:38:14,396 --> 00:38:15,606 A:middle
and then set that
as a new value.

892
00:38:16,476 --> 00:38:18,016 A:middle
And then once you're
done setting values,

893
00:38:18,016 --> 00:38:19,086 A:middle
you can get an output image.

894
00:38:19,876 --> 00:38:21,266 A:middle
So with just a few
lines of code,

895
00:38:21,266 --> 00:38:24,166 A:middle
you can leverage all
of our RAW pipeline.

896
00:38:24,486 --> 00:38:27,576 A:middle
So to show this in
much more detail,

897
00:38:27,576 --> 00:38:29,086 A:middle
I'm going to pass the
stage over to Serhan

898
00:38:29,086 --> 00:38:30,526 A:middle
who will be giving
a live demo of this.

899
00:38:30,806 --> 00:38:31,096 A:middle
Thanks.

900
00:38:31,986 --> 00:38:34,456 A:middle
>> In this part of our talk,
I would like to show you some

901
00:38:34,456 --> 00:38:36,526 A:middle
of the great things
that you can also do

902
00:38:36,526 --> 00:38:39,666 A:middle
in your applications
using the CIRAWFilter

903
00:38:39,796 --> 00:38:43,136 A:middle
and OS X's built-in support
for RAW camera files.

904
00:38:44,056 --> 00:38:47,866 A:middle
To do that, we created a
very basic simple application

905
00:38:48,446 --> 00:38:52,556 A:middle
that simply puts
up an NSOpenGLView

906
00:38:52,556 --> 00:38:55,136 A:middle
which is tied up
to a CIRAWFilter.

907
00:38:55,776 --> 00:38:59,026 A:middle
And another NSView which is tied

908
00:38:59,026 --> 00:39:00,946 A:middle
up to the controls
of the CIRAWFilter.

909

910
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

911
00:38:59,026 --> 00:39:00,946 A:middle
up to the controls
of the CIRAWFilter.

912
00:39:01,436 --> 00:39:05,866 A:middle
So let me run that and
point it to a RAW image.

913
00:39:09,776 --> 00:39:13,226 A:middle
Now, by default, when you
actually open up a RAW file,

914
00:39:13,286 --> 00:39:15,766 A:middle
we will tap into our
own calibration database

915
00:39:15,866 --> 00:39:18,036 A:middle
and make sure that we
apply the correct set

916
00:39:18,036 --> 00:39:21,606 A:middle
of calibration settings that
are specific to the make

917
00:39:21,606 --> 00:39:23,086 A:middle
and model for this RAW file.

918
00:39:23,926 --> 00:39:28,026 A:middle
And some of the settings are
for you under lens correction,

919
00:39:28,626 --> 00:39:33,176 A:middle
white balance settings,
noise reduction settings

920
00:39:33,176 --> 00:39:36,016 A:middle
that we will go into more
detail in just a second,

921
00:39:36,556 --> 00:39:39,386 A:middle
exposure and boost controls.

922
00:39:40,726 --> 00:39:42,896 A:middle
So there is not much going

923
00:39:43,246 --> 00:39:45,366 A:middle
on with this very good
image in the first place.

924
00:39:45,366 --> 00:39:49,566 A:middle
So let me pull up a
more challenging image

925
00:39:49,566 --> 00:39:54,856 A:middle
to show the great benefits
of using RAW files.

926
00:39:55,396 --> 00:39:58,576 A:middle
Now, on this image, by
default when you load it,

927
00:39:58,576 --> 00:40:01,046 A:middle
you see that parts
of the image is close

928

929
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

930
00:39:58,576 --> 00:40:01,046 A:middle
you see that parts
of the image is close

931
00:40:01,046 --> 00:40:04,636 A:middle
to clipping point especially the
sky and the mountainous region.

932
00:40:05,046 --> 00:40:08,146 A:middle
So we're probably losing some
color fidelity in this region.

933
00:40:08,736 --> 00:40:13,016 A:middle
What's more interesting
is the part of the trees

934
00:40:13,016 --> 00:40:16,036 A:middle
which are underexposed and we're
probably not getting the right

935
00:40:16,036 --> 00:40:16,866 A:middle
amount of detail.

936
00:40:17,406 --> 00:40:19,706 A:middle
So let's see if we can
actually improve this image.

937
00:40:20,506 --> 00:40:22,456 A:middle
The first thing that I would

938
00:40:22,456 --> 00:40:24,776 A:middle
like to try is setting
the exposure

939
00:40:24,826 --> 00:40:26,326 A:middle
to see how it actually
looks like.

940
00:40:27,216 --> 00:40:30,776 A:middle
Want to probably increase
the exposure to make sure

941
00:40:30,776 --> 00:40:33,426 A:middle
that I get the detail in
the tree part of the image.

942
00:40:33,546 --> 00:40:34,976 A:middle
But as you can quickly see,

943
00:40:34,976 --> 00:40:36,926 A:middle
we're losing all the
detail in the highlights.

944
00:40:38,016 --> 00:40:39,836 A:middle
And the opposite is also true.

945
00:40:39,896 --> 00:40:41,766 A:middle
Once you start decreasing
the exposure,

946
00:40:42,236 --> 00:40:44,086 A:middle
you're getting back
the color in the sky

947
00:40:44,456 --> 00:40:47,376 A:middle
but you're losing all the
detail in the low lights.

948
00:40:48,776 --> 00:40:52,876 A:middle
So there is something that can
be done better and the answer

949
00:40:52,876 --> 00:40:55,406 A:middle
to that is CI Highlights
and Shadows Filters.

950
00:40:56,186 --> 00:40:59,276 A:middle
Normally, if you were shooting
JPEG, you would tie the output

951
00:40:59,276 --> 00:41:02,276 A:middle
of the JPEG decoder to this
highlights and shadows filters.

952

953
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

954
00:40:59,276 --> 00:41:02,276 A:middle
of the JPEG decoder to this
highlights and shadows filters.

955
00:41:02,506 --> 00:41:05,446 A:middle
But what's interesting
when you're shooting RAW is

956
00:41:05,446 --> 00:41:08,996 A:middle
that you can actually insert
this filter into the middle

957
00:41:09,036 --> 00:41:12,066 A:middle
of our RAW processing
pipeline and take advantage

958
00:41:12,066 --> 00:41:14,876 A:middle
of the linear input space
that we're operating in.

959
00:41:15,416 --> 00:41:16,826 A:middle
That means that you will be able

960
00:41:16,826 --> 00:41:18,726 A:middle
to better keep the
color fidelity.

961
00:41:18,726 --> 00:41:21,396 A:middle
You'll operate on a
linear 16-bit pipeline

962
00:41:21,816 --> 00:41:23,596 A:middle
and at the end, get
better results.

963
00:41:23,826 --> 00:41:25,626 A:middle
So let's try that.

964
00:41:26,356 --> 00:41:29,766 A:middle
The first thing that I want
to do is increase the shadows

965
00:41:30,306 --> 00:41:33,086 A:middle
and almost immediately I
can see that all the detail

966
00:41:33,086 --> 00:41:36,776 A:middle
in the shadow part is
kept, is brought back.

967
00:41:37,326 --> 00:41:38,486 A:middle
Same for the sky.

968
00:41:38,486 --> 00:41:40,276 A:middle
I want to bring it
down to make sure

969
00:41:40,276 --> 00:41:42,516 A:middle
that I can see more
of the sky colors.

970
00:41:43,526 --> 00:41:47,266 A:middle
And I can easily do that
without overblowing any part

971
00:41:47,266 --> 00:41:47,996 A:middle
of that image.

972
00:41:49,656 --> 00:41:52,106 A:middle
So that is a good example

973
00:41:52,106 --> 00:41:55,216 A:middle
of how you can actually use
the CIRAWFilter to make sure

974
00:41:55,216 --> 00:41:58,516 A:middle
that you can double up your
own images in the best way

975
00:41:58,516 --> 00:42:00,186 A:middle
that you think is appropriate.

976

977
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

978
00:41:58,516 --> 00:42:00,186 A:middle
that you think is appropriate.

979
00:42:01,296 --> 00:42:07,236 A:middle
Next noise filter.

980
00:42:08,146 --> 00:42:11,526 A:middle
Now noise reduction is a
very challenging problem

981
00:42:11,526 --> 00:42:16,216 A:middle
and traditionally it
is very computationally

982
00:42:16,386 --> 00:42:18,336 A:middle
expensive algorithm.

983
00:42:18,986 --> 00:42:22,656 A:middle
We're very happy to offer you
a new noise reduction algorithm

984
00:42:22,656 --> 00:42:24,476 A:middle
starting in OS X Yosemite.

985
00:42:24,976 --> 00:42:28,206 A:middle
That doesn't compromise on the
quality and you can still use it

986
00:42:28,376 --> 00:42:30,696 A:middle
at an interactive 60
frames per second rate.

987
00:42:31,246 --> 00:42:34,296 A:middle
To show you that, we have
this very noisy image

988
00:42:35,456 --> 00:42:37,976 A:middle
of the Moscone Center
and I want to focus

989
00:42:37,976 --> 00:42:39,096 A:middle
on this part of the image.

990
00:42:40,016 --> 00:42:42,626 A:middle
Just for fun, I'm going to turn
off all the noise reduction

991
00:42:42,626 --> 00:42:44,556 A:middle
to see what we are
dealing with initially.

992
00:42:47,556 --> 00:42:49,186 A:middle
So this is the original --

993
00:42:49,236 --> 00:42:51,176 A:middle
this is how the original
image looks like.

994
00:42:51,966 --> 00:42:57,866 A:middle
And using the CIRAW LNR and
CNR noise filter settings,

995
00:42:57,866 --> 00:42:59,816 A:middle
I can get it to a
state where I feel

996
00:42:59,956 --> 00:43:02,336 A:middle
that is most comfortable
for my image.

997

998
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

999
00:42:59,956 --> 00:43:02,336 A:middle
that is most comfortable
for my image.

1000
00:43:02,926 --> 00:43:05,446 A:middle
So probably the first thing
that I want to do is get rid

1001
00:43:05,446 --> 00:43:10,546 A:middle
of all the color noise and I'm
using the CNR slider to do that.

1002
00:43:10,546 --> 00:43:12,726 A:middle
And look how interactive
this process is.

1003
00:43:13,876 --> 00:43:17,016 A:middle
Same for LNR, you have a
wide variety of settings

1004
00:43:17,016 --> 00:43:17,896 A:middle
that you can play with.

1005
00:43:17,956 --> 00:43:21,266 A:middle
You can go with something that
is very smooth or something

1006
00:43:21,266 --> 00:43:23,686 A:middle
which keeps all the
luminance noise.

1007
00:43:24,076 --> 00:43:26,076 A:middle
So I want to probably hit
somewhere in the middle

1008
00:43:26,076 --> 00:43:29,956 A:middle
where I got rid of most of
the noise but still kept some.

1009
00:43:30,826 --> 00:43:34,006 A:middle
Another good thing that you
can do is brought back some

1010
00:43:34,006 --> 00:43:36,746 A:middle
of the fine high
detail back to the image

1011
00:43:36,746 --> 00:43:38,486 A:middle
after you clean up
all the bad noise.

1012
00:43:38,576 --> 00:43:40,566 A:middle
So the detail slider is the one

1013
00:43:40,566 --> 00:43:41,966 A:middle
that you would be
using for that.

1014
00:43:42,756 --> 00:43:47,666 A:middle
And quickly you can get back to
this film grain type of look.

1015
00:43:49,036 --> 00:43:52,456 A:middle
Same is true for high frequency
contrast and if you choose

1016
00:43:52,456 --> 00:43:54,606 A:middle
to do that, you can also play

1017
00:43:54,606 --> 00:43:57,166 A:middle
with it again 60
frames per second.

1018
00:43:59,246 --> 00:44:01,006 A:middle
So that is the noise filter.

1019

1020
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1021
00:43:59,246 --> 00:44:01,006 A:middle
So that is the noise filter.

1022
00:44:01,426 --> 00:44:04,056 A:middle
Starting with OS X
Yosemite, you'll also be able

1023
00:44:04,056 --> 00:44:08,446 A:middle
to use this filter for your
JPEG images and this is going

1024
00:44:08,446 --> 00:44:11,646 A:middle
to be a really nice advancement
on top of our offerings.

1025
00:44:12,446 --> 00:44:14,586 A:middle
The last thing that I want

1026
00:44:14,586 --> 00:44:16,486 A:middle
to show you today
is lens correction.

1027
00:44:17,406 --> 00:44:19,716 A:middle
So a lot of the point-and-shoot
cameras

1028
00:44:19,716 --> 00:44:22,476 A:middle
in the market today
are actually relying

1029
00:44:22,476 --> 00:44:26,676 A:middle
on digital signal processing
techniques to fix some

1030
00:44:26,676 --> 00:44:30,386 A:middle
of the compromises that
are made in the lenses.

1031
00:44:31,286 --> 00:44:34,226 A:middle
What I mean by that, the
input image as you can see

1032
00:44:34,296 --> 00:44:36,986 A:middle
by default is looking
correct to us.

1033
00:44:37,426 --> 00:44:39,806 A:middle
But actual, the RAW
image that is coming

1034
00:44:39,806 --> 00:44:41,516 A:middle
in is looking like this.

1035
00:44:43,006 --> 00:44:46,146 A:middle
So whenever that data is
available in the file,

1036
00:44:46,146 --> 00:44:47,956 A:middle
RAW camera will try
to do the right thing

1037
00:44:47,956 --> 00:44:50,546 A:middle
and actually correct
for this aberration.

1038
00:44:51,326 --> 00:44:54,896 A:middle
But for your own application,
you may choose to skip this step

1039
00:44:54,896 --> 00:44:57,416 A:middle
and actually do your
own set of filters

1040
00:44:57,416 --> 00:44:58,806 A:middle
or your own lens correction.

1041
00:44:59,346 --> 00:45:03,786 A:middle
And it's an easy way
to actually go back

1042

1043
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1044
00:44:59,346 --> 00:45:03,786 A:middle
And it's an easy way
to actually go back

1045
00:45:03,786 --> 00:45:08,016 A:middle
to the actual RAW sample
of the file itself.

1046
00:45:09,736 --> 00:45:12,836 A:middle
I'm going to now quickly turn
it back to David who's going

1047
00:45:12,836 --> 00:45:16,266 A:middle
to talk about usages
of the second GPU.

1048
00:45:17,041 --> 00:45:19,041 A:middle
[ Applause ]

1049
00:45:19,066 --> 00:45:20,516 A:middle
>> Thank you, Serhan.

1050
00:45:20,516 --> 00:45:23,136 A:middle
So as you saw, we have this
great new noise reduction

1051
00:45:23,136 --> 00:45:26,836 A:middle
and it's a very complex Core
Image filter that we developed

1052
00:45:26,836 --> 00:45:32,086 A:middle
and it makes great use of
the GPU which brings us

1053
00:45:32,086 --> 00:45:33,576 A:middle
up to talking about
the second GPU.

1054
00:45:34,336 --> 00:45:37,956 A:middle
So a year ago, we announced
at the WWDC our new Mac Pro

1055
00:45:37,956 --> 00:45:41,306 A:middle
which has this great feature
of having a second GPU,

1056
00:45:41,856 --> 00:45:43,346 A:middle
just waiting for
your application

1057
00:45:43,346 --> 00:45:44,266 A:middle
to take advantage of it.

1058
00:45:44,916 --> 00:45:49,056 A:middle
So let's talk a little
of how that can be used.

1059
00:45:49,936 --> 00:45:54,756 A:middle
So we had some thoughts about
for Core Image and for RAWs.

1060
00:45:54,756 --> 00:45:57,926 A:middle
When is a good time where you
might want to use a second GPU?

1061
00:45:58,536 --> 00:46:00,366 A:middle
And a couple of scenarios
come to mind.

1062

1063
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1064
00:45:58,536 --> 00:46:00,366 A:middle
And a couple of scenarios
come to mind.

1065
00:46:00,706 --> 00:46:03,286 A:middle
One is if your application
has ability

1066
00:46:03,286 --> 00:46:04,616 A:middle
to do speculative renders.

1067
00:46:04,616 --> 00:46:07,346 A:middle
For example, you may have
a large list of images.

1068
00:46:07,346 --> 00:46:10,676 A:middle
The user might be looking
at one but he may switch

1069
00:46:10,676 --> 00:46:14,266 A:middle
to the previous or the
following image at any time.

1070
00:46:14,846 --> 00:46:19,226 A:middle
Your application could be
speculatively rendering the next

1071
00:46:19,226 --> 00:46:21,676 A:middle
or previous image
on a second thread.

1072
00:46:22,566 --> 00:46:24,576 A:middle
Similarly, your application
may have the ability

1073
00:46:24,576 --> 00:46:27,156 A:middle
to do a large batch
export and you want to do

1074
00:46:27,156 --> 00:46:30,076 A:middle
that in the background and
you want to use the GPU

1075
00:46:30,946 --> 00:46:33,716 A:middle
but you don't want
that background GPU

1076
00:46:33,716 --> 00:46:35,746 A:middle
to affect your foreground
GPU usage.

1077
00:46:36,016 --> 00:46:39,066 A:middle
So these are both great
reasons to use the second GPU

1078
00:46:39,646 --> 00:46:42,836 A:middle
because it allows you to
get the best performance

1079
00:46:42,956 --> 00:46:45,556 A:middle
without causing your
user interface

1080
00:46:45,556 --> 00:46:47,506 A:middle
to stutter for its usage.

1081
00:46:48,316 --> 00:46:50,426 A:middle
So how does one do that?

1082
00:46:50,746 --> 00:46:53,236 A:middle
Well, you could do this
today on Mavericks.

1083
00:46:53,416 --> 00:46:57,376 A:middle
It takes around 80 lines
of OpenGL code to tell,

1084
00:46:57,726 --> 00:47:00,516 A:middle
to create a CIContext
that refers

1085

1086
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1087
00:46:57,726 --> 00:47:00,516 A:middle
to create a CIContext
that refers

1088
00:47:00,516 --> 00:47:02,386 A:middle
to the second offline GPU.

1089
00:47:03,446 --> 00:47:08,446 A:middle
However, we've added a simpler
API in Core Image on Yosemite

1090
00:47:08,816 --> 00:47:11,976 A:middle
which is CIContext
offlineGPUAtIndex

1091
00:47:11,976 --> 00:47:13,616 A:middle
and typically you
just specify zero.

1092
00:47:13,986 --> 00:47:18,086 A:middle
So with one API call, you get
a CIContext and that when using

1093
00:47:18,086 --> 00:47:20,476 A:middle
that all renders will
use the second GPU.

1094
00:47:20,836 --> 00:47:22,106 A:middle
So it's very easy.

1095
00:47:22,676 --> 00:47:25,216 A:middle
And to show that in action,
I'm going to bring Serhan back

1096
00:47:25,216 --> 00:47:26,036 A:middle
up to do a quick demo.

1097
00:47:27,876 --> 00:47:29,116 A:middle
>> Well, in our first demo,

1098
00:47:29,176 --> 00:47:32,246 A:middle
we showed that even the most
computationally expensive noise

1099
00:47:32,246 --> 00:47:35,086 A:middle
filter algorithm can be done
at 60 frames per second.

1100
00:47:36,116 --> 00:47:38,986 A:middle
I'm going to bring that
application back and open

1101
00:47:38,986 --> 00:47:40,296 A:middle
up a very noisy image.

1102
00:47:49,046 --> 00:47:52,876 A:middle
So our LNR controls can be
done at 60 frames per second.

1103
00:47:53,296 --> 00:47:57,176 A:middle
To show you that, we actually
wrote a little bit of code

1104
00:47:57,346 --> 00:48:01,216 A:middle
to display the frames per second
when I'm actually sweeping

1105

1106
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1107
00:47:57,346 --> 00:48:01,216 A:middle
to display the frames per second
when I'm actually sweeping

1108
00:48:01,216 --> 00:48:02,936 A:middle
through all the noise
filter settings.

1109
00:48:03,386 --> 00:48:07,606 A:middle
And as you can see, I'm
getting 60 frames per second all

1110
00:48:07,606 --> 00:48:07,896 A:middle
the time.

1111
00:48:08,356 --> 00:48:10,856 A:middle
Now let's say that you
have a background trait

1112
00:48:11,186 --> 00:48:13,416 A:middle
where you are constantly
exporting images

1113
00:48:13,486 --> 00:48:15,096 A:middle
and for some reason you wanted

1114
00:48:15,096 --> 00:48:19,096 A:middle
to do a GPU pipe
on your first GPU.

1115
00:48:19,856 --> 00:48:22,786 A:middle
To simulate that, we
have written a little bit

1116
00:48:23,106 --> 00:48:27,326 A:middle
of text application which
is using the first GPU.

1117
00:48:27,926 --> 00:48:30,486 A:middle
And when I go back
to my own application

1118
00:48:30,546 --> 00:48:32,666 A:middle
which is now also
using my first GPU,

1119
00:48:32,736 --> 00:48:38,246 A:middle
I can see that the frame rate is
actually suffering a little bit.

1120
00:48:38,616 --> 00:48:41,396 A:middle
I'm going to run my test shoot
one more time to see what type

1121
00:48:41,396 --> 00:48:42,976 A:middle
of frame rate I'm
getting out of this.

1122
00:48:43,756 --> 00:48:47,856 A:middle
And you can quickly see that
it has dropped down to 50%.

1123
00:48:47,856 --> 00:48:50,476 A:middle
I'm getting 24 frames
per second.

1124
00:48:51,026 --> 00:48:55,516 A:middle
So can we do something
better than that?

1125
00:48:55,516 --> 00:48:56,656 A:middle
And the answer is yes.

1126
00:48:57,576 --> 00:49:00,026 A:middle
If we can offload this work

1127

1128
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1129
00:48:57,576 --> 00:49:00,026 A:middle
If we can offload this work

1130
00:49:00,026 --> 00:49:05,366 A:middle
to our second GPU using
the CIGLOfflineContext,

1131
00:49:05,536 --> 00:49:11,176 A:middle
I will get back to my original
performance in my active app.

1132
00:49:11,476 --> 00:49:14,216 A:middle
And to show you that,
here we go one more time.

1133
00:49:15,056 --> 00:49:18,686 A:middle
I can see that the user controls
are once again very smooth

1134
00:49:18,986 --> 00:49:22,896 A:middle
and the frame rate that I'm
going to get is close to 60.

1135
00:49:28,896 --> 00:49:31,806 A:middle
So once again, this is a
great way to take advantage

1136
00:49:31,806 --> 00:49:35,946 A:middle
of the second GPU if you are
constantly doing computationally

1137
00:49:35,946 --> 00:49:37,516 A:middle
heavy algorithms
in the background.

1138
00:49:38,506 --> 00:49:40,816 A:middle
I'm going to hand it
back once over to David.

1139
00:49:42,036 --> 00:49:43,666 A:middle
>> So to summarize what
we've talked about today.

1140
00:49:43,666 --> 00:49:45,966 A:middle
We've talked about
some key concepts

1141
00:49:45,966 --> 00:49:47,276 A:middle
to understand about Core Image.

1142
00:49:47,856 --> 00:49:50,426 A:middle
We've talked about what's
new in Core Image on iOS 8,

1143
00:49:50,836 --> 00:49:53,856 A:middle
most notably Custom CIKernels
and large image support.

1144
00:49:54,856 --> 00:49:57,206 A:middle
We talked about some
new things in Core Image

1145
00:49:57,386 --> 00:50:01,896 A:middle
on Yosemite notably
some API modernization

1146

1147
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1148
00:49:57,386 --> 00:50:01,896 A:middle
on Yosemite notably
some API modernization

1149
00:50:01,896 --> 00:50:05,196 A:middle
and some great new noise
reduction and RAW support.

1150
00:50:05,306 --> 00:50:09,956 A:middle
We've also talked about how
to use the latest CIDetectors

1151
00:50:11,016 --> 00:50:13,546 A:middle
and how to work with
RAW images in ways

1152
00:50:13,546 --> 00:50:14,786 A:middle
that you may have
not imagined before.

1153
00:50:15,366 --> 00:50:18,756 A:middle
So this is the usual information
about who to contact.

1154
00:50:18,756 --> 00:50:20,026 A:middle
Allan's a great person to talk

1155
00:50:20,026 --> 00:50:21,916 A:middle
to if you have a request
for more information.

1156
00:50:22,486 --> 00:50:25,746 A:middle
Related sessions, there's one
I really hope you guys can come

1157
00:50:25,746 --> 00:50:28,726 A:middle
to is our second session this
afternoon where we're going

1158
00:50:28,726 --> 00:50:32,496 A:middle
to be talking about how to
write Custom CIKernels on iOS.

1159
00:50:33,016 --> 00:50:35,656 A:middle
And also, we have a lab
session that follows that so

1160
00:50:35,656 --> 00:50:38,846 A:middle
if you have coding questions,
please come and we would love

1161
00:50:38,846 --> 00:50:40,976 A:middle
to hear your questions
or suggestions.

1162
00:50:42,276 --> 00:50:42,906 A:middle
So that's all.

1163
00:50:43,216 --> 00:50:44,166 A:middle
Thank you so much for coming.

1164
00:50:45,516 --> 00:50:53,520 A:middle
[ Applause ]

1165
