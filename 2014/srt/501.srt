X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:13,046 --> 00:00:14,086 A:middle
>> Good morning everyone.

2
00:00:14,436 --> 00:00:17,996 A:middle
And welcome to Session 501,
"What's New with Core Audio".

3
00:00:18,026 --> 00:00:19,766 A:middle
I'm the first emcee
on the mic today.

4
00:00:19,766 --> 00:00:20,556 A:middle
My name is Torrey.

5
00:00:20,996 --> 00:00:23,246 A:middle
And we have been very busy.

6
00:00:23,246 --> 00:00:25,456 A:middle
We have a lot of interesting
things to share with you today.

7
00:00:26,026 --> 00:00:29,056 A:middle
We're going to start off by
talking about some enhancements

8
00:00:29,056 --> 00:00:30,516 A:middle
that we've made to
Core MIDI and how

9
00:00:30,516 --> 00:00:32,555 A:middle
that affects you and your apps.

10
00:00:32,946 --> 00:00:34,856 A:middle
Then we'll move on to
Inter-App Audio views,

11
00:00:35,426 --> 00:00:38,576 A:middle
and then we will have a large
section on the new and improved

12
00:00:38,576 --> 00:00:41,316 A:middle
and Enhanced AV Foundation
audio.

13
00:00:41,316 --> 00:00:44,246 A:middle
And that will include a talk
about the Audio Unit Manager,

14
00:00:44,766 --> 00:00:47,606 A:middle
AVAudioSession, some
Utility classes,

15
00:00:47,896 --> 00:00:50,086 A:middle
and that last bullet point
there, AVAudioEngine,

16
00:00:50,086 --> 00:00:53,706 A:middle
is such a large topic
that it gets a session all

17
00:00:53,706 --> 00:00:55,426 A:middle
to itself directly
following this one

18
00:00:55,426 --> 00:00:58,676 A:middle
in the same room
starting at 10:15 a.m.

19
00:00:59,036 --> 00:01:00,516 A:middle
So without further ado,

20

21
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

22
00:00:59,036 --> 00:01:00,516 A:middle
So without further ado,

23
00:01:01,566 --> 00:01:03,436 A:middle
let's talk about what's
new with Core MIDI.

24
00:01:03,846 --> 00:01:08,146 A:middle
If you have a studio, a
music studio, that you use

25
00:01:08,146 --> 00:01:11,116 A:middle
to make music, it may
look something like this.

26
00:01:11,836 --> 00:01:15,096 A:middle
So maybe there's a Mac in the
center of it, or an iOS device,

27
00:01:15,096 --> 00:01:17,946 A:middle
they're also very capable to
be the center of your studio.

28
00:01:18,476 --> 00:01:21,066 A:middle
And connected to it may be
several USB MIDI devices,

29
00:01:21,216 --> 00:01:23,796 A:middle
controllers, break out
boxes that are connected

30
00:01:24,136 --> 00:01:29,146 A:middle
by a 5-pin DIN to legacy
equipment, musical instruments,

31
00:01:29,206 --> 00:01:31,506 A:middle
and then also you may have
a network session going.

32
00:01:32,296 --> 00:01:35,896 A:middle
Well, beginning in iOS
8 and Mac OS X Yosemite,

33
00:01:36,096 --> 00:01:38,176 A:middle
your studio can start
to look like this.

34
00:01:38,956 --> 00:01:42,216 A:middle
So imagine after making a very
quick Bluetooth connection

35
00:01:42,216 --> 00:01:44,436 A:middle
and sitting down on a couch
on the other side of the room

36
00:01:44,436 --> 00:01:46,836 A:middle
of your studio and
controlling all of your music.

37
00:01:47,226 --> 00:01:49,966 A:middle
That's what you'll be able to
do with MIDI over Bluetooth.

38
00:01:51,026 --> 00:01:54,986 A:middle
So starting in iOS 8 and in Mac
OS X Yosemite, you'll be able

39
00:01:54,986 --> 00:01:57,466 A:middle
to send and receive MIDI data

40
00:01:57,466 --> 00:02:01,666 A:middle
over Bluetooth Low Energy
connections on any device or Mac

41

42
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

43
00:01:57,466 --> 00:02:01,666 A:middle
over Bluetooth Low Energy
connections on any device or Mac

44
00:02:01,736 --> 00:02:03,906 A:middle
that has native Bluetooth
Low Energy support.

45
00:02:05,206 --> 00:02:07,176 A:middle
The connections you
established is secure meaning

46
00:02:07,176 --> 00:02:08,446 A:middle
that pairing is enforced.

47
00:02:08,675 --> 00:02:10,175 A:middle
No one can connect
to your devices

48
00:02:10,175 --> 00:02:11,426 A:middle
without your explicit consent,

49
00:02:12,266 --> 00:02:15,706 A:middle
and after the connection is
established, it just appears

50
00:02:15,706 --> 00:02:18,426 A:middle
as an ordinary MIDI device that
any application that knows how

51
00:02:18,426 --> 00:02:20,536 A:middle
to communicate with a
MIDI device can talk to.

52
00:02:20,536 --> 00:02:23,996 A:middle
So to talk a little bit more
about how this connection works

53
00:02:23,996 --> 00:02:27,216 A:middle
over Bluetooth, I want to talk
about the two key roles involved

54
00:02:27,216 --> 00:02:28,086 A:middle
in a Bluetooth connection.

55
00:02:28,916 --> 00:02:30,716 A:middle
There's the Central
and the Peripheral.

56
00:02:31,256 --> 00:02:33,586 A:middle
You already have some
familiarity with this.

57
00:02:33,746 --> 00:02:35,166 A:middle
Maybe not with these names.

58
00:02:35,516 --> 00:02:37,906 A:middle
You can view your Central
as like your iPhone

59
00:02:37,946 --> 00:02:40,036 A:middle
and your Peripheral as like
your Bluetooth earpiece.

60
00:02:40,706 --> 00:02:44,716 A:middle
The Peripheral's job is to
become discoverable and say,

61
00:02:44,716 --> 00:02:45,526 A:middle
"Hey, I can do something.

62
00:02:45,526 --> 00:02:46,256 A:middle
You can connect to me."

63
00:02:47,076 --> 00:02:48,596 A:middle
So for Bluetooth MIDI,

64
00:02:48,796 --> 00:02:53,416 A:middle
the peripheral side will
advertise the MIDI capabilities.

65
00:02:53,416 --> 00:02:54,536 A:middle
It'll say, "Hey, I can do MIDI.

66
00:02:54,536 --> 00:02:55,586 A:middle
You can connect to me now."

67
00:02:55,886 --> 00:02:57,076 A:middle
And then that side waits.

68
00:02:57,716 --> 00:03:00,316 A:middle
The Central can scan
for a device

69

70
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

71
00:02:57,716 --> 00:03:00,316 A:middle
The Central can scan
for a device

72
00:03:00,516 --> 00:03:03,626 A:middle
that says they can do MIDI and
then establish a connection.

73
00:03:04,756 --> 00:03:07,216 A:middle
After that Bluetooth
connection has been established,

74
00:03:07,676 --> 00:03:10,656 A:middle
MIDI data can be
shuttled bi-directionally

75
00:03:10,656 --> 00:03:11,616 A:middle
between both of these.

76
00:03:12,476 --> 00:03:14,296 A:middle
Now in order to have a
Bluetooth connection you have

77
00:03:14,296 --> 00:03:16,706 A:middle
to have one Central, and you
have to have one Peripheral.

78
00:03:16,976 --> 00:03:20,806 A:middle
And we allow Macs and iOS
devices to play either role.

79
00:03:20,866 --> 00:03:23,716 A:middle
So you can connect Mac
to Mac, iOS to iOS,

80
00:03:24,026 --> 00:03:25,736 A:middle
Mac to iOS, and vice versa.

81
00:03:27,306 --> 00:03:29,396 A:middle
So what does this mean for
you and your application?

82
00:03:29,806 --> 00:03:32,586 A:middle
If you are writing a
Mac OS X application,

83
00:03:32,586 --> 00:03:37,116 A:middle
the good news is you are
already ready, already ready.

84
00:03:37,866 --> 00:03:40,466 A:middle
This is the MIDI Studio
Panel from Audio MIDI Setup,

85
00:03:40,466 --> 00:03:42,076 A:middle
which I'm sure you're
all familiar with.

86
00:03:42,316 --> 00:03:44,806 A:middle
If you look there
you'll see a new icon,

87
00:03:45,196 --> 00:03:46,746 A:middle
the Bluetooth Configuration
icon.

88
00:03:47,216 --> 00:03:48,876 A:middle
If you double click that icon,

89
00:03:49,006 --> 00:03:50,496 A:middle
you are going to
get a new window.

90
00:03:51,156 --> 00:03:55,116 A:middle
And this window will allow
you to play either the Central

91
00:03:55,116 --> 00:03:56,156 A:middle
or the Peripheral role.

92
00:03:56,406 --> 00:03:58,706 A:middle
If you look at kind of the
top third of the window,

93
00:03:58,706 --> 00:04:00,846 A:middle
you'll see where there's a
button that says Advertise.

94

95
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

96
00:03:58,706 --> 00:04:00,846 A:middle
you'll see where there's a
button that says Advertise.

97
00:04:00,846 --> 00:04:04,026 A:middle
And click Advertise to become
discoverable as Fresh Air.

98
00:04:04,026 --> 00:04:05,386 A:middle
That's a name that
you can modify.

99
00:04:05,696 --> 00:04:08,516 A:middle
Fresh Air is the name of my
MacBook Air because it's fresh.

100
00:04:09,446 --> 00:04:13,076 A:middle
Then the bottom two thirds
of it is the central view.

101
00:04:13,456 --> 00:04:16,016 A:middle
If someone is advertising, "Hey,
I can do MIDI," it will show

102
00:04:16,016 --> 00:04:17,836 A:middle
up in the bottom,
you click Connect

103
00:04:17,836 --> 00:04:18,986 A:middle
to establish the connection.

104
00:04:19,416 --> 00:04:20,386 A:middle
The pairing will happen,

105
00:04:20,386 --> 00:04:22,766 A:middle
and then a new MIDI device
will appear in the setup

106
00:04:22,766 --> 00:04:25,496 A:middle
that any application that
uses MIDI devices can see

107
00:04:25,636 --> 00:04:26,346 A:middle
and communicate will.

108
00:04:27,276 --> 00:04:30,016 A:middle
Now on iOS, there is
no audio MIDI setup.

109
00:04:30,126 --> 00:04:32,306 A:middle
So how do you manage your
Bluetooth MIDI connections?

110
00:04:32,786 --> 00:04:35,776 A:middle
You'll be using new
CoreAudioKit View Controllers.

111
00:04:36,626 --> 00:04:39,486 A:middle
There are 2 new CoreAudioKit
View Controllers

112
00:04:39,486 --> 00:04:40,756 A:middle
that you can add to
your application.

113
00:04:41,056 --> 00:04:43,636 A:middle
One of them that allows you to
play the role of the Central,

114
00:04:43,636 --> 00:04:46,616 A:middle
which means you scan and connect
and another that allows you

115
00:04:46,616 --> 00:04:47,746 A:middle
to play the role of Peripheral,

116
00:04:47,816 --> 00:04:49,386 A:middle
which means you advertise
and wait.

117
00:04:49,386 --> 00:04:52,936 A:middle
If you establish a
connection between 2 devices

118
00:04:52,936 --> 00:04:55,656 A:middle
over Bluetooth MIDI, and they're
not communicating for a while

119
00:04:55,656 --> 00:04:57,186 A:middle
and they are unused
by the application,

120
00:04:57,356 --> 00:04:59,506 A:middle
after several minutes we
will terminate the Bluetooth

121
00:04:59,506 --> 00:05:01,036 A:middle
connection to save power.

122

123
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

124
00:04:59,506 --> 00:05:01,036 A:middle
connection to save power.

125
00:05:02,106 --> 00:05:04,716 A:middle
So what does all of this
look like in practice?

126
00:05:05,286 --> 00:05:07,216 A:middle
I'm going to show
you a short UI demo

127
00:05:08,136 --> 00:05:11,846 A:middle
of how users would use
this in their studios.

128
00:05:12,326 --> 00:05:14,896 A:middle
OK. I've got my demo
machine ready here.

129
00:05:15,406 --> 00:05:18,306 A:middle
And what I'm going
to do is I'm going

130
00:05:18,306 --> 00:05:21,266 A:middle
to launch audio MIDI setup.

131
00:05:23,836 --> 00:05:25,706 A:middle
This is the audio window.

132
00:05:25,706 --> 00:05:28,506 A:middle
We'll close this, and we
will go to the MIDI window.

133
00:05:28,506 --> 00:05:31,626 A:middle
Now if you'll notice here

134
00:05:31,626 --> 00:05:33,146 A:middle
in the MIDI window
there's this new Bluetooth

135
00:05:33,146 --> 00:05:34,336 A:middle
Configuration panel.

136
00:05:34,666 --> 00:05:37,046 A:middle
So if I double click
this, then I will see

137
00:05:37,366 --> 00:05:40,186 A:middle
that there are currently
no advertising Bluetooth

138
00:05:40,186 --> 00:05:40,886 A:middle
MIDI devices.

139
00:05:42,356 --> 00:05:44,326 A:middle
I want my Mac to play
the role of Central.

140
00:05:44,536 --> 00:05:46,056 A:middle
So I'm going to wait for someone

141
00:05:46,056 --> 00:05:47,336 A:middle
to become available
to connect to.

142
00:05:48,406 --> 00:05:51,606 A:middle
And I'm going to use
my iPad for that.

143
00:05:54,016 --> 00:05:55,396 A:middle
So here's my iPad.

144
00:05:55,496 --> 00:05:59,146 A:middle
And this is a little test
application that we wrote

145
00:05:59,146 --> 00:06:02,146 A:middle
to implement the
CoreAudioKit View Controllers

146

147
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

148
00:05:59,146 --> 00:06:02,146 A:middle
to implement the
CoreAudioKit View Controllers

149
00:06:02,146 --> 00:06:03,086 A:middle
that I talked about earlier.

150
00:06:03,286 --> 00:06:05,236 A:middle
I am going to go to
Advertisement Setup,

151
00:06:05,236 --> 00:06:06,786 A:middle
and this will give me
the Peripheral view.

152
00:06:07,166 --> 00:06:09,606 A:middle
If you look here at the
top, you see the name

153
00:06:09,606 --> 00:06:12,246 A:middle
of this iPad Air
is iPad Air MIDI.

154
00:06:12,696 --> 00:06:14,716 A:middle
If I want to change this
name I could tap the "i",

155
00:06:15,496 --> 00:06:16,476 A:middle
but I'm OK with that name.

156
00:06:17,226 --> 00:06:19,526 A:middle
And then I will say
Advertise the MIDI Service.

157
00:06:20,386 --> 00:06:22,836 A:middle
Now after I'm advertising
the MIDI service,

158
00:06:23,836 --> 00:06:27,376 A:middle
back on the Mac OS X machine
you'll see iPad Air MIDI has

159
00:06:27,376 --> 00:06:28,086 A:middle
shown up here.

160
00:06:28,086 --> 00:06:32,866 A:middle
If I click connect, after a few
minutes you'll see a new device

161
00:06:32,866 --> 00:06:33,886 A:middle
appear in the MIDI setup.

162
00:06:34,556 --> 00:06:38,636 A:middle
I'm going to launch Main Stage

163
00:06:38,636 --> 00:06:43,476 A:middle
because Main Stage can receive
MIDI notes and play back audio.

164
00:06:46,316 --> 00:06:47,936 A:middle
Go into Performance
Mode [music playing].

165
00:06:48,436 --> 00:06:53,816 A:middle
OK. So a big confession
here, I don't play keys.

166
00:06:54,326 --> 00:06:55,856 A:middle
But I do have an application

167
00:06:55,856 --> 00:06:59,476 A:middle
that plays keys really well
called Arpeggionome Pro.

168
00:06:59,806 --> 00:07:03,496 A:middle
So I'm going to launch that,
and I'm going to use it

169

170
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

171
00:06:59,806 --> 00:07:03,496 A:middle
So I'm going to launch that,
and I'm going to use it

172
00:07:03,496 --> 00:07:11,996 A:middle
to send MIDI data over
to the Main Stage 3.

173
00:07:13,206 --> 00:07:15,066 A:middle
OK. Now one thing I want

174
00:07:15,066 --> 00:07:18,656 A:middle
to do really quickly here is
check my connection status

175
00:07:18,656 --> 00:07:21,196 A:middle
because I left it inactive
for quite a while here.

176
00:07:21,406 --> 00:07:27,916 A:middle
So I'm going to go back and make
myself advertise one more time.

177
00:07:28,516 --> 00:07:30,546 A:middle
[ Music Playing ]

178
00:07:31,046 --> 00:07:40,096 A:middle
So now this is live MIDI data
being sent over Bluetooth.

179
00:07:40,096 --> 00:07:43,916 A:middle
If I could get that volume
a little louder please.

180
00:07:45,426 --> 00:07:47,596 A:middle
Thank you.

181
00:07:48,726 --> 00:07:52,606 A:middle
So if I wanted to do this
preset, it's called Epic Fall.

182
00:07:54,336 --> 00:07:56,386 A:middle
And it is epic.

183
00:07:57,066 --> 00:08:00,646 A:middle
So that's Bluetooth
being sent over MIDI.

184

185
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

186
00:07:57,066 --> 00:08:00,646 A:middle
So that's Bluetooth
being sent over MIDI.

187
00:08:00,886 --> 00:08:03,656 A:middle
And also this sends not
only the controller data,

188
00:08:04,006 --> 00:08:07,836 A:middle
but it also sends the SISX
data that you may have

189
00:08:07,906 --> 00:08:09,256 A:middle
or any other type of MIDI.

190
00:08:09,846 --> 00:08:13,066 A:middle
A few final words before
I turn the mic over.

191
00:08:13,766 --> 00:08:16,426 A:middle
This Bluetooth, being
able to connect

192
00:08:16,846 --> 00:08:21,086 A:middle
with Bluetooth MIDI connections
will work on both OS X Yosemite

193
00:08:21,086 --> 00:08:24,166 A:middle
and iOS 8 using those
view controllers

194
00:08:24,166 --> 00:08:25,886 A:middle
that I told you about.

195
00:08:25,886 --> 00:08:27,616 A:middle
And it will work
on any Mac, iPhone,

196
00:08:27,616 --> 00:08:30,066 A:middle
or iPad that has native
Bluetooth Low Energy support.

197
00:08:30,496 --> 00:08:31,996 A:middle
So now I'm going to tell
you which ones those are.

198
00:08:31,996 --> 00:08:36,626 A:middle
For Macs, any Mac that was
manufactured in 2012 or later

199
00:08:36,946 --> 00:08:38,586 A:middle
and a mixed bag of
Macs that were released

200
00:08:38,586 --> 00:08:41,116 A:middle
in 2011 also have native
Bluetooth Low Energy support.

201
00:08:41,956 --> 00:08:45,086 A:middle
For the iPhone, the iPhone 4S
and greater have Bluetooth LE.

202
00:08:45,186 --> 00:08:48,916 A:middle
For the iPad, the first iPad
with the Retina display has LE

203
00:08:48,916 --> 00:08:50,396 A:middle
and the ones from that point

204
00:08:50,806 --> 00:08:53,826 A:middle
and all iPad Minis have native
Bluetooth Low Energy support.

205
00:08:54,336 --> 00:08:56,036 A:middle
So this will work on
all of those systems.

206
00:08:56,886 --> 00:08:59,636 A:middle
Also, the connection
is really low latency.

207
00:08:59,636 --> 00:09:00,516 A:middle
It's very sensitive.

208

209
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

210
00:08:59,636 --> 00:09:00,516 A:middle
It's very sensitive.

211
00:09:01,356 --> 00:09:05,676 A:middle
And the Bluetooth LE bandwidth
greatly exceeds the minimum MIDI

212
00:09:05,676 --> 00:09:09,546 A:middle
bandwidth requirement for MIDI
of 3,125 bytes per second.

213
00:09:10,116 --> 00:09:11,806 A:middle
Standardization is in the works.

214
00:09:11,806 --> 00:09:14,286 A:middle
We're working with standards
bodies to standardize this

215
00:09:14,286 --> 00:09:16,316 A:middle
so more people can get in on it.

216
00:09:16,316 --> 00:09:17,686 A:middle
And the key takeaway for you is

217
00:09:17,686 --> 00:09:19,896 A:middle
if you're making your
iOS applications,

218
00:09:20,296 --> 00:09:24,246 A:middle
please start adding these
Bluetooth UI View controllers

219
00:09:24,666 --> 00:09:26,206 A:middle
immediately to your applications

220
00:09:26,236 --> 00:09:30,256 A:middle
so that users can manage
Bluetooth MIDI connections using

221
00:09:30,256 --> 00:09:31,126 A:middle
your app.

222
00:09:31,436 --> 00:09:32,896 A:middle
And the person who is
going to show you how to do

223
00:09:32,896 --> 00:09:36,296 A:middle
that is my colleague and
homeboy Michael Hopkins.

224
00:09:36,526 --> 00:09:37,696 A:middle
And I'll turn the
mic over to him.

225
00:09:38,436 --> 00:09:39,556 A:middle
>> Thank you very much, Torrey.

226
00:09:40,196 --> 00:09:43,806 A:middle
I'd like to talk to you this
morning about a new framework

227
00:09:44,186 --> 00:09:46,636 A:middle
for iOS called CoreAudioKit.

228
00:09:47,096 --> 00:09:50,996 A:middle
This framework provides
standardized user interface

229
00:09:50,996 --> 00:09:55,416 A:middle
elements for you to add to
your application to do things

230
00:09:55,416 --> 00:09:59,136 A:middle
like show the MIDI
over Bluetooth LE UI

231
00:09:59,136 --> 00:10:03,536 A:middle
that Torrey just demonstrated as
well as some new views for those

232

233
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

234
00:09:59,136 --> 00:10:03,536 A:middle
that Torrey just demonstrated as
well as some new views for those

235
00:10:03,536 --> 00:10:05,306 A:middle
of you that are doing
Inter-App Audio.

236
00:10:06,436 --> 00:10:09,746 A:middle
We've designed these so that
we do all the heavy lifting

237
00:10:09,746 --> 00:10:12,236 A:middle
so that you don't have to worry
about rolling your own UI,

238
00:10:12,236 --> 00:10:15,566 A:middle
and you can just concentrate
on what makes your app unique.

239
00:10:16,166 --> 00:10:18,856 A:middle
Therefore, they are very easy
to adopt with a minimal amount

240
00:10:18,856 --> 00:10:24,126 A:middle
of source code, and they
work on both iPhone and iPad.

241
00:10:26,006 --> 00:10:29,736 A:middle
Looking specifically about these
interface elements for MIDI

242
00:10:29,736 --> 00:10:37,366 A:middle
over Bluetooth LE, as Torrey
showed you we have separated

243
00:10:37,366 --> 00:10:39,436 A:middle
these into two different
view controllers

244
00:10:39,436 --> 00:10:41,766 A:middle
so that you can choose
which one is appropriate

245
00:10:41,766 --> 00:10:44,606 A:middle
for your own application
or you can use both.

246
00:10:45,046 --> 00:10:48,466 A:middle
For example, if you use the UI
split view controller you can

247
00:10:48,466 --> 00:10:50,536 A:middle
have those both visible
at the same time.

248
00:10:51,136 --> 00:10:53,806 A:middle
The first one is
the CABTMIDILocal

249
00:10:53,806 --> 00:10:55,096 A:middle
PeripheralViewController.

250
00:10:55,226 --> 00:10:57,116 A:middle
That's quite a mouthful
this early in the morning.

251
00:10:58,636 --> 00:11:01,646 A:middle
If you want to advertise
your iOS device

252

253
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

254
00:10:58,636 --> 00:11:01,646 A:middle
If you want to advertise
your iOS device

255
00:11:01,646 --> 00:11:04,486 A:middle
as a Peripheral,
you use this class.

256
00:11:06,076 --> 00:11:09,676 A:middle
The source code for adopting
this is very straightforward.

257
00:11:10,306 --> 00:11:12,536 A:middle
You create a new instance
of that view controller,

258
00:11:13,266 --> 00:11:18,556 A:middle
get the navigation controller
object for your app and push

259
00:11:18,556 --> 00:11:20,966 A:middle
that view controller
onto the stack.

260
00:11:22,856 --> 00:11:27,696 A:middle
The CABTMIDICentral
ViewController is required

261
00:11:27,696 --> 00:11:28,926 A:middle
if you want to discover

262
00:11:28,926 --> 00:11:31,326 A:middle
and connect two Bluetooth
Peripherals.

263
00:11:32,566 --> 00:11:34,486 A:middle
And you use that
in the same way.

264
00:11:34,566 --> 00:11:37,456 A:middle
You create the view
controller and push it

265
00:11:37,456 --> 00:11:38,986 A:middle
onto your view controller stack.

266
00:11:40,026 --> 00:11:43,386 A:middle
Now I'd like to switch over
and talk about Inter-App Audio.

267
00:11:44,086 --> 00:11:47,576 A:middle
For those of you that weren't
present last year at WWDC,

268
00:11:47,576 --> 00:11:51,086 A:middle
we had a session talking
about this new technology

269
00:11:51,086 --> 00:11:52,916 A:middle
that we released with iOS 7.

270
00:11:53,976 --> 00:11:57,526 A:middle
In review, Inter-App Audio
allows you to stream audio

271
00:11:57,526 --> 00:11:59,986 A:middle
between one or more
apps in real time.

272

273
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

274
00:12:00,556 --> 00:12:05,766 A:middle
A host application can discover
available node apps even

275
00:12:05,766 --> 00:12:06,676 A:middle
if they are not running.

276
00:12:08,046 --> 00:12:10,356 A:middle
And please refer to
last year's session,

277
00:12:11,516 --> 00:12:15,026 A:middle
"What's New in Core Audio"
Session 206 for further details.

278
00:12:16,506 --> 00:12:18,656 A:middle
But looking at how this
works with the Host App

279
00:12:18,656 --> 00:12:22,086 A:middle
and a connected Node App, the
Node App can be an instrument,

280
00:12:22,086 --> 00:12:23,816 A:middle
an effect, or a generator.

281
00:12:24,546 --> 00:12:27,526 A:middle
And the Host App and Node App
can send audio back and forth.

282
00:12:28,036 --> 00:12:30,846 A:middle
In the case of an instrument,

283
00:12:30,846 --> 00:12:34,336 A:middle
the Host App can also send a
MIDI to that instrument app

284
00:12:34,916 --> 00:12:36,306 A:middle
and receive audio back.

285
00:12:36,916 --> 00:12:43,176 A:middle
The two user interface
elements that we provide

286
00:12:43,416 --> 00:12:48,206 A:middle
in iOS 8 are firstly the
Inter-App Audio switch review,

287
00:12:48,706 --> 00:12:52,186 A:middle
which provides an easy way to
see all the Inter-App Audio apps

288
00:12:52,186 --> 00:12:55,046 A:middle
that are connected
together and switch

289
00:12:55,046 --> 00:12:57,176 A:middle
between them using a
simple tap gesture.

290
00:12:59,516 --> 00:13:03,766 A:middle
We also provide an Inter-App
Audio Host Transport view.

291

292
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

293
00:12:59,516 --> 00:13:03,766 A:middle
We also provide an Inter-App
Audio Host Transport view.

294
00:13:04,576 --> 00:13:07,346 A:middle
This displays the transport
of the host you're connected

295
00:13:07,346 --> 00:13:09,696 A:middle
to in your Node App
and allows you

296
00:13:09,696 --> 00:13:13,136 A:middle
to control the transport
playback, rewind,

297
00:13:13,806 --> 00:13:16,376 A:middle
and record in addition
to displaying

298
00:13:16,376 --> 00:13:21,156 A:middle
where in the Host Transport you
are via that numeric time code.

299
00:13:21,656 --> 00:13:25,026 A:middle
And I'd like to show a
demo of this in action.

300
00:13:25,746 --> 00:13:28,086 A:middle
I have 3 different
applications here

301
00:13:28,086 --> 00:13:31,106 A:middle
that we'll be using together in
our Inter-App Audio Scenario.

302
00:13:31,616 --> 00:13:33,616 A:middle
The first of which
is GarageBand,

303
00:13:33,616 --> 00:13:35,876 A:middle
which is the current
version of that application

304
00:13:35,876 --> 00:13:38,046 A:middle
that I've downloaded
from the iTunes store.

305
00:13:39,086 --> 00:13:43,596 A:middle
I also have a Delay
application and a Sampler.

306
00:13:44,256 --> 00:13:46,186 A:middle
Let's take a look at
the Sampler first.

307
00:13:47,336 --> 00:13:51,166 A:middle
This allows me to trigger sample
playback via the keyboard.

308
00:13:52,516 --> 00:13:56,706 A:middle
[ Music ]

309
00:13:57,206 --> 00:13:59,616 A:middle
So now let's go ahead and
connect this to GarageBand.

310
00:13:59,806 --> 00:14:01,226 A:middle
I'm going to launch GarageBand.

311

312
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

313
00:13:59,806 --> 00:14:01,226 A:middle
I'm going to launch GarageBand.

314
00:14:07,796 --> 00:14:11,236 A:middle
I'm going to connect
to that Sampler app,

315
00:14:11,366 --> 00:14:13,876 A:middle
and now this is connected
to GarageBand.

316
00:14:14,556 --> 00:14:17,096 A:middle
So the first thing I'd like to
demonstrate is the Inter-App

317
00:14:17,096 --> 00:14:19,136 A:middle
Audio Switch Review in action,

318
00:14:19,726 --> 00:14:21,946 A:middle
which this application
has implemented

319
00:14:22,136 --> 00:14:24,286 A:middle
as visible via a button.

320
00:14:25,076 --> 00:14:27,016 A:middle
I press that, and
you can see now

321
00:14:27,016 --> 00:14:29,746 A:middle
that we have two Nodes shown.

322
00:14:30,116 --> 00:14:33,176 A:middle
The Host, as well as
our current application.

323
00:14:33,176 --> 00:14:36,816 A:middle
And I can switch over to
GarageBand simply by tapping.

324
00:14:37,856 --> 00:14:38,826 A:middle
I'm going to add

325
00:14:38,826 --> 00:14:44,426 A:middle
in an additional Inter-App
Audio App, the Delay effect.

326
00:14:44,426 --> 00:14:51,106 A:middle
And now if I was to switch
over to this application

327
00:14:51,106 --> 00:14:53,996 A:middle
without using the Switch
Review, I could double tap

328
00:14:53,996 --> 00:14:58,476 A:middle
on my Home key, look, and
try to find that application.

329
00:14:58,476 --> 00:14:59,246 A:middle
Where is it?

330
00:14:59,246 --> 00:15:00,616 A:middle
It's difficult to find.

331

332
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

333
00:14:59,246 --> 00:15:00,616 A:middle
It's difficult to find.

334
00:15:00,996 --> 00:15:04,906 A:middle
And that's why we've provided
the Inter-App Switch Review.

335
00:15:05,466 --> 00:15:07,066 A:middle
In this application, the Delay,

336
00:15:07,066 --> 00:15:09,016 A:middle
you can see that on the
lower right-hand corner.

337
00:15:09,506 --> 00:15:13,726 A:middle
And now that is showing
our Host, the Sampler,

338
00:15:13,726 --> 00:15:15,486 A:middle
as well as our current effect.

339
00:15:16,226 --> 00:15:20,766 A:middle
So it's very easy to
switch back and forth.

340
00:15:20,766 --> 00:15:22,846 A:middle
And you can see that it
just showed up there.

341
00:15:23,156 --> 00:15:25,166 A:middle
So that's the first view
I'd like to demonstrate.

342
00:15:25,796 --> 00:15:27,606 A:middle
And if I play back
on my keyboard,

343
00:15:29,416 --> 00:15:31,346 A:middle
we can hear that we're
now getting that Delay.

344
00:15:31,346 --> 00:15:36,136 A:middle
And this is interesting because
we have, we're sending audio

345
00:15:36,136 --> 00:15:39,536 A:middle
from the host to our Sampler,
and then through an effect

346
00:15:39,796 --> 00:15:41,326 A:middle
to playing that delay,
and then back.

347
00:15:42,246 --> 00:15:44,896 A:middle
Now the second view, the
Transport view, you'll see just

348
00:15:44,896 --> 00:15:48,826 A:middle
above that view, let me hide
that for you, and that allows me

349
00:15:48,826 --> 00:15:50,626 A:middle
to control the transport of
the Host [music playing].

350
00:15:50,626 --> 00:15:55,976 A:middle
I can do recording.

351
00:15:56,516 --> 00:15:59,786 A:middle
[ Music Playing ]

352

353
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

354
00:16:00,286 --> 00:16:01,506 A:middle
Sorry. I'm no Dr. Dre.

355
00:16:01,506 --> 00:16:04,476 A:middle
It's too early in the morning
for that, but you get the idea.

356
00:16:04,476 --> 00:16:06,366 A:middle
And these are the views

357
00:16:06,366 --> 00:16:08,346 A:middle
that we're providing
for your benefit.

358
00:16:08,346 --> 00:16:09,396 A:middle
So please adopt those

359
00:16:09,396 --> 00:16:11,556 A:middle
to add this functionality
to your application.

360
00:16:12,416 --> 00:16:15,836 A:middle
OK. So the goal between these
user interface elements are

361
00:16:15,836 --> 00:16:19,936 A:middle
to provide a consistent
experience for your customers.

362
00:16:20,156 --> 00:16:22,586 A:middle
You do have some flexibility
in controlling some

363
00:16:22,586 --> 00:16:25,416 A:middle
of the visual appearances
of those controls.

364
00:16:25,946 --> 00:16:28,066 A:middle
They support a number
of different sizes.

365
00:16:28,066 --> 00:16:31,526 A:middle
So if you want a ginormous
UI you can have that,

366
00:16:31,526 --> 00:16:33,666 A:middle
or if you want them very
small you can do that.

367
00:16:34,126 --> 00:16:36,656 A:middle
The source code, as I'm going
to show you, is very easy

368
00:16:36,656 --> 00:16:37,926 A:middle
to add to your application.

369
00:16:38,336 --> 00:16:41,846 A:middle
And because these are subclasses
of UIView, you can choose

370
00:16:41,846 --> 00:16:44,366 A:middle
to create a view controller
if you want to add them

371
00:16:44,366 --> 00:16:48,176 A:middle
to a UI popover view
on your iPad, or if,

372
00:16:48,176 --> 00:16:51,046 A:middle
the example demonstrated it, if
you want to embed that directly

373
00:16:51,046 --> 00:16:53,486 A:middle
in the content of your app
you can do that as well.

374
00:16:54,116 --> 00:16:56,216 A:middle
Let's take a look at the code.

375
00:16:56,566 --> 00:16:59,006 A:middle
We import the umbrella header.

376
00:16:59,436 --> 00:17:01,326 A:middle
In this case, I'm
demonstrating how

377

378
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

379
00:16:59,436 --> 00:17:01,326 A:middle
In this case, I'm
demonstrating how

380
00:17:01,326 --> 00:17:03,856 A:middle
to add the Switcher
View from a nib file.

381
00:17:03,856 --> 00:17:06,906 A:middle
So you go into IV,
drag out your UI view,

382
00:17:07,016 --> 00:17:10,715 A:middle
assign that to be the class of
the CAInterAppAudioSwitcherView,

383
00:17:11,146 --> 00:17:13,106 A:middle
create an outlet for that view,

384
00:17:13,215 --> 00:17:19,296 A:middle
and then in the viewDidLoad
method we specified a visual

385
00:17:19,296 --> 00:17:20,685 A:middle
appearance of that view.

386
00:17:20,866 --> 00:17:25,406 A:middle
And then we need to associate
an audio unit with that view

387
00:17:25,616 --> 00:17:28,046 A:middle
so that it can automatically
find the other apps

388
00:17:28,046 --> 00:17:28,986 A:middle
that are connected.

389
00:17:29,616 --> 00:17:34,026 A:middle
And that's all there is to it.

390
00:17:34,026 --> 00:17:36,686 A:middle
And creating the Transport
view programmatically,

391
00:17:36,686 --> 00:17:41,556 A:middle
as this example shows, we create
the view, specify initial size

392
00:17:41,556 --> 00:17:42,956 A:middle
and location of that view,

393
00:17:43,956 --> 00:17:46,546 A:middle
configure it's visual
appearances,

394
00:17:47,046 --> 00:17:49,886 A:middle
associate an output
audio unit with a view,

395
00:17:49,936 --> 00:17:53,106 A:middle
and then finally we
add that transport view

396
00:17:53,106 --> 00:17:57,806 A:middle
as a subview of our
main content.

397
00:17:58,576 --> 00:18:01,936 A:middle
OK. Now I'd like to switch
gears a little bit now back

398

399
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

400
00:17:58,576 --> 00:18:01,936 A:middle
OK. Now I'd like to switch
gears a little bit now back

401
00:18:01,936 --> 00:18:03,406 A:middle
to AV Foundation.

402
00:18:03,826 --> 00:18:06,766 A:middle
The rest of my presenters
including myself will be

403
00:18:06,856 --> 00:18:10,016 A:middle
focusing on this framework and
some of the new enhancements

404
00:18:10,016 --> 00:18:12,076 A:middle
and abilities that
we've added for you

405
00:18:12,356 --> 00:18:13,726 A:middle
to add to your application.

406
00:18:14,386 --> 00:18:17,706 A:middle
The first new feature is
for Audio Unit Management.

407
00:18:17,706 --> 00:18:21,336 A:middle
And that's the
AVAudioUnitComponentManager.

408
00:18:22,416 --> 00:18:28,416 A:middle
This is a Mac OS X Yosemite
API, Objective C-based.

409
00:18:28,416 --> 00:18:33,446 A:middle
And it's primarily designed for
Audio Unit host applications.

410
00:18:33,726 --> 00:18:34,746 A:middle
However, as you'll see,

411
00:18:34,746 --> 00:18:37,106 A:middle
we do have some end-user
features as well.

412
00:18:37,836 --> 00:18:40,496 A:middle
We provide a number of
different querying methods,

413
00:18:40,496 --> 00:18:43,706 A:middle
which enable your host
to find the Audio Units

414
00:18:43,706 --> 00:18:46,506 A:middle
on the system given some
criteria, for example,

415
00:18:46,506 --> 00:18:47,866 A:middle
number of supported channels.

416
00:18:48,816 --> 00:18:51,356 A:middle
We have a simple API
for getting information

417
00:18:51,356 --> 00:18:53,206 A:middle
about each individual
Audio Unit.

418
00:18:53,926 --> 00:18:55,926 A:middle
We have some new
tagging facilities

419
00:18:55,926 --> 00:18:57,606 A:middle
that I'll demonstrate
in a moment.

420
00:18:58,146 --> 00:19:01,676 A:middle
And finally we have a
centralized Audio Unit cache

421

422
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

423
00:18:58,146 --> 00:19:01,676 A:middle
And finally we have a
centralized Audio Unit cache

424
00:19:02,086 --> 00:19:04,816 A:middle
so that if you have
multiple host applications

425
00:19:04,816 --> 00:19:08,686 A:middle
on your system, once one
host has scanned Audio Units,

426
00:19:08,686 --> 00:19:11,396 A:middle
and for a lot of people they
have a large number of them

427
00:19:11,396 --> 00:19:14,306 A:middle
so this can take quite some
time, all the other hosts

428
00:19:14,306 --> 00:19:18,396 A:middle
on the system share that
information so they don't have

429
00:19:18,396 --> 00:19:20,576 A:middle
to perform that exhaustive
scan again.

430
00:19:21,126 --> 00:19:25,106 A:middle
Let's take a look at
the API in more detail.

431
00:19:25,876 --> 00:19:28,486 A:middle
As I said, these are in AV
Foundation, and they're new.

432
00:19:29,446 --> 00:19:32,736 A:middle
The first class is the
AVAudioUnitComponentManager.

433
00:19:33,036 --> 00:19:36,176 A:middle
And this provides three
different search mechanisms

434
00:19:36,176 --> 00:19:37,976 A:middle
for finding Audio Units.

435
00:19:38,006 --> 00:19:41,036 A:middle
The first of which is
based on the NSPredicates.

436
00:19:41,616 --> 00:19:45,296 A:middle
We can use a SQL-based
language to provide strings,

437
00:19:45,296 --> 00:19:49,376 A:middle
which I'll show you in a
source code example later

438
00:19:49,746 --> 00:19:52,436 A:middle
for finding audio units
matching the given criteria.

439
00:19:53,156 --> 00:19:55,176 A:middle
We also have a block-based
mechanism

440
00:19:55,246 --> 00:19:57,136 A:middle
for finer programmatic control.

441
00:19:57,536 --> 00:20:00,246 A:middle
And for those of you
using older host apps

442

443
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

444
00:19:57,536 --> 00:20:00,246 A:middle
And for those of you
using older host apps

445
00:20:00,626 --> 00:20:02,696 A:middle
with our current
audio component API,

446
00:20:03,246 --> 00:20:05,626 A:middle
we have a backwards-compatible
mode as well.

447
00:20:06,806 --> 00:20:12,266 A:middle
Each of these search
methodologies return an NSArray

448
00:20:12,266 --> 00:20:14,186 A:middle
of AVAudioUnitComponents.

449
00:20:14,556 --> 00:20:15,866 A:middle
And that class can be used

450
00:20:15,866 --> 00:20:19,376 A:middle
to get information
about the audio unit.

451
00:20:20,016 --> 00:20:23,076 A:middle
Now using our prior API,
if I wanted to do something

452
00:20:23,076 --> 00:20:27,966 A:middle
like find all stereo effects
that support two-channel input

453
00:20:27,966 --> 00:20:32,706 A:middle
and two-channel output, I'd have
to write a great deal of code.

454
00:20:33,026 --> 00:20:33,876 A:middle
That's OK.

455
00:20:33,876 --> 00:20:38,386 A:middle
But now with this new API we can
reduce all that to this simple,

456
00:20:38,386 --> 00:20:39,836 A:middle
elegant four lines of code.

457
00:20:40,496 --> 00:20:42,846 A:middle
The first of which is
retrieving an instance

458
00:20:42,846 --> 00:20:45,076 A:middle
of the sharedAudioUnitManager.

459
00:20:45,806 --> 00:20:50,246 A:middle
And here I'm using the
block-based search mechanism

460
00:20:50,246 --> 00:20:54,086 A:middle
to find all components
that pass a specific test.

461
00:20:54,776 --> 00:20:58,726 A:middle
And in this block I'm checking
to see if the type name

462
00:20:58,766 --> 00:21:00,406 A:middle
of that audio unit is equal

463

464
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

465
00:20:58,766 --> 00:21:00,406 A:middle
of that audio unit is equal

466
00:21:00,406 --> 00:21:05,606 A:middle
to the preset string
AVAudioUnitTypeEffect.

467
00:21:05,606 --> 00:21:08,326 A:middle
And then furthermore
we're checking to see

468
00:21:08,326 --> 00:21:11,886 A:middle
if that Audio Unit supports
stereo input and output.

469
00:21:12,976 --> 00:21:16,146 A:middle
You'll notice there is a stop
parameter, so if you wanted

470
00:21:16,146 --> 00:21:19,806 A:middle
to return only the
first instance

471
00:21:19,806 --> 00:21:22,396 A:middle
of the audio component
matching this criteria,

472
00:21:22,756 --> 00:21:25,686 A:middle
you could return yes
and the stop would,

473
00:21:25,686 --> 00:21:27,126 A:middle
and it would stop immediately.

474
00:21:30,366 --> 00:21:33,436 A:middle
OK. Now I'd like to move
on to talk about tagging.

475
00:21:34,156 --> 00:21:36,646 A:middle
A lot of people,
especially Dr. Dre

476
00:21:36,646 --> 00:21:39,876 A:middle
in his studio has a large
number of Audio Units.

477
00:21:39,876 --> 00:21:43,456 A:middle
So finding the right one
can be a bit challenging

478
00:21:43,866 --> 00:21:46,146 A:middle
because they're sorted
alphabetically

479
00:21:46,146 --> 00:21:48,216 A:middle
or by manufacturer.

480
00:21:48,636 --> 00:21:51,376 A:middle
And there's a lot
easier way for users

481
00:21:51,406 --> 00:21:53,556 A:middle
to find these Audio
Units now with tagging.

482
00:21:53,556 --> 00:21:56,596 A:middle
It's very similar to what
we have done with a finder

483
00:21:56,596 --> 00:21:58,386 A:middle
of the previous Mac
OS X release.

484
00:21:59,036 --> 00:22:03,606 A:middle
Users can now specify their own
tags with an audio unit in order

485

486
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

487
00:21:59,036 --> 00:22:03,606 A:middle
Users can now specify their own
tags with an audio unit in order

488
00:22:03,606 --> 00:22:07,376 A:middle
to create broad categories
or even specific categories

489
00:22:07,736 --> 00:22:10,736 A:middle
of how they want to
organize their audio units.

490
00:22:11,336 --> 00:22:14,986 A:middle
They can apply one or more tags
in two different categories.

491
00:22:14,986 --> 00:22:16,806 A:middle
The first of which
is a system tag.

492
00:22:17,736 --> 00:22:21,416 A:middle
This is defined by the
creator of the audio unit.

493
00:22:21,416 --> 00:22:25,286 A:middle
And, for example, in Mavericks,
excuse me, in Yosemite,

494
00:22:25,286 --> 00:22:28,556 A:middle
I have to get that name in my
head, I personally liked Weed,

495
00:22:28,556 --> 00:22:32,266 A:middle
but I didn't get to vote.

496
00:22:32,376 --> 00:22:35,576 A:middle
The system tags are
defined by the creator.

497
00:22:35,576 --> 00:22:39,076 A:middle
And we at Apple have
added standard tags

498
00:22:39,076 --> 00:22:41,486 A:middle
to all the Audio Units that
we feel would be useful

499
00:22:41,486 --> 00:22:42,716 A:middle
to most of our users.

500
00:22:42,796 --> 00:22:45,666 A:middle
You can also have user tags.

501
00:22:46,066 --> 00:22:49,366 A:middle
These are specified by each
individual user on the system.

502
00:22:49,366 --> 00:22:52,216 A:middle
So if you have three users they
can each have their own set

503
00:22:52,216 --> 00:22:52,716 A:middle
of tags.

504
00:22:53,426 --> 00:22:58,156 A:middle
A tag is a localized string
in the user's own language.

505
00:22:58,636 --> 00:23:00,246 A:middle
Swedish, Swahili,
it doesn't matter.

506

507
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

508
00:22:58,636 --> 00:23:00,246 A:middle
Swedish, Swahili,
it doesn't matter.

509
00:23:00,336 --> 00:23:03,676 A:middle
They can be arbitrary, or they
can be a pre-defined type.

510
00:23:03,676 --> 00:23:04,506 A:middle
And these are all

511
00:23:04,506 --> 00:23:09,576 A:middle
in AudioComponent.h. They can
be either based on the type

512
00:23:09,576 --> 00:23:12,966 A:middle
of Audio Unit, for example a
filter or a distortion effect,

513
00:23:13,506 --> 00:23:16,036 A:middle
or they can be based
on the intended usage,

514
00:23:16,326 --> 00:23:21,046 A:middle
for example an audio unit useful
in a guitar or vocal track.

515
00:23:21,766 --> 00:23:27,796 A:middle
Now I'd like to show
a demo of tagging

516
00:23:27,796 --> 00:23:31,986 A:middle
in action using a
modified version of AU Lab.

517
00:23:32,296 --> 00:23:37,676 A:middle
So in AU Lab we can look
at all the tags associated

518
00:23:37,676 --> 00:23:39,366 A:middle
with all the built-in
audio units.

519
00:23:39,926 --> 00:23:41,886 A:middle
And here you see
that, for example,

520
00:23:41,886 --> 00:23:46,716 A:middle
the AU time pitch
has two standard tags

521
00:23:46,906 --> 00:23:49,306 A:middle
that are associated with
it, time effect and pitch.

522
00:23:49,626 --> 00:23:51,146 A:middle
And those are defined by us.

523
00:23:51,736 --> 00:23:55,006 A:middle
In addition you can see

524
00:23:55,006 --> 00:23:59,646 A:middle
that this distortion effect has
two user tags, one specifying

525
00:23:59,646 --> 00:24:01,706 A:middle
that it's useful
for a drum track

526

527
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

528
00:23:59,646 --> 00:24:01,706 A:middle
that it's useful
for a drum track

529
00:24:01,706 --> 00:24:03,306 A:middle
and another one for
a guitar track.

530
00:24:04,256 --> 00:24:08,376 A:middle
The API also provides developers
the ability to get a list

531
00:24:08,376 --> 00:24:12,576 A:middle
of all the system-defined
tags localized in the language

532
00:24:12,576 --> 00:24:15,486 A:middle
of the running host
as you can see here.

533
00:24:15,986 --> 00:24:19,176 A:middle
And I can also see
all of the user tags

534
00:24:19,246 --> 00:24:23,216 A:middle
that the users assigned to all
the Audio Units on this system.

535
00:24:25,216 --> 00:24:28,216 A:middle
Adding tags are as simple
as typing a new one.

536
00:24:28,966 --> 00:24:33,796 A:middle
Now that's been added
to that Audio Unit.

537
00:24:33,796 --> 00:24:38,956 A:middle
And I can do a search
using this predicate-based

538
00:24:38,956 --> 00:24:40,356 A:middle
and other search mechanisms.

539
00:24:41,856 --> 00:24:43,796 A:middle
And it will search all
the audience looking

540
00:24:43,796 --> 00:24:45,086 A:middle
for that particular tag.

541
00:24:45,676 --> 00:24:47,446 A:middle
So this is something
that is really exciting,

542
00:24:47,446 --> 00:24:52,256 A:middle
and we hope that you'll use this
API to add tagging functionality

543
00:24:52,256 --> 00:24:53,736 A:middle
to your own host application.

544
00:24:54,276 --> 00:24:56,126 A:middle
Let's take a look
now at the API.

545
00:24:57,416 --> 00:24:59,936 A:middle
To find an Audio Unit
with a specific tag,

546

547
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

548
00:25:00,176 --> 00:25:01,366 A:middle
in this example I'm going

549
00:25:01,366 --> 00:25:05,606 A:middle
to use the NSPredicate
filtering mechanism.

550
00:25:05,956 --> 00:25:07,376 A:middle
Here I'm defining a predicate.

551
00:25:07,376 --> 00:25:12,336 A:middle
It says that the component has

552
00:25:12,336 --> 00:25:16,556 A:middle
to have the old tag name's
property containing a particular

553
00:25:16,556 --> 00:25:18,736 A:middle
string, in this case,
"My Favorite Tag",

554
00:25:19,236 --> 00:25:21,156 A:middle
and this is the identical
searching

555
00:25:21,156 --> 00:25:22,696 A:middle
that you just saw in my demo.

556
00:25:24,166 --> 00:25:26,606 A:middle
Once you've defined the
predicate you get an instance

557
00:25:26,606 --> 00:25:28,926 A:middle
of the shared AU Manager,

558
00:25:30,426 --> 00:25:32,606 A:middle
and then call
componentsMatchingPredicate,

559
00:25:32,606 --> 00:25:33,986 A:middle
which returns an array.

560
00:25:37,816 --> 00:25:42,036 A:middle
To get a list of
the tags associated

561
00:25:42,036 --> 00:25:44,666 A:middle
with this particular
AVAudioUnitComponent,

562
00:25:44,666 --> 00:25:46,616 A:middle
you use the userTags
named property.

563
00:25:47,766 --> 00:25:49,446 A:middle
You can assign to that as well.

564
00:25:49,446 --> 00:25:53,486 A:middle
And in this example I'm adding
two tags to the audio Unit.

565
00:25:54,256 --> 00:25:57,946 A:middle
We could get all tags
for a specific component,

566
00:25:57,946 --> 00:26:01,196 A:middle
and these will include the user
tags as well as the system tags.

567

568
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

569
00:25:57,946 --> 00:26:01,196 A:middle
and these will include the user
tags as well as the system tags.

570
00:26:02,106 --> 00:26:03,426 A:middle
All tagNames property.

571
00:26:05,016 --> 00:26:08,356 A:middle
We can get a localized list of
all the standard system tags

572
00:26:08,356 --> 00:26:09,896 A:middle
by getting the Component Manager

573
00:26:09,896 --> 00:26:12,466 A:middle
and then calling the
standardLocalizedTagNames

574
00:26:12,496 --> 00:26:13,006 A:middle
property.

575
00:26:13,786 --> 00:26:16,846 A:middle
This is what I was displaying
in the pop up in my demo.

576
00:26:17,746 --> 00:26:21,246 A:middle
And finally I can get a list
of all the localized tags

577
00:26:21,246 --> 00:26:22,766 A:middle
that this user has assigned

578
00:26:22,766 --> 00:26:24,736 A:middle
across all the audio
units on the system.

579
00:26:25,226 --> 00:26:26,926 A:middle
And that, again,
you saw in my demo.

580
00:26:27,626 --> 00:26:32,976 A:middle
For those of you that ship
Audio Units, and you want

581
00:26:32,976 --> 00:26:35,486 A:middle
to add your own built-in
tags to those Audio Units,

582
00:26:35,866 --> 00:26:39,336 A:middle
you need to go into your
AudioComponent bundle.

583
00:26:39,336 --> 00:26:43,486 A:middle
And in your info.plist, look at
your Audio Component Dictionary

584
00:26:43,486 --> 00:26:45,066 A:middle
and add a tag section.

585
00:26:46,076 --> 00:26:50,626 A:middle
These first two items are
examples of using standard tags,

586
00:26:51,286 --> 00:26:53,806 A:middle
and the third item
is a custom tag.

587
00:26:54,186 --> 00:26:57,206 A:middle
So you can have that
be something meaningful

588
00:26:57,206 --> 00:26:59,316 A:middle
to your own company,
for example,

589
00:26:59,316 --> 00:27:02,606 A:middle
if you have like the
Silver Effect Package,

590

591
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

592
00:26:59,316 --> 00:27:02,606 A:middle
if you have like the
Silver Effect Package,

593
00:27:02,606 --> 00:27:03,646 A:middle
you could add that tag.

594
00:27:05,076 --> 00:27:08,336 A:middle
If you do so, you can
also localize that tag

595
00:27:08,406 --> 00:27:10,746 A:middle
by adding an
AudioUnitsTag.strings file

596
00:27:10,746 --> 00:27:14,926 A:middle
into your bundle and then adding
localizations for each language

597
00:27:14,926 --> 00:27:16,266 A:middle
that you wish to support.

598
00:27:16,766 --> 00:27:20,136 A:middle
And please do not localize any
of our standard system tags.

599
00:27:20,136 --> 00:27:21,466 A:middle
We've already done so for you.

600
00:27:22,746 --> 00:27:27,706 A:middle
So, in summary, if you're a
host developer please adopt the

601
00:27:27,706 --> 00:27:29,896 A:middle
AVAudioComponentManager API,

602
00:27:29,896 --> 00:27:33,606 A:middle
so your users can tag
all their Audio Units.

603
00:27:33,666 --> 00:27:35,846 A:middle
And if you're an
Audio Unit developer,

604
00:27:35,846 --> 00:27:38,346 A:middle
please add system tags
to your audio units.

605
00:27:38,876 --> 00:27:41,976 A:middle
So without further
ado I'd like to turn

606
00:27:41,976 --> 00:27:43,946 A:middle
over this session
to Eric Johnson.

607
00:27:43,946 --> 00:27:47,056 A:middle
He'll be discussing tips and
tricks and new functionality

608
00:27:47,056 --> 00:27:48,176 A:middle
in the AVAudioSession.

609
00:27:48,796 --> 00:27:48,976 A:middle
Eric?

610
00:27:49,516 --> 00:27:54,126 A:middle
[ Applause ]

611
00:27:54,626 --> 00:27:55,006 A:middle
>> Good morning.

612
00:27:55,006 --> 00:27:58,086 A:middle
So I'll be continuing on with
the AV Foundation framework.

613
00:27:58,166 --> 00:28:02,376 A:middle
This time we're on iOS
only with AVAudioSession.

614

615
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

616
00:27:58,166 --> 00:28:02,376 A:middle
This time we're on iOS
only with AVAudioSession.

617
00:28:02,866 --> 00:28:05,756 A:middle
So today we're just going to
spend a few minutes talking

618
00:28:05,756 --> 00:28:08,396 A:middle
about some best practices
focusing

619
00:28:08,396 --> 00:28:11,196 A:middle
on managing your
session's activation state,

620
00:28:11,746 --> 00:28:13,456 A:middle
and then also talking
about just a little bit

621
00:28:13,456 --> 00:28:15,066 A:middle
of new things in iOS 8.

622
00:28:16,676 --> 00:28:19,126 A:middle
Before we dive in I wanted
to call your attention

623
00:28:19,166 --> 00:28:22,016 A:middle
to an updated Audio Session
Programming Guide that's

624
00:28:22,016 --> 00:28:25,686 A:middle
available on
developer.apple.com.

625
00:28:25,686 --> 00:28:28,256 A:middle
Since we saw you all
last year at this time,

626
00:28:28,256 --> 00:28:31,976 A:middle
this guide has been updated
so that it has been rewritten

627
00:28:32,436 --> 00:28:35,296 A:middle
in terms of AVAudioSession,
so it's no longer referring

628
00:28:35,296 --> 00:28:36,856 A:middle
to the deprecated C API.

629
00:28:37,806 --> 00:28:39,066 A:middle
That's a really great update.

630
00:28:39,356 --> 00:28:42,356 A:middle
And for those of you who
are maybe not that familiar

631
00:28:42,356 --> 00:28:46,466 A:middle
with Audio Session, there
was a talk from two years ago

632
00:28:46,696 --> 00:28:49,476 A:middle
where Torrey talked
about Audio Session

633
00:28:49,476 --> 00:28:51,546 A:middle
and also Multi-Route
Audio in iOS.

634
00:28:53,126 --> 00:28:53,916 A:middle
All right.

635
00:28:53,916 --> 00:28:55,646 A:middle
So let's dive into talking

636
00:28:55,646 --> 00:28:58,606 A:middle
about managing your
session's activation state.

637
00:28:59,636 --> 00:29:02,296 A:middle
So there's your application
state.

638

639
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

640
00:28:59,636 --> 00:29:02,296 A:middle
So there's your application
state.

641
00:29:02,466 --> 00:29:04,596 A:middle
And then there's
Audio Session state.

642
00:29:04,596 --> 00:29:05,866 A:middle
And they're separate things.

643
00:29:05,866 --> 00:29:07,276 A:middle
They're managed independently
of each other.

644
00:29:08,126 --> 00:29:09,726 A:middle
So if you've been
doing development

645
00:29:09,886 --> 00:29:12,716 A:middle
for iOS you are probably
familiar with app states.

646
00:29:12,716 --> 00:29:15,926 A:middle
So this is whether your app is
running or not, whether it's

647
00:29:15,926 --> 00:29:17,576 A:middle
in the foreground
or the background,

648
00:29:17,696 --> 00:29:18,596 A:middle
if it's been suspended.

649
00:29:19,806 --> 00:29:22,626 A:middle
Your Audio Session
activation state is binary.

650
00:29:23,206 --> 00:29:25,266 A:middle
It's either inactive or active.

651
00:29:26,366 --> 00:29:29,016 A:middle
Once you've made your
session active you do need

652
00:29:29,016 --> 00:29:31,976 A:middle
to be prepared to handle
interruptions, and we'll talk

653
00:29:31,976 --> 00:29:32,866 A:middle
about what that means.

654
00:29:33,726 --> 00:29:35,736 A:middle
So let's look at an example

655
00:29:35,736 --> 00:29:39,446 A:middle
of how an Audio Session
state changes over time.

656
00:29:39,836 --> 00:29:42,386 A:middle
So here we're on an iPhone.

657
00:29:42,556 --> 00:29:45,506 A:middle
We have our application
on top, our Audio Session.

658
00:29:46,096 --> 00:29:48,586 A:middle
Let's say that we're
developing a game app.

659
00:29:48,586 --> 00:29:51,036 A:middle
And then on the bottom we have
the phone's Audio Session.

660
00:29:51,746 --> 00:29:54,546 A:middle
And right now the user
is not in a phone call,

661
00:29:54,856 --> 00:29:56,426 A:middle
and they haven't
launched their app yet,

662
00:29:56,426 --> 00:29:59,476 A:middle
so both sessions
are idle, inactive.

663
00:29:59,606 --> 00:30:02,286 A:middle
So now the user launches
our app.

664

665
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

666
00:29:59,606 --> 00:30:02,286 A:middle
So now the user launches
our app.

667
00:30:03,796 --> 00:30:06,796 A:middle
When we first come into the
foreground our Audio Session is

668
00:30:06,796 --> 00:30:07,586 A:middle
still inactive.

669
00:30:08,316 --> 00:30:11,296 A:middle
And because we're a game app, we
want to make our session active

670
00:30:11,556 --> 00:30:12,556 A:middle
when we're in the foreground

671
00:30:12,556 --> 00:30:13,966 A:middle
so that we can be
ready to play audio.

672
00:30:13,966 --> 00:30:14,696 A:middle
So we'll do that.

673
00:30:15,806 --> 00:30:17,556 A:middle
And we're going to
just play some music,

674
00:30:17,556 --> 00:30:20,136 A:middle
so we're now happily playing
music in the foreground

675
00:30:20,136 --> 00:30:21,286 A:middle
with an active Audio Session.

676
00:30:23,056 --> 00:30:27,506 A:middle
So then the phone
starts ringing.

677
00:30:27,506 --> 00:30:29,246 A:middle
We get interrupted by,

678
00:30:29,246 --> 00:30:32,406 A:middle
the system sends us
an interruption event.

679
00:30:33,356 --> 00:30:36,066 A:middle
The phone's Audio
Session becomes active

680
00:30:36,066 --> 00:30:37,306 A:middle
and plays the ringtone.

681
00:30:38,086 --> 00:30:40,726 A:middle
And the user decides
to accept the call.

682
00:30:41,436 --> 00:30:43,596 A:middle
So the phone's Audio
Session stays active,

683
00:30:43,996 --> 00:30:47,616 A:middle
and our Audio Session has been
interrupted, so we're inactive.

684
00:30:47,616 --> 00:30:52,236 A:middle
And then the user ends the
call, hangs up, says goodbye,

685
00:30:53,456 --> 00:30:54,636 A:middle
and now the system is going

686
00:30:54,636 --> 00:30:57,876 A:middle
to deliver an end interruption
event to our Audio Session.

687
00:30:57,876 --> 00:31:01,576 A:middle
And we're going to
use that as a signal

688

689
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

690
00:30:57,876 --> 00:31:01,576 A:middle
And we're going to
use that as a signal

691
00:31:01,576 --> 00:31:04,426 A:middle
to make our session active
again and presume playback.

692
00:31:05,866 --> 00:31:07,086 A:middle
And we continue in this state.

693
00:31:07,686 --> 00:31:11,666 A:middle
So this is a typical
example of how something

694
00:31:11,666 --> 00:31:14,346 A:middle
like a game application
interacts with the phones,

695
00:31:14,726 --> 00:31:16,816 A:middle
the phone app's Audio
Session on an iPhone.

696
00:31:19,096 --> 00:31:20,776 A:middle
So the way that you need

697
00:31:20,776 --> 00:31:25,176 A:middle
to manage your application's
Audio Session state is actually

698
00:31:25,176 --> 00:31:26,816 A:middle
going to depend on
how you use audio.

699
00:31:27,446 --> 00:31:30,266 A:middle
We've identified a number of
different types of applications

700
00:31:30,526 --> 00:31:33,046 A:middle
that commonly use audio on iOS.

701
00:31:33,686 --> 00:31:36,376 A:middle
And we don't have time to talk
about all of these this morning,

702
00:31:36,376 --> 00:31:38,076 A:middle
and you'd probably be
bored to death if we did.

703
00:31:38,436 --> 00:31:42,576 A:middle
So we're just going to
talk about a few of these.

704
00:31:42,576 --> 00:31:44,006 A:middle
So let's continue
on with the idea

705
00:31:44,006 --> 00:31:45,696 A:middle
that we're developing
a game app.

706
00:31:46,136 --> 00:31:49,756 A:middle
So for game apps usually what
we recommend is that when you're

707
00:31:49,756 --> 00:31:51,106 A:middle
in the foreground, you'll want

708
00:31:51,106 --> 00:31:53,806 A:middle
to have your Audio
Session active.

709
00:31:53,806 --> 00:31:57,246 A:middle
So a good place to make
your Audio Session active is

710
00:31:57,246 --> 00:31:59,836 A:middle
in the app delegate's
applicationDidBecomeActive

711
00:31:59,876 --> 00:32:00,236 A:middle
method.

712

713
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

714
00:31:59,876 --> 00:32:00,236 A:middle
method.

715
00:32:00,816 --> 00:32:03,446 A:middle
So that will cover the case
when you're being launched.

716
00:32:03,826 --> 00:32:06,636 A:middle
If you're coming from the
background into the foreground,

717
00:32:07,246 --> 00:32:08,956 A:middle
or if you are already
in the foreground

718
00:32:09,186 --> 00:32:12,676 A:middle
and the user had swiped
up the control panel

719
00:32:12,676 --> 00:32:15,196 A:middle
and then dismissed it, you'll be
covered in each of those cases.

720
00:32:16,336 --> 00:32:19,466 A:middle
So once you've made your session
active you can leave it active,

721
00:32:19,806 --> 00:32:22,746 A:middle
but you do need to be prepared
to deal with interruptions.

722
00:32:23,866 --> 00:32:25,966 A:middle
So if you get a begin
interruption event,

723
00:32:26,336 --> 00:32:28,446 A:middle
you should update
your internal state

724
00:32:28,446 --> 00:32:29,956 A:middle
so that you know
that you're paused.

725
00:32:31,266 --> 00:32:33,196 A:middle
And then if you get an
end interruption event,

726
00:32:33,956 --> 00:32:36,166 A:middle
that's your opportunity to
make your session active

727
00:32:36,446 --> 00:32:37,626 A:middle
and to resume audio playback.

728
00:32:37,716 --> 00:32:40,446 A:middle
And this is just like the
example that we looked

729
00:32:40,446 --> 00:32:44,156 A:middle
at just a few minutes ago.

730
00:32:44,226 --> 00:32:45,476 A:middle
Media playback apps need

731
00:32:45,476 --> 00:32:48,116 A:middle
to manage their Audio Session
state a little bit differently.

732
00:32:48,776 --> 00:32:50,536 A:middle
So I'm talking about
applications

733
00:32:50,536 --> 00:32:53,856 A:middle
like the built-in music app
or podcast or streaming radio.

734
00:32:53,896 --> 00:32:55,726 A:middle
And these are the
types of applications

735
00:32:55,726 --> 00:32:58,206 A:middle
that we usually have
a play/pause button,

736
00:32:58,326 --> 00:33:01,396 A:middle
and they're what we refer
to as non-mixable meaning

737

738
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

739
00:32:58,326 --> 00:33:01,396 A:middle
and they're what we refer
to as non-mixable meaning

740
00:33:02,236 --> 00:33:03,796 A:middle
that they'll interrupt the audio

741
00:33:03,796 --> 00:33:06,296 A:middle
of other non-mixable
Audio Sessions.

742
00:33:07,416 --> 00:33:09,926 A:middle
So for these types of
applications we recommend

743
00:33:10,086 --> 00:33:12,906 A:middle
that instead of making your
session active immediately

744
00:33:12,906 --> 00:33:14,556 A:middle
when you enter the
foreground that you wait

745
00:33:14,886 --> 00:33:16,516 A:middle
until a user presses
thePplay button.

746
00:33:17,336 --> 00:33:18,586 A:middle
And the reason that we give you

747
00:33:18,586 --> 00:33:21,446 A:middle
that advice is sometimes
the user brings your app

748
00:33:21,526 --> 00:33:22,696 A:middle
into the foreground just to see

749
00:33:22,696 --> 00:33:25,786 A:middle
if they have a particular
podcast episode downloaded

750
00:33:25,786 --> 00:33:27,556 A:middle
or to see if they have
a song in their library.

751
00:33:27,556 --> 00:33:28,936 A:middle
And they don't necessarily want

752
00:33:28,936 --> 00:33:31,096 A:middle
to interrupt other
audio that was playing.

753
00:33:31,496 --> 00:33:33,016 A:middle
So it's good to wait
until they press Play.

754
00:33:34,666 --> 00:33:37,306 A:middle
So like in the case of a game
app once you've made your

755
00:33:37,306 --> 00:33:39,536 A:middle
session active you
can leave it active.

756
00:33:40,236 --> 00:33:41,936 A:middle
But, again, you need
to be prepared

757
00:33:41,936 --> 00:33:42,856 A:middle
to handle interruptions.

758
00:33:44,076 --> 00:33:45,896 A:middle
So if you get a begin
interruption event,

759
00:33:46,396 --> 00:33:47,816 A:middle
you should update your UI.

760
00:33:47,816 --> 00:33:50,176 A:middle
So if you have a play/pause
button it's a good time

761
00:33:50,176 --> 00:33:53,026 A:middle
to change that state
and also keep track

762
00:33:53,026 --> 00:33:54,966 A:middle
of your internal states so that
you know that you're paused.

763
00:33:56,286 --> 00:33:58,596 A:middle
One thing you do not need
to do is you do not need

764
00:33:58,596 --> 00:33:59,836 A:middle
to make your session inactive

765

766
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

767
00:34:00,056 --> 00:34:02,476 A:middle
because the system has
already done that for you.

768
00:34:03,006 --> 00:34:04,236 A:middle
That's what the interruption is.

769
00:34:06,006 --> 00:34:08,496 A:middle
So then if you get an
end interruption event,

770
00:34:09,036 --> 00:34:12,646 A:middle
we ask that you honor
the ShouldResume option.

771
00:34:13,045 --> 00:34:16,386 A:middle
So if this option is part of
the info dictionary that's part

772
00:34:16,386 --> 00:34:19,775 A:middle
of that notification, that's
the system giving you a hint

773
00:34:19,826 --> 00:34:21,516 A:middle
that it's OK to make
your session active

774
00:34:21,616 --> 00:34:23,216 A:middle
and to immediately
resume playback.

775
00:34:23,216 --> 00:34:26,936 A:middle
If you don't see that option
as part of the notification,

776
00:34:26,936 --> 00:34:28,946 A:middle
then you should wait for the
user to press play again.

777
00:34:31,616 --> 00:34:35,416 A:middle
OK. So we talked about for game
apps and media playback apps

778
00:34:35,815 --> 00:34:37,226 A:middle
when you would make
your session active.

779
00:34:37,315 --> 00:34:38,916 A:middle
What about making
your session inactive.

780
00:34:40,436 --> 00:34:44,426 A:middle
So if you are something like
a navigation or a fitness app,

781
00:34:44,946 --> 00:34:49,376 A:middle
you're typically going to be
playing short prompts of audio.

782
00:34:50,045 --> 00:34:54,646 A:middle
And you're going to be using
the duck others category option

783
00:34:55,085 --> 00:34:56,406 A:middle
which will lower the volume

784
00:34:56,516 --> 00:34:58,606 A:middle
of other audio applications
on the system.

785
00:34:58,896 --> 00:35:02,186 A:middle
So it's important when you're
done playing your short prompts

786

787
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

788
00:34:58,896 --> 00:35:02,186 A:middle
So it's important when you're
done playing your short prompts

789
00:35:02,236 --> 00:35:03,676 A:middle
that you make your
session inactive

790
00:35:04,236 --> 00:35:06,946 A:middle
so that the other audio is
able to resume at full volume.

791
00:35:08,076 --> 00:35:14,376 A:middle
If you're a voiceover IP app
or a chat app or maybe one

792
00:35:14,376 --> 00:35:19,446 A:middle
of these apps that has like
kind of like a browser view

793
00:35:19,446 --> 00:35:21,006 A:middle
where you're playing
short videos,

794
00:35:21,706 --> 00:35:25,356 A:middle
then you are usually going to be
what we refer to as non-mixable,

795
00:35:25,356 --> 00:35:27,586 A:middle
meaning that you're going
to interrupt other audio.

796
00:35:28,536 --> 00:35:30,906 A:middle
And so it's important that
when you're done playing audio

797
00:35:30,906 --> 00:35:32,866 A:middle
that you make your
session inactive

798
00:35:33,456 --> 00:35:36,146 A:middle
so that other sessions
are able to resume.

799
00:35:37,866 --> 00:35:42,346 A:middle
And it's a good idea to use
the NotifyOthersOnDeactivation

800
00:35:42,466 --> 00:35:44,446 A:middle
option when you make
your session inactive.

801
00:35:44,646 --> 00:35:47,086 A:middle
And that way the system is able

802
00:35:47,086 --> 00:35:50,536 A:middle
to tell an interrupted
Audio Session

803
00:35:50,536 --> 00:35:52,246 A:middle
that it's OK for them to resume.

804
00:35:52,246 --> 00:35:52,966 A:middle
All right.

805
00:35:53,936 --> 00:35:58,416 A:middle
So now let's shift gears
a little bit and talk

806
00:35:58,416 --> 00:36:02,946 A:middle
about managing your secondary
audio in response to other audio

807

808
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

809
00:35:58,416 --> 00:36:02,946 A:middle
about managing your secondary
audio in response to other audio

810
00:36:02,946 --> 00:36:03,896 A:middle
on the system playing.

811
00:36:04,696 --> 00:36:06,966 A:middle
So first let me explain
what I mean

812
00:36:06,966 --> 00:36:08,886 A:middle
by secondary audio
and primary audio.

813
00:36:09,886 --> 00:36:12,356 A:middle
So let's say we're
developing a game application.

814
00:36:12,876 --> 00:36:16,426 A:middle
Our primary audio is going
to be our sound effects,

815
00:36:16,426 --> 00:36:19,936 A:middle
our explosions, beeps and
bloops, short bits of dialog.

816
00:36:20,586 --> 00:36:23,576 A:middle
And it's the kind of audio that
really enhances the gameplay.

817
00:36:24,366 --> 00:36:28,356 A:middle
And it's also the kind of audio
that, if the user was listening

818
00:36:28,356 --> 00:36:30,926 A:middle
to music when they launched your
app, you still want it to play.

819
00:36:31,336 --> 00:36:35,576 A:middle
And it's OK that it mixes
in with the other music.

820
00:36:35,626 --> 00:36:38,196 A:middle
By secondary audio, I am really
talking about your soundtrack.

821
00:36:38,856 --> 00:36:41,776 A:middle
This is the audio where it
also enhances the gameplay,

822
00:36:42,326 --> 00:36:45,436 A:middle
but if the user was previously
listening to their music

823
00:36:45,436 --> 00:36:46,966 A:middle
or their podcast, you'd just

824
00:36:46,966 --> 00:36:48,556 A:middle
as soon have your
soundtrack be muted.

825
00:36:49,586 --> 00:36:53,366 A:middle
And then if the user
stops their music playback

826
00:36:53,366 --> 00:36:55,986 A:middle
on their podcast then you'd like
to have your soundtrack resume.

827
00:36:57,146 --> 00:37:01,876 A:middle
So in iOS 8 we've added a bit
of new API to help you do this.

828

829
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

830
00:36:57,146 --> 00:37:01,876 A:middle
So in iOS 8 we've added a bit
of new API to help you do this.

831
00:37:02,336 --> 00:37:04,626 A:middle
We've added a new property
and a new notification.

832
00:37:05,686 --> 00:37:08,166 A:middle
The property is called
secondaryAudio

833
00:37:08,166 --> 00:37:09,356 A:middle
ShouldBeSilencedHint.

834
00:37:09,356 --> 00:37:13,456 A:middle
As the name implies, it's a hint
that the system is giving you

835
00:37:13,966 --> 00:37:16,736 A:middle
that it's a good time to
mute your secondary audio.

836
00:37:17,746 --> 00:37:20,806 A:middle
So this is meant to be used by
apps that are in the foreground.

837
00:37:21,976 --> 00:37:24,606 A:middle
And we recommend that you
would check this property

838
00:37:24,606 --> 00:37:26,656 A:middle
in applicationDidBecomeActive.

839
00:37:27,286 --> 00:37:30,366 A:middle
Going along with the
new property is our

840
00:37:30,366 --> 00:37:31,336 A:middle
new notification.

841
00:37:32,506 --> 00:37:35,886 A:middle
This is the AVAudioSession
SilenceSecondary

842
00:37:35,886 --> 00:37:37,086 A:middle
AudioHintNotification.

843
00:37:37,206 --> 00:37:39,546 A:middle
Another mouthful for this
early in the morning.

844
00:37:40,256 --> 00:37:43,506 A:middle
So this notification will be
delivered to apps that are

845
00:37:43,506 --> 00:37:45,436 A:middle
in the foreground with
active Audio Sessions.

846
00:37:46,406 --> 00:37:47,776 A:middle
And it's kind of similar

847
00:37:47,776 --> 00:37:50,696 A:middle
to our interruption notification
that it's two-sided.

848
00:37:50,786 --> 00:37:54,586 A:middle
There's a begin event, there's
an end event all wrapped

849
00:37:54,586 --> 00:37:56,056 A:middle
up in the same notification.

850
00:37:57,066 --> 00:38:00,656 A:middle
So when you get a
begin SilenceSecondary

851

852
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

853
00:37:57,066 --> 00:38:00,656 A:middle
So when you get a
begin SilenceSecondary

854
00:38:00,656 --> 00:38:03,446 A:middle
AudioHintNotification that
means that it's a good time

855
00:38:03,446 --> 00:38:04,856 A:middle
to mute your secondary audio.

856
00:38:05,266 --> 00:38:07,326 A:middle
And if you get the end
event it's a good time

857
00:38:07,326 --> 00:38:08,696 A:middle
to resume your soundtrack.

858
00:38:09,526 --> 00:38:11,306 A:middle
So let's look at what
this looks like in action.

859
00:38:12,696 --> 00:38:15,716 A:middle
So on the far right we have
the built-in music app,

860
00:38:15,716 --> 00:38:17,546 A:middle
and it's currently
in the background.

861
00:38:17,546 --> 00:38:18,506 A:middle
It's not playing audio.

862
00:38:19,826 --> 00:38:22,676 A:middle
On the far left we have our
game app that we're developing.

863
00:38:23,346 --> 00:38:26,126 A:middle
So we're playing our primary
audio, the sound effects,

864
00:38:26,126 --> 00:38:27,616 A:middle
and we're also playing
our soundtrack

865
00:38:27,906 --> 00:38:29,736 A:middle
because there was no
other music playing.

866
00:38:30,816 --> 00:38:33,776 A:middle
And in the middle we have iOS
helping to negotiate things.

867
00:38:34,886 --> 00:38:38,736 A:middle
So the user has his
headphones plugged in,

868
00:38:38,736 --> 00:38:40,306 A:middle
and he presses that
middle button.

869
00:38:41,026 --> 00:38:43,556 A:middle
And the music app responds
to remote control events.

870
00:38:43,556 --> 00:38:46,556 A:middle
So it uses that as a
signal to begin playback.

871
00:38:47,906 --> 00:38:50,556 A:middle
The music app also informs iOS

872
00:38:50,556 --> 00:38:52,556 A:middle
that it's using its
audio output.

873
00:38:53,496 --> 00:38:57,376 A:middle
And so then the system is able
to send a begin notification

874
00:38:57,376 --> 00:38:58,856 A:middle
to our app that's
in the foreground.

875
00:38:59,606 --> 00:39:02,076 A:middle
And in response to that we
can mute our soundtrack.

876

877
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

878
00:38:59,606 --> 00:39:02,076 A:middle
And in response to that we
can mute our soundtrack.

879
00:39:02,846 --> 00:39:04,946 A:middle
So our app is still
in the foreground.

880
00:39:04,946 --> 00:39:06,426 A:middle
The only thing that's
really changed is

881
00:39:06,426 --> 00:39:11,246 A:middle
that the user used their middle
button to play their music.

882
00:39:12,656 --> 00:39:14,816 A:middle
And we've responded
to the notification

883
00:39:14,816 --> 00:39:15,746 A:middle
that we got from the system.

884
00:39:17,576 --> 00:39:18,816 A:middle
So now some time passes.

885
00:39:18,896 --> 00:39:20,246 A:middle
We're in this state for a while,

886
00:39:20,246 --> 00:39:22,416 A:middle
and the user presses
the middle button again.

887
00:39:22,856 --> 00:39:26,916 A:middle
So the music app responds
by pausing its playback

888
00:39:27,216 --> 00:39:29,866 A:middle
and telling the system that
it's pausing its audio output.

889
00:39:29,866 --> 00:39:33,906 A:middle
And then the system is able
to send the end notification

890
00:39:33,906 --> 00:39:35,966 A:middle
to our app that's still
in the foreground.

891
00:39:35,966 --> 00:39:39,066 A:middle
And in response to that,
we resume our soundtrack.

892
00:39:40,046 --> 00:39:45,286 A:middle
So hopefully this will
be pretty easy to use.

893
00:39:45,286 --> 00:39:48,596 A:middle
There's one new property and
then the two-sided notification

894
00:39:48,596 --> 00:39:50,186 A:middle
that you can use to
manage your soundtrack.

895
00:39:51,876 --> 00:39:56,976 A:middle
So kind of on a similar thread,
in the past we've given advice

896
00:39:57,056 --> 00:40:00,916 A:middle
about how you could manage
your secondary audio based

897

898
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

899
00:39:57,056 --> 00:40:00,916 A:middle
about how you could manage
your secondary audio based

900
00:40:00,916 --> 00:40:03,016 A:middle
on the isOtherAudioPlaying
property.

901
00:40:03,796 --> 00:40:07,066 A:middle
And we had given
advice about choosing

902
00:40:07,066 --> 00:40:10,536 A:middle
between the ambient category
or solo ambient based

903
00:40:10,536 --> 00:40:12,246 A:middle
on the state of this property.

904
00:40:13,046 --> 00:40:15,846 A:middle
What we're recommending now
is that if you're this type

905
00:40:15,846 --> 00:40:18,336 A:middle
of application, that you
just use the ambient category

906
00:40:18,336 --> 00:40:21,396 A:middle
and then use the new property
and the new notification

907
00:40:21,556 --> 00:40:22,586 A:middle
to manage your soundtrack.

908
00:40:23,246 --> 00:40:23,396 A:middle
All right.

909
00:40:23,396 --> 00:40:25,206 A:middle
I'm going to hand things
over to Doug Wyatt.

910
00:40:25,256 --> 00:40:27,146 A:middle
He's going to tell us about
some new utility classes

911
00:40:27,146 --> 00:40:27,896 A:middle
in AV Foundation.

912
00:40:28,686 --> 00:40:29,276 A:middle
>> Thank you.

913
00:40:29,276 --> 00:40:29,796 A:middle
Good morning.

914
00:40:29,796 --> 00:40:30,506 A:middle
I'm Doug Wyatt.

915
00:40:30,506 --> 00:40:32,186 A:middle
I'm an engineer in
the Core Audio Group,

916
00:40:32,816 --> 00:40:35,276 A:middle
and I'd like to talk to you
about some new audio classes

917
00:40:35,326 --> 00:40:37,016 A:middle
in the AV Foundation framework.

918
00:40:38,596 --> 00:40:41,986 A:middle
I'll give you, we'll start
out with some background

919
00:40:41,986 --> 00:40:43,676 A:middle
and tell you what
we're up to and why.

920
00:40:44,856 --> 00:40:47,266 A:middle
Then we'll start looking through
these classes one by one.

921
00:40:47,356 --> 00:40:49,846 A:middle
And I'll tie things up at
the end with an example.

922
00:40:50,666 --> 00:40:54,596 A:middle
So in the past our CoreAudio
and AudioToolbox APIs,

923
00:40:54,596 --> 00:40:57,746 A:middle
they're very powerful, but
they're not always easy

924
00:40:57,856 --> 00:41:01,066 A:middle
for developers to get their
hands around at the beginning.

925

926
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

927
00:40:57,856 --> 00:41:01,066 A:middle
for developers to get their
hands around at the beginning.

928
00:41:01,706 --> 00:41:03,086 A:middle
We've tried to work around this

929
00:41:03,166 --> 00:41:07,206 A:middle
by providing some C++
utility classes in our SDK,

930
00:41:07,206 --> 00:41:09,756 A:middle
and that's helped
to some extent,

931
00:41:10,356 --> 00:41:13,786 A:middle
but example code
gets copied around.

932
00:41:13,786 --> 00:41:14,996 A:middle
It evolves over time.

933
00:41:15,536 --> 00:41:18,256 A:middle
And we think it's best in
the long run if we sort

934
00:41:18,256 --> 00:41:20,956 A:middle
of solidify these things
in the form of API,

935
00:41:20,956 --> 00:41:23,746 A:middle
and that's what we're
providing now with these classes

936
00:41:23,746 --> 00:41:26,006 A:middle
in the AV Foundation
framework starting

937
00:41:26,006 --> 00:41:30,766 A:middle
with Mac OS X 10.10 and iOS 8.

938
00:41:31,496 --> 00:41:34,676 A:middle
So our goals here, we don't want

939
00:41:34,676 --> 00:41:36,366 A:middle
to make a complete
break with the past.

940
00:41:36,616 --> 00:41:40,916 A:middle
We want to build on
what we've already got.

941
00:41:41,106 --> 00:41:44,716 A:middle
So we're going to,
in many cases,

942
00:41:44,716 --> 00:41:47,596 A:middle
wrap our existing
low-level C structures inside

943
00:41:47,596 --> 00:41:48,966 A:middle
Objective-C objects.

944
00:41:49,576 --> 00:41:53,006 A:middle
And in doing so, these lower
level C structures become easier

945
00:41:53,006 --> 00:41:53,446 A:middle
to build.

946
00:41:53,446 --> 00:41:57,326 A:middle
But we can also extract them
from our Objective-C objects

947
00:41:57,326 --> 00:42:00,726 A:middle
and pass them to the low-level
APIs we might already be using.

948

949
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

950
00:41:57,326 --> 00:42:00,726 A:middle
and pass them to the low-level
APIs we might already be using.

951
00:42:02,006 --> 00:42:05,786 A:middle
And this is a philosophy we used
also with the AVAudioEngine,

952
00:42:06,386 --> 00:42:09,866 A:middle
which we'll be examining in more
detail in the next session here.

953
00:42:10,496 --> 00:42:13,486 A:middle
And I should also mention an
overriding goal here is for us

954
00:42:13,516 --> 00:42:14,956 A:middle
to stay real-time safe,

955
00:42:14,956 --> 00:42:17,046 A:middle
which isn't always
easy with Objective-C.

956
00:42:17,476 --> 00:42:21,336 A:middle
We can't access methods
for properties

957
00:42:21,646 --> 00:42:23,146 A:middle
on the audio rendering thread.

958
00:42:23,826 --> 00:42:25,726 A:middle
So we've taken some
great care to do

959
00:42:25,726 --> 00:42:29,476 A:middle
that in our implementations and
as we go I'll give you a couple

960
00:42:29,476 --> 00:42:33,726 A:middle
of examples of places where
you need to do this to be aware

961
00:42:33,726 --> 00:42:35,966 A:middle
of real-time issues when
you're using these classes.

962
00:42:36,536 --> 00:42:40,386 A:middle
OK. So here are the
classes we'll be looking

963
00:42:40,386 --> 00:42:42,756 A:middle
at today in this session.

964
00:42:43,286 --> 00:42:47,026 A:middle
At the bottom in green
we've got AVAudioFormat,

965
00:42:47,766 --> 00:42:49,606 A:middle
which has an
AVAudioChannelLayout.

966
00:42:51,556 --> 00:42:53,706 A:middle
In blue we have
AVAudioPCMBuffer,

967
00:42:53,706 --> 00:42:55,316 A:middle
which has an audio format.

968
00:42:55,316 --> 00:42:58,186 A:middle
Every buffer has a
format describing it.

969
00:42:58,666 --> 00:43:01,346 A:middle
And finally we'll be
talking about AVAudioFile,

970

971
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

972
00:42:58,666 --> 00:43:01,346 A:middle
And finally we'll be
talking about AVAudioFile,

973
00:43:01,536 --> 00:43:04,276 A:middle
which uses AVAudioPCMBuffer
for I/O

974
00:43:04,736 --> 00:43:07,916 A:middle
and as you would expect the
file also has format objects

975
00:43:08,056 --> 00:43:10,586 A:middle
describing the file's
data format.

976
00:43:11,176 --> 00:43:16,056 A:middle
So first let's look
at AVAudioFormat.

977
00:43:17,186 --> 00:43:21,266 A:middle
This class describes the actual
format of data you might find

978
00:43:21,266 --> 00:43:25,476 A:middle
in an audio file or stream
and also the audio you,

979
00:43:25,476 --> 00:43:28,446 A:middle
the format of the audio
you might be passing

980
00:43:28,446 --> 00:43:29,766 A:middle
to and from APIs.

981
00:43:30,326 --> 00:43:32,386 A:middle
So our low-level structure here

982
00:43:32,386 --> 00:43:34,476 A:middle
for describing an
audio format is an

983
00:43:34,476 --> 00:43:36,166 A:middle
AudioStreamBasicDescription,

984
00:43:36,686 --> 00:43:39,486 A:middle
which in retrospect might have
been called "audio stream not

985
00:43:39,486 --> 00:43:41,976 A:middle
so basic" or "audio stream
complete description"

986
00:43:42,476 --> 00:43:44,036 A:middle
because there's a
lot of fields there,

987
00:43:44,036 --> 00:43:46,536 A:middle
and it can be a little
challenging to get them all set

988
00:43:46,536 --> 00:43:49,066 A:middle
up consistently especially
for PCM formats.

989
00:43:49,606 --> 00:43:52,166 A:middle
But, you know, the beauty
of this structure is

990
00:43:52,226 --> 00:43:57,546 A:middle
that it describes just about
everything we would want to use

991
00:43:57,596 --> 00:43:59,206 A:middle
to describe an audio format.

992
00:43:59,856 --> 00:44:01,576 A:middle
But, again, it's a
little challenging.

993

994
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

995
00:43:59,856 --> 00:44:01,576 A:middle
But, again, it's a
little challenging.

996
00:44:02,066 --> 00:44:05,476 A:middle
But, in any case, you can
always create an AVAudioFormat

997
00:44:05,736 --> 00:44:07,526 A:middle
from an
AudioStreamBasicDescription,

998
00:44:07,526 --> 00:44:09,556 A:middle
which you might have
obtained from a low-level API.

999
00:44:10,246 --> 00:44:12,846 A:middle
And you can always access
a stream description

1000
00:44:13,246 --> 00:44:14,636 A:middle
from an AVAudioFormat.

1001
00:44:15,346 --> 00:44:18,666 A:middle
But now we can move
on to other ways

1002
00:44:18,726 --> 00:44:20,396 A:middle
to interact with AVAudioFormat.

1003
00:44:22,416 --> 00:44:28,976 A:middle
So in the past we've had this
concept of canonical formats.

1004
00:44:29,616 --> 00:44:32,426 A:middle
And this concept goes
back to about 2002

1005
00:44:32,426 --> 00:44:34,956 A:middle
in Mac OS 10.0 or 10.1 or so.

1006
00:44:35,766 --> 00:44:39,736 A:middle
So this format was
floating-point, 32-bit,

1007
00:44:40,036 --> 00:44:43,116 A:middle
de-interleaved, but then
we got along to iOS,

1008
00:44:43,356 --> 00:44:46,696 A:middle
and we couldn't really
recommend using float everywhere

1009
00:44:46,696 --> 00:44:48,496 A:middle
because we didn't have the
greatest floating-point

1010
00:44:48,496 --> 00:44:49,576 A:middle
performance initially.

1011
00:44:50,026 --> 00:44:54,866 A:middle
So for a while canonical
was 8.24 fixed-point.

1012
00:44:55,986 --> 00:44:58,646 A:middle
But because of that
schism we want to reunite

1013
00:44:58,646 --> 00:45:00,166 A:middle
under something new now.

1014

1015
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1016
00:44:58,646 --> 00:45:00,166 A:middle
under something new now.

1017
00:45:00,456 --> 00:45:03,266 A:middle
We've deprecated the
concept of canonical formats.

1018
00:45:03,666 --> 00:45:05,516 A:middle
Now we have what we
call a standard format.

1019
00:45:05,856 --> 00:45:09,776 A:middle
We're back to non-interleaved
32-bit floats on both platforms.

1020
00:45:10,136 --> 00:45:12,556 A:middle
So this is the simplest way

1021
00:45:12,556 --> 00:45:15,296 A:middle
to construct an AVAudioFormat
now is with,

1022
00:45:16,166 --> 00:45:17,856 A:middle
you can create a standard format

1023
00:45:17,906 --> 00:45:20,316 A:middle
by specifying just a sample
rate and a channel count.

1024
00:45:21,776 --> 00:45:24,926 A:middle
You can also query any
AVAudioFormat you might come

1025
00:45:24,926 --> 00:45:28,416 A:middle
across and find out if it is
a standard format using the

1026
00:45:28,416 --> 00:45:29,346 A:middle
standard property.

1027
00:45:32,166 --> 00:45:38,336 A:middle
We've also provided for
using Common Formats

1028
00:45:38,816 --> 00:45:40,276 A:middle
with AVAudioFormat.

1029
00:45:40,406 --> 00:45:43,726 A:middle
And we define Common Formats
as formats you would often use

1030
00:45:43,726 --> 00:45:46,726 A:middle
in signal processing
such as 16-bit integers

1031
00:45:47,236 --> 00:45:50,216 A:middle
if you've been using that
on iOS or other platforms.

1032
00:45:50,786 --> 00:45:52,866 A:middle
We also provide for
64-bit floats.

1033
00:45:53,126 --> 00:45:56,436 A:middle
And it's very easy to create
an AVAudioFormat in one

1034
00:45:56,436 --> 00:45:59,646 A:middle
of these formats by
specifying which one you want,

1035
00:45:59,776 --> 00:46:01,936 A:middle
the sample rate channel count,
and whether it's inter-leaved.

1036

1037
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1038
00:45:59,776 --> 00:46:01,936 A:middle
the sample rate channel count,
and whether it's inter-leaved.

1039
00:46:02,606 --> 00:46:05,936 A:middle
You can query any format to
see if it is some common format

1040
00:46:06,356 --> 00:46:10,246 A:middle
or something else using
the Common Format property.

1041
00:46:10,916 --> 00:46:15,826 A:middle
OK. So that's AVAudioFormat.

1042
00:46:15,826 --> 00:46:17,586 A:middle
Let's look at
AVAudioChannelLayout.

1043
00:46:19,866 --> 00:46:22,936 A:middle
Briefly here, this describes
the ordering or the roles

1044
00:46:22,936 --> 00:46:25,376 A:middle
of multiple channels, which
is especially important,

1045
00:46:25,606 --> 00:46:27,006 A:middle
for example, in surround sound.

1046
00:46:27,416 --> 00:46:30,246 A:middle
You might have left, right,
center, or you might have left,

1047
00:46:30,246 --> 00:46:32,376 A:middle
center, right, and so on.

1048
00:46:32,376 --> 00:46:34,866 A:middle
It's important to know the
actual order of the channels.

1049
00:46:35,446 --> 00:46:39,226 A:middle
So every AVAudioFormat may
have an AVAudioChannelLayout.

1050
00:46:39,226 --> 00:46:42,216 A:middle
And, in fact, when
constructing the AVAudioFormat,

1051
00:46:42,806 --> 00:46:45,556 A:middle
if you were describing three
or more channels you have

1052
00:46:45,586 --> 00:46:46,966 A:middle
to tell us what the layout is.

1053
00:46:47,356 --> 00:46:51,096 A:middle
So it becomes unambiguous to
anyplace else in the system

1054
00:46:51,096 --> 00:46:53,386 A:middle
that sees that AVAudioFormat
what the order

1055
00:46:53,386 --> 00:46:54,546 A:middle
of the channels are.

1056
00:46:55,656 --> 00:46:59,126 A:middle
So the underlying
AudioChannelLayout object is

1057
00:46:59,316 --> 00:47:00,966 A:middle
pretty much exposed
the way it is here.

1058

1059
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1060
00:46:59,316 --> 00:47:00,966 A:middle
pretty much exposed
the way it is here.

1061
00:47:00,966 --> 00:47:03,386 A:middle
You can go look at that
in the CoreAudioTypes.h,

1062
00:47:03,476 --> 00:47:04,976 A:middle
but we have wrapped that up

1063
00:47:04,976 --> 00:47:07,276 A:middle
in the AVAudioChannelLayout
for you.

1064
00:47:08,006 --> 00:47:14,466 A:middle
OK. Moving on let's look
at AVAudioPCMBuffer.

1065
00:47:20,026 --> 00:47:24,106 A:middle
So buffer can be a sort of
funny term when we're dealing

1066
00:47:24,106 --> 00:47:25,376 A:middle
with de-interleaved audio

1067
00:47:25,376 --> 00:47:27,686 A:middle
because of the audioBufferList
structure,

1068
00:47:28,196 --> 00:47:32,076 A:middle
but that aside you can
think of it simply as memory

1069
00:47:32,136 --> 00:47:33,476 A:middle
for storing your audio data

1070
00:47:33,566 --> 00:47:36,336 A:middle
in any format including
non-interleaved formats.

1071
00:47:36,646 --> 00:47:40,816 A:middle
And here at the low-level
structures, which these ones

1072
00:47:40,816 --> 00:47:43,856 A:middle
in particular can also be
a bit of a bother to deal

1073
00:47:43,856 --> 00:47:46,836 A:middle
with because AudioBufferList
is variable length.

1074
00:47:47,396 --> 00:47:50,226 A:middle
So you can simply create
an AVAudioPCMBuffer.

1075
00:47:50,506 --> 00:47:54,256 A:middle
It'll create an audioBufferList
for you of the right size.

1076
00:47:54,906 --> 00:47:58,186 A:middle
And you can always fetch it back
out of the AVAudioPCMBuffer.

1077
00:47:58,776 --> 00:48:02,526 A:middle
Here's the initializer.

1078

1079
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1080
00:47:58,776 --> 00:48:02,526 A:middle
Here's the initializer.

1081
00:48:03,096 --> 00:48:06,206 A:middle
So to create a buffer
you specify the format

1082
00:48:06,476 --> 00:48:09,016 A:middle
and a capacity in
audio sample frames.

1083
00:48:10,166 --> 00:48:14,186 A:middle
You can always fetch back the
buffer's format and the capacity

1084
00:48:14,186 --> 00:48:15,586 A:middle
with which it was constructed.

1085
00:48:16,506 --> 00:48:21,086 A:middle
And unlike audioBufferList,
which has a simple byte size

1086
00:48:21,216 --> 00:48:24,496 A:middle
for every buffer, here
we've separated the concept

1087
00:48:24,496 --> 00:48:25,686 A:middle
of capacity and length.

1088
00:48:26,206 --> 00:48:28,916 A:middle
So there's the fixed
capacity it was created with

1089
00:48:29,456 --> 00:48:32,006 A:middle
and the frame length,
which expresses the number

1090
00:48:32,006 --> 00:48:36,226 A:middle
of currently valid
frames in the buffer.

1091
00:48:36,776 --> 00:48:38,486 A:middle
Some more methods here.

1092
00:48:38,646 --> 00:48:42,516 A:middle
To get to the underlying samples
we provide these simple type

1093
00:48:42,516 --> 00:48:43,856 A:middle
safe assessors.

1094
00:48:45,566 --> 00:48:49,326 A:middle
And this is a good
time now to say a word

1095
00:48:49,326 --> 00:48:52,376 A:middle
about real-time safety
because these are properties.

1096
00:48:52,376 --> 00:48:55,026 A:middle
And as useful as they may be for
actually getting to the data,

1097
00:48:55,426 --> 00:48:58,196 A:middle
since they're properties they
may involve a method lookup,

1098
00:48:58,866 --> 00:49:04,006 A:middle
which can, in principle,
take a miss on the lookup

1099

1100
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1101
00:48:58,866 --> 00:49:04,006 A:middle
which can, in principle,
take a miss on the lookup

1102
00:49:04,416 --> 00:49:06,456 A:middle
and cause you to block.

1103
00:49:06,676 --> 00:49:09,986 A:middle
So if you're going to be
using AVAudioPCMBuffers

1104
00:49:09,986 --> 00:49:13,966 A:middle
on audio real-time threads,
it's best to cache these members

1105
00:49:14,536 --> 00:49:17,286 A:middle
in some safe context when you're
first looking at the buffer

1106
00:49:18,136 --> 00:49:22,526 A:middle
and use those cached members
on the real-time thread.

1107
00:49:23,416 --> 00:49:27,316 A:middle
OK. That's PCM Buffer.

1108
00:49:27,316 --> 00:49:28,776 A:middle
Now we can look at AudioFile,

1109
00:49:28,816 --> 00:49:31,216 A:middle
which wraps all these
other classes together.

1110
00:49:33,376 --> 00:49:35,886 A:middle
So here we let you
read and write files

1111
00:49:35,886 --> 00:49:37,866 A:middle
of any CoreAudio
supported format.

1112
00:49:37,906 --> 00:49:42,546 A:middle
This ranges from .M4A,
.MP4, .WAV, .CAF, .AIFF,

1113
00:49:42,546 --> 00:49:45,816 A:middle
and more I can't
think of right now.

1114
00:49:46,106 --> 00:49:51,266 A:middle
So in accessing the file, here
we give you a single way to read

1115
00:49:51,266 --> 00:49:54,396 A:middle
and write the file
completely independent

1116
00:49:54,396 --> 00:49:56,176 A:middle
of the file's actual
data format.

1117
00:49:56,586 --> 00:50:00,766 A:middle
So if it's an encoded format
like AAC or Apple Lossless

1118

1119
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1120
00:49:56,586 --> 00:50:00,766 A:middle
So if it's an encoded format
like AAC or Apple Lossless

1121
00:50:00,766 --> 00:50:04,406 A:middle
or MP3, if there's a
codec on the system,

1122
00:50:04,406 --> 00:50:07,766 A:middle
and in most cases there is,
we will, transparently to you,

1123
00:50:07,766 --> 00:50:11,206 A:middle
decode from that format
as you read the file.

1124
00:50:12,676 --> 00:50:15,806 A:middle
Similarly when you're writing
an audio file we will encode

1125
00:50:15,806 --> 00:50:19,106 A:middle
from PCM into that encoded
format if we have an encoder.

1126
00:50:21,146 --> 00:50:23,696 A:middle
So to do this, the
file has this concept

1127
00:50:23,696 --> 00:50:25,146 A:middle
of the processing format.

1128
00:50:25,696 --> 00:50:28,766 A:middle
And the processing format
is simply the PCM format

1129
00:50:29,086 --> 00:50:31,236 A:middle
with which you will
interact with the file.

1130
00:50:32,076 --> 00:50:35,736 A:middle
So you specify the PCM format
when you create the file,

1131
00:50:35,816 --> 00:50:38,646 A:middle
and it has to be either a
standard or common format.

1132
00:50:39,676 --> 00:50:41,066 A:middle
The only limitation here is

1133
00:50:41,156 --> 00:50:44,046 A:middle
that we don't permit sample
rate conversion as you read

1134
00:50:44,046 --> 00:50:45,826 A:middle
from or write to a file.

1135
00:50:46,076 --> 00:50:47,716 A:middle
Your processing format
needs to be

1136
00:50:47,716 --> 00:50:50,466 A:middle
at the same sample rate
as the file itself.

1137
00:50:51,006 --> 00:50:53,996 A:middle
Now, if you're familiar with
the Audio Toolbox Extended Audio

1138
00:50:53,996 --> 00:50:56,426 A:middle
File API, this is
functionally very similar,

1139
00:50:56,766 --> 00:50:59,906 A:middle
and it's just a bit
simpler to use.

1140

1141
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1142
00:51:00,556 --> 00:51:04,446 A:middle
So I'm looking now
at the initializers

1143
00:51:05,046 --> 00:51:07,776 A:middle
and some assessors
for AVAudioFile.

1144
00:51:07,896 --> 00:51:10,366 A:middle
Here's the initializer
for reading from a file.

1145
00:51:10,626 --> 00:51:14,246 A:middle
If you don't specify a
processing format you simply

1146
00:51:14,246 --> 00:51:18,436 A:middle
are, you get the
default behavior,

1147
00:51:18,436 --> 00:51:20,456 A:middle
which is that your
processing format will be a

1148
00:51:20,456 --> 00:51:21,466 A:middle
standard format.

1149
00:51:23,796 --> 00:51:27,476 A:middle
Very similarly to creating
an AVAudioFile for writing,

1150
00:51:27,536 --> 00:51:29,236 A:middle
the only extra information
you need

1151
00:51:29,236 --> 00:51:30,916 A:middle
to give us is a settings
dictionary.

1152
00:51:31,326 --> 00:51:33,516 A:middle
This is the same
settings dictionary passed

1153
00:51:33,516 --> 00:51:35,006 A:middle
to AV Audio Recorder.

1154
00:51:35,536 --> 00:51:37,226 A:middle
And in there there are keys,

1155
00:51:37,646 --> 00:51:41,366 A:middle
which specify the file format
you want to use, and in the case

1156
00:51:41,366 --> 00:51:45,036 A:middle
of example, for example AAC
you can specify the bit rate

1157
00:51:45,446 --> 00:51:46,966 A:middle
and any other encoder settings.

1158
00:51:47,016 --> 00:51:48,836 A:middle
Those are in the
settings dictionary.

1159
00:51:50,776 --> 00:51:55,726 A:middle
So once you've built a file
you can always access back the

1160
00:51:55,726 --> 00:51:57,826 A:middle
actual file format on disk.

1161
00:51:58,186 --> 00:52:03,026 A:middle
So that might be, for example,
AAC, 44 kHz, two channels.

1162

1163
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1164
00:51:58,186 --> 00:52:03,026 A:middle
So that might be, for example,
AAC, 44 kHz, two channels.

1165
00:52:03,396 --> 00:52:06,446 A:middle
But you can also query
the processing format

1166
00:52:07,056 --> 00:52:08,476 A:middle
with which you created the file.

1167
00:52:08,756 --> 00:52:12,726 A:middle
And in the case of the
two simplest initializers,

1168
00:52:13,446 --> 00:52:16,716 A:middle
this would be floating-point,
32-bit,

1169
00:52:16,866 --> 00:52:18,316 A:middle
same sample rate as the file.

1170
00:52:18,446 --> 00:52:20,176 A:middle
Same channel count as the file.

1171
00:52:22,726 --> 00:52:24,826 A:middle
OK. So to read and write

1172
00:52:24,886 --> 00:52:28,506 A:middle
from AVAudioFiles there's a
simple method, readIntoBuffer,

1173
00:52:28,656 --> 00:52:31,596 A:middle
and that will simply
fill the AVAudioPCMBuffer

1174
00:52:31,686 --> 00:52:33,806 A:middle
to its capacity assuming
you have,

1175
00:52:33,876 --> 00:52:34,996 A:middle
you don't hit the end of file.

1176
00:52:36,986 --> 00:52:39,256 A:middle
writeFromBuffer is a
little in that it looks

1177
00:52:39,256 --> 00:52:43,546 A:middle
like the buffer is frame length
rather than the capacity,

1178
00:52:43,546 --> 00:52:45,716 A:middle
so it writes all
of the valid frames

1179
00:52:46,346 --> 00:52:47,996 A:middle
from that buffer to the file.

1180
00:52:49,886 --> 00:52:53,816 A:middle
And you can do random access I/O
when reading from audio files.

1181
00:52:54,486 --> 00:52:57,496 A:middle
So this is like the
standard C-library's seek

1182
00:52:57,496 --> 00:53:00,946 A:middle
and tell functions,
F seek and F tell.

1183

1184
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1185
00:52:57,496 --> 00:53:00,946 A:middle
and tell functions,
F seek and F tell.

1186
00:53:01,786 --> 00:53:04,346 A:middle
You can query the frame
position to see where you are

1187
00:53:04,346 --> 00:53:05,586 A:middle
when reading an audio file.

1188
00:53:06,126 --> 00:53:09,946 A:middle
And you can also seek to a
different position in the file

1189
00:53:09,946 --> 00:53:13,596 A:middle
by setting the frame position
pointer before you read.

1190
00:53:14,026 --> 00:53:17,416 A:middle
And the next read will proceed
sequentially from that point.

1191
00:53:18,216 --> 00:53:24,846 A:middle
OK. I'd like to tie all
these classes together now

1192
00:53:24,846 --> 00:53:25,896 A:middle
with this short example.

1193
00:53:26,186 --> 00:53:27,526 A:middle
And I've got four screens here.

1194
00:53:27,526 --> 00:53:31,476 A:middle
We'll see what it's like
to open an audio file,

1195
00:53:31,476 --> 00:53:34,866 A:middle
extract some basic
information from it and read

1196
00:53:34,866 --> 00:53:36,576 A:middle
through every sample
in the file.

1197
00:53:36,966 --> 00:53:39,406 A:middle
So here we have initForReading.

1198
00:53:39,956 --> 00:53:41,396 A:middle
We simply pass the URL.

1199
00:53:41,936 --> 00:53:44,626 A:middle
I'm using the variant
here that's explicit,

1200
00:53:44,626 --> 00:53:47,416 A:middle
but I'm passing PCM
Float 32 always.

1201
00:53:47,786 --> 00:53:50,736 A:middle
I could have left those off
and gotten a standard format.

1202
00:53:53,676 --> 00:53:56,296 A:middle
I'm going to fetch some basic
information from the file

1203
00:53:56,296 --> 00:54:00,356 A:middle
and print it, including
the files on disk format

1204

1205
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1206
00:53:56,296 --> 00:54:00,356 A:middle
and print it, including
the files on disk format

1207
00:54:00,496 --> 00:54:01,926 A:middle
and the processing format.

1208
00:54:03,056 --> 00:54:05,326 A:middle
I can query the audio
file's length

1209
00:54:05,326 --> 00:54:07,326 A:middle
and frames, sample frames.

1210
00:54:08,166 --> 00:54:12,306 A:middle
And I can convert that length in
frames to a duration by dividing

1211
00:54:12,306 --> 00:54:13,596 A:middle
by the file's sample rate.

1212
00:54:14,006 --> 00:54:17,016 A:middle
OK. Next I'm going to create
a PCM Buffer to read from.

1213
00:54:17,676 --> 00:54:20,286 A:middle
Since the file might be
large, I don't want to try

1214
00:54:20,286 --> 00:54:21,906 A:middle
to read it all into
memory at once.

1215
00:54:22,046 --> 00:54:25,546 A:middle
So I'm going to loop through it
128K sample frames at a time.

1216
00:54:26,336 --> 00:54:28,656 A:middle
So I'm going to create a
buffer with that capacity.

1217
00:54:30,216 --> 00:54:31,176 A:middle
And notice I'm just going

1218
00:54:31,176 --> 00:54:33,646 A:middle
to pass the audio files
processing format.

1219
00:54:34,596 --> 00:54:36,856 A:middle
When allocating this
buffer, and that ensures

1220
00:54:36,856 --> 00:54:38,616 A:middle
that the buffer is
the same format

1221
00:54:38,616 --> 00:54:42,036 A:middle
that the file will be giving me.

1222
00:54:43,226 --> 00:54:47,276 A:middle
And here I'm ready to start
reading through the file.

1223
00:54:47,516 --> 00:54:51,346 A:middle
And I'm going to read one buffer
at a time until I get to the end

1224
00:54:51,876 --> 00:54:55,066 A:middle
so I can query the current frame
position and to see if it's less

1225
00:54:55,166 --> 00:54:57,516 A:middle
than the length I
discovered earlier.

1226
00:54:58,476 --> 00:55:00,016 A:middle
I can read into buffer,

1227

1228
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1229
00:54:58,476 --> 00:55:00,016 A:middle
I can read into buffer,

1230
00:55:00,016 --> 00:55:02,706 A:middle
which will again fill
the buffer to capacity.

1231
00:55:03,896 --> 00:55:06,456 A:middle
I can double check to
see if I'm done by seeing

1232
00:55:06,456 --> 00:55:07,946 A:middle
if I got a zero length buffer.

1233
00:55:10,306 --> 00:55:15,766 A:middle
And this is a lot of code, but
it boils down to two for loops.

1234
00:55:15,996 --> 00:55:19,316 A:middle
The outer one is walking
through all of the channels

1235
00:55:19,316 --> 00:55:21,146 A:middle
in the buffer if it's
a multichannel file.

1236
00:55:22,676 --> 00:55:25,426 A:middle
And then the inner-loop
will look

1237
00:55:25,426 --> 00:55:27,576 A:middle
at every sample in that buffer.

1238
00:55:29,456 --> 00:55:32,856 A:middle
So given every sample, I can
look at its absolute level

1239
00:55:32,856 --> 00:55:35,826 A:middle
and see if it's the
loudest, or if it's louder

1240
00:55:35,826 --> 00:55:38,266 A:middle
than the loudest sample I've
found so far, and if so,

1241
00:55:38,266 --> 00:55:41,066 A:middle
I can record that level and
where I found it in the file.

1242
00:55:41,736 --> 00:55:45,056 A:middle
So there, in about four screens
of code, I opened an audio file.

1243
00:55:45,056 --> 00:55:49,356 A:middle
I read through the whole
thing one sample at a time.

1244
00:55:49,776 --> 00:55:53,686 A:middle
OK. So moving on I'd like to
just sort of foreshadow the uses

1245
00:55:53,686 --> 00:55:59,796 A:middle
of these classes in the
AVAudioEngine session,

1246
00:55:59,996 --> 00:56:01,636 A:middle
which will follow this one.

1247

1248
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1249
00:55:59,996 --> 00:56:01,636 A:middle
which will follow this one.

1250
00:56:02,266 --> 00:56:04,706 A:middle
So at the bottom
we see AVAudioFile

1251
00:56:04,706 --> 00:56:05,606 A:middle
and AVAudioPCMBuffer.

1252
00:56:05,916 --> 00:56:06,936 A:middle
And those are both used

1253
00:56:06,976 --> 00:56:09,266 A:middle
by something called
AVAudioPlayerNode,

1254
00:56:09,846 --> 00:56:11,676 A:middle
which will be your
basic mechanism

1255
00:56:11,726 --> 00:56:13,686 A:middle
for scheduling audio
to play back.

1256
00:56:14,846 --> 00:56:17,696 A:middle
If the AudioPlayerNode
is a subclass

1257
00:56:18,116 --> 00:56:22,056 A:middle
of a more generic AVAudioNode
class, which is some unit

1258
00:56:22,056 --> 00:56:26,976 A:middle
of audio processing, and we'll
see how AVAudioFormats are used

1259
00:56:26,976 --> 00:56:29,606 A:middle
when describing how to
connect AVAudioNodes.

1260
00:56:32,696 --> 00:56:35,366 A:middle
So that brings us to the end
of my section of this talk.

1261
00:56:35,676 --> 00:56:38,016 A:middle
We saw the AVAudioFormat
ChannelLayout,

1262
00:56:38,256 --> 00:56:40,156 A:middle
PCM Buffer and file classes.

1263
00:56:40,616 --> 00:56:44,206 A:middle
You can use these without
AVAudioEngine using your

1264
00:56:44,206 --> 00:56:46,906 A:middle
existing code with the
Core Audio, Audio Toolbox,

1265
00:56:46,906 --> 00:56:48,516 A:middle
and Audio Unit C APIs.

1266
00:56:48,996 --> 00:56:51,176 A:middle
If you're careful, just
do real-time saves,

1267
00:56:51,626 --> 00:56:53,496 A:middle
and you can use those
assessor methods

1268
00:56:53,956 --> 00:56:57,226 A:middle
to extract the low
level C structures.

1269
00:56:57,996 --> 00:57:00,786 A:middle
And, again, we'll be seeing how
these are used in more detail

1270

1271
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1272
00:56:57,996 --> 00:57:00,786 A:middle
And, again, we'll be seeing how
these are used in more detail

1273
00:57:00,786 --> 00:57:03,136 A:middle
in the next session
on AVAudioEngine.

1274
00:57:03,996 --> 00:57:06,806 A:middle
And that's the end
of our hour here.

1275
00:57:07,196 --> 00:57:08,696 A:middle
We've looked at MIDI
over Bluetooth,

1276
00:57:09,086 --> 00:57:12,366 A:middle
the Inter-App Audio UI
Views, lots of features

1277
00:57:12,366 --> 00:57:16,676 A:middle
of AV Foundation audio,
and we hope you'll stick

1278
00:57:16,676 --> 00:57:18,686 A:middle
around for the next
session on AVAudioEngine.

1279
00:57:21,496 --> 00:57:24,076 A:middle
If you need more information,
Filip is our Evangelist,

1280
00:57:24,076 --> 00:57:25,586 A:middle
and there are the
developer forums.

1281
00:57:27,686 --> 00:57:30,566 A:middle
Here's the next session
I keep talking about.

1282
