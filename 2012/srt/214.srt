
1
99:59:59,999 --> 99:59:59,999
Good morning, everyone

2
99:59:59,999 --> 99:59:59,999
My name is Ben Trumbull and I'm a manager for Core Data

3
99:59:59,999 --> 99:59:59,999
and I'm here to begin the Core Data Best Practices session.

4
99:59:59,999 --> 99:59:59,999
And today, we're going to talk about a number of topics

5
99:59:59,999 --> 99:59:59,999
We're going to talk about concurrency, nested contexts

6
99:59:59,999 --> 99:59:59,999
and then I'm going to bring Melissa Turner on stage to talk about schema design and search optimization

7
99:59:59,999 --> 99:59:59,999
So, as part of these ?? we're going to talk about using Core Data with multiple threads,

8
99:59:59,999 --> 99:59:59,999
sharing unsaved changes between context, debugging performance with Instruments

9
99:59:59,999 --> 99:59:59,999
tuning your model, and improving your predicate usage.

10
99:59:59,999 --> 99:59:59,999
First up, concurrency:

11
99:59:59,999 --> 99:59:59,999
So, when using Core Data,

12
99:59:59,999 --> 99:59:59,999
or really any modeling objects, there are some challenges you're going to face

13
99:59:59,999 --> 99:59:59,999
the first is obviously thread-safety

14
99:59:59,999 --> 99:59:59,999
look at some issues with transactionality when you have a bunch of changes together

15
99:59:59,999 --> 99:59:59,999
and of course you need to balance that with performance

16
99:59:59,999 --> 99:59:59,999
So, in the past, a lot of people have done something like this;

17
99:59:59,999 --> 99:59:59,999
they had a bunch of different contexts together and used performSelector: to route, say, a merge notification

18
99:59:59,999 --> 99:59:59,999
or another message onto the main thread or a specific thread

19
99:59:59,999 --> 99:59:59,999
to get to a context.

20
99:59:59,999 --> 99:59:59,999
This makes us a little sad, though.

21
99:59:59,999 --> 99:59:59,999
So, in Lion and iOS 5, we introduced some new methods

22
99:59:59,999 --> 99:59:59,999
and some new concurrency types for Managed Object.

23
99:59:59,999 --> 99:59:59,999
And instead of having to trampouline through performSelector:,

24
99:59:59,999 --> 99:59:59,999
you can use performBlock: and performBlockAndWait:

25
99:59:59,999 --> 99:59:59,999
and it's going to look a little bit something like this:

26
99:59:59,999 --> 99:59:59,999
when you create a managed object context you'll specify what kind of concurrency you want it to use;

27
99:59:59,999 --> 99:59:59,999
it will manage that itself and then use performBlock: to route it tasks.

28
99:59:59,999 --> 99:59:59,999
So, there are three concurrency options you can use with Core Data:

29
99:59:59,999 --> 99:59:59,999
the first one is, you tell a managed object context that you want it to be bound to the main thread.

30
99:59:59,999 --> 99:59:59,999
and this is great for interacting with view controllers and other aspects of the system that are bound to the main thread

31
99:59:59,999 --> 99:59:59,999
or don't really know much about Core Data and its concurrency.

32
99:59:59,999 --> 99:59:59,999
And then for a lot of your background tasks, and your own work, you can use private queue concurrency.

33
99:59:59,999 --> 99:59:59,999
And finally, there's the confinement concurrency type,

34
99:59:59,999 --> 99:59:59,999
which is what people have been using in the past

35
99:59:59,999 --> 99:59:59,999
before we introduced these new options

36
99:59:59,999 --> 99:59:59,999
So, for the confinement concurrency type, you're basically required to have a separate context

37
99:59:59,999 --> 99:59:59,999
for every thread

38
99:59:59,999 --> 99:59:59,999
and a managed object context can only be used on the thread or queue that created them.

39
99:59:59,999 --> 99:59:59,999
This is the default, legacy option.

40
99:59:59,999 --> 99:59:59,999
So, with the confinement type, everything is going to be serialized against your ??

41
99:59:59,999 --> 99:59:59,999
and you can use either a serialized dispatch queue or an NSOperationQueue with a maximum concurrency manually set to one

42
99:59:59,999 --> 99:59:59,999
in addition to a specific thread.

43
99:59:59,999 --> 99:59:59,999
So here I just want to point out that Core Data isn't using and thread-local state

44
99:59:59,999 --> 99:59:59,999
and we're really interested in having a single control flow;

45
99:59:59,999 --> 99:59:59,999
we're not really as focused on whether or not dispatch queues work with multiple threads,

46
99:59:59,999 --> 99:59:59,999
or how that's happening underneath the covers.

47
99:59:59,999 --> 99:59:59,999
So, thread confinement is pretty straight forward; it's safe; it's efficient.

48
99:59:59,999 --> 99:59:59,999
The transactions are obviously scoped to the managed object context so something else gets to interfere with it.

49
99:59:59,999 --> 99:59:59,999
But it does put a burden on you to manage all these issues.

50
99:59:59,999 --> 99:59:59,999
So, in particular, tracking which context goes with which thread,

51
99:59:59,999 --> 99:59:59,999
potentially keeping extra threads around for background tasks,

52
99:59:59,999 --> 99:59:59,999
and then all of the special behaviors that Core Data uses to integrate with view controllers,

53
99:59:59,999 --> 99:59:59,999
Cocoa bindings, undo management.

54
99:59:59,999 --> 99:59:59,999
We're going to have to infer from context whether you created the managed object context on the main thread

55
99:59:59,999 --> 99:59:59,999
and those things are driven--those we call "user events", typically--are driven by the run loop of the application.

56
99:59:59,999 --> 99:59:59,999
So, in contrast to confinement, private queue concurrency maintains its own private serialized queue

57
99:59:59,999 --> 99:59:59,999
and you can only use it on this queue, and you do that

58
99:59:59,999 --> 99:59:59,999
by setting up blocks as tasks, and enqueueing them using performBlock: and performBlockAndWait:

59
99:59:59,999 --> 99:59:59,999
Now, within those blocks you can use the managed object context API normally.

60
99:59:59,999 --> 99:59:59,999
And I just want to really emphasize that in this case, the queue is private and you shouldn't yank it out

61
99:59:59,999 --> 99:59:59,999
and interact with it directly.

62
99:59:59,999 --> 99:59:59,999
If you want to, you can dispatch work to your own queues, you can dispatch_sync at the end of those blocks.

63
99:59:59,999 --> 99:59:59,999
And there are a number of advantages to this,

64
99:59:59,999 --> 99:59:59,999
It lets the managed object context maintain which queue it's using and handle whether or not its in the right state,

65
99:59:59,999 --> 99:59:59,999
the right thread

66
99:59:59,999 --> 99:59:59,999
and other threads can easily interact with that managed object context by calling performBlock:

67
99:59:59,999 --> 99:59:59,999
unlike with the confinement concurrency type; those other threads really can't message that managed object context at all.

68
99:59:59,999 --> 99:59:59,999
And these can be created from any thread, and the queues are going to be much more efficient than

69
99:59:59,999 --> 99:59:59,999
keeping extra threads lying around in the background to do their tasks

70
99:59:59,999 --> 99:59:59,999
like background fetching.

71
99:59:59,999 --> 99:59:59,999
And the third type is the main queue concurrency type.

72
99:59:59,999 --> 99:59:59,999
This is going to behave very similarly to the private queue concurrency type,

73
99:59:59,999 --> 99:59:59,999
only the queue is obviously always the main thread,

74
99:59:59,999 --> 99:59:59,999
and non-main threads can just call performBlock: on that as well.

75
99:59:59,999 --> 99:59:59,999
And it will integrate all of those behaviors that I talked about: undo management and other life cycle events

76
99:59:59,999 --> 99:59:59,999
with the main run loop.

77
99:59:59,999 --> 99:59:59,999
So, what that means is that when you create a managed object context with the main queue concurrency type,

78
99:59:59,999 --> 99:59:59,999
your view controllers and other things can just message it directly;

79
99:59:59,999 --> 99:59:59,999
they don't have to know about all of these different performBlock: APIs,

80
99:59:59,999 --> 99:59:59,999
and it's very easy for other tasks that you have in the background to just enqueue performBlock: on it

81
99:59:59,999 --> 99:59:59,999
and have those then update view state.

82
99:59:59,999 --> 99:59:59,999
So, just sort of a diagram of what I mean going on here is,

83
99:59:59,999 --> 99:59:59,999
a background thread can enqueue a block directly,

84
99:59:59,999 --> 99:59:59,999
but the view controllers can just start using managed object context API.

85
99:59:59,999 --> 99:59:59,999
So in this way, Cocoa bindings, for instance, doesn't know about concurrency types or performBlock:,

86
99:59:59,999 --> 99:59:59,999
but it can just work with the managed object context the way it always has,

87
99:59:59,999 --> 99:59:59,999
and you have have background threads and other queues enqueue messages

88
99:59:59,999 --> 99:59:59,999
to happen on the main thread context in that way.

89
99:59:59,999 --> 99:59:59,999
So, I mentioned that we had these notions of user events,

90
99:59:59,999 --> 99:59:59,999
and for the main thread, that's going to be tightly integrated with with the application's runloop

91
99:59:59,999 --> 99:59:59,999
but for contexts running off the main thread,

92
99:59:59,999 --> 99:59:59,999
either in a private queue or on your own thread,

93
99:59:59,999 --> 99:59:59,999
Core Data is going to defer a bunch of tasks and then coalesce work later on;

94
99:59:59,999 --> 99:59:59,999
this is the change notification--coalescing changes for notifications, delete propagation,

95
99:59:59,999 --> 99:59:59,999
setting up the undo groupings; stuff like that.

96
99:59:59,999 --> 99:59:59,999
And, for the most part, on background threads, we consider this to be the time in between calls to processPendingChanges:.

97
99:59:59,999 --> 99:59:59,999
So, a couple of useful points for all the concurrency types

98
99:59:59,999 --> 99:59:59,999
is that managed objects are always owned by their managed object contexts

99
99:59:59,999 --> 99:59:59,999
and that Object IDs are a great way to pass references around between contexts

100
99:59:59,999 --> 99:59:59,999
because they're going to be safe, immutable objects.

101
99:59:59,999 --> 99:59:59,999
And something else that's a nice point is that retain and release are going to be thread-safe

102
99:59:59,999 --> 99:59:59,999
on all Core Data objects, everywhere, all the time, without exception.

103
99:59:59,999 --> 99:59:59,999
They should be thread-safe on all Cocoa objects, but your mileage may vary on that one.

104
99:59:59,999 --> 99:59:59,999
That means that you can actually retain a managed object independently of its requirement on the managed object context;

105
99:59:59,999 --> 99:59:59,999
you just can't necessarily use it directly.

106
99:59:59,999 --> 99:59:59,999
So, some good times for you to pass around updates to other contexts or to update the views

107
99:59:59,999 --> 99:59:59,999
are going to be with these NSNotifications that Core Data provides,

108
99:59:59,999 --> 99:59:59,999
with the ObjectsDidChange notification and the ContextDidSave notification.

109
99:59:59,999 --> 99:59:59,999
and you can refresh other managed object contexts pretty easily, after they save,

110
99:59:59,999 --> 99:59:59,999
with the mergeChangesFromContextDidSaveNotification.

111
99:59:59,999 --> 99:59:59,999
And here I'd just like to call out that you're responsible for the thread safety of the managed object contexts receiving this message

112
99:59:59,999 --> 99:59:59,999
but you don't have to worry about the notification data that's being generated here;

113
99:59:59,999 --> 99:59:59,999
Core Data will manage the thread-safety of that information.

114
99:59:59,999 --> 99:59:59,999
So, you just have to maintain the rules that we've outlined in the past on the receiver of the merge method.

115
99:59:59,999 --> 99:59:59,999
And, when you're inside some of these notifications as the observer,

116
99:59:59,999 --> 99:59:59,999
you can find out some useful methods of taking a look at the state of what's changed in the merged objects,

117
99:59:59,999 --> 99:59:59,999
something that we added last release was changedValuesForCurrentEvent,

118
99:59:59,999 --> 99:59:59,999
which will give you the values that changed since the previous call to savePendingChanges:

119
99:59:59,999 --> 99:59:59,999
and then some older methods,

120
99:59:59,999 --> 99:59:59,999
changedValues and committedValuesForKeys will go back to the last time the object was saved.

121
99:59:59,999 --> 99:59:59,999
So now I'm going to go into a little more depth

122
99:59:59,999 --> 99:59:59,999
about these performBlock and performBlockAndWait: methods that I mentioned earlier,

123
99:59:59,999 --> 99:59:59,999
and our challenge here is to find a way to pass work to other threads,

124
99:59:59,999 --> 99:59:59,999
these managed object contexts running on their own queue or the main queue,

125
99:59:59,999 --> 99:59:59,999
and to sort of demarcate the actual group of changes you want to be coalesced together,

126
99:59:59,999 --> 99:59:59,999
whether it's for an undo grouping, or for validation,

127
99:59:59,999 --> 99:59:59,999
or potentially to save,

128
99:59:59,999 --> 99:59:59,999
as well as a convenient way to integrate with all of the other APIs on the platform.

129
99:59:59,999 --> 99:59:59,999
and that's part of the reason we chose blocks.

130
99:59:59,999 --> 99:59:59,999
So, performBlock: is an asynchronous request to enqueue this.

131
99:59:59,999 --> 99:59:59,999
We consider this its own isolated user event, and it also includes an autorelease pool.

132
99:59:59,999 --> 99:59:59,999
I really want to call out, that in all of these methods, it is very illegal to throw an exception outside of the block,

133
99:59:59,999 --> 99:59:59,999
so if you do have exceptions, please catch them and resolve them inside the block.

134
99:59:59,999 --> 99:59:59,999
And there's no support for reentrancy in this performBlock: method

135
99:59:59,999 --> 99:59:59,999
And by that what I mean is, when you call performBlock: on a managed object context,

136
99:59:59,999 --> 99:59:59,999
and within that performBlock: call, you call performBlock: again,

137
99:59:59,999 --> 99:59:59,999
you're basically just getting the same effect as if you had iteratively called performBlock:.

138
99:59:59,999 --> 99:59:59,999
So, this is an asynchronous call, and all it's doing is enqueuing up a task to be happening later.

139
99:59:59,999 --> 99:59:59,999
So, in contrast, we have performBlockAndWait:.

140
99:59:59,999 --> 99:59:59,999
This is synchronous, it's very lightweight, we don't consider it to be any kind of event,

141
99:59:59,999 --> 99:59:59,999
It doesn't even include an autorelease pool.

142
99:59:59,999 --> 99:59:59,999
But what it does do is, it will support some reentrancy,

143
99:59:59,999 --> 99:59:59,999
so if you call performBlockAndWait: from within another performBlock:

144
99:59:59,999 --> 99:59:59,999
you'll basically get them nested;

145
99:59:59,999 --> 99:59:59,999
they'll be executed immediately inline

146
99:59:59,999 --> 99:59:59,999
as opposed to enqueued later

147
99:59:59,999 --> 99:59:59,999
So, this is very convenient as long as you're just working with one managed object context

148
99:59:59,999 --> 99:59:59,999
for these blocks.

149
99:59:59,999 --> 99:59:59,999
So, these APIs are very fast and lightweight.

150
99:59:59,999 --> 99:59:59,999
The performBlockAndWait: API is on the same order of magnitude as valueForKey:, for instance

151
99:59:59,999 --> 99:59:59,999
and the changes there, from Core Data's perspective

152
99:59:59,999 --> 99:59:59,999
are going to be scoped by the block.

153
99:59:59,999 --> 99:59:59,999
So, however large or small you make the block,

154
99:59:59,999 --> 99:59:59,999
it's going to be sort of one self-encapsulated change set.

155
99:59:59,999 --> 99:59:59,999
So, when you're working with data between blocks, like I said,

156
99:59:59,999 --> 99:59:59,999
you can retain objects independently of their threads

157
99:59:59,999 --> 99:59:59,999
and pass them between blocks, but object IDs are often going to be useful,

158
99:59:59,999 --> 99:59:59,999
you can rematerialize them into managed objects when they get inside the block

159
99:59:59,999 --> 99:59:59,999
using managedObjectWithID:

160
99:59:59,999 --> 99:59:59,999
and this will reuse whatever cached state you have around,

161
99:59:59,999 --> 99:59:59,999
perhaps at the persistent store coordinator level

162
99:59:59,999 --> 99:59:59,999
We keep a cache there as well as at the managed object context.

163
99:59:59,999 --> 99:59:59,999
So if the data is already in memory we're not going to go back to disk to get it

164
99:59:59,999 --> 99:59:59,999
and this lets you use object IDs is immutable objects to be passed around

165
99:59:59,999 --> 99:59:59,999
and not worry too much about the thread-safety of your references

166
99:59:59,999 --> 99:59:59,999
and then when you get into the block you can rematerialize those into managed objects

167
99:59:59,999 --> 99:59:59,999
But you can on occasion you'll find it useful to pass managed objects around

168
99:59:59,999 --> 99:59:59,999
you just can't actually look or use them; when you do so you can just retain them.

169
99:59:59,999 --> 99:59:59,999
And of course __block variables are a great way to pass out results.

170
99:59:59,999 --> 99:59:59,999
And a lot of our APIs return NSErrors, so it's very important to remember that these are autoreleased,

171
99:59:59,999 --> 99:59:59,999
and as I mentioned performBlock: includes an autorelease pool,

172
99:59:59,999 --> 99:59:59,999
so you'll probably want to either handle or retain the errors before returning from your blocks.

173
99:59:59,999 --> 99:59:59,999
So, a simple example of how you might use some of these APIs.

174
99:59:59,999 --> 99:59:59,999
Here we have a context, and it's synchronously calling performBlockAndWait:

175
99:59:59,999 --> 99:59:59,999
to execute a fetch request that's been captured by this block from some code further up

176
99:59:59,999 --> 99:59:59,999
and, if we don't have an error, then we just ask the array of managed objects to give us back

177
99:59:59,999 --> 99:59:59,999
its object IDs, and we return those out of the block with a __block variable.

178
99:59:59,999 --> 99:59:59,999
So, as I mentioned, the queue is often going to be very private to the managed object context,

179
99:59:59,999 --> 99:59:59,999
and we don't want you changing anything about it,

180
99:59:59,999 --> 99:59:59,999
so if you need to, and you're using your own queues as I'd expect,

181
99:59:59,999 --> 99:59:59,999
you can just simply at the end of the work block that you passed the managed object context,

182
99:59:59,999 --> 99:59:59,999
enqueue another block back onto your own queue as the callback

183
99:59:59,999 --> 99:59:59,999
to let it know that it's done and process any results.

184
99:59:59,999 --> 99:59:59,999
But there are a number of other ways that you can either coordinate with your own queues,

185
99:59:59,999 --> 99:59:59,999
or other queues in the system, and dispatch semaphores are one way of doing that.

186
99:59:59,999 --> 99:59:59,999
You can create a semaphore, and then at the end of the block, signal the semaphore

187
99:59:59,999 --> 99:59:59,999
and then in this particular code snippet, the context is asynchronously performing this block

188
99:59:59,999 --> 99:59:59,999
and the code that is calling perform: here is actually waiting until that is done

189
99:59:59,999 --> 99:59:59,999
on the semaphore.

190
99:59:59,999 --> 99:59:59,999
And then, something else that I'd like to give a little shout-out

191
99:59:59,999 --> 99:59:59,999
are dispatch groups,

192
99:59:59,999 --> 99:59:59,999
and if you haven't used them they have some very interesting behaviors.

193
99:59:59,999 --> 99:59:59,999
And you can use them to organize some pretty complex depedencies

194
99:59:59,999 --> 99:59:59,999
between a variety of queues and blocks between them.

195
99:59:59,999 --> 99:59:59,999
So when you use dispatch<u>group</u>enter, it's a little like incrementing a retain count

196
99:59:59,999 --> 99:59:59,999
on when the queue will be done.

197
99:59:59,999 --> 99:59:59,999
And then, the worker blocks can call leave to decrement it

198
99:59:59,999 --> 99:59:59,999
and when it ends up getting back down to zero,

199
99:59:59,999 --> 99:59:59,999
conceptually, dispatch_wait will return, or

200
99:59:59,999 --> 99:59:59,999
dispatch<u>group</u>notify will enqueue a block that you passed it onto your own queue.

201
99:59:59,999 --> 99:59:59,999
So what this lets you do is basically, you don't actually have to know how many waiters

202
99:59:59,999 --> 99:59:59,999
you want to float around, you can just call dispatch<u>group</u>wait as you add more work

203
99:59:59,999 --> 99:59:59,999
or as you decide to build in these dependencies

204
99:59:59,999 --> 99:59:59,999
and then have them call dispatch<u>group</u>leave.

205
99:59:59,999 --> 99:59:59,999
So, this is a very simple example.

206
99:59:59,999 --> 99:59:59,999
It's very similar to the semaphore example.

207
99:59:59,999 --> 99:59:59,999
This becomes more interesting when you have more queues involved.

208
99:59:59,999 --> 99:59:59,999
So, now I'd like to move on from concurrency to talk about nested managed object contexts.

209
99:59:59,999 --> 99:59:59,999
And in particular the reasons you'd be interested in nested managed object contexts

210
99:59:59,999 --> 99:59:59,999
are going to be passing objects around between managed object contexts

211
99:59:59,999 --> 99:59:59,999
and implementing something like an asynchronous save.

212
99:59:59,999 --> 99:59:59,999
So in the past, working with managed object contexts,

213
99:59:59,999 --> 99:59:59,999
you can push and pull changes that have been saved between contexts

214
99:59:59,999 --> 99:59:59,999
and use the merge notification to do that.

215
99:59:59,999 --> 99:59:59,999
But passing unsaved changes between contexts, or having them really work with unsaved changes

216
99:59:59,999 --> 99:59:59,999
can be very difficult.

217
99:59:59,999 --> 99:59:59,999
And similarly it's very difficult to break up the save operation to be asynchronous.

218
99:59:59,999 --> 99:59:59,999
So here, for a nested context, the parent contexts are going to act

219
99:59:59,999 --> 99:59:59,999
kind of like the persistent store, from the perspective of the child contexts.

220
99:59:59,999 --> 99:59:59,999
And the child context is going to see the state of its objects as they currently exist in the parent.

221
99:59:59,999 --> 99:59:59,999
Children will then inherit unsaved changes from the parent whenever they fault things in

222
99:59:59,999 --> 99:59:59,999
or they execute a save request

223
99:59:59,999 --> 99:59:59,999
and they'll marshall their saves in memory.

224
99:59:59,999 --> 99:59:59,999
So instead of saving back to disk, the children will just turn around and save to their parent context.

225
99:59:59,999 --> 99:59:59,999
So it looks a little something like this

226
99:59:59,999 --> 99:59:59,999
and the child doesn't know that it's not actually talking to the persistent store

227
99:59:59,999 --> 99:59:59,999
it's just talking to a parent context

228
99:59:59,999 --> 99:59:59,999
and the behaviors are going to be very analogous in the way that saving works, and faulting.

229
99:59:59,999 --> 99:59:59,999
So, in this way, peers that all inherit from the same parent context

230
99:59:59,999 --> 99:59:59,999
can all push and pull changes between them,

231
99:59:59,999 --> 99:59:59,999
and you can implement an asynchronous save by setting up the parent context

232
99:59:59,999 --> 99:59:59,999
to have a private queue and having the child contexts, typically on the main thread,

233
99:59:59,999 --> 99:59:59,999
save into the parent context, and then tell the parent context to save.

234
99:59:59,999 --> 99:59:59,999
And one of the ways you might leverage that is something like a detail inspector.

235
99:59:59,999 --> 99:59:59,999
So the detail inspector will inherit the view state as it is in your main context.

236
99:59:59,999 --> 99:59:59,999
So for sharing unsaved changes, when you save the child context,

237
99:59:59,999 --> 99:59:59,999
they'll just push up one level, and then you can pull those changes back down using a fetch

238
99:59:59,999 --> 99:59:59,999
or the merge notification between child contexts, or by calling refreshObject:.

239
99:59:59,999 --> 99:59:59,999
It's the same way you would with not-nested managed object contexts.

240
99:59:59,999 --> 99:59:59,999
For an asynchronous save,

241
99:59:59,999 --> 99:59:59,999
when you save the child, the parent context gets those changes and holds onto them until it's told to save

242
99:59:59,999 --> 99:59:59,999
and the changes won't be written to disk until the root most parent calls save.

243
99:59:59,999 --> 99:59:59,999
So that would look something like this, where a parent context has a private queue concurrency type

244
99:59:59,999 --> 99:59:59,999
so it will execute requests asynchronously

245
99:59:59,999 --> 99:59:59,999
and the child contexts get set up and create a reference to this parent context

246
99:59:59,999 --> 99:59:59,999
so when the child saves, it pushes its changes up to the parent

247
99:59:59,999 --> 99:59:59,999
and then here, it enqueues an asynchronous block to tell the parent that you want the parent to save.

248
99:59:59,999 --> 99:59:59,999
For inheriting changes in the detail inspector, you just create a child context for the detail inspector.

249
99:59:59,999 --> 99:59:59,999
and if you decide to commit the changes within the inspector,

250
99:59:59,999 --> 99:59:59,999
they'll get pushed into the parent, which is probably going to be something like the main context

251
99:59:59,999 --> 99:59:59,999
for your view state

252
99:59:59,999 --> 99:59:59,999
and anything you do in the child context for the inspector,

253
99:59:59,999 --> 99:59:59,999
it's just going to incorporate the current unsaved state in the parent

254
99:59:59,999 --> 99:59:59,999
and you don't even necessarily have to do anything special

255
99:59:59,999 --> 99:59:59,999
if you decide to cancel out of the inspector; you can just throw away the child context.

256
99:59:59,999 --> 99:59:59,999
So, some important things to remember.

257
99:59:59,999 --> 99:59:59,999
is that saving with the child context is only going to push the changes up a single level,

258
99:59:59,999 --> 99:59:59,999
but fetching is going to go to the database and pull data through all the levels.

259
99:59:59,999 --> 99:59:59,999
Keep in mind, though that in general, Core Data isn't going to change any objects that you already have

260
99:59:59,999 --> 99:59:59,999
out from underneath you

261
99:59:59,999 --> 99:59:59,999
so if you fetch an object that you already have, you will see it's previous state,

262
99:59:59,999 --> 99:59:59,999
so if you say, yeah, it's been dirtied, we're not going to blow away your changes.

263
99:59:59,999 --> 99:59:59,999
We're simply going to keep, in the fetched results, the reference to that object.

264
99:59:59,999 --> 99:59:59,999
And you can call refreshObject: if you want to get new values for it.

265
99:59:59,999 --> 99:59:59,999
objectWithID: on a child context will pull from the fewest number of levels necessary to get that data

266
99:59:59,999 --> 99:59:59,999
so it might go to the database, or it might only go up a single level to the parent.

267
99:59:59,999 --> 99:59:59,999
And, all parent contexts must adopt one of the queue types for concurrency.

268
99:59:59,999 --> 99:59:59,999
So they can either be main queue concurrency type or private queue concurrency type

269
99:59:59,999 --> 99:59:59,999
but we don't support them with the legacy confinement concurrency type.

270
99:59:59,999 --> 99:59:59,999
Child contexts depend pretty heavily on their parents,

271
99:59:59,999 --> 99:59:59,999
so the parent context really should not do blocking operations down on their children.

272
99:59:59,999 --> 99:59:59,999
By this, the children are going to call performBlockAndWait: and do a lot of operations for you.

273
99:59:59,999 --> 99:59:59,999
For instance, executeFetchRequest: on a child context internally is going to turn around

274
99:59:59,999 --> 99:59:59,999
and ask its parent context to do part of the fetch

275
99:59:59,999 --> 99:59:59,999
and then pull down those changes into itself.

276
99:59:59,999 --> 99:59:59,999
So what this means is, there's sort of naturally a dependency there,

277
99:59:59,999 --> 99:59:59,999
and if the parent contexts turn around and call performBlockAndWait: on their children,

278
99:59:59,999 --> 99:59:59,999
you'll basically end up deadlocking, because you'll have all these queues trying to synchronously wait on each other.

279
99:59:59,999 --> 99:59:59,999
So in general, you should imagine that requests are going to flow up

280
99:59:59,999 --> 99:59:59,999
this hierarchy of managed object contexts finally to the database at the root,

281
99:59:59,999 --> 99:59:59,999
and results are going to flow back down.

282
99:59:59,999 --> 99:59:59,999
And now I'm going to bring Melissa Turner on stage

283
99:59:59,999 --> 99:59:59,999
to talk to you about performance.

284
99:59:59,999 --> 99:59:59,999
Thank you.

285
99:59:59,999 --> 99:59:59,999
[Applause]

286
99:59:59,999 --> 99:59:59,999
Thanks, Ben.

287
99:59:59,999 --> 99:59:59,999
So, performance.

288
99:59:59,999 --> 99:59:59,999
How do you know when you've got a performance problem?

289
99:59:59,999 --> 99:59:59,999
How do you figure out what you need to do when you've got a performance problem?

290
99:59:59,999 --> 99:59:59,999
Lots of questions.

291
99:59:59,999 --> 99:59:59,999
The first stage, when you're starting to sit down in front of your application,

292
99:59:59,999 --> 99:59:59,999
"Is this thing ready to release to my customers?

293
99:59:59,999 --> 99:59:59,999
Is it performant enough?

294
99:59:59,999 --> 99:59:59,999
Are they going to be annoyed with me?

295
99:59:59,999 --> 99:59:59,999
Are they going to file bad reports on me in the App Store

296
99:59:59,999 --> 99:59:59,999
or are they going to give me five stars?"

297
99:59:59,999 --> 99:59:59,999
is to start asking yourself questions about the application.

298
99:59:59,999 --> 99:59:59,999
What environment does it run in, and have I designed it to be compatible with that environment?

299
99:59:59,999 --> 99:59:59,999
What should it be doing, and are the "shoulds" and "dos" compatible?

300
99:59:59,999 --> 99:59:59,999
What kind of things do you need to know about the environment?

301
99:59:59,999 --> 99:59:59,999
Well, actually, very little nowadays.

302
99:59:59,999 --> 99:59:59,999
As long as you're using the Apple-supplied frameworks,

303
99:59:59,999 --> 99:59:59,999
things like libDispatch, then we will take care of making sure that you're doing things properly from, say,

304
99:59:59,999 --> 99:59:59,999
the confinement standpoint,

305
99:59:59,999 --> 99:59:59,999
but you will need to do things like design for your network environment.

306
99:59:59,999 --> 99:59:59,999
If you have an application that goes out, use the NSIncrementalStore APIs to build a store

307
99:59:59,999 --> 99:59:59,999
that talks to a Web service,

308
99:59:59,999 --> 99:59:59,999
you probbaly want to make sur ehta whenever your users triggers an action

309
99:59:59,999 --> 99:59:59,999
that will require going out and talking to that Web service

310
99:59:59,999 --> 99:59:59,999
it doesn't block the main UI of the application.

311
99:59:59,999 --> 99:59:59,999
You'll need to think about stuff like that.

312
99:59:59,999 --> 99:59:59,999
That is a performance issue.

313
99:59:59,999 --> 99:59:59,999
You'll need to think about what is sufficient performance

314
99:59:59,999 --> 99:59:59,999
versus what is optimal performance.

315
99:59:59,999 --> 99:59:59,999
Sufficient is, your application gets up and gets the job done.

316
99:59:59,999 --> 99:59:59,999
Optimal is, it really "wows" your user and allows you

317
99:59:59,999 --> 99:59:59,999
to spend more time doing interesting things in your application because you're not wasting cycles

318
99:59:59,999 --> 99:59:59,999
doing things inefficiently.

319
99:59:59,999 --> 99:59:59,999
One crucial point to remember is that if you're building an application that supports multiple platforms,

320
99:59:59,999 --> 99:59:59,999
test on the minimal configuration.

321
99:59:59,999 --> 99:59:59,999
This cannot be emphasized enough,

322
99:59:59,999 --> 99:59:59,999
because if it works on your minimal configuration,

323
99:59:59,999 --> 99:59:59,999
it's going to blow people away on all other platforms.

324
99:59:59,999 --> 99:59:59,999
What should your application be going?

325
99:59:59,999 --> 99:59:59,999
You should know this; you've written it.

326
99:59:59,999 --> 99:59:59,999
You know things like, well, it opens documents.

327
99:59:59,999 --> 99:59:59,999
If you open a document, there's very little way to get around it,

328
99:59:59,999 --> 99:59:59,999
you need to do file system access and load at least some of the data

329
99:59:59,999 --> 99:59:59,999
so you can show it to the user; that's what they're expecting.

330
99:59:59,999 --> 99:59:59,999
If the user instigates a network access, it's the same thing.

331
99:59:59,999 --> 99:59:59,999
Know when the user is accessing the network and how' they're accessing the network

332
99:59:59,999 --> 99:59:59,999
so you don't do things like accidentally go out and fetch the same piece of data three or four times.

333
99:59:59,999 --> 99:59:59,999
And you need to know what kind of random processing your user is likely to kick off:

334
99:59:59,999 --> 99:59:59,999
calculate me some transform on an image; scale it; apply a filter.

335
99:59:59,999 --> 99:59:59,999
Do something interesting like that.

336
99:59:59,999 --> 99:59:59,999
These are things you know your application can do,

337
99:59:59,999 --> 99:59:59,999
and you should expect to see them in your performance analysis.

338
99:59:59,999 --> 99:59:59,999
And then there's what the application does do, stuff it does automatically.

339
99:59:59,999 --> 99:59:59,999
You have a data set that you need to go out and check periodically

340
99:59:59,999 --> 99:59:59,999
to see if there's new data on your Web service.

341
99:59:59,999 --> 99:59:59,999
That kind of thing happens automatically; you should build it into your calculations.

342
99:59:59,999 --> 99:59:59,999
Try not to do it when the user has kicked off that image transform.

343
99:59:59,999 --> 99:59:59,999
Does it post notifications?

344
99:59:59,999 --> 99:59:59,999
You should try to do that in some unobtrusive way

345
99:59:59,999 --> 99:59:59,999
using our APIs that will make it all happen nice and smoothly.

346
99:59:59,999 --> 99:59:59,999
And if for some reason you want to calculate the 2438th digit of pi,

347
99:59:59,999 --> 99:59:59,999
Try and do it at 3 o'clock in the morning on a Friday when they're not likely to be using the application.

348
99:59:59,999 --> 99:59:59,999
How do you figure out what your application does

349
99:59:59,999 --> 99:59:59,999
once you know what you think it should be doing?

350
99:59:59,999 --> 99:59:59,999
Measure it.

351
99:59:59,999 --> 99:59:59,999
Measure, measure, measure, measure.

352
99:59:59,999 --> 99:59:59,999
This is where everything starts.

353
99:59:59,999 --> 99:59:59,999
Figure out where your application is actually spending time

354
99:59:59,999 --> 99:59:59,999
so you don't end up spending two weeks optimizing what turns out to be

355
99:59:59,999 --> 99:59:59,999
one percent of your application's workload.

356
99:59:59,999 --> 99:59:59,999
It's much better to spend two weeks optimizing fifty percent of your application's workload.

357
99:59:59,999 --> 99:59:59,999
Start with the Time Profiler in Instruments.

358
99:59:59,999 --> 99:59:59,999
This will tell you exactly where your application is spending all of its time,

359
99:59:59,999 --> 99:59:59,999
method by method.

360
99:59:59,999 --> 99:59:59,999
There's also the Core Data template in Instruments.

361
99:59:59,999 --> 99:59:59,999
This will tell you when Core Data is touching the file system.

362
99:59:59,999 --> 99:59:59,999
We have a template that contains instruments for fetching, for saving, for firing relationship faults,

363
99:59:59,999 --> 99:59:59,999
and for when we have to go to the database because the data we're looking for is not in the cache.

364
99:59:59,999 --> 99:59:59,999
And there's also the com.apple.CoreData.SQLDebug default.

365
99:59:59,999 --> 99:59:59,999
If you pass this to your application when you launch it,

366
99:59:59,999 --> 99:59:59,999
or have in your defaults write,

367
99:59:59,999 --> 99:59:59,999
it will cause Core Data to print out all of the SQL that is being sent to the database,

368
99:59:59,999 --> 99:59:59,999
and you can have a look at that, see what you're sending to the database,

369
99:59:59,999 --> 99:59:59,999
look at the SQL that's being generated,

370
99:59:59,999 --> 99:59:59,999
figure out if this is really the SQL that should be generated in that case,

371
99:59:59,999 --> 99:59:59,999
if you're doing too much work, doing too little work, or doing too many trips to the database,

372
99:59:59,999 --> 99:59:59,999
this kind of thing; this default will tell you that.

373
99:59:59,999 --> 99:59:59,999
Many of you have probably heard this before,

374
99:59:59,999 --> 99:59:59,999
because it's a very common phrase in the real world, if you're building anything with your hands.

375
99:59:59,999 --> 99:59:59,999
Measure twice. Cut once.

376
99:59:59,999 --> 99:59:59,999
You cannot uncut a piece of lumber.

377
99:59:59,999 --> 99:59:59,999
And it's less important in the virtual world, because we have SCM systems.

378
99:59:59,999 --> 99:59:59,999
It's always possible to revert to yesterday's build.

379
99:59:59,999 --> 99:59:59,999
But the thing is, you can't get back the time you have invested

380
99:59:59,999 --> 99:59:59,999
going down that false path.

381
99:59:59,999 --> 99:59:59,999
So make sure you're fixing the right thing before you go off and fix it.

382
99:59:59,999 --> 99:59:59,999
For the rest of this presentation I'm going to do a series of demos,

383
99:59:59,999 --> 99:59:59,999
or I will be having my lovely assistant do a series of demos

384
99:59:59,999 --> 99:59:59,999
that are based around a table view.

385
99:59:59,999 --> 99:59:59,999
And this is primarily because table views are easy to visualize;

386
99:59:59,999 --> 99:59:59,999
if I say there's too much data being loaded,

387
99:59:59,999 --> 99:59:59,999
you can get a grasp of what that says.

388
99:59:59,999 --> 99:59:59,999
If I say there's too little data, or the wrong data--it's badly formed--

389
99:59:59,999 --> 99:59:59,999
you can get an idea what that means.

390
99:59:59,999 --> 99:59:59,999
But the lessons are generally applicable to anything that's going to be loading and processing data

391
99:59:59,999 --> 99:59:59,999
from a store.

392
99:59:59,999 --> 99:59:59,999
Just as a disclaimer: the demos are specifically chosen so that they have performance issues

393
99:59:59,999 --> 99:59:59,999
that are visible on stage.

394
99:59:59,999 --> 99:59:59,999
Any performance problems that you have in your app will probably

395
99:59:59,999 --> 99:59:59,999
be a bit more subtle, but they'll have the same basic patterns.

396
99:59:59,999 --> 99:59:59,999
In the beginning, there was a table view.

397
99:59:59,999 --> 99:59:59,999
You know, your customers are not going to pay you for this

398
99:59:59,999 --> 99:59:59,999
because that's not terribly interesting.

399
99:59:59,999 --> 99:59:59,999
You need something, and in my case, I went on vacation.

400
99:59:59,999 --> 99:59:59,999
Those of you who are familiar with this picture will probably realize I was in Rome.

401
99:59:59,999 --> 99:59:59,999
and that this is a picture of the Colosseum; it's an architecture picture.

402
99:59:59,999 --> 99:59:59,999
These are all pieces of information that I want to build into an application that displays my holiday photos.

403
99:59:59,999 --> 99:59:59,999
My first pass is going to be to take all of those pieces of information that I've got

404
99:59:59,999 --> 99:59:59,999
and combine those into an object that I can use to back my table view.

405
99:59:59,999 --> 99:59:59,999
Call it a Photo object; it's got a label: "This was taken in Rome."

406
99:59:59,999 --> 99:59:59,999
It's got a blob that is the photo bytes,

407
99:59:59,999 --> 99:59:59,999
some tags: architecture and Colosseum,

408
99:59:59,999 --> 99:59:59,999
and a timestamp, when the photo was taken.

409
99:59:59,999 --> 99:59:59,999
At this point, I'm going to bring Shane up on stage

410
99:59:59,999 --> 99:59:59,999
and he's going to see how well that worked in a first pass.

411
99:59:59,999 --> 99:59:59,999
Hello, my name's Shane ???

412
99:59:59,999 --> 99:59:59,999
and I am a QA engineer with the Core Data team

413
99:59:59,999 --> 99:59:59,999
So here we have the first demo that Melissa mentioned;

414
99:59:59,999 --> 99:59:59,999
this is version one of the photos application.

415
99:59:59,999 --> 99:59:59,999
As you can see this is simply mapped over, a simple Photo entity. It's a single-entity application.

416
99:59:59,999 --> 99:59:59,999
And when you click on the record, we can see the photo.

417
99:59:59,999 --> 99:59:59,999
So this works as promised.

418
99:59:59,999 --> 99:59:59,999
Now what we're going to do is hook this up to Instruments

419
99:59:59,999 --> 99:59:59,999
and get some measurements.

420
99:59:59,999 --> 99:59:59,999
Now for those of you who haven't used Instruments before, I'd like to show you what you see when you first launch it.

421
99:59:59,999 --> 99:59:59,999
What you'll notice here is that you get a sheet with all of your instrument templates.

422
99:59:59,999 --> 99:59:59,999
In our case we're going to use the iOS Simulator.

423
99:59:59,999 --> 99:59:59,999
Off to the left you have some groups which allow you to target a specific platform.

424
99:59:59,999 --> 99:59:59,999
OS X, iOS, or the Simulator.

425
99:59:59,999 --> 99:59:59,999
You want to keep in mind when you're using the Simulator what Melissa mentioned earlier

426
99:59:59,999 --> 99:59:59,999
about your environment.

427
99:59:59,999 --> 99:59:59,999
This is actually a simulated application,

428
99:59:59,999 --> 99:59:59,999
so while it looks like iOS, it's running on our development hardware

429
99:59:59,999 --> 99:59:59,999
so we don't have the same constraints that we would have if we were using a device,

430
99:59:59,999 --> 99:59:59,999
such as memory, processor, and disk space.

431
99:59:59,999 --> 99:59:59,999
If you select the Core Data template you will get the instruments that Melissa mentioned earlier:
