X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:22,516 --> 00:00:25,886 A:middle
[ Applause ]

2
00:00:26,386 --> 00:00:28,356 A:middle
>> PETER TSOI: Hey, everyone.

3
00:00:28,416 --> 00:00:28,926 A:middle
Good afternoon.

4
00:00:28,926 --> 00:00:31,606 A:middle
And welcome to Advanced
Touch Input on iOS.

5
00:00:32,476 --> 00:00:33,256 A:middle
My name is Peter.

6
00:00:33,566 --> 00:00:35,636 A:middle
I work on the iOS
Performance team on Apple.

7
00:00:36,306 --> 00:00:39,236 A:middle
Today with my friend
Jacob, from the UIKit team,

8
00:00:39,236 --> 00:00:41,116 A:middle
we would like to tell
you a little bit more

9
00:00:41,386 --> 00:00:44,706 A:middle
about how touch input works
on iOS and how you can use

10
00:00:44,706 --> 00:00:47,266 A:middle
that information to make
your applications even more

11
00:00:47,266 --> 00:00:48,586 A:middle
responsive to touch input.

12
00:00:49,576 --> 00:00:51,386 A:middle
We've got a lot to
talk about today.

13
00:00:51,906 --> 00:00:56,016 A:middle
As the previous slide alluded
to, reducing latency is the name

14
00:00:56,016 --> 00:00:57,396 A:middle
of the game when it comes

15
00:00:57,526 --> 00:00:59,556 A:middle
to making your applications
even more responsive.

16
00:00:59,556 --> 00:01:03,136 A:middle
We will talk about what latency
is and why you should care

17

18
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

19
00:00:59,556 --> 00:01:03,136 A:middle
We will talk about what latency
is and why you should care

20
00:01:03,136 --> 00:01:04,696 A:middle
about latency in
your application

21
00:01:05,135 --> 00:01:06,906 A:middle
and latency in iOS as a whole.

22
00:01:08,046 --> 00:01:10,336 A:middle
In order to discuss where
this latency comes from,

23
00:01:10,566 --> 00:01:14,306 A:middle
we will discuss and dissect
the major pieces of iOS,

24
00:01:14,306 --> 00:01:16,106 A:middle
which are responsible
for everything

25
00:01:16,106 --> 00:01:17,576 A:middle
between handling
your touch input

26
00:01:17,966 --> 00:01:20,086 A:middle
to drawing the pixels
underneath your finger

27
00:01:20,086 --> 00:01:21,336 A:middle
in response to that touch.

28
00:01:22,506 --> 00:01:25,006 A:middle
We have made a lot of
improvements to this system

29
00:01:25,176 --> 00:01:27,666 A:middle
over the last year in iOS 9,
and we would like to tell you

30
00:01:27,666 --> 00:01:29,306 A:middle
about the improvements
as well as some

31
00:01:29,306 --> 00:01:31,616 A:middle
of the APIs you guys can
use to take advantage

32
00:01:31,616 --> 00:01:33,096 A:middle
of all these improvements
we have made.

33
00:01:34,166 --> 00:01:36,586 A:middle
And finally, we would like
to leave you with some tips

34
00:01:36,656 --> 00:01:39,846 A:middle
and best practices about
how to find, diagnose,

35
00:01:40,116 --> 00:01:42,916 A:middle
and fix the performance
bottlenecks in your application.

36
00:01:43,446 --> 00:01:45,886 A:middle
So why should you care

37
00:01:46,146 --> 00:01:48,136 A:middle
about reducing latency
in your application?

38
00:01:49,346 --> 00:01:51,856 A:middle
Touch input on iOS is
built around the idea

39
00:01:51,856 --> 00:01:53,386 A:middle
of direct manipulation.

40
00:01:53,846 --> 00:01:57,416 A:middle
This is the idea that a user
is actually touching a physical

41
00:01:57,416 --> 00:01:59,826 A:middle
object with their
finger and moving it

42
00:01:59,826 --> 00:02:00,926 A:middle
around in a virtual space.

43

44
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

45
00:01:59,826 --> 00:02:00,926 A:middle
around in a virtual space.

46
00:02:01,956 --> 00:02:06,076 A:middle
For example, if a user was
trying to move this circle

47
00:02:06,076 --> 00:02:11,076 A:middle
from point A to point B,
the expected result is

48
00:02:11,076 --> 00:02:13,866 A:middle
that the circle feels glued
to the end of the finger.

49
00:02:14,836 --> 00:02:16,036 A:middle
You'll notice that
in this example,

50
00:02:16,306 --> 00:02:19,466 A:middle
the circle tracks very
precisely and responsively

51
00:02:19,836 --> 00:02:20,736 A:middle
with the user's finger.

52
00:02:22,086 --> 00:02:24,556 A:middle
However, as soon as
you reduce latency,

53
00:02:24,836 --> 00:02:26,936 A:middle
or the lag between
when the finger moves

54
00:02:27,346 --> 00:02:29,866 A:middle
and the circle moves,
this illusion

55
00:02:29,866 --> 00:02:31,836 A:middle
of direct manipulation
starts to break down.

56
00:02:31,836 --> 00:02:33,806 A:middle
In this case, you can see

57
00:02:33,806 --> 00:02:36,946 A:middle
that the circle is following
the finger and it doesn't feel

58
00:02:36,946 --> 00:02:38,676 A:middle
like you are moving it around
with your finger anymore.

59
00:02:40,056 --> 00:02:41,736 A:middle
This effect is compounded

60
00:02:41,846 --> 00:02:43,416 A:middle
when the user is
moving really quickly.

61
00:02:44,066 --> 00:02:47,236 A:middle
In this case, the finger gets
a substantial distance away

62
00:02:47,236 --> 00:02:49,496 A:middle
from the circle, and
it no longer feels

63
00:02:49,496 --> 00:02:51,456 A:middle
like the finger is
glued to the circle,

64
00:02:51,636 --> 00:02:54,766 A:middle
rather the circle is now playing
catch-up with the finger.

65
00:02:55,876 --> 00:03:01,516 A:middle
So this type of latency affects
iOS as a whole, from everything

66

67
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

68
00:02:55,876 --> 00:03:01,516 A:middle
So this type of latency affects
iOS as a whole, from everything

69
00:03:01,516 --> 00:03:03,946 A:middle
from button presses to
moving objects around,

70
00:03:04,376 --> 00:03:06,826 A:middle
to scrolling anything
even a web page.

71
00:03:07,836 --> 00:03:11,106 A:middle
But we have identified a couple
of applications where increases

72
00:03:11,106 --> 00:03:13,136 A:middle
in latency are even
more noticeable.

73
00:03:13,796 --> 00:03:15,686 A:middle
One of these types

74
00:03:15,686 --> 00:03:17,806 A:middle
of applications are
drawing applications.

75
00:03:18,456 --> 00:03:21,336 A:middle
Not only is the artist then
distracted by the amount

76
00:03:21,336 --> 00:03:24,896 A:middle
of distance between the end of
the line and a user's finger.

77
00:03:26,236 --> 00:03:29,856 A:middle
Artists often rely on
quick, responsive updates

78
00:03:29,976 --> 00:03:33,386 A:middle
to their application or to
the user interface in order

79
00:03:33,386 --> 00:03:36,476 A:middle
to quickly adjust their
physical behaviors in order

80
00:03:36,476 --> 00:03:38,006 A:middle
to get the result
they are going for.

81
00:03:39,086 --> 00:03:41,866 A:middle
In addition, latency
in applications

82
00:03:41,896 --> 00:03:43,866 A:middle
like games makes the
games harder to play,

83
00:03:44,596 --> 00:03:47,156 A:middle
in effect the perceived
quality of your application.

84
00:03:48,696 --> 00:03:50,396 A:middle
Where does this latency
come from?

85
00:03:50,396 --> 00:03:52,176 A:middle
It comes from a lot
of different places.

86
00:03:52,626 --> 00:03:57,306 A:middle
In order to discuss where
it's caused, we'll discuss all

87
00:03:57,306 --> 00:03:59,506 A:middle
of the different parts
of the system involved

88
00:03:59,506 --> 00:04:02,716 A:middle
in handling your touches and
drawing the touches in response.

89

90
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

91
00:03:59,506 --> 00:04:02,716 A:middle
in handling your touches and
drawing the touches in response.

92
00:04:04,156 --> 00:04:05,816 A:middle
Throughout the next
portion of the talk,

93
00:04:05,816 --> 00:04:08,506 A:middle
we will be relying heavily
on these pipeline diagrams.

94
00:04:08,866 --> 00:04:09,856 A:middle
So let's make sure we are all

95
00:04:09,856 --> 00:04:11,456 A:middle
on the same page as
to what they mean.

96
00:04:12,306 --> 00:04:14,516 A:middle
Up on the screen, you
see five different boxes.

97
00:04:15,126 --> 00:04:17,286 A:middle
Each of these boxes
represents the amount

98
00:04:17,286 --> 00:04:19,666 A:middle
of time a frame is shown
on the display for.

99
00:04:19,666 --> 00:04:23,386 A:middle
Our products refresh
the screen at 60 hertz

100
00:04:23,616 --> 00:04:24,846 A:middle
or 60 times per second.

101
00:04:25,216 --> 00:04:27,796 A:middle
So the amount of time
represented by each

102
00:04:27,796 --> 00:04:32,496 A:middle
of these boxes is approximately
one-sixtieth of a second.

103
00:04:32,496 --> 00:04:36,836 A:middle
You may hear me refer to each of
these boxes as a display frame,

104
00:04:37,076 --> 00:04:39,236 A:middle
a display interval,
or a display cycle.

105
00:04:39,616 --> 00:04:42,026 A:middle
They all mean the same thing.

106
00:04:42,246 --> 00:04:44,256 A:middle
Now, the vertical
lines separating each

107
00:04:44,256 --> 00:04:46,496 A:middle
of these boxes is
the display refresh.

108
00:04:46,826 --> 00:04:48,946 A:middle
This is the point in
time where one frame

109
00:04:48,946 --> 00:04:51,776 A:middle
on the display is swapped out
with the next one to be shown.

110
00:04:52,636 --> 00:04:56,066 A:middle
You will hear me refer to this
as either the display refresh

111
00:04:56,156 --> 00:04:59,126 A:middle
or the v-sync, again they
mean basically the same thing.

112
00:04:59,946 --> 00:05:02,306 A:middle
The display refresh
is important in iOS

113

114
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

115
00:04:59,946 --> 00:05:02,306 A:middle
The display refresh
is important in iOS

116
00:05:02,606 --> 00:05:06,896 A:middle
because many important system
processes are kicked off

117
00:05:06,896 --> 00:05:09,116 A:middle
or triggered by this
display refresh.

118
00:05:09,446 --> 00:05:11,596 A:middle
So let's actually talk
about what's going

119
00:05:11,596 --> 00:05:12,946 A:middle
on inside this pipeline.

120
00:05:13,296 --> 00:05:15,946 A:middle
The first stage of the
pipeline is Multi-Touch.

121
00:05:16,586 --> 00:05:20,996 A:middle
This is the process where the
hardware will scan the surface

122
00:05:20,996 --> 00:05:22,846 A:middle
of the display looking
for touches.

123
00:05:23,876 --> 00:05:26,176 A:middle
On most of our products,
this can take less

124
00:05:26,176 --> 00:05:30,036 A:middle
than the entire display frame,
but on some of our products,

125
00:05:30,036 --> 00:05:32,536 A:middle
it can take up to that
entire display frame.

126
00:05:33,006 --> 00:05:34,526 A:middle
In order to symbolize
that, we will fill

127
00:05:34,526 --> 00:05:36,176 A:middle
in the entire box
with this green box.

128
00:05:37,076 --> 00:05:42,316 A:middle
Once Multi-Touch is finished
scanning this display

129
00:05:42,966 --> 00:05:46,626 A:middle
and is finished filtering
out any of the noise

130
00:05:46,736 --> 00:05:48,586 A:middle
which was present
on this screen,

131
00:05:49,346 --> 00:05:53,126 A:middle
your UI application's UITouch
callback will be called near the

132
00:05:53,126 --> 00:05:56,206 A:middle
beginning of the next
touch frame, usually right

133
00:05:56,206 --> 00:05:57,676 A:middle
after a display refresh
has occurred.

134
00:05:58,526 --> 00:06:01,906 A:middle
This is the point in time where
your application should respond

135

136
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

137
00:05:58,526 --> 00:06:01,906 A:middle
This is the point in time where
your application should respond

138
00:06:01,906 --> 00:06:04,526 A:middle
to the touch inputs and,
in a drawing application,

139
00:06:04,966 --> 00:06:07,586 A:middle
maybe plot the points and
connect the dots in between.

140
00:06:08,336 --> 00:06:11,136 A:middle
You may want to do any smoothing
to make the line very smooth.

141
00:06:11,136 --> 00:06:14,156 A:middle
In an application that
isn't a drawing application,

142
00:06:14,466 --> 00:06:16,866 A:middle
this is where you would
respond to button presses

143
00:06:16,866 --> 00:06:21,076 A:middle
or key presses, maybe create
views, view controllers

144
00:06:21,136 --> 00:06:22,356 A:middle
and present them to the user.

145
00:06:23,216 --> 00:06:26,036 A:middle
The amount of time spent here
is variable, but can take

146
00:06:26,036 --> 00:06:27,236 A:middle
up to one display frame.

147
00:06:27,516 --> 00:06:29,306 A:middle
So, again, I filled
in the entire box.

148
00:06:30,856 --> 00:06:33,636 A:middle
Once your application is done
responding to the touch events

149
00:06:33,666 --> 00:06:35,766 A:middle
and has updated the
state accordingly,

150
00:06:36,346 --> 00:06:39,796 A:middle
Core Animation will wake up
at the next display refresh

151
00:06:40,256 --> 00:06:43,836 A:middle
and begin translating
your views and your layers

152
00:06:44,476 --> 00:06:47,136 A:middle
into GPU commands that can
be rendered by the GPU.

153
00:06:47,216 --> 00:06:51,086 A:middle
You will notice that the
GPU does not have to wait

154
00:06:51,086 --> 00:06:52,956 A:middle
until the next display
refresh to begin.

155
00:06:53,186 --> 00:06:54,776 A:middle
It begins immediately as soon

156
00:06:54,776 --> 00:06:57,636 A:middle
as Core Animation has
given it the instructions

157
00:06:57,636 --> 00:06:59,216 A:middle
that it needs to
render the frame.

158

159
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

160
00:07:00,016 --> 00:07:03,296 A:middle
Again, the time in these
stages is variable,

161
00:07:03,896 --> 00:07:07,266 A:middle
based upon how complicated the
views in your application are.

162
00:07:08,406 --> 00:07:11,046 A:middle
Finally, once the GPU has
finished rendering your frame,

163
00:07:11,446 --> 00:07:13,496 A:middle
that frame is then
enqueued to be displayed

164
00:07:13,886 --> 00:07:16,716 A:middle
on the display once the
next display refresh occurs.

165
00:07:17,316 --> 00:07:23,156 A:middle
As you can tell, between sensing
your touch on the display,

166
00:07:23,386 --> 00:07:26,106 A:middle
all the way through to drawing
it, can take several frames.

167
00:07:26,316 --> 00:07:27,846 A:middle
In this case, it
takes four frames.

168
00:07:28,596 --> 00:07:29,506 A:middle
So it's not instant.

169
00:07:30,846 --> 00:07:32,456 A:middle
In addition, this is a pipeline.

170
00:07:32,796 --> 00:07:36,386 A:middle
So other touches that may
occur while your application is

171
00:07:36,386 --> 00:07:38,816 A:middle
processing that previous
touch can also be happening.

172
00:07:39,456 --> 00:07:40,826 A:middle
These just go through
the process

173
00:07:40,826 --> 00:07:42,816 A:middle
at different points
in the pipeline.

174
00:07:43,346 --> 00:07:46,656 A:middle
Let's talk about what you as
a developer have control over.

175
00:07:47,226 --> 00:07:50,506 A:middle
There are no APIs to alter the
behavior of the Multi-Touch

176
00:07:50,556 --> 00:07:51,996 A:middle
or the display hardware layers.

177
00:07:52,336 --> 00:07:54,186 A:middle
This is handled for
you by the system.

178
00:07:55,146 --> 00:07:56,886 A:middle
You exercise indirect control

179
00:07:57,156 --> 00:08:00,626 A:middle
over the Core Animation render
server and the GPU based

180

181
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

182
00:07:57,156 --> 00:08:00,626 A:middle
over the Core Animation render
server and the GPU based

183
00:08:00,626 --> 00:08:03,066 A:middle
on how complicated the views
in your application are.

184
00:08:03,456 --> 00:08:06,616 A:middle
But you have almost complete
control over your application.

185
00:08:07,186 --> 00:08:08,576 A:middle
So that's where we will begin.

186
00:08:09,346 --> 00:08:12,466 A:middle
As I mentioned earlier,
this is the point

187
00:08:12,466 --> 00:08:14,476 A:middle
where you update the
stay of your application

188
00:08:14,636 --> 00:08:16,276 A:middle
in response to the touch inputs.

189
00:08:16,916 --> 00:08:19,016 A:middle
For example, in a drawing
application, you plot the points

190
00:08:19,016 --> 00:08:21,206 A:middle
and connect them,
or you create views

191
00:08:21,206 --> 00:08:22,426 A:middle
in response to button presses.

192
00:08:22,906 --> 00:08:25,246 A:middle
This also might be where
you issue your OpenGL

193
00:08:25,246 --> 00:08:25,926 A:middle
or Metal commands.

194
00:08:26,206 --> 00:08:28,606 A:middle
The amount of time
spent here is variable.

195
00:08:28,976 --> 00:08:32,356 A:middle
You can optimize this to take
a smaller amount of time,

196
00:08:32,395 --> 00:08:35,316 A:middle
and we encourage you to do
this, but you will notice

197
00:08:35,676 --> 00:08:37,765 A:middle
that when we optimize
the application,

198
00:08:38,076 --> 00:08:41,796 A:middle
Core Animation does not slide in
to fill in the space left behind

199
00:08:41,796 --> 00:08:44,116 A:middle
by UIKit or your application.

200
00:08:45,326 --> 00:08:47,486 A:middle
This is because of how updates

201
00:08:47,486 --> 00:08:50,456 A:middle
to your views have worked
historically in the past on iOS.

202
00:08:51,636 --> 00:08:53,446 A:middle
When you update the state
of your views on iOS,

203
00:08:53,756 --> 00:08:56,576 A:middle
you can either explicitly
commit A CATransaction

204
00:08:57,296 --> 00:08:59,906 A:middle
or UIKit will implicitly
generate one for you

205

206
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

207
00:09:00,306 --> 00:09:02,806 A:middle
if you update the views
properties with the UIMethods.

208
00:09:03,506 --> 00:09:06,576 A:middle
We will represent this
CATransaction commit

209
00:09:06,576 --> 00:09:07,356 A:middle
with this red dot.

210
00:09:08,816 --> 00:09:11,756 A:middle
Now, the reason why Core
Animation doesn't slide

211
00:09:11,756 --> 00:09:13,436 A:middle
in to fill in the time is

212
00:09:13,436 --> 00:09:14,996 A:middle
because your application
is allowed

213
00:09:15,226 --> 00:09:18,316 A:middle
to update its state several
time during one display frame,

214
00:09:18,476 --> 00:09:21,016 A:middle
in this case, symbolized
by the second dot.

215
00:09:22,006 --> 00:09:25,096 A:middle
Now, in order to reduce the
amount of redundant work or work

216
00:09:25,096 --> 00:09:26,726 A:middle
that will never be
shown on the display,

217
00:09:27,166 --> 00:09:31,496 A:middle
Core Animation will batch
up all of your updates

218
00:09:31,496 --> 00:09:33,726 A:middle
and render it once at
the display refresh.

219
00:09:34,106 --> 00:09:37,006 A:middle
So we will only render
the combined state of both

220
00:09:37,006 --> 00:09:39,576 A:middle
of those Core Animation
transactions.

221
00:09:39,956 --> 00:09:44,366 A:middle
Once Core Animation decides
to snapshot your view

222
00:09:44,496 --> 00:09:48,646 A:middle
at the display refresh, it
will begin translating all

223
00:09:48,646 --> 00:09:51,896 A:middle
of the logical views and layers
that you have created for it

224
00:09:51,896 --> 00:09:54,346 A:middle
into GPU commands that can
be rendered by the GPU.

225
00:09:54,996 --> 00:09:58,366 A:middle
As I mentioned earlier, the
GPU starts immediately as soon

226
00:09:58,366 --> 00:10:00,026 A:middle
as it has the necessary
instructions

227

228
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

229
00:09:58,366 --> 00:10:00,026 A:middle
as it has the necessary
instructions

230
00:10:00,026 --> 00:10:00,816 A:middle
from Core Animation.

231
00:10:01,276 --> 00:10:04,786 A:middle
So if you optimize the amount
of time spent in Core Animation

232
00:10:04,786 --> 00:10:07,796 A:middle
or in the GPU, the GPU
will fill in the space

233
00:10:07,796 --> 00:10:09,806 A:middle
that was left behind it.

234
00:10:10,106 --> 00:10:12,366 A:middle
The view debugger in Xcode
is a very helpful way

235
00:10:12,366 --> 00:10:15,116 A:middle
to understand how complicated
your view hierarchy is

236
00:10:15,416 --> 00:10:18,636 A:middle
and a great way to find
views that you can take out

237
00:10:18,636 --> 00:10:20,406 A:middle
and therefore optimize
your application.

238
00:10:22,006 --> 00:10:24,976 A:middle
However, we recognize
the need for views

239
00:10:24,976 --> 00:10:26,146 A:middle
that are very complicated,

240
00:10:26,376 --> 00:10:28,256 A:middle
that can't possibly
be represented

241
00:10:28,256 --> 00:10:29,206 A:middle
in one display frame.

242
00:10:30,296 --> 00:10:33,506 A:middle
So the iOS pipeline is
flexible enough to handle that.

243
00:10:34,446 --> 00:10:35,626 A:middle
If your application needs

244
00:10:35,626 --> 00:10:37,186 A:middle
to spend additional
time rendering views,

245
00:10:37,316 --> 00:10:39,566 A:middle
we can split the Core
Animation and GPU work

246
00:10:39,616 --> 00:10:41,236 A:middle
over two display frames.

247
00:10:41,856 --> 00:10:43,966 A:middle
Of course, this adds an
additional frame of latency,

248
00:10:44,196 --> 00:10:47,426 A:middle
but you can still get 60 frames
per second smooth animations

249
00:10:47,756 --> 00:10:50,506 A:middle
everywhere in your application,
with more complicated views.

250
00:10:51,556 --> 00:10:54,176 A:middle
There is no manual trigger to go

251
00:10:54,176 --> 00:10:56,586 A:middle
between the faster mode
and the slower mode.

252
00:10:56,946 --> 00:11:00,256 A:middle
This, again, happens for you
and is arbitrated by the system.

253

254
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

255
00:10:56,946 --> 00:11:00,256 A:middle
This, again, happens for you
and is arbitrated by the system.

256
00:11:00,746 --> 00:11:03,546 A:middle
So it's important that we
understand what things can

257
00:11:03,546 --> 00:11:05,076 A:middle
trigger you into the faster mode

258
00:11:05,326 --> 00:11:10,406 A:middle
and what things can trigger
you into the slower mode.

259
00:11:10,406 --> 00:11:13,486 A:middle
The faster mode is called double
buffering, and we call it this

260
00:11:13,486 --> 00:11:16,846 A:middle
because there are two buffers,
one for the GPU to draw into,

261
00:11:17,026 --> 00:11:19,336 A:middle
and one for the LCD
to show to the user.

262
00:11:20,126 --> 00:11:23,036 A:middle
At the display refresh,
as you will recall,

263
00:11:23,036 --> 00:11:26,116 A:middle
Core Animation grabs a buffer
for it and the GPU to use,

264
00:11:26,116 --> 00:11:28,746 A:middle
and it will begin outputting
GPU commands for that frame.

265
00:11:29,506 --> 00:11:32,696 A:middle
Once the GPU has those commands,
the GPU will begin rendering,

266
00:11:33,176 --> 00:11:36,116 A:middle
and if the render completes
before the next display refresh

267
00:11:36,116 --> 00:11:40,216 A:middle
has to occur, we enqueue
that frame for display

268
00:11:40,476 --> 00:11:41,716 A:middle
at the next display refresh.

269
00:11:42,386 --> 00:11:43,896 A:middle
Once we reach that
display refresh,

270
00:11:44,436 --> 00:11:46,416 A:middle
the frame is then
swapped onto the screen

271
00:11:46,736 --> 00:11:48,886 A:middle
and we begin the process
with the next frame.

272
00:11:49,876 --> 00:11:52,846 A:middle
Again, the GPU will render
and then enqueue the frame

273
00:11:52,846 --> 00:11:54,466 A:middle
for display at the
next display refresh.

274
00:11:55,036 --> 00:11:56,416 A:middle
Once we hit that
display refresh,

275
00:11:56,716 --> 00:11:59,576 A:middle
these two frames
will swap places,

276
00:11:59,576 --> 00:12:03,076 A:middle
we will reclaim the green buffer
and continue this process,

277

278
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

279
00:11:59,576 --> 00:12:03,076 A:middle
we will reclaim the green buffer
and continue this process,

280
00:12:03,216 --> 00:12:06,406 A:middle
as long as your application has
views that it wants to render.

281
00:12:07,666 --> 00:12:08,796 A:middle
Now, this is all fine and good.

282
00:12:08,856 --> 00:12:11,456 A:middle
We have finished our Core
Animation and our GPU work

283
00:12:11,706 --> 00:12:12,746 A:middle
within one display frame.

284
00:12:13,106 --> 00:12:14,056 A:middle
We have good performance.

285
00:12:14,056 --> 00:12:17,576 A:middle
But what happens if you
can't do all of this?

286
00:12:18,426 --> 00:12:19,616 A:middle
If you can't do it in one frame?

287
00:12:20,256 --> 00:12:22,176 A:middle
Then we fall into a mode
called triple buffering.

288
00:12:22,876 --> 00:12:25,776 A:middle
Again, Core Animation
will output GPU commands,

289
00:12:25,886 --> 00:12:28,866 A:middle
which the GPU will then
render but in this example,

290
00:12:29,306 --> 00:12:31,756 A:middle
the GPU hasn't finished
rendering the green frame

291
00:12:31,876 --> 00:12:33,906 A:middle
by the time we hit
the display refresh.

292
00:12:34,706 --> 00:12:38,056 A:middle
In this example, since we can't
show it yet, the blue frame has

293
00:12:38,056 --> 00:12:40,566 A:middle
to be extended on the
screen for an extra frame.

294
00:12:42,096 --> 00:12:44,386 A:middle
Core Animation now needs
to allocate a third buffer

295
00:12:44,386 --> 00:12:47,236 A:middle
to begin work on the next
frame, and it will do

296
00:12:47,236 --> 00:12:48,856 A:middle
so by creating this
third buffer.

297
00:12:49,636 --> 00:12:52,116 A:middle
Then Core Animation will
start outputting GPU commands

298
00:12:52,116 --> 00:12:54,876 A:middle
for it while the GPU finishes
rendering the previous frame.

299
00:12:55,896 --> 00:12:58,716 A:middle
And then the previous frame
will be enqueued for display

300
00:12:58,876 --> 00:13:00,266 A:middle
at the next display refresh.

301

302
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

303
00:12:58,876 --> 00:13:00,266 A:middle
at the next display refresh.

304
00:13:01,386 --> 00:13:02,486 A:middle
This process then repeats

305
00:13:02,876 --> 00:13:06,946 A:middle
with the Core Animation render
server outputting GPU commands,

306
00:13:06,946 --> 00:13:08,606 A:middle
and the GPU will
then render them.

307
00:13:09,206 --> 00:13:10,076 A:middle
You get the idea.

308
00:13:10,156 --> 00:13:12,576 A:middle
We swap the buffers,
reclaim the buffer,

309
00:13:12,906 --> 00:13:14,746 A:middle
and then the process repeats.

310
00:13:16,896 --> 00:13:20,906 A:middle
So you might be thinking, all of
these slides say Core Animation.

311
00:13:21,336 --> 00:13:22,526 A:middle
What if I don't use
Core Animation?

312
00:13:22,786 --> 00:13:24,946 A:middle
What if I have optimized
my application

313
00:13:25,336 --> 00:13:27,096 A:middle
to use Metal or OpenGL?

314
00:13:28,086 --> 00:13:31,476 A:middle
You might think instead of
your pipeline looking like this

315
00:13:31,906 --> 00:13:34,926 A:middle
and getting your frame out
to the display in four frames

316
00:13:34,926 --> 00:13:37,966 A:middle
of latency, that you can do
it in three frames of latency.

317
00:13:39,676 --> 00:13:42,456 A:middle
Unfortunately that's
not the case.

318
00:13:42,566 --> 00:13:45,796 A:middle
Under iOS 8, if you
use Metal or OpenGL,

319
00:13:46,216 --> 00:13:48,826 A:middle
Core Animation still acts
an arbiter, to make sure

320
00:13:48,826 --> 00:13:51,756 A:middle
that any updates you make to
any Core Animation content

321
00:13:51,756 --> 00:13:56,146 A:middle
on the screen are synchronized
with any GPU, OpenGL,

322
00:13:56,146 --> 00:13:58,536 A:middle
Metal updates that you
make to those layers.

323
00:13:59,556 --> 00:14:01,596 A:middle
So you still have
four frames of latency

324

325
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

326
00:13:59,556 --> 00:14:01,596 A:middle
So you still have
four frames of latency

327
00:14:01,926 --> 00:14:05,866 A:middle
when you use OpenGL
or Metal in iOS 8.

328
00:14:06,636 --> 00:14:11,796 A:middle
So we talked about how the iOS
pipeline is flexible enough

329
00:14:11,866 --> 00:14:13,506 A:middle
to handle very complicated
views,

330
00:14:13,796 --> 00:14:18,166 A:middle
getting you 60 frames per second
animation but at five frames

331
00:14:18,166 --> 00:14:21,326 A:middle
of latency and how you can
optimize your application

332
00:14:21,656 --> 00:14:23,676 A:middle
to bring that latency
down to four frames

333
00:14:23,966 --> 00:14:25,836 A:middle
by optimizing what
you are drawing.

334
00:14:26,786 --> 00:14:30,576 A:middle
However, in this example,
there is no real way

335
00:14:30,576 --> 00:14:33,286 A:middle
to make it any faster, because
Core Animation needs to wait

336
00:14:33,286 --> 00:14:34,556 A:middle
until the display refresh

337
00:14:34,936 --> 00:14:37,386 A:middle
to start generating
the GPU commands.

338
00:14:37,916 --> 00:14:42,436 A:middle
In iOS 9, we are
removing that dependency.

339
00:14:43,556 --> 00:14:46,406 A:middle
You can now start Core Animation
work immediately as soon

340
00:14:46,406 --> 00:14:48,186 A:middle
as your application is
done updating the state

341
00:14:48,186 --> 00:14:48,886 A:middle
of your application.

342
00:14:49,906 --> 00:14:51,556 A:middle
In order to take
advantage of these,

343
00:14:51,556 --> 00:14:53,966 A:middle
we have introduced some new APIs

344
00:14:53,966 --> 00:14:55,856 A:middle
and new tricks in
the iOS system.

345
00:14:56,206 --> 00:14:57,676 A:middle
To tell you a little
bit more about them,

346
00:14:57,676 --> 00:14:59,476 A:middle
I would like to introduce
Jacob [applause].

347

348
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

349
00:15:01,186 --> 00:15:01,626 A:middle
>> JACOB XIAO: Thanks, Peter.

350
00:15:02,686 --> 00:15:04,186 A:middle
So I would like to tell you

351
00:15:04,466 --> 00:15:06,736 A:middle
about some additions
we have made in iOS 9,

352
00:15:07,346 --> 00:15:10,886 A:middle
and how you can use them to get
even lower latency in your apps.

353
00:15:11,936 --> 00:15:13,726 A:middle
I will be talking about
three things today.

354
00:15:14,526 --> 00:15:17,536 A:middle
First, low latency
support in Core Animation.

355
00:15:18,576 --> 00:15:22,796 A:middle
Then, a new system for touch
coalescing, and finally,

356
00:15:23,156 --> 00:15:24,936 A:middle
a really cool system
for touch prediction

357
00:15:25,156 --> 00:15:26,406 A:middle
that we built into UIKit.

358
00:15:27,936 --> 00:15:30,736 A:middle
So let's get started with low
latency in Core Animation.

359
00:15:31,356 --> 00:15:34,806 A:middle
As Peter just showed
you in iOS 8,

360
00:15:35,166 --> 00:15:37,646 A:middle
even with a well-optimized
app there was a limit

361
00:15:37,646 --> 00:15:39,386 A:middle
to how far you could
get your latency down.

362
00:15:40,636 --> 00:15:43,406 A:middle
By using low latency
Core Animation in iOS 9,

363
00:15:43,956 --> 00:15:47,026 A:middle
we can combine the app's frame
with Core Animation frame,

364
00:15:47,236 --> 00:15:48,836 A:middle
and this gives you
much lower latency.

365
00:15:49,786 --> 00:15:51,356 A:middle
The best thing about
this feature is

366
00:15:51,356 --> 00:15:52,376 A:middle
that it happens automatically.

367
00:15:52,376 --> 00:15:54,846 A:middle
There are no changes you have
to make to your app other

368
00:15:54,846 --> 00:15:56,176 A:middle
than optimizing your
performance.

369
00:15:57,776 --> 00:15:59,506 A:middle
However, there's one
thing to keep in mind,

370
00:15:59,816 --> 00:16:02,616 A:middle
which is that this low latency
mode is automatically disabled

371

372
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

373
00:15:59,816 --> 00:16:02,616 A:middle
which is that this low latency
mode is automatically disabled

374
00:16:02,996 --> 00:16:05,386 A:middle
when you have animations
active in your app.

375
00:16:05,926 --> 00:16:09,056 A:middle
This includes CA animations
and UIKit animations,

376
00:16:09,546 --> 00:16:12,036 A:middle
so if you want the absolute
lowest latency in your app,

377
00:16:12,476 --> 00:16:15,316 A:middle
you want to make sure to disable
those animations while touches

378
00:16:15,316 --> 00:16:21,986 A:middle
are active on the display.

379
00:16:22,916 --> 00:16:26,306 A:middle
Now this system also works
with Metal and OpenGL content.

380
00:16:26,976 --> 00:16:29,726 A:middle
So as you saw earlier
before in iOS 8,

381
00:16:30,206 --> 00:16:31,646 A:middle
we had to wait an
additional frame

382
00:16:31,826 --> 00:16:33,616 A:middle
to get your GPU content
to the display.

383
00:16:33,616 --> 00:16:37,146 A:middle
But with the new low
latency mode, we can now get

384
00:16:37,186 --> 00:16:39,426 A:middle
that content to the display
as quickly as possible

385
00:16:39,426 --> 00:16:40,366 A:middle
in the very next frame.

386
00:16:41,416 --> 00:16:43,116 A:middle
This happens automatically just

387
00:16:43,116 --> 00:16:45,566 A:middle
by using CAeagllayer
or CAMetalLayer.

388
00:16:45,816 --> 00:16:49,076 A:middle
However, if there's one thing
to keep in mind in your app

389
00:16:49,556 --> 00:16:51,546 A:middle
if you have Core Animation
content that you want

390
00:16:51,546 --> 00:16:54,196 A:middle
to draw along with this
OpenGL or Metal content.

391
00:16:55,426 --> 00:16:58,626 A:middle
In this case, the GPU content
will be drawn to the display

392
00:16:58,626 --> 00:17:02,266 A:middle
as quickly as possible but your
Core Animation content may take

393

394
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

395
00:16:58,626 --> 00:17:02,266 A:middle
as quickly as possible but your
Core Animation content may take

396
00:17:02,266 --> 00:17:03,816 A:middle
a little longer to go through.

397
00:17:04,685 --> 00:17:08,116 A:middle
And if that happens, then by
default, it's not guaranteed

398
00:17:08,376 --> 00:17:11,165 A:middle
that your GPU content will
arrive in the same frame

399
00:17:11,165 --> 00:17:12,445 A:middle
as your Core Animation content.

400
00:17:13,326 --> 00:17:15,915 A:middle
Now this may be a problem if you
want those two to be in sync,

401
00:17:15,915 --> 00:17:17,816 A:middle
and that could happen,
for example,

402
00:17:17,816 --> 00:17:20,316 A:middle
if you had an OpenGL map
view, that you wanted

403
00:17:20,316 --> 00:17:22,016 A:middle
to draw UIKit content on top of.

404
00:17:23,096 --> 00:17:25,935 A:middle
In that case, you may want
to synchronize those updates

405
00:17:26,185 --> 00:17:28,626 A:middle
in something like this,
and there's a property

406
00:17:28,626 --> 00:17:29,366 A:middle
that allows you to do

407
00:17:29,366 --> 00:17:31,816 A:middle
that called Presents
With Transaction.

408
00:17:32,206 --> 00:17:34,466 A:middle
It's on CAeagllayer
and CAMetalLayer.

409
00:17:35,316 --> 00:17:37,536 A:middle
When this is set to False,
which is the default value,

410
00:17:38,206 --> 00:17:40,426 A:middle
then it will get your GPU
content to the display

411
00:17:40,426 --> 00:17:41,476 A:middle
as quickly as possible.

412
00:17:42,266 --> 00:17:43,536 A:middle
But when you set it to True,

413
00:17:44,076 --> 00:17:45,986 A:middle
then we synchronize
your GPU content

414
00:17:46,256 --> 00:17:48,836 A:middle
with the Core Animation
content so they both appear

415
00:17:48,916 --> 00:17:50,726 A:middle
on the display at the same time.

416
00:17:51,296 --> 00:17:52,326 A:middle
All right.

417
00:17:52,496 --> 00:17:55,256 A:middle
Next, let's talk about
touch coalescing.

418
00:17:56,256 --> 00:17:57,406 A:middle
But before we do, I would

419
00:17:57,406 --> 00:17:59,826 A:middle
like to tell you a little
bit about the iPad Air 2.

420

421
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

422
00:18:01,086 --> 00:18:02,956 A:middle
We introduced the
iPad Air 2 last year,

423
00:18:03,746 --> 00:18:05,936 A:middle
and it has a 60-hertz
display update rate,

424
00:18:06,246 --> 00:18:09,186 A:middle
which means the display
updates at 60 times per second

425
00:18:09,606 --> 00:18:10,886 A:middle
like our other iOS devices.

426
00:18:11,786 --> 00:18:14,456 A:middle
It also has a really cool
feature that affects touch

427
00:18:14,456 --> 00:18:16,456 A:middle
and touch latency that
I'm really excited

428
00:18:16,456 --> 00:18:17,136 A:middle
to announce to you today.

429
00:18:17,136 --> 00:18:21,316 A:middle
And that's the fact that it has
a 120-hertz touch scan update

430
00:18:21,316 --> 00:18:21,536 A:middle
rate [applause].

431
00:18:25,366 --> 00:18:25,796 A:middle
It's pretty cool.

432
00:18:27,606 --> 00:18:30,006 A:middle
This means that it scans for
touches at twice the rate

433
00:18:30,136 --> 00:18:31,516 A:middle
of all other iOS devices.

434
00:18:31,616 --> 00:18:34,286 A:middle
And this is great, because you
can get a lot more information

435
00:18:34,506 --> 00:18:35,986 A:middle
about where the user's
finger is going

436
00:18:36,036 --> 00:18:37,386 A:middle
as they interact
with the display.

437
00:18:38,976 --> 00:18:41,776 A:middle
Let's take a look at how this
affects your app in practice.

438
00:18:42,976 --> 00:18:46,356 A:middle
With the 60-hertz touch scan
rate, as the user's finger moves

439
00:18:46,356 --> 00:18:48,866 A:middle
across the display, we
will periodically sample

440
00:18:48,866 --> 00:18:52,016 A:middle
where that finger is and give
that information to the app.

441
00:18:53,456 --> 00:18:56,036 A:middle
The same thing happens with
the 120-hertz scan rate,

442
00:18:56,456 --> 00:18:59,716 A:middle
but since it's twice as fast,
you get twice as many samples,

443
00:18:59,716 --> 00:19:02,296 A:middle
and this gives you a
lot more information

444

445
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

446
00:18:59,716 --> 00:19:02,296 A:middle
and this gives you a
lot more information

447
00:19:02,296 --> 00:19:09,206 A:middle
about what the user is doing.

448
00:19:09,396 --> 00:19:12,196 A:middle
Now, once we get those samples,
we will pass them to your app,

449
00:19:12,196 --> 00:19:15,496 A:middle
and you can use those to
know what the user is trying

450
00:19:15,496 --> 00:19:16,336 A:middle
to do with their touches.

451
00:19:16,806 --> 00:19:19,726 A:middle
For example, in a drawing app,
you might connect them together

452
00:19:20,056 --> 00:19:22,346 A:middle
to represent the drawing that
the user is trying to perform,

453
00:19:23,346 --> 00:19:26,856 A:middle
and this 120-hertz information
gives you a lot more information

454
00:19:26,976 --> 00:19:29,766 A:middle
that you can use to get a better
representation of their drawing.

455
00:19:30,306 --> 00:19:32,806 A:middle
So now that we have
seen the benefits

456
00:19:32,806 --> 00:19:36,046 A:middle
of 120-hertz touch scan
rate, let's take a look

457
00:19:36,046 --> 00:19:39,446 A:middle
at how it affects the
touch to display pipeline.

458
00:19:40,026 --> 00:19:43,146 A:middle
This is the 60-hertz
touch scan rate pipeline

459
00:19:43,146 --> 00:19:43,866 A:middle
that we saw earlier.

460
00:19:44,706 --> 00:19:46,906 A:middle
And let's focus in on
just the Multi-Touch stage

461
00:19:46,976 --> 00:19:47,636 A:middle
of the pipeline.

462
00:19:49,096 --> 00:19:52,726 A:middle
At 60 hertz, we get a new
touch sample every frame.

463
00:19:53,776 --> 00:19:56,906 A:middle
And with 120 hertz, we'll now
get two samples every time.

464
00:19:57,786 --> 00:19:59,196 A:middle
However, note that the size

465
00:19:59,196 --> 00:20:00,886 A:middle
of the display frame
is still the same,

466

467
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

468
00:19:59,196 --> 00:20:00,886 A:middle
of the display frame
is still the same,

469
00:20:01,246 --> 00:20:03,816 A:middle
since we have the same update
rate for the display itself.

470
00:20:03,946 --> 00:20:08,076 A:middle
Now, we could take those new
touch samples and pass them

471
00:20:08,076 --> 00:20:11,316 A:middle
to your app, and your app could
use that to update its drawing,

472
00:20:11,666 --> 00:20:13,826 A:middle
which would update what it
showed in Core Animation

473
00:20:13,826 --> 00:20:15,066 A:middle
and on to the display.

474
00:20:16,076 --> 00:20:17,346 A:middle
But you will notice
that if we did,

475
00:20:17,346 --> 00:20:20,056 A:middle
that your app would actually
be updating twice as often

476
00:20:20,056 --> 00:20:21,806 A:middle
as the display updates,
which would lead

477
00:20:21,806 --> 00:20:23,746 A:middle
to wasted work in your app.

478
00:20:24,026 --> 00:20:26,016 A:middle
So we introduced the
touch coalescing system

479
00:20:26,116 --> 00:20:27,316 A:middle
to get the best of both worlds.

480
00:20:28,076 --> 00:20:30,196 A:middle
This allows you to get
the increased information

481
00:20:30,196 --> 00:20:32,936 A:middle
from the 120-hertz
touch scan rate but not

482
00:20:32,936 --> 00:20:35,586 A:middle
to have any wasted work in
your app withdrawing too much.

483
00:20:36,336 --> 00:20:38,926 A:middle
Let's take a look at how
this pipeline changes

484
00:20:38,926 --> 00:20:39,666 A:middle
with coalescing.

485
00:20:41,026 --> 00:20:42,756 A:middle
Now we will only deliver a touch

486
00:20:42,756 --> 00:20:45,166 A:middle
to your app once
per display frame,

487
00:20:45,756 --> 00:20:48,106 A:middle
so when the first touch comes
in, we will deliver that to you.

488
00:20:49,036 --> 00:20:51,926 A:middle
And then in the next frame,
we will deliver you the touch

489
00:20:51,926 --> 00:20:54,816 A:middle
for that frame, and also
any intermediate touches

490
00:20:54,816 --> 00:20:56,916 A:middle
that happened since the
last time we sent touches

491
00:20:56,916 --> 00:20:58,326 A:middle
to your app.

492
00:20:58,836 --> 00:21:02,656 A:middle
This repeats each time the
user makes more touches

493

494
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

495
00:20:58,836 --> 00:21:02,656 A:middle
This repeats each time the
user makes more touches

496
00:21:02,656 --> 00:21:03,186 A:middle
to the display.

497
00:21:03,686 --> 00:21:05,856 A:middle
We'll give you the current
touch and any coalesce touches,

498
00:21:06,206 --> 00:21:08,476 A:middle
and that continues as long
as touches are active.

499
00:21:09,056 --> 00:21:12,636 A:middle
Now, the API to use these
coalesced touches is

500
00:21:12,636 --> 00:21:13,196 A:middle
really simple.

501
00:21:13,926 --> 00:21:16,556 A:middle
It's a new method on UIEvent
called Coalesce Touches

502
00:21:16,556 --> 00:21:17,106 A:middle
For Touch.

503
00:21:18,056 --> 00:21:20,276 A:middle
You pass into that method the
touch that you're looking at,

504
00:21:20,766 --> 00:21:23,496 A:middle
and we'll give you back an array
of all the coalesced touches

505
00:21:23,496 --> 00:21:27,246 A:middle
since the last time we delivered
that touch to your app.

506
00:21:28,116 --> 00:21:30,186 A:middle
To get a better idea
of how to use this API,

507
00:21:30,186 --> 00:21:33,146 A:middle
let's look at how touch handling
works in iOS in general.

508
00:21:33,746 --> 00:21:36,786 A:middle
When the user first
touches the display,

509
00:21:36,786 --> 00:21:40,016 A:middle
we will call Touches
Began on your app.

510
00:21:40,246 --> 00:21:43,616 A:middle
As their finger moves, we will
call Touches Moved, and finally,

511
00:21:43,936 --> 00:21:45,666 A:middle
as their finger is
removed from the display,

512
00:21:45,666 --> 00:21:46,856 A:middle
we will call Touches Ended.

513
00:21:48,066 --> 00:21:50,016 A:middle
Now, as we are talking
about these touch callbacks,

514
00:21:50,476 --> 00:21:53,016 A:middle
another very important
callback is Touches Canceled.

515
00:21:54,076 --> 00:21:55,726 A:middle
This gets called when
the stream of touches

516
00:21:55,726 --> 00:21:56,906 A:middle
to your app is interrupted.

517
00:21:57,516 --> 00:21:59,496 A:middle
For example, if the user
swipes from the bottom

518
00:21:59,636 --> 00:22:00,686 A:middle
to activate Control Center.

519

520
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

521
00:21:59,636 --> 00:22:00,686 A:middle
to activate Control Center.

522
00:22:02,126 --> 00:22:04,986 A:middle
In that case, your app will get
some the initial touch callback,

523
00:22:04,986 --> 00:22:06,616 A:middle
and we will get Touches Canceled

524
00:22:07,146 --> 00:22:09,286 A:middle
when the system gesture
takes over.

525
00:22:09,916 --> 00:22:13,476 A:middle
It's important to implement
this method to do any cleanup

526
00:22:13,476 --> 00:22:16,636 A:middle
for things that you started in
the previous touch callbacks

527
00:22:17,056 --> 00:22:18,616 A:middle
and roll back any
changes you made.

528
00:22:19,246 --> 00:22:21,376 A:middle
For example, in a drawing
app, you might want

529
00:22:21,376 --> 00:22:23,176 A:middle
to remove the line that
the user was drawing.

530
00:22:23,536 --> 00:22:27,016 A:middle
So now that we have seen how
these touch callbacks work,

531
00:22:27,326 --> 00:22:29,376 A:middle
let's see how they interact
with coalesce touches.

532
00:22:30,576 --> 00:22:32,066 A:middle
The touches we deliver to all

533
00:22:32,066 --> 00:22:34,136 A:middle
of those callbacks are
what we call main touches,

534
00:22:34,596 --> 00:22:38,046 A:middle
and these work the same with the
120-hertz scan rate as they do

535
00:22:38,046 --> 00:22:39,186 A:middle
with 60-hertz devices.

536
00:22:39,256 --> 00:22:43,756 A:middle
However, with the Coalesce
Touches For Touch method,

537
00:22:43,966 --> 00:22:46,116 A:middle
you can get access
to more information

538
00:22:46,116 --> 00:22:47,186 A:middle
with these coalesced touches.

539
00:22:48,286 --> 00:22:51,566 A:middle
The coalesced touches
not only have information

540
00:22:51,566 --> 00:22:54,966 A:middle
about the intermediate touches
but they also give you a copy

541
00:22:55,176 --> 00:22:56,176 A:middle
of the main touch itself.

542
00:22:56,826 --> 00:22:59,686 A:middle
And the great thing about this
is that it allows you a choice.

543

544
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

545
00:23:00,176 --> 00:23:01,776 A:middle
You can look at the main touches

546
00:23:02,126 --> 00:23:03,866 A:middle
if you don't need the
increased information

547
00:23:04,376 --> 00:23:07,556 A:middle
of the higher touch scan
rate in your app, or,

548
00:23:07,556 --> 00:23:09,406 A:middle
if you want that
information, you can look

549
00:23:09,406 --> 00:23:11,726 A:middle
at just the coalesced touches
and you don't have to worry

550
00:23:11,726 --> 00:23:12,576 A:middle
about the main touches.

551
00:23:17,276 --> 00:23:21,166 A:middle
So now let's revisit the touch
sequence that we saw and see how

552
00:23:21,166 --> 00:23:23,836 A:middle
that works with both main
touches and coalesced touches.

553
00:23:24,776 --> 00:23:26,566 A:middle
As the user's finger comes down,

554
00:23:26,566 --> 00:23:29,886 A:middle
we will give your app a
main touch, and also a copy

555
00:23:29,886 --> 00:23:31,176 A:middle
of that as a coalesced touch.

556
00:23:32,346 --> 00:23:33,416 A:middle
Then as their finger moves,

557
00:23:33,416 --> 00:23:35,756 A:middle
we will deliver you new
main touches and a set

558
00:23:35,756 --> 00:23:37,226 A:middle
of coalesced touches
for each one.

559
00:23:38,066 --> 00:23:39,536 A:middle
And finally, as their
finger leaves,

560
00:23:39,646 --> 00:23:41,066 A:middle
we will give you
the last main touch

561
00:23:41,526 --> 00:23:42,946 A:middle
and any remaining
coalesced touches.

562
00:23:43,606 --> 00:23:45,986 A:middle
Now here, I have shown only one

563
00:23:45,986 --> 00:23:48,836 A:middle
or two coalesced touches
for each main touch.

564
00:23:49,396 --> 00:23:50,626 A:middle
But it's important
to keep in mind

565
00:23:50,626 --> 00:23:52,076 A:middle
that your app can receive
a different amount.

566
00:23:53,036 --> 00:23:55,216 A:middle
If your app takes a long
time to process a touch,

567
00:23:55,616 --> 00:23:57,636 A:middle
then we will give you some
time to catch up and wait

568
00:23:57,636 --> 00:24:00,866 A:middle
to send you new touches
until you have caught up.

569

570
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

571
00:23:57,636 --> 00:24:00,866 A:middle
to send you new touches
until you have caught up.

572
00:24:01,106 --> 00:24:02,696 A:middle
And if this happens,
then the touches

573
00:24:02,696 --> 00:24:04,256 A:middle
that weren't delivered
you to will be sent

574
00:24:04,256 --> 00:24:05,886 A:middle
to you later as coalesced
touches.

575
00:24:06,416 --> 00:24:08,506 A:middle
So make sure that you don't
hard code any dependencies

576
00:24:08,736 --> 00:24:10,536 A:middle
on the number of coalesced
touches that you receive.

577
00:24:11,226 --> 00:24:14,786 A:middle
Now, there are a few
differences between the way

578
00:24:14,786 --> 00:24:16,716 A:middle
that coalesced touches
behave and the way

579
00:24:16,716 --> 00:24:17,666 A:middle
that main touches behave.

580
00:24:18,496 --> 00:24:20,736 A:middle
One of those is related
to previous location.

581
00:24:21,776 --> 00:24:24,696 A:middle
And previous location is
something that you can get

582
00:24:24,696 --> 00:24:27,406 A:middle
with the method Previous
Location In View from UITouch.

583
00:24:28,336 --> 00:24:32,106 A:middle
For main touches, this gives
your app the last location

584
00:24:32,106 --> 00:24:33,696 A:middle
that that touch had when
it was delivered to you.

585
00:24:34,436 --> 00:24:36,676 A:middle
And for coalesced touches,
it behaves very similarly.

586
00:24:36,856 --> 00:24:38,226 A:middle
It gives you the location

587
00:24:38,326 --> 00:24:40,366 A:middle
of the last coalesced
touch to your app.

588
00:24:41,606 --> 00:24:43,696 A:middle
And this is one of the reasons
that it's really important

589
00:24:43,696 --> 00:24:45,216 A:middle
to focus on just
the main touches

590
00:24:45,426 --> 00:24:46,586 A:middle
or just the coalesced touches.

591
00:24:47,346 --> 00:24:49,546 A:middle
That way, you won't
get any confusion

592
00:24:49,546 --> 00:24:50,616 A:middle
with the previous locations.

593
00:24:51,056 --> 00:24:52,936 A:middle
So it's really important
not to cross the streams.

594
00:24:54,516 --> 00:24:58,576 A:middle
[ Applause ]

595
00:24:59,076 --> 00:25:00,866 A:middle
Now, another difference
between main touches

596

597
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

598
00:24:59,076 --> 00:25:00,866 A:middle
Now, another difference
between main touches

599
00:25:00,866 --> 00:25:02,196 A:middle
and coalesced touches is

600
00:25:02,196 --> 00:25:04,236 A:middle
in how the UITouch
objects themselves behave.

601
00:25:05,666 --> 00:25:09,156 A:middle
With main touches, the same
UITouch instance is reused every

602
00:25:09,156 --> 00:25:11,836 A:middle
time the touch is
delivered to your app.

603
00:25:12,246 --> 00:25:14,566 A:middle
This is helpful because it
allows you to differentiate

604
00:25:14,726 --> 00:25:17,606 A:middle
between different touches if
the users has multiple fingers

605
00:25:17,606 --> 00:25:18,566 A:middle
on the display at once.

606
00:25:19,216 --> 00:25:22,866 A:middle
And for coalesced touches, this
works a little bit differently.

607
00:25:23,596 --> 00:25:26,386 A:middle
There, each time we deliver a
coalesced touch to your app,

608
00:25:26,896 --> 00:25:28,476 A:middle
we deliver a new
UITouch instance

609
00:25:29,486 --> 00:25:30,626 A:middle
that has the new properties.

610
00:25:30,726 --> 00:25:33,696 A:middle
And so you can think of
these as snapshots instead

611
00:25:33,696 --> 00:25:35,906 A:middle
of the shared identity
that the main touches have.

612
00:25:35,966 --> 00:25:39,476 A:middle
So now that you understand
how touch coalescing works,

613
00:25:39,616 --> 00:25:42,426 A:middle
let's dig into some code for
how to use coalesced touches.

614
00:25:43,216 --> 00:25:45,106 A:middle
This is some code that
you might have in an app

615
00:25:45,566 --> 00:25:48,326 A:middle
that does something like drawing
and you could have something

616
00:25:48,326 --> 00:25:49,456 A:middle
like this in touches moved.

617
00:25:50,466 --> 00:25:52,836 A:middle
Here we are iterating through
the touches that we have,

618
00:25:53,436 --> 00:25:55,776 A:middle
and we are grabbing the line
that corresponds to each touch.

619
00:25:57,066 --> 00:25:59,446 A:middle
Then we are adding the
latest touch as a new sample

620
00:25:59,446 --> 00:26:00,526 A:middle
onto the end of that line.

621

622
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

623
00:25:59,446 --> 00:26:00,526 A:middle
onto the end of that line.

624
00:26:01,116 --> 00:26:04,786 A:middle
And to add touch coalescing
support, we just need

625
00:26:04,786 --> 00:26:06,106 A:middle
to add this small bit of code.

626
00:26:07,136 --> 00:26:09,956 A:middle
Now, we are iterating through
all the coalesced touches

627
00:26:09,956 --> 00:26:12,516 A:middle
for the given main
touch, and for each

628
00:26:12,516 --> 00:26:14,276 A:middle
of those coalesced
touches, we are adding it

629
00:26:14,276 --> 00:26:15,896 A:middle
for the sample to the line.

630
00:26:16,726 --> 00:26:18,616 A:middle
Notice that we are only
adding the coalesced touches

631
00:26:18,616 --> 00:26:20,236 A:middle
of the samples, not
the main touches.

632
00:26:21,056 --> 00:26:22,246 A:middle
And that's touch coalescing.

633
00:26:22,246 --> 00:26:29,346 A:middle
Now I would like to tell
you about touch prediction.

634
00:26:30,066 --> 00:26:32,396 A:middle
This is a really cool system
that we have added right

635
00:26:32,396 --> 00:26:34,156 A:middle
into UIKit that you can use

636
00:26:34,156 --> 00:26:36,006 A:middle
to get even lower
latency in your apps.

637
00:26:37,086 --> 00:26:38,946 A:middle
Now, as we deliver your app,

638
00:26:38,946 --> 00:26:42,156 A:middle
new touches will also give
you a look into the future

639
00:26:42,426 --> 00:26:44,696 A:middle
at what we predict that the
user's touches will be doing

640
00:26:44,776 --> 00:26:45,496 A:middle
in the near future.

641
00:26:46,436 --> 00:26:49,416 A:middle
And the API for this works
very similarly to the API

642
00:26:49,556 --> 00:26:50,396 A:middle
for coalesced touches.

643
00:26:51,326 --> 00:26:54,026 A:middle
It's another method on UIEvent
called Predicted Touches

644
00:26:54,026 --> 00:26:54,536 A:middle
For Touch.

645
00:26:55,726 --> 00:26:58,016 A:middle
Once again, you pass in a
main touch to this method

646
00:26:58,016 --> 00:27:00,276 A:middle
and you will get back an
array of predicted touches.

647

648
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

649
00:26:58,016 --> 00:27:00,276 A:middle
and you will get back an
array of predicted touches.

650
00:27:01,526 --> 00:27:04,916 A:middle
And you can use those predicted
touches to update your drawing

651
00:27:05,026 --> 00:27:07,156 A:middle
or whatever else you are
doing with the user's touches,

652
00:27:07,946 --> 00:27:09,026 A:middle
to get even lower latency.

653
00:27:10,556 --> 00:27:12,506 A:middle
So earlier, we saw
how main touches

654
00:27:12,506 --> 00:27:13,846 A:middle
and coalesced touches
are related,

655
00:27:14,696 --> 00:27:16,816 A:middle
and predicted touches work
in a very similar way.

656
00:27:17,536 --> 00:27:20,466 A:middle
They are another set of touches
associated with a main touch,

657
00:27:21,556 --> 00:27:25,566 A:middle
and they behave as snapshots
just like coalesced touches do.

658
00:27:25,826 --> 00:27:27,986 A:middle
Now, one thing that's different
about predicted touches compared

659
00:27:27,986 --> 00:27:30,006 A:middle
to coalesced touches
is what happens

660
00:27:30,006 --> 00:27:31,076 A:middle
when new touches come in.

661
00:27:31,976 --> 00:27:34,096 A:middle
As you get a new main touch,
you will get a new set

662
00:27:34,096 --> 00:27:38,246 A:middle
of predicted touches, and the
new predicted touches are the

663
00:27:38,246 --> 00:27:39,726 A:middle
only thing you want to use then.

664
00:27:40,236 --> 00:27:42,536 A:middle
Any previous predicted
touches are no longer useful

665
00:27:42,806 --> 00:27:44,106 A:middle
since we now have information

666
00:27:44,106 --> 00:27:46,416 A:middle
about where the user actually
touched during that time.

667
00:27:46,736 --> 00:27:50,126 A:middle
So you generally want to throw
those old predicted touches out.

668
00:27:51,156 --> 00:27:53,446 A:middle
Now, previous location
in view works similarly

669
00:27:53,446 --> 00:27:55,656 A:middle
for predicted touches as it
does for other touch types.

670
00:27:56,546 --> 00:27:57,806 A:middle
It points to the location

671
00:27:57,806 --> 00:28:00,526 A:middle
that the previous
predicted touch had, or,

672

673
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

674
00:27:57,806 --> 00:28:00,526 A:middle
that the previous
predicted touch had, or,

675
00:28:00,526 --> 00:28:03,346 A:middle
for the first predicted touch,
it points to the last location

676
00:28:03,456 --> 00:28:05,286 A:middle
that was delivered to your app.

677
00:28:05,916 --> 00:28:08,336 A:middle
So you may be wondering how we
actually get these predicted

678
00:28:08,336 --> 00:28:09,676 A:middle
touches, and it's pretty simple.

679
00:28:10,476 --> 00:28:12,516 A:middle
We built a time machine into
every iOS device [laughter].

680
00:28:14,596 --> 00:28:15,556 A:middle
That's not quite how it works.

681
00:28:16,216 --> 00:28:19,186 A:middle
What we are actually doing
is looking at the touches

682
00:28:19,286 --> 00:28:21,636 A:middle
that are delivered to
your app and using a set

683
00:28:21,636 --> 00:28:24,026 A:middle
of highly tuned algorithms
to determine

684
00:28:24,026 --> 00:28:27,386 A:middle
where the user's finger looks
like it's going at this time.

685
00:28:28,186 --> 00:28:30,826 A:middle
And as we get new touch samples,
we will update our prediction

686
00:28:30,936 --> 00:28:34,006 A:middle
and deliver new predicted
touches to your app.

687
00:28:34,236 --> 00:28:37,496 A:middle
Now, each of those predicted
touches are complete UITouch

688
00:28:37,496 --> 00:28:39,816 A:middle
objects and they have all of
their properties filled out,

689
00:28:40,126 --> 00:28:42,246 A:middle
like their location
and time stamp.

690
00:28:43,156 --> 00:28:46,196 A:middle
So now we can look at how those
predicted touches affect the

691
00:28:46,196 --> 00:28:47,946 A:middle
pipeline that we
have been looking at.

692
00:28:48,796 --> 00:28:50,996 A:middle
This is what we saw
earlier from main touches

693
00:28:51,026 --> 00:28:53,316 A:middle
and coalesced touches,
and we can easily add

694
00:28:53,316 --> 00:28:54,646 A:middle
in predicted touches as well.

695
00:28:56,166 --> 00:28:58,246 A:middle
Each frame, as your
app gets a main touch,

696
00:28:58,346 --> 00:29:00,306 A:middle
you also get a set
of predicted touches.

697

698
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

699
00:28:58,346 --> 00:29:00,306 A:middle
you also get a set
of predicted touches.

700
00:29:00,676 --> 00:29:04,106 A:middle
And if you get main touches
and coalesced touches as well,

701
00:29:04,396 --> 00:29:06,356 A:middle
then the predicted touches
are just more information

702
00:29:06,356 --> 00:29:07,836 A:middle
that you have available to you.

703
00:29:08,686 --> 00:29:11,356 A:middle
And this process just repeats
as new touches are delivered.

704
00:29:12,436 --> 00:29:14,936 A:middle
One thing to note is
that coalesced touches

705
00:29:14,936 --> 00:29:16,506 A:middle
and predicted touches
are independent.

706
00:29:16,506 --> 00:29:17,966 A:middle
You can use one without
the other,

707
00:29:18,756 --> 00:29:21,356 A:middle
and predicted touches are
supported on both 60-hertz

708
00:29:21,406 --> 00:29:23,686 A:middle
and 120-hertz touch
scan rate devices.

709
00:29:24,346 --> 00:29:27,716 A:middle
So now let's take a look at
how we can add touch prediction

710
00:29:28,056 --> 00:29:30,386 A:middle
to the code that we were
taking a look at earlier.

711
00:29:30,436 --> 00:29:34,216 A:middle
All you need to do is add
this small bit of code,

712
00:29:34,216 --> 00:29:38,676 A:middle
and what we are doing is first
removing any previous predicted

713
00:29:38,676 --> 00:29:39,996 A:middle
touches that we added
to our line.

714
00:29:40,216 --> 00:29:43,116 A:middle
And this is important since we
now have the actual locations

715
00:29:43,416 --> 00:29:44,286 A:middle
where those touches were.

716
00:29:44,886 --> 00:29:53,336 A:middle
Then we are iterating through
the predicted touches we have.

717
00:29:54,216 --> 00:29:56,806 A:middle
And for each of those predicted
touches, we are adding it

718
00:29:56,966 --> 00:29:58,696 A:middle
as a sample to our line.

719
00:29:59,706 --> 00:30:01,556 A:middle
But notice that we are
calling a different method here

720

721
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

722
00:29:59,706 --> 00:30:01,556 A:middle
But notice that we are
calling a different method here

723
00:30:01,666 --> 00:30:03,936 A:middle
to add the predicted
sample as what we called

724
00:30:03,936 --> 00:30:05,266 A:middle
to call the normal samples.

725
00:30:05,776 --> 00:30:08,066 A:middle
This is so that we can mark
that sample as something

726
00:30:08,066 --> 00:30:09,786 A:middle
that will need to be
removed the next time we go

727
00:30:09,786 --> 00:30:11,106 A:middle
through this code.

728
00:30:11,676 --> 00:30:13,836 A:middle
So that's touch coalescing
and touch prediction.

729
00:30:14,226 --> 00:30:16,746 A:middle
Now that you have seen
all of these techniques,

730
00:30:17,066 --> 00:30:18,906 A:middle
let's see what happens when
we combine them all together.

731
00:30:20,326 --> 00:30:23,536 A:middle
In iOS 8, with a
well-optimized app,

732
00:30:24,136 --> 00:30:25,806 A:middle
this was the touch latency
view that you could get.

733
00:30:25,806 --> 00:30:28,356 A:middle
We measured the latency
as the time

734
00:30:28,356 --> 00:30:30,946 A:middle
between when the touch
first comes down to

735
00:30:30,946 --> 00:30:33,436 A:middle
when the display has updated
with that touch's information.

736
00:30:34,246 --> 00:30:35,836 A:middle
And so you can see
that in iOS 8,

737
00:30:35,836 --> 00:30:37,536 A:middle
we would have four
frames of latency.

738
00:30:38,186 --> 00:30:42,586 A:middle
Now by using low latency
Core Animation and iOS 9,

739
00:30:42,876 --> 00:30:44,606 A:middle
we can remove one frame
of latency from that.

740
00:30:45,656 --> 00:30:48,576 A:middle
And by using touch
coalescing and running

741
00:30:48,576 --> 00:30:50,156 A:middle
on a high-touch-scan-rate
device,

742
00:30:50,816 --> 00:30:52,566 A:middle
you can not only get
increased information

743
00:30:52,566 --> 00:30:55,476 A:middle
about the user's touch, you
can also remove a half frame

744
00:30:55,476 --> 00:30:58,936 A:middle
of latency from the
beginning [applause].

745
00:30:59,046 --> 00:30:59,576 A:middle
But there's more!

746

747
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

748
00:31:02,356 --> 00:31:05,296 A:middle
By also using touch prediction
you can get information

749
00:31:05,296 --> 00:31:07,166 A:middle
about approximately a
frame into the future

750
00:31:07,216 --> 00:31:08,636 A:middle
of where the user's
touches are going.

751
00:31:09,186 --> 00:31:13,026 A:middle
And this lets you give the user
an effective latency that's

752
00:31:13,026 --> 00:31:14,936 A:middle
reduced by about a
frame more as well.

753
00:31:15,646 --> 00:31:17,466 A:middle
And so altogether, in iOS 9,

754
00:31:17,466 --> 00:31:19,246 A:middle
you can get down to
approximately one

755
00:31:19,246 --> 00:31:21,136 A:middle
and a half frames of
latency for your users

756
00:31:21,366 --> 00:31:24,056 A:middle
which is a huge improvement from
iOS 8's four frames of latency.

757
00:31:25,516 --> 00:31:31,586 A:middle
[ Applause ]

758
00:31:32,086 --> 00:31:33,096 A:middle
So we think this
is really great,

759
00:31:33,096 --> 00:31:35,256 A:middle
and I highly encourage you
to adopt these techniques

760
00:31:35,256 --> 00:31:38,296 A:middle
in your app to give your users
a great low latency experience.

761
00:31:38,766 --> 00:31:41,126 A:middle
Now I would like to turn
things back over to Peter

762
00:31:41,126 --> 00:31:42,716 A:middle
to tell you how to
fine-tune your app.

763
00:31:44,516 --> 00:31:48,956 A:middle
[ Applause ]

764
00:31:49,456 --> 00:31:50,446 A:middle
>> PETER TSOI: Thanks, Jacob.

765
00:31:50,506 --> 00:31:53,196 A:middle
So now that you know about all
of the new low latency modes

766
00:31:53,546 --> 00:31:56,526 A:middle
in iOS 9, we would like to tell
you how you can take advantage

767
00:31:56,526 --> 00:31:59,866 A:middle
of those by fine-tuning your
applications so you can fit

768
00:31:59,866 --> 00:32:03,616 A:middle
within one display frame of
time so you can get your frames

769

770
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

771
00:31:59,866 --> 00:32:03,616 A:middle
within one display frame of
time so you can get your frames

772
00:32:03,616 --> 00:32:05,316 A:middle
out to the display that quickly.

773
00:32:05,726 --> 00:32:08,326 A:middle
The first way to ensure

774
00:32:08,326 --> 00:32:11,346 A:middle
that your application is doing
the least amount of work is

775
00:32:11,376 --> 00:32:13,326 A:middle
to minimize the amount of work

776
00:32:13,606 --> 00:32:15,306 A:middle
that your application
needs to do.

777
00:32:15,596 --> 00:32:18,626 A:middle
By using the coalesced touches
API that Jacob just introduced

778
00:32:18,626 --> 00:32:22,426 A:middle
to you, you can get the benefits
of high-fidelity touch inputs

779
00:32:22,686 --> 00:32:24,816 A:middle
of the iPad Air 2
while making sure

780
00:32:24,816 --> 00:32:26,906 A:middle
that your application
only renders images

781
00:32:27,096 --> 00:32:28,446 A:middle
that will make it
onto the screen.

782
00:32:29,196 --> 00:32:32,176 A:middle
In addition, keep in mind
that your user only cares

783
00:32:32,176 --> 00:32:35,406 A:middle
about the content that they can
see on the device's display.

784
00:32:36,026 --> 00:32:40,096 A:middle
Your application may do the
work to keep track of the state

785
00:32:40,246 --> 00:32:43,166 A:middle
of the world outside of
the screen, but ultimately,

786
00:32:43,166 --> 00:32:46,336 A:middle
you should make sure that the
rendering work is restricted

787
00:32:46,676 --> 00:32:50,096 A:middle
to only the work that is
necessary to generate the image

788
00:32:50,316 --> 00:32:52,416 A:middle
that ultimately shows
up on the screen.

789
00:32:53,466 --> 00:32:57,356 A:middle
If you are trying to
profile your application,

790
00:32:57,526 --> 00:33:00,436 A:middle
to figure out how much time
your application is spending

791

792
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

793
00:32:57,526 --> 00:33:00,436 A:middle
to figure out how much time
your application is spending

794
00:33:00,436 --> 00:33:03,986 A:middle
on the CPU, Time Profiler
is a great way to do this.

795
00:33:04,626 --> 00:33:07,366 A:middle
Time Profiler will show you how
much time your application is

796
00:33:07,366 --> 00:33:10,786 A:middle
using on the CPU by sampling
it at a fixed interval.

797
00:33:11,436 --> 00:33:14,286 A:middle
In this case, in Time Profiler,

798
00:33:14,286 --> 00:33:17,386 A:middle
I selected a 16-millisecond
interval,

799
00:33:17,616 --> 00:33:19,716 A:middle
which corresponds roughly
to one display frame.

800
00:33:20,726 --> 00:33:23,616 A:middle
You can also tell
that my application

801
00:33:23,856 --> 00:33:26,516 A:middle
in this case is using
only a small fraction

802
00:33:26,516 --> 00:33:27,406 A:middle
of that amount of time.

803
00:33:28,066 --> 00:33:29,706 A:middle
In this case, 3 milliseconds.

804
00:33:30,256 --> 00:33:33,196 A:middle
Now this is all fine and good
if you are trying to measure

805
00:33:33,196 --> 00:33:36,316 A:middle
and profile how you are
doing in terms of CPU work.

806
00:33:36,816 --> 00:33:37,886 A:middle
What about GPU work?

807
00:33:39,196 --> 00:33:42,696 A:middle
The frames per second gauge
in the GPU report available

808
00:33:42,696 --> 00:33:47,036 A:middle
in the Xcode debugging session
give you a high-level view

809
00:33:47,086 --> 00:33:48,826 A:middle
of your application's
GPU performance.

810
00:33:49,566 --> 00:33:50,856 A:middle
In this case, you can see

811
00:33:50,856 --> 00:33:53,276 A:middle
that this application is
hitting 60 frames per second,

812
00:33:53,806 --> 00:33:57,346 A:middle
and it has a relatively low
amount of GPU frame time.

813
00:33:57,706 --> 00:33:59,806 A:middle
In this case, just
3.8 milliseconds.

814

815
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

816
00:34:00,786 --> 00:34:04,506 A:middle
Keep in mind, though, that this
is just a high-level overview

817
00:34:04,916 --> 00:34:06,306 A:middle
of what your application
is doing.

818
00:34:06,846 --> 00:34:09,176 A:middle
It doesn't give you
fine-grained information

819
00:34:09,206 --> 00:34:13,025 A:middle
about individual frames that may
be causing you to drop frames.

820
00:34:14,126 --> 00:34:17,366 A:middle
If you require that type of
precision, then you will want

821
00:34:17,366 --> 00:34:20,366 A:middle
to turn to the new
GPU driver instrument,

822
00:34:20,766 --> 00:34:22,696 A:middle
which we have introduced
in Xcode this year.

823
00:34:23,686 --> 00:34:27,166 A:middle
The GPU driver instrument can
show you exactly how long the

824
00:34:27,166 --> 00:34:30,206 A:middle
GPU is active for while you
are using your application.

825
00:34:30,866 --> 00:34:33,795 A:middle
In this case, you can see
that the amount of time spent

826
00:34:33,795 --> 00:34:35,436 A:middle
in the vertex and
fragment shaders

827
00:34:35,466 --> 00:34:38,065 A:middle
of my application
is relatively small.

828
00:34:38,206 --> 00:34:41,076 A:middle
In fact, it's just a small
fraction of the amount of time

829
00:34:41,426 --> 00:34:43,666 A:middle
that a frame is shown
on the display for.

830
00:34:45,176 --> 00:34:48,416 A:middle
Notice you only see
two colors here.

831
00:34:49,045 --> 00:34:52,076 A:middle
These two colors represent
the two buffers which are used

832
00:34:52,076 --> 00:34:53,366 A:middle
in the double-buffering scheme.

833
00:34:54,485 --> 00:34:58,106 A:middle
If our application is spending
more time in Core Animation

834
00:34:58,106 --> 00:35:01,426 A:middle
and in GPU, you will
see three colors here

835

836
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

837
00:34:58,106 --> 00:35:01,426 A:middle
and in GPU, you will
see three colors here

838
00:35:01,426 --> 00:35:03,426 A:middle
to represent the
triple buffering

839
00:35:03,426 --> 00:35:04,906 A:middle
which is happening
in the system.

840
00:35:05,456 --> 00:35:10,676 A:middle
We have talked a lot about
reducing latency and how

841
00:35:10,676 --> 00:35:13,406 A:middle
to make your application more
responsive, but ultimately,

842
00:35:13,486 --> 00:35:17,026 A:middle
building a great iOS experience
is about building a natural

843
00:35:17,026 --> 00:35:18,976 A:middle
and intuitive experience
for your user

844
00:35:19,316 --> 00:35:22,966 A:middle
and making your application feel
more alive is another great way

845
00:35:22,966 --> 00:35:24,506 A:middle
of doing that.

846
00:35:24,506 --> 00:35:28,166 A:middle
Over the last year, we thought
long and hard about each part

847
00:35:28,166 --> 00:35:29,826 A:middle
of our system, and we found ways

848
00:35:29,966 --> 00:35:31,916 A:middle
to make it better
and faster than ever.

849
00:35:32,706 --> 00:35:34,876 A:middle
Throughout this process,
we have improved our APIs

850
00:35:35,246 --> 00:35:37,626 A:middle
to give you more control
and more information

851
00:35:37,926 --> 00:35:39,056 A:middle
over how the system works.

852
00:35:40,006 --> 00:35:43,276 A:middle
With the new low latency
modes on OpenGL, Metal,

853
00:35:43,366 --> 00:35:46,456 A:middle
and Core Animation,
you have more control

854
00:35:46,456 --> 00:35:50,026 A:middle
over when your frame is shown to
the user and how it synchronizes

855
00:35:50,136 --> 00:35:51,906 A:middle
with any other content
you have on the screen.

856
00:35:52,846 --> 00:35:56,366 A:middle
With touch coalescing, you
can take advantage of all

857
00:35:56,366 --> 00:35:58,786 A:middle
of our hardware and all of
its awesome capabilities

858
00:35:59,136 --> 00:36:00,326 A:middle
to provide that to your user.

859

860
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

861
00:35:59,136 --> 00:36:00,326 A:middle
to provide that to your user.

862
00:36:00,616 --> 00:36:02,996 A:middle
And with touch prediction, we
are offering you a small glimpse

863
00:36:02,996 --> 00:36:05,896 A:middle
into the future as to where
that touch is going to go.

864
00:36:06,876 --> 00:36:10,426 A:middle
And finally, we have built
and created some great tools

865
00:36:10,426 --> 00:36:12,606 A:middle
in order for you to
understand the performance

866
00:36:12,606 --> 00:36:15,036 A:middle
of your application so that
you can improve upon it

867
00:36:15,166 --> 00:36:17,546 A:middle
to provide an even better
experience for your users.

868
00:36:18,016 --> 00:36:21,826 A:middle
We at Apple are committed
to making the experience

869
00:36:21,826 --> 00:36:24,756 A:middle
of using our products
feel more alive than ever,

870
00:36:24,796 --> 00:36:27,356 A:middle
and we think reducing latency
is a great way of doing that,

871
00:36:27,636 --> 00:36:29,506 A:middle
and we would like to invite
you along on this journey.

872
00:36:30,106 --> 00:36:33,736 A:middle
You can find more information
about the technology, tools,

873
00:36:33,736 --> 00:36:36,996 A:middle
and APIs we've discussed
today at developer.apple.com.

874
00:36:36,996 --> 00:36:39,726 A:middle
We would also like to
invite you to take part

875
00:36:39,726 --> 00:36:43,536 A:middle
in the developer
technical conversation

876
00:36:43,956 --> 00:36:46,116 A:middle
on our developer forums.

877
00:36:46,676 --> 00:36:48,656 A:middle
We talked about a lot

878
00:36:48,656 --> 00:36:50,636 A:middle
of different new
technologies today,

879
00:36:50,966 --> 00:36:53,716 A:middle
and there have been really
great sessions both this year

880
00:36:53,716 --> 00:36:55,996 A:middle
and in previous years
that go over topics

881
00:36:56,306 --> 00:36:57,616 A:middle
which are related to this talk.

882
00:36:58,436 --> 00:37:00,056 A:middle
For example, if you
are very interested

883

884
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

885
00:36:58,436 --> 00:37:00,056 A:middle
For example, if you
are very interested

886
00:37:00,056 --> 00:37:03,246 A:middle
in profiling the GPU
performance of your application,

887
00:37:03,696 --> 00:37:07,266 A:middle
and if you are really, really,
really excited to get your hands

888
00:37:07,266 --> 00:37:10,856 A:middle
on that new GPU instrument,
I would like to point you

889
00:37:10,856 --> 00:37:13,236 A:middle
at the Metal Performance
Optimization Techniques talk,

890
00:37:13,516 --> 00:37:16,236 A:middle
which was given earlier
today, where they talk

891
00:37:16,236 --> 00:37:20,366 A:middle
about a whole bunch of different
techniques that you can use

892
00:37:20,366 --> 00:37:23,836 A:middle
to optimize your GPU work, not
just if you are using Metal.

893
00:37:25,216 --> 00:37:29,236 A:middle
In addition, if Time Profiler is
your jam, then you want to check

894
00:37:29,236 --> 00:37:33,046 A:middle
out the new Profiling in Depth
talk, which was given yesterday,

895
00:37:33,556 --> 00:37:36,536 A:middle
which goes into a deep dive
on how to use Time Profiler

896
00:37:36,586 --> 00:37:38,886 A:middle
to get a great idea of what
your application is doing.

897
00:37:39,896 --> 00:37:42,176 A:middle
And finally, if you guys
are really interested

898
00:37:42,176 --> 00:37:44,896 A:middle
in what is happening in the
Core Animation and GPU stages

899
00:37:44,896 --> 00:37:46,596 A:middle
of the pipeline we
have discussed today,

900
00:37:46,596 --> 00:37:48,836 A:middle
I would like to point you
to the Advanced Graphics

901
00:37:48,836 --> 00:37:52,426 A:middle
and Animation talk
from last year's WWDC.

902
00:37:52,616 --> 00:37:55,466 A:middle
All of these talks and
many, many more can be found

903
00:37:55,466 --> 00:37:57,906 A:middle
on our developer portal
at developer.apple.com.

904
00:37:58,716 --> 00:38:02,346 A:middle
I hope you learned a lot today
and over the entire course

905

906
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

907
00:37:58,716 --> 00:38:02,346 A:middle
I hope you learned a lot today
and over the entire course

908
00:38:02,346 --> 00:38:05,636 A:middle
of this week, and I hope
you had an enjoyable WWDC.

909
00:38:06,106 --> 00:38:06,436 A:middle
Thank you.

910
00:38:07,516 --> 00:38:21,230 A:middle
[ Applause ]

911
