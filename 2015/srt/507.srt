X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:25,516 --> 00:00:30,606 A:middle
[ Applause ]

2
00:00:31,106 --> 00:00:31,806 A:middle
>>AKSHATHA NAGESH: Thank you.

3
00:00:32,246 --> 00:00:34,256 A:middle
Good afternoon everyone, welcome

4
00:00:34,256 --> 00:00:36,466 A:middle
to the session What's
New in Code Audio.

5
00:00:37,366 --> 00:00:40,576 A:middle
I am Akshatha Nagesh, and
I will be the first speaker

6
00:00:40,576 --> 00:00:44,126 A:middle
in this session.

7
00:00:44,126 --> 00:00:47,646 A:middle
I will be talking about
[unintelligible] AVAudioEngine

8
00:00:48,306 --> 00:00:52,686 A:middle
and its new features for this
year's iOS and OS X releases.

9
00:00:53,936 --> 00:00:56,186 A:middle
Later, my colleague
Torrey will be talking

10
00:00:56,186 --> 00:00:58,986 A:middle
about other exciting
new features we have

11
00:00:58,986 --> 00:01:02,046 A:middle
for you this year like
inter-device audio

12

13
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

14
00:00:58,986 --> 00:01:02,046 A:middle
for you this year like
inter-device audio

15
00:01:02,516 --> 00:01:05,866 A:middle
and what's new in our
good old AVAudioSession.

16
00:01:07,066 --> 00:01:10,966 A:middle
Tomorrow morning we have another
Core Audio presentation called

17
00:01:11,036 --> 00:01:15,276 A:middle
Audio Unit Extensions and it's
about a whole new set of APIs

18
00:01:15,276 --> 00:01:18,306 A:middle
which I am sure you will
find very interesting,

19
00:01:18,746 --> 00:01:23,386 A:middle
so do catch that
session as well.

20
00:01:23,546 --> 00:01:23,886 A:middle
All right.

21
00:01:24,476 --> 00:01:28,006 A:middle
Let's begin with a
recap of AVAudioEngine.

22
00:01:28,596 --> 00:01:33,516 A:middle
If you know about Core
Audio, you may be aware

23
00:01:33,886 --> 00:01:36,956 A:middle
that we offer a wide
variety of APIs

24
00:01:37,306 --> 00:01:39,756 A:middle
for implementing
powerful audio features.

25
00:01:40,836 --> 00:01:45,266 A:middle
Last year, in iOS 8
and OS X Yosemite,

26
00:01:45,756 --> 00:01:47,456 A:middle
we introduced a new set

27
00:01:47,456 --> 00:01:51,876 A:middle
of Objective-C APIs called
AVAudioEngine as a part

28
00:01:51,876 --> 00:01:54,066 A:middle
of AVFoundation framework.

29
00:01:55,496 --> 00:01:58,386 A:middle
If you are not very
familiar with AVAudioEngine,

30
00:01:58,606 --> 00:02:00,856 A:middle
I would highly encourage
you to check

31

32
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

33
00:01:58,606 --> 00:02:00,856 A:middle
I would highly encourage
you to check

34
00:02:00,856 --> 00:02:05,976 A:middle
out our last year's WWDC session
AVAudioEngine In Practice.

35
00:02:06,526 --> 00:02:10,886 A:middle
Let's look at some of the
goals behind this effort.

36
00:02:11,756 --> 00:02:13,536 A:middle
There were three
important goals.

37
00:02:14,276 --> 00:02:19,216 A:middle
First, to provide a powerful
and a feature-rich API set.

38
00:02:20,716 --> 00:02:25,866 A:middle
AVAudioEngine is built on top
of our C frameworks; hence,

39
00:02:25,926 --> 00:02:28,516 A:middle
it supports most of
the powerful features

40
00:02:28,796 --> 00:02:31,436 A:middle
that our C frameworks
already do.

41
00:02:32,056 --> 00:02:36,286 A:middle
The second goal was to
enable you to achieve simple,

42
00:02:36,286 --> 00:02:40,926 A:middle
as well as complex tasks with
only a fraction of the amount

43
00:02:40,926 --> 00:02:45,126 A:middle
of code that you would write if
using our C frameworks directly.

44
00:02:46,276 --> 00:02:50,446 A:middle
Now, the task can be as simple
as a playback of an audio file

45
00:02:51,086 --> 00:02:53,066 A:middle
to as complex as, say,

46
00:02:53,066 --> 00:02:56,136 A:middle
implementing an entire
audio engine for a game.

47
00:02:56,696 --> 00:03:01,716 A:middle
The third important goal was
to simplify real-time audio.

48

49
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

50
00:02:56,696 --> 00:03:01,716 A:middle
The third important goal was
to simplify real-time audio.

51
00:03:02,916 --> 00:03:06,316 A:middle
AVAudioEngine is a
real-time audio system,

52
00:03:07,046 --> 00:03:11,476 A:middle
but yet it offers a
non-real-time interface for you

53
00:03:11,476 --> 00:03:15,886 A:middle
to interact with and, hence,
hides most of the complexities

54
00:03:15,996 --> 00:03:19,086 A:middle
in dealing with real-time
audio underneath.

55
00:03:20,426 --> 00:03:24,736 A:middle
This, again, enhances the ease
of usability of AVAudioEngine.

56
00:03:25,276 --> 00:03:28,506 A:middle
On to some of the features.

57
00:03:29,906 --> 00:03:32,766 A:middle
It is an Objective-C
API set and, hence,

58
00:03:32,976 --> 00:03:35,086 A:middle
accessible from Swift as well.

59
00:03:36,316 --> 00:03:39,406 A:middle
It supports low latency
real-time audio.

60
00:03:40,616 --> 00:03:44,406 A:middle
Using AVAudioEngine, you will
be able to perform a variety

61
00:03:44,406 --> 00:03:47,706 A:middle
of audio tasks, like
play and record audio,

62
00:03:48,746 --> 00:03:51,796 A:middle
connect various audio
processing blocks together

63
00:03:51,986 --> 00:03:53,476 A:middle
to form your processing chain.

64
00:03:54,516 --> 00:03:58,406 A:middle
You could capture audio at any
point in this processing chain,

65
00:03:58,586 --> 00:04:00,836 A:middle
say for your analysis
or debugging.

66

67
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

68
00:03:58,586 --> 00:04:00,836 A:middle
say for your analysis
or debugging.

69
00:04:01,766 --> 00:04:05,226 A:middle
And also, you could
implement 3D audio for games.

70
00:04:07,876 --> 00:04:10,336 A:middle
Now, what is the
engine comprised of?

71
00:04:11,616 --> 00:04:14,606 A:middle
A node is a basic building
block of the engine.

72
00:04:15,676 --> 00:04:18,856 A:middle
The engine itself
manages a graph of nodes

73
00:04:19,026 --> 00:04:20,546 A:middle
that you connect together.

74
00:04:21,956 --> 00:04:25,976 A:middle
A node can be one of
three types, source nodes

75
00:04:26,426 --> 00:04:30,096 A:middle
that provide data for
entering, processing nodes

76
00:04:30,156 --> 00:04:33,656 A:middle
that process this data,
and the destination node,

77
00:04:33,906 --> 00:04:37,396 A:middle
which is usually the terminating
node in your processing graph

78
00:04:37,696 --> 00:04:40,106 A:middle
and refers to the
output node connected

79
00:04:40,166 --> 00:04:41,286 A:middle
to the output hardware.

80
00:04:41,286 --> 00:04:45,346 A:middle
Now, let's look at a
sample engine setup.

81
00:04:46,016 --> 00:04:49,506 A:middle
This could represent
a simple karaoke app.

82
00:04:51,216 --> 00:04:53,286 A:middle
You could be capturing
users voice

83
00:04:53,546 --> 00:04:55,936 A:middle
through the microphone
implicitly connected

84
00:04:56,006 --> 00:04:59,996 A:middle
to the input node, processing
it through an effect node,

85
00:04:59,996 --> 00:05:01,436 A:middle
which could be a simple delay.

86

87
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

88
00:04:59,996 --> 00:05:01,436 A:middle
which could be a simple delay.

89
00:05:02,606 --> 00:05:05,866 A:middle
You could also be
tapping the users voice

90
00:05:06,326 --> 00:05:10,396 A:middle
through a node tap block,
and analyzing it say

91
00:05:10,396 --> 00:05:14,556 A:middle
to determine how the user is
performing and based on that,

92
00:05:14,846 --> 00:05:18,086 A:middle
you could be playing some sound
effects through the player node,

93
00:05:19,266 --> 00:05:22,156 A:middle
and you could have another
player node that's playing a

94
00:05:22,156 --> 00:05:24,896 A:middle
backing track in your app.

95
00:05:24,896 --> 00:05:28,426 A:middle
And all these signals can be
mixed together using a mixer

96
00:05:28,426 --> 00:05:32,176 A:middle
node and finally played
through the speaker connected

97
00:05:32,176 --> 00:05:33,166 A:middle
to the output node.

98
00:05:34,326 --> 00:05:37,246 A:middle
Now, in this setup, your input

99
00:05:37,246 --> 00:05:39,436 A:middle
and the players form
the source nodes.

100
00:05:40,886 --> 00:05:45,076 A:middle
The effect and the mixer are
your processing nodes input

101
00:05:45,076 --> 00:05:48,526 A:middle
and the output node is
the destination node.

102
00:05:50,956 --> 00:05:54,756 A:middle
Now let's look at these mixer
nodes in a little bit of detail.

103
00:05:55,926 --> 00:05:59,286 A:middle
There are two kinds of
mixer nodes in the engine.

104

105
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

106
00:06:00,056 --> 00:06:03,606 A:middle
First is the AV audio
mixer node that we just saw

107
00:06:03,606 --> 00:06:07,226 A:middle
in the previous example,
and this is mainly used

108
00:06:07,606 --> 00:06:11,156 A:middle
for sample rate conversion,
up or down mixing of channels,

109
00:06:12,336 --> 00:06:15,906 A:middle
it supports mono, stereo,
and multichannel inputs.

110
00:06:17,216 --> 00:06:20,746 A:middle
And the second type of mixer
is called the environment node,

111
00:06:20,976 --> 00:06:23,516 A:middle
which is mainly used
in gaming applications.

112
00:06:24,996 --> 00:06:30,046 A:middle
It simulates a 3D space in which
the sources that are connected

113
00:06:30,046 --> 00:06:33,456 A:middle
to the environment node are
specialized with respect

114
00:06:33,516 --> 00:06:34,876 A:middle
to an implicit listener.

115
00:06:36,246 --> 00:06:40,046 A:middle
And environment node supports
mono and stereo inputs

116
00:06:40,276 --> 00:06:43,126 A:middle
and spatializes mono inputs.

117
00:06:45,556 --> 00:06:49,426 A:middle
Now, associated with the mixer
nodes and the source nodes,

118
00:06:49,676 --> 00:06:52,796 A:middle
there is something called
AVAudioMixing protocol.

119
00:06:53,976 --> 00:06:58,046 A:middle
This protocol defines a set of
properties that are applicable

120
00:06:58,046 --> 00:07:00,366 A:middle
at the input bus
of a mixer node.

121

122
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

123
00:06:58,046 --> 00:07:00,366 A:middle
at the input bus
of a mixer node.

124
00:07:01,626 --> 00:07:05,706 A:middle
And the source nodes conform
to this protocol and, in turn,

125
00:07:06,206 --> 00:07:08,436 A:middle
control the properties
on the mixers

126
00:07:08,526 --> 00:07:10,516 A:middle
that they are connected to.

127
00:07:11,396 --> 00:07:15,246 A:middle
Now, if you set these properties
before making a connection

128
00:07:15,286 --> 00:07:19,096 A:middle
from the source to the mixer
node, the properties are cached

129
00:07:19,346 --> 00:07:20,546 A:middle
at the source node level.

130
00:07:21,676 --> 00:07:24,386 A:middle
And when you actually make a
connection between the source

131
00:07:24,386 --> 00:07:27,866 A:middle
and the mixer, the properties
take effect on the mixer.

132
00:07:28,426 --> 00:07:32,396 A:middle
Let's look at some of the
examples for these properties.

133
00:07:33,586 --> 00:07:34,966 A:middle
There are mainly three types --

134
00:07:35,906 --> 00:07:38,456 A:middle
common mixing properties
that are applicable

135
00:07:38,576 --> 00:07:40,076 A:middle
on all the mixer nodes.

136
00:07:40,616 --> 00:07:42,266 A:middle
The example is volume.

137
00:07:43,246 --> 00:07:47,616 A:middle
Stereo mixing properties like
pan that's applicable only

138
00:07:47,616 --> 00:07:49,276 A:middle
on the AV audio mixer node.

139
00:07:50,526 --> 00:07:54,196 A:middle
And 3D mixing properties
like position, obstruction,

140
00:07:54,196 --> 00:07:57,276 A:middle
occlusion, which is mainly
used in the gaming use case,

141
00:07:57,526 --> 00:08:00,746 A:middle
and those are applicable
on the environment node.

142

143
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

144
00:07:57,526 --> 00:08:00,746 A:middle
and those are applicable
on the environment node.

145
00:08:02,596 --> 00:08:04,486 A:middle
Now let's look at
a sample setup.

146
00:08:05,076 --> 00:08:08,706 A:middle
Suppose you have a player
node and both these mixers,

147
00:08:09,036 --> 00:08:11,786 A:middle
mixer node and the
environment node in your engine,

148
00:08:12,336 --> 00:08:15,316 A:middle
and suppose you set a bunch

149
00:08:15,316 --> 00:08:17,446 A:middle
of mixing properties
on the player node.

150
00:08:17,766 --> 00:08:22,196 A:middle
Now, at this point, since
the player is not connected

151
00:08:22,196 --> 00:08:23,326 A:middle
to either of the mixers,

152
00:08:23,656 --> 00:08:28,676 A:middle
the properties remain
cached at the player level.

153
00:08:28,676 --> 00:08:30,956 A:middle
Now suppose you make a
connection to the mixer node.

154
00:08:31,776 --> 00:08:36,196 A:middle
Now the properties like
volume and pan take effect

155
00:08:36,196 --> 00:08:40,416 A:middle
on the mixer node, while the 3D
mixing property, like position,

156
00:08:40,765 --> 00:08:43,275 A:middle
does not affect the mixer node.

157
00:08:43,826 --> 00:08:47,556 A:middle
Now, if you disconnect
from the mixer and connect

158
00:08:47,626 --> 00:08:48,846 A:middle
to the environment node,

159
00:08:49,396 --> 00:08:53,366 A:middle
volume and position take
effect while pan has no effect

160
00:08:53,546 --> 00:08:54,556 A:middle
on the environment node.

161
00:08:55,576 --> 00:08:59,176 A:middle
So this way you could have a
bunch of mixing properties set

162
00:08:59,176 --> 00:09:02,906 A:middle
on a player and move the
player from one mixer

163

164
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

165
00:08:59,176 --> 00:09:02,906 A:middle
on a player and move the
player from one mixer

166
00:09:03,176 --> 00:09:05,496 A:middle
to the other mixer
in your application

167
00:09:05,696 --> 00:09:07,516 A:middle
with the mixing settings intact.

168
00:09:09,056 --> 00:09:12,106 A:middle
We will revisit this
AVAudioMixing protocol

169
00:09:12,276 --> 00:09:14,616 A:middle
when we discuss one
of our new features

170
00:09:14,616 --> 00:09:16,776 A:middle
for this year in a few minutes.

171
00:09:17,366 --> 00:09:23,266 A:middle
Now, I would like to review
another important aspect

172
00:09:23,656 --> 00:09:26,506 A:middle
that is how to handle
multichannel audio

173
00:09:26,756 --> 00:09:28,136 A:middle
with AVAudioEngine.

174
00:09:28,546 --> 00:09:32,156 A:middle
There are two parts to
the setup involved here.

175
00:09:32,986 --> 00:09:37,046 A:middle
First is configuring
your hardware to be able

176
00:09:37,046 --> 00:09:38,956 A:middle
to receive multichannel audio.

177
00:09:40,026 --> 00:09:42,626 A:middle
Now, the hardware
could be HDMI device

178
00:09:42,826 --> 00:09:44,736 A:middle
or a USB device and so on.

179
00:09:46,066 --> 00:09:49,446 A:middle
And the second part is actually
setting the engine itself

180
00:09:49,806 --> 00:09:52,376 A:middle
to be able to render
multichannel audio

181
00:09:52,586 --> 00:09:53,456 A:middle
to this hardware.

182
00:09:54,036 --> 00:09:58,976 A:middle
We will look at these
one by one.

183
00:09:59,406 --> 00:10:01,446 A:middle
First, hardware setup on OS X.

184

185
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

186
00:09:59,406 --> 00:10:01,446 A:middle
First, hardware setup on OS X.

187
00:10:01,446 --> 00:10:07,576 A:middle
On OS X, there is a built-in
system tool called audio MIDI

188
00:10:07,576 --> 00:10:11,216 A:middle
setup, using which the
user can configure his

189
00:10:11,256 --> 00:10:12,456 A:middle
multichannel hardware.

190
00:10:13,366 --> 00:10:15,396 A:middle
So he could use this
tool to, say,

191
00:10:15,396 --> 00:10:17,316 A:middle
set up the speaker
configuration,

192
00:10:17,576 --> 00:10:19,166 A:middle
channel layout, et cetera.

193
00:10:20,116 --> 00:10:24,166 A:middle
And then the app can
set up AVAudioEngine

194
00:10:24,386 --> 00:10:27,386 A:middle
to use this hardware for
multichannel rendering.

195
00:10:29,416 --> 00:10:34,546 A:middle
But on iOS, in order to enable
multichannel on the hardware,

196
00:10:34,876 --> 00:10:38,056 A:middle
the app needs to configure
its AVAudioSession.

197
00:10:38,596 --> 00:10:41,386 A:middle
We will assume a
playback use case

198
00:10:41,516 --> 00:10:43,796 A:middle
and see what are
the steps involved.

199
00:10:45,466 --> 00:10:49,546 A:middle
The first thing to do would be
to activate your audio session.

200
00:10:50,456 --> 00:10:55,856 A:middle
Next you need to check for the
maximum number of open channels

201
00:10:56,046 --> 00:10:58,116 A:middle
that are available
for your session.

202
00:10:59,496 --> 00:11:02,016 A:middle
Then you set your
preferred number of channels,

203

204
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

205
00:10:59,496 --> 00:11:02,016 A:middle
Then you set your
preferred number of channels,

206
00:11:02,746 --> 00:11:06,696 A:middle
and as a final step, you
query back the actual number

207
00:11:06,756 --> 00:11:09,946 A:middle
of output channels to
verify whether the request

208
00:11:09,996 --> 00:11:12,026 A:middle
that you just made
went through or not.

209
00:11:13,706 --> 00:11:17,966 A:middle
Now, note that whenever you make
a request for a certain number

210
00:11:17,966 --> 00:11:20,476 A:middle
of channels, it does
not guarantee

211
00:11:20,476 --> 00:11:22,526 A:middle
that the request
is always accepted.

212
00:11:23,176 --> 00:11:24,436 A:middle
Hence, the final step

213
00:11:24,646 --> 00:11:28,506 A:middle
of verifying the actual output
number of channels is necessary.

214
00:11:29,066 --> 00:11:32,706 A:middle
Now, in code, it
looks like this.

215
00:11:32,706 --> 00:11:36,596 A:middle
We will assume an
audio playback use case

216
00:11:36,866 --> 00:11:39,856 A:middle
and assume you want
a 5.1 rendering.

217
00:11:40,416 --> 00:11:45,006 A:middle
So the first thing to do would
be to get a shared instance

218
00:11:45,186 --> 00:11:48,846 A:middle
of the audio session,
set your category

219
00:11:49,076 --> 00:11:50,896 A:middle
and make the session active.

220
00:11:51,426 --> 00:11:56,596 A:middle
Next, check the maximum
number of output channels

221
00:11:56,596 --> 00:11:58,246 A:middle
that are available
in your session.

222
00:11:58,796 --> 00:12:03,006 A:middle
And based on that, you
set your preferred number

223

224
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

225
00:11:58,796 --> 00:12:03,006 A:middle
And based on that, you
set your preferred number

226
00:12:03,006 --> 00:12:04,396 A:middle
of channels on the session.

227
00:12:04,826 --> 00:12:09,636 A:middle
And as a final step, you
query back the actual number

228
00:12:09,636 --> 00:12:11,366 A:middle
of output channels
and then adapt

229
00:12:11,856 --> 00:12:16,816 A:middle
to the corresponding
channel count.

230
00:12:16,986 --> 00:12:19,486 A:middle
Okay. So this was all
the hardware setup part.

231
00:12:20,036 --> 00:12:23,136 A:middle
Now we'll see how to set
up the engine to be able

232
00:12:23,136 --> 00:12:24,726 A:middle
to render multichannel audio.

233
00:12:26,536 --> 00:12:28,696 A:middle
Again here there
are two use cases.

234
00:12:29,496 --> 00:12:33,396 A:middle
First, say you have a
multichannel audio content

235
00:12:33,396 --> 00:12:35,506 A:middle
available that needs
to be played back

236
00:12:35,646 --> 00:12:37,036 A:middle
through the multichannel
hardware.

237
00:12:37,866 --> 00:12:41,396 A:middle
And in this case, you would
use an AV audio mixer node.

238
00:12:41,396 --> 00:12:46,426 A:middle
And in the second case,
as a gaming scenario

239
00:12:46,626 --> 00:12:50,286 A:middle
where you want your content to
be spatialized and then played

240
00:12:50,286 --> 00:12:51,976 A:middle
through the multichannel
hardware.

241
00:12:52,626 --> 00:12:55,586 A:middle
And here you would use
an environment node.

242
00:12:57,776 --> 00:13:01,566 A:middle
Case one, you have a
multichannel audio content

243

244
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

245
00:12:57,776 --> 00:13:01,566 A:middle
Case one, you have a
multichannel audio content

246
00:13:02,126 --> 00:13:04,936 A:middle
and a multichannel hardware
that's just been set

247
00:13:04,936 --> 00:13:06,756 A:middle
up as we discussed
a few minutes back.

248
00:13:08,486 --> 00:13:11,636 A:middle
Now, note that although
the format of the content

249
00:13:11,636 --> 00:13:14,496 A:middle
and the hardware are shown
to be identical here,

250
00:13:14,626 --> 00:13:15,896 A:middle
they could very well differ.

251
00:13:17,176 --> 00:13:21,016 A:middle
And the mixer node here will
take care of channel mapping

252
00:13:21,546 --> 00:13:23,786 A:middle
between the content and
the hardware format.

253
00:13:24,466 --> 00:13:27,536 A:middle
So the first thing you need

254
00:13:27,586 --> 00:13:32,186 A:middle
to do is propagate the hardware
format to the connection

255
00:13:32,336 --> 00:13:34,606 A:middle
between the mixer
and the output node.

256
00:13:35,626 --> 00:13:38,216 A:middle
So in code, it looks like this.

257
00:13:39,246 --> 00:13:43,406 A:middle
You would query the output
format of the output node,

258
00:13:43,596 --> 00:13:48,076 A:middle
which is the hardware format,
and then use that format

259
00:13:48,316 --> 00:13:51,036 A:middle
to make the connection
between the mixer node

260
00:13:51,356 --> 00:13:52,826 A:middle
and the output node.

261
00:13:55,496 --> 00:13:58,676 A:middle
The next thing is similar
on the content side.

262
00:13:58,906 --> 00:14:02,126 A:middle
You propagate the content
format to the connection

263

264
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

265
00:13:58,906 --> 00:14:02,126 A:middle
You propagate the content
format to the connection

266
00:14:02,226 --> 00:14:04,946 A:middle
between the player
and the mixer node.

267
00:14:05,796 --> 00:14:08,946 A:middle
So assume you have the
multichannel audio content

268
00:14:08,946 --> 00:14:09,956 A:middle
in the form of a file.

269
00:14:10,586 --> 00:14:12,456 A:middle
You can open the
file for reading

270
00:14:12,756 --> 00:14:16,326 A:middle
and use its processing
format to make the connection

271
00:14:16,366 --> 00:14:18,316 A:middle
from the player to
the mixer node.

272
00:14:18,806 --> 00:14:24,006 A:middle
And then you schedule
your file on the player,

273
00:14:24,506 --> 00:14:26,766 A:middle
you start your engine
and start the player,

274
00:14:26,846 --> 00:14:30,066 A:middle
and the content will flow
through your processing chain.

275
00:14:30,646 --> 00:14:37,836 A:middle
Now case two, where it's
typically a gaming scenario

276
00:14:37,836 --> 00:14:40,946 A:middle
and you need your content to
be spatialized and then played

277
00:14:40,946 --> 00:14:42,226 A:middle
through the multichannel
hardware.

278
00:14:43,506 --> 00:14:47,526 A:middle
So the steps here are very
much similar, except a couple

279
00:14:47,526 --> 00:14:48,836 A:middle
of subtle differences.

280
00:14:49,466 --> 00:14:53,146 A:middle
So the first thing is you
get your hardware format

281
00:14:53,366 --> 00:14:54,806 A:middle
and set the connection format

282
00:14:54,806 --> 00:14:59,136 A:middle
between your environment
node and the output node.

283
00:14:59,346 --> 00:15:03,426 A:middle
Now, since the environment node
supports only specific channel

284

285
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

286
00:14:59,346 --> 00:15:03,426 A:middle
Now, since the environment node
supports only specific channel

287
00:15:03,426 --> 00:15:08,046 A:middle
layouts, you need to map the
hardware format to a layout

288
00:15:08,106 --> 00:15:09,806 A:middle
that the environment
node supports.

289
00:15:10,696 --> 00:15:12,226 A:middle
So that's the first difference.

290
00:15:12,576 --> 00:15:15,506 A:middle
So assuming we have
a 5.1 hardware,

291
00:15:16,186 --> 00:15:20,016 A:middle
we can choose audio
unit 5.0 layout pack

292
00:15:20,676 --> 00:15:22,736 A:middle
that is supported
by the audio node.

293
00:15:23,546 --> 00:15:26,516 A:middle
We can create an AV audio
channel layout using this

294
00:15:26,516 --> 00:15:27,266 A:middle
layout tag.

295
00:15:27,896 --> 00:15:31,766 A:middle
And then an AV audio
format using this layout.

296
00:15:32,516 --> 00:15:36,806 A:middle
And then you make a connection
from the environment node

297
00:15:36,906 --> 00:15:39,766 A:middle
to the output node
using this format.

298
00:15:41,236 --> 00:15:43,606 A:middle
The second step is
exactly the same,

299
00:15:43,846 --> 00:15:46,886 A:middle
propagating your content
format between the connection

300
00:15:47,466 --> 00:15:49,446 A:middle
from player to the
environment node.

301
00:15:50,536 --> 00:15:54,706 A:middle
So we open the file for reading
and use its processing format

302
00:15:55,206 --> 00:15:57,976 A:middle
to make a connection from the
player to the environment.

303
00:15:58,576 --> 00:16:03,676 A:middle
And the next thing here is
to set a rendering algorithm

304

305
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

306
00:15:58,576 --> 00:16:03,676 A:middle
And the next thing here is
to set a rendering algorithm

307
00:16:03,676 --> 00:16:08,176 A:middle
on the player to one which
supports multichannel rendering.

308
00:16:09,456 --> 00:16:11,946 A:middle
This rendering algorithm is one

309
00:16:11,946 --> 00:16:14,396 A:middle
of the 3D mixing
protocol properties

310
00:16:14,436 --> 00:16:17,316 A:middle
that we just saw a
few minutes back,

311
00:16:17,316 --> 00:16:19,806 A:middle
and this will tell
the environment node

312
00:16:20,146 --> 00:16:22,996 A:middle
that the corresponding
source is requesting a

313
00:16:22,996 --> 00:16:24,386 A:middle
multichannel rendering.

314
00:16:24,916 --> 00:16:28,246 A:middle
And then the usual stuff.

315
00:16:28,326 --> 00:16:32,696 A:middle
You schedule your file on the
player, you start your engine

316
00:16:32,696 --> 00:16:35,776 A:middle
and the player, and then your
content will be spatialized

317
00:16:35,926 --> 00:16:37,666 A:middle
by the environment node.

318
00:16:41,246 --> 00:16:46,786 A:middle
Okay. So this was
AVAudioEngine as it existed

319
00:16:46,946 --> 00:16:49,526 A:middle
in iOS 8 and OS X Yosemite.

320
00:16:50,726 --> 00:16:52,596 A:middle
Now on to the more
exciting stuff.

321
00:16:53,406 --> 00:16:54,916 A:middle
What's new for this year?

322
00:16:55,296 --> 00:17:00,676 A:middle
We have three main new features.

323

324
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

325
00:16:55,296 --> 00:17:00,676 A:middle
We have three main new features.

326
00:17:01,676 --> 00:17:03,936 A:middle
First is the splitting support,

327
00:17:04,215 --> 00:17:06,606 A:middle
which I will be talking
about in a minute.

328
00:17:07,616 --> 00:17:11,006 A:middle
Second is the audio
format conversion support,

329
00:17:11,195 --> 00:17:13,506 A:middle
and we have a couple
of new classes here,

330
00:17:13,836 --> 00:17:16,266 A:middle
the main one being
AVAudioConverter.

331
00:17:17,776 --> 00:17:20,965 A:middle
And then finally, we have
another new class called

332
00:17:20,965 --> 00:17:24,826 A:middle
AVAudioSequencer, which supports
play back of MIDI files.

333
00:17:25,425 --> 00:17:30,126 A:middle
Moving to the splitting support.

334
00:17:30,886 --> 00:17:34,016 A:middle
Now, let's consider
this sample setup,

335
00:17:34,796 --> 00:17:37,156 A:middle
which by now I guess
should be pretty familiar.

336
00:17:38,086 --> 00:17:42,876 A:middle
So in the API that
existed as of last week,

337
00:17:43,576 --> 00:17:47,226 A:middle
only one-to-one connections
were supported in the engine.

338
00:17:47,956 --> 00:17:52,566 A:middle
That is the output of any
node could only be connected

339
00:17:52,566 --> 00:17:54,846 A:middle
to one other node in the engine.

340
00:17:55,386 --> 00:18:02,526 A:middle
But now, instead of this, we
have added support to do this.

341

342
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

343
00:17:55,386 --> 00:18:02,526 A:middle
But now, instead of this, we
have added support to do this.

344
00:18:03,356 --> 00:18:07,796 A:middle
That is to be able to
split output of a node

345
00:18:07,886 --> 00:18:11,156 A:middle
into multiple paths in
your processing chain.

346
00:18:11,216 --> 00:18:16,356 A:middle
So in this example, the
output of the player is split

347
00:18:16,416 --> 00:18:17,766 A:middle
into three different paths

348
00:18:18,216 --> 00:18:20,986 A:middle
and then eventually
connected to the mixer node.

349
00:18:22,356 --> 00:18:26,686 A:middle
Now, splitting is very useful
in use cases like mixing

350
00:18:27,046 --> 00:18:32,106 A:middle
where you need to blend in some
amount of wet or process signals

351
00:18:32,706 --> 00:18:35,976 A:middle
with a dry signal all
driven by the same source.

352
00:18:37,106 --> 00:18:40,066 A:middle
In this example, the
connection from the player

353
00:18:40,326 --> 00:18:44,646 A:middle
to the mixer node forms your dry
signal path while the other two

354
00:18:44,716 --> 00:18:48,196 A:middle
paths going through the
effect nodes forms your wet

355
00:18:48,266 --> 00:18:48,776 A:middle
signal paths.

356
00:18:49,626 --> 00:18:53,246 A:middle
And all these three signals are
mixed together using a mixer

357
00:18:53,246 --> 00:18:56,426 A:middle
node to give you the mix.

358
00:18:56,616 --> 00:18:59,616 A:middle
Now, note that when you
split the output of a node,

359

360
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

361
00:19:00,066 --> 00:19:04,026 A:middle
the entire output is actually
rendered through multiple paths,

362
00:19:04,636 --> 00:19:07,626 A:middle
and there is no splitting
of channels involved.

363
00:19:10,556 --> 00:19:14,926 A:middle
Now let's see in code how
to set these connections up.

364
00:19:16,766 --> 00:19:19,876 A:middle
As you can see, the
player is connected

365
00:19:19,876 --> 00:19:21,186 A:middle
to three different nodes.

366
00:19:22,486 --> 00:19:26,236 A:middle
We will call these as
connection points represented

367
00:19:26,526 --> 00:19:29,586 A:middle
by a very simple new
class called AV audio

368
00:19:29,586 --> 00:19:30,546 A:middle
connection point.

369
00:19:30,546 --> 00:19:36,656 A:middle
The first thing to do
is to create an array

370
00:19:36,656 --> 00:19:39,486 A:middle
of connection points that
you want your player node

371
00:19:39,486 --> 00:19:40,396 A:middle
to be connected to.

372
00:19:41,156 --> 00:19:45,776 A:middle
So in this example, we want
connections to the input bus:

373
00:19:45,846 --> 00:19:51,886 A:middle
0 of the two effects and input
bus: 1 of the mixer node.

374
00:19:53,606 --> 00:19:56,926 A:middle
Then you use the new
connection API we have

375
00:19:57,336 --> 00:20:00,216 A:middle
to connect the player to
these connection points.

376

377
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

378
00:19:57,336 --> 00:20:00,216 A:middle
to connect the player to
these connection points.

379
00:20:00,856 --> 00:20:04,866 A:middle
And that's it, so you are set
up for the split connections.

380
00:20:05,266 --> 00:20:08,586 A:middle
So you move on and make
your other connections

381
00:20:08,586 --> 00:20:13,976 A:middle
in the engine as you need.

382
00:20:14,066 --> 00:20:16,786 A:middle
Now let's revisit the
AVAudioMixing protocol

383
00:20:16,786 --> 00:20:18,736 A:middle
that we discussed sometime back

384
00:20:18,736 --> 00:20:22,716 A:middle
and see how it affects
splitting use case.

385
00:20:23,176 --> 00:20:26,256 A:middle
Assume we have a player
node whose output is split

386
00:20:26,256 --> 00:20:27,956 A:middle
into two different paths,

387
00:20:27,956 --> 00:20:30,606 A:middle
going through the effect
nodes to a mixer node.

388
00:20:31,906 --> 00:20:35,776 A:middle
Now, suppose you set a
property on the player node.

389
00:20:36,326 --> 00:20:38,776 A:middle
In this example,
say you set volume.

390
00:20:38,776 --> 00:20:44,906 A:middle
Now, at this point, the
property will take effect on all

391
00:20:44,906 --> 00:20:49,086 A:middle
of its existing mixer
connections, so in this example,

392
00:20:49,266 --> 00:20:52,066 A:middle
both input bus: 0 and input bus:

393
00:20:52,066 --> 00:20:58,466 A:middle
1 of the mixer node
get a volume of .5.

394
00:20:58,676 --> 00:21:02,426 A:middle
But if you wanted to
overwrite any of the properties

395

396
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

397
00:20:58,676 --> 00:21:02,426 A:middle
But if you wanted to
overwrite any of the properties

398
00:21:02,496 --> 00:21:04,306 A:middle
on a particular mixer
connection,

399
00:21:04,576 --> 00:21:05,776 A:middle
you could still do that.

400
00:21:06,386 --> 00:21:10,066 A:middle
And the way to do it is
using our new class called

401
00:21:10,066 --> 00:21:11,936 A:middle
AVAudioMixing destination.

402
00:21:13,196 --> 00:21:14,876 A:middle
So you query the player node

403
00:21:15,346 --> 00:21:18,396 A:middle
to give you the destination
object corresponding

404
00:21:18,456 --> 00:21:19,956 A:middle
to the mixer that you want,

405
00:21:20,756 --> 00:21:23,656 A:middle
and you then set a
property on that object.

406
00:21:24,486 --> 00:21:28,086 A:middle
So in this example, we
are overwriting the volume

407
00:21:28,266 --> 00:21:33,606 A:middle
on mixer input bus: 0 to .8.

408
00:21:33,886 --> 00:21:39,076 A:middle
Now, okay, so similarly, you can
also overwrite the properties

409
00:21:39,146 --> 00:21:43,476 A:middle
on the other mixer
connection as well.

410
00:21:43,686 --> 00:21:45,716 A:middle
Now, let's see what
happens in a disconnection.

411
00:21:46,826 --> 00:21:49,446 A:middle
Suppose you disconnect
the effect

412
00:21:49,756 --> 00:21:51,786 A:middle
to mixer input bus:
1 connection.

413
00:21:52,896 --> 00:21:57,466 A:middle
Now, note that the settings
that you may have overwritten

414
00:21:57,466 --> 00:21:59,806 A:middle
on that particular mixer
connection will not

415
00:21:59,806 --> 00:22:00,466 A:middle
be preserved.

416

417
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

418
00:21:59,806 --> 00:22:00,466 A:middle
be preserved.

419
00:22:01,126 --> 00:22:05,536 A:middle
Hence, the state of mixing
settings will look like this.

420
00:22:06,036 --> 00:22:09,746 A:middle
The player's mixing
settings remain intact,

421
00:22:09,746 --> 00:22:13,826 A:middle
and the other connection that is
active will also have its mixing

422
00:22:13,826 --> 00:22:15,586 A:middle
settings intact.

423
00:22:17,236 --> 00:22:20,536 A:middle
Now, if you end up making
the connection back again

424
00:22:20,736 --> 00:22:25,076 A:middle
to mixer input bus: 1, since
the earliest settings were not

425
00:22:25,166 --> 00:22:29,226 A:middle
preserved, the base settings off
the player node will now take

426
00:22:29,226 --> 00:22:30,836 A:middle
effect in this new connection.

427
00:22:32,136 --> 00:22:36,326 A:middle
So hence, the volume of input
bus: 1 will again be set

428
00:22:36,386 --> 00:22:39,416 A:middle
to .5 based on the
player's mixing settings.

429
00:22:39,946 --> 00:22:45,736 A:middle
So to summarize, when a
source node is connected

430
00:22:45,806 --> 00:22:50,676 A:middle
to multiple mixers, the
properties that you set

431
00:22:50,676 --> 00:22:53,316 A:middle
on the source node
will be applied to all

432
00:22:53,316 --> 00:22:56,646 A:middle
of its existing mixer
connections as well

433
00:22:56,646 --> 00:22:59,686 A:middle
as any new mixer
connection that you make.

434

435
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

436
00:23:00,286 --> 00:23:02,436 A:middle
And the properties

437
00:23:02,436 --> 00:23:05,786 A:middle
on the individual mixer
connections can be overwritten

438
00:23:05,786 --> 00:23:09,466 A:middle
if you want to, but remember
that they will not be preserved

439
00:23:09,656 --> 00:23:10,926 A:middle
on any disconnections.

440
00:23:14,536 --> 00:23:16,686 A:middle
Final words on the
splitting support.

441
00:23:16,686 --> 00:23:20,656 A:middle
The engine supports
splitting of any node

442
00:23:20,986 --> 00:23:24,796 A:middle
in the processing graph,
provided you adhere

443
00:23:24,896 --> 00:23:26,156 A:middle
to a couple of restrictions.

444
00:23:27,446 --> 00:23:31,656 A:middle
Now, starting from the node
whose output is split till the

445
00:23:31,656 --> 00:23:36,956 A:middle
mixer where all the parts
terminate, you cannot have any

446
00:23:36,956 --> 00:23:38,176 A:middle
of the time effect nodes.

447
00:23:38,576 --> 00:23:41,826 A:middle
That is you cannot have
speed and time pitch.

448
00:23:42,386 --> 00:23:45,946 A:middle
Nor can you have any
rate conversions.

449
00:23:47,276 --> 00:23:51,086 A:middle
So in other words,
all the split parts

450
00:23:51,446 --> 00:23:55,146 A:middle
from the base node should be
rendering at the same rate

451
00:23:55,426 --> 00:23:57,136 A:middle
until they reach a common mixer.

452
00:23:57,136 --> 00:24:01,096 A:middle
So if you stick to
these restrictions,

453

454
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

455
00:23:57,136 --> 00:24:01,096 A:middle
So if you stick to
these restrictions,

456
00:24:01,256 --> 00:24:04,206 A:middle
then you could split
the output of any node

457
00:24:04,356 --> 00:24:07,466 A:middle
in the engine into
multiple parts.

458
00:24:10,386 --> 00:24:15,596 A:middle
Okay. So now moving on to the
second new feature we have

459
00:24:16,106 --> 00:24:18,936 A:middle
for this year, audio
format conversion support.

460
00:24:20,096 --> 00:24:22,066 A:middle
So we have a couple
of new classes here,

461
00:24:22,156 --> 00:24:25,936 A:middle
AVAudioCompressedBuffer,
and AV Audio Converter.

462
00:24:26,566 --> 00:24:32,046 A:middle
Now, in the API that
existed as of last week,

463
00:24:32,346 --> 00:24:36,006 A:middle
we have an AVAudioBuffer and one

464
00:24:36,006 --> 00:24:38,826 A:middle
of its subclasses
called AVAudioPCMBuffer,

465
00:24:39,826 --> 00:24:41,086 A:middle
and as the name suggests,

466
00:24:41,396 --> 00:24:44,516 A:middle
the PCM buffer holds
uncompressed audio data,

467
00:24:45,386 --> 00:24:47,756 A:middle
and the data flow
through the engine is

468
00:24:47,756 --> 00:24:49,386 A:middle
in the form of PCM buffers.

469
00:24:51,046 --> 00:24:53,686 A:middle
Now, starting this year,
we have another subclass

470
00:24:53,686 --> 00:24:57,366 A:middle
of AVAudioBuffer called
AVAudioCompressedBuffer,

471
00:24:58,256 --> 00:25:00,716 A:middle
and this holds compressed
audio data.

472

473
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

474
00:24:58,256 --> 00:25:00,716 A:middle
and this holds compressed
audio data.

475
00:25:02,026 --> 00:25:06,246 A:middle
And this can be used with
the new class we have called

476
00:25:06,246 --> 00:25:09,586 A:middle
AVAudioConverter that
I will talk about next.

477
00:25:12,876 --> 00:25:15,766 A:middle
AVAudioConverter is
a new utility class,

478
00:25:16,286 --> 00:25:18,346 A:middle
and it's a higher-level
equivalent

479
00:25:18,566 --> 00:25:22,586 A:middle
for our audio converter from
the audio toolbox framework.

480
00:25:23,896 --> 00:25:28,406 A:middle
This supports all audio format
conversion, so you could convert

481
00:25:28,466 --> 00:25:32,946 A:middle
from PCM to PCM format while
changing, say, integer to float,

482
00:25:33,296 --> 00:25:36,046 A:middle
bit depth, sample
rate, et cetera.

483
00:25:36,676 --> 00:25:41,166 A:middle
Or you could convert between
PCM and compressed format

484
00:25:41,406 --> 00:25:45,216 A:middle
that is you can use it for
encoding and decoding purposes.

485
00:25:45,826 --> 00:25:50,156 A:middle
And AVAudioConverter can
be used in conjunction

486
00:25:50,156 --> 00:25:56,396 A:middle
with AVAudioEngine, as we
will see in an example.

487
00:25:56,396 --> 00:26:00,546 A:middle
Okay. So suppose you have your
engine set up for a playback.

488

489
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

490
00:25:56,396 --> 00:26:00,546 A:middle
Okay. So suppose you have your
engine set up for a playback.

491
00:26:00,626 --> 00:26:03,146 A:middle
So we have a player
node connected

492
00:26:03,186 --> 00:26:04,996 A:middle
to an effect node
and an output node.

493
00:26:06,366 --> 00:26:09,376 A:middle
And suppose you have a
compressed audio stream

494
00:26:09,446 --> 00:26:10,576 A:middle
coming in.

495
00:26:11,816 --> 00:26:15,726 A:middle
Now, we know that the data
flow through the engine is

496
00:26:15,726 --> 00:26:17,966 A:middle
in the form of PCM buffers.

497
00:26:18,916 --> 00:26:22,366 A:middle
So now you could use
an AVAudioConverter

498
00:26:22,716 --> 00:26:27,046 A:middle
to convert your input compressed
stream into PCM buffers,

499
00:26:27,316 --> 00:26:30,396 A:middle
and then you can use
these buffers to schedule

500
00:26:30,396 --> 00:26:33,596 A:middle
on the player node, hence
the playback can happen

501
00:26:33,756 --> 00:26:34,486 A:middle
through the engine.

502
00:26:35,046 --> 00:26:41,666 A:middle
Now let's consider a
code example and see how

503
00:26:41,666 --> 00:26:44,656 A:middle
to use AVAudioConverter
for encoding purposes.

504
00:26:45,906 --> 00:26:48,776 A:middle
Now, here we want to
convert from a PCM

505
00:26:49,076 --> 00:26:50,776 A:middle
to an ASC compressed format.

506
00:26:51,386 --> 00:26:55,406 A:middle
So the first thing to
do is define your input

507
00:26:55,546 --> 00:26:56,736 A:middle
as well as output format.

508
00:26:57,486 --> 00:27:01,256 A:middle
So here I have an input
format which is a PCM format,

509

510
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

511
00:26:57,486 --> 00:27:01,256 A:middle
So here I have an input
format which is a PCM format,

512
00:27:01,836 --> 00:27:04,956 A:middle
and I have an output format,

513
00:27:05,136 --> 00:27:10,446 A:middle
which is a compressed
ASC format.

514
00:27:10,566 --> 00:27:14,826 A:middle
Next you create an
AVAudioConverter and asking it

515
00:27:15,006 --> 00:27:18,526 A:middle
to convert from your input
to the output format.

516
00:27:20,136 --> 00:27:22,646 A:middle
Then you create your
audio buffers.

517
00:27:23,596 --> 00:27:26,206 A:middle
The input buffer in this
case is a PCM buffer,

518
00:27:26,206 --> 00:27:31,086 A:middle
and the output buffer is our
new AVAudioCompressedBuffer

519
00:27:31,526 --> 00:27:33,826 A:middle
in the ASC format.

520
00:27:35,936 --> 00:27:37,746 A:middle
The next thing to do is

521
00:27:37,776 --> 00:27:43,226 A:middle
to define something called
AVAudioConverter input block.

522
00:27:43,226 --> 00:27:46,886 A:middle
This is the block that the
converter will call whenever it

523
00:27:46,886 --> 00:27:47,926 A:middle
needs input data.

524
00:27:49,446 --> 00:27:51,876 A:middle
So there are a couple of things
that you need to do here.

525
00:27:53,086 --> 00:27:55,636 A:middle
First, you need to
inform the converter

526
00:27:55,976 --> 00:27:57,826 A:middle
about the status of your input.

527
00:27:58,816 --> 00:28:01,026 A:middle
So suppose when the
block gets called,

528

529
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

530
00:27:58,816 --> 00:28:01,026 A:middle
So suppose when the
block gets called,

531
00:28:01,336 --> 00:28:03,596 A:middle
you do not have any
input data available.

532
00:28:04,386 --> 00:28:07,806 A:middle
So at that point, you
can say no data now

533
00:28:08,206 --> 00:28:10,486 A:middle
and return a nil
buffer to the converter.

534
00:28:11,066 --> 00:28:14,606 A:middle
Now, suppose you have
reached end of stream,

535
00:28:15,116 --> 00:28:18,096 A:middle
so you can inform the converter
saying it's end of stream

536
00:28:18,296 --> 00:28:21,276 A:middle
and again return a nil buffer.

537
00:28:22,226 --> 00:28:23,986 A:middle
Otherwise, in the normal cases,

538
00:28:24,156 --> 00:28:27,356 A:middle
you can see that you
do have data, and fill

539
00:28:27,356 --> 00:28:33,086 A:middle
and return your input
buffer to the converter.

540
00:28:33,196 --> 00:28:35,096 A:middle
Now, this is the
main conversion loop.

541
00:28:36,256 --> 00:28:39,896 A:middle
In every operation of this loop,
we are asking the converter

542
00:28:40,116 --> 00:28:42,446 A:middle
to produce one output
buffer of data,

543
00:28:43,236 --> 00:28:46,306 A:middle
and we are providing the input
block that we just defined

544
00:28:46,646 --> 00:28:49,956 A:middle
to the converter so that it
can be called by the converter

545
00:28:50,056 --> 00:28:52,376 A:middle
as many times as it needs input.

546
00:28:52,846 --> 00:28:57,476 A:middle
Now, the converter will
also return your status,

547
00:28:57,536 --> 00:29:00,616 A:middle
which you can check to see
the state of conversion.

548

549
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

550
00:28:57,536 --> 00:29:00,616 A:middle
which you can check to see
the state of conversion.

551
00:29:01,216 --> 00:29:03,836 A:middle
So if the converter
says it's end of stream

552
00:29:04,046 --> 00:29:06,146 A:middle
or if it says there
was an error,

553
00:29:06,146 --> 00:29:09,956 A:middle
you could handle it accordingly.

554
00:29:09,956 --> 00:29:11,696 A:middle
Otherwise, in the normal cases,

555
00:29:11,866 --> 00:29:15,686 A:middle
every iteration will provide
you one output buffer of data.

556
00:29:19,696 --> 00:29:23,116 A:middle
Okay. So coming to
our final new class

557
00:29:23,116 --> 00:29:26,276 A:middle
for this year, AVAudioSequencer.

558
00:29:30,036 --> 00:29:33,146 A:middle
This supports playback
of MIDI files,

559
00:29:33,696 --> 00:29:39,326 A:middle
and AVAudioSequencer is
associated with an AVAudioEngine

560
00:29:39,326 --> 00:29:41,876 A:middle
at the time of instantiation.

561
00:29:42,346 --> 00:29:48,106 A:middle
And the sequencer is responsible
for sending MIDI events

562
00:29:48,516 --> 00:29:52,266 A:middle
to the instrument nodes that you
may have attached in the engine.

563
00:29:52,996 --> 00:29:56,436 A:middle
Now, the example for instrument
nodes, audio samplers,

564
00:29:56,556 --> 00:29:58,626 A:middle
MIDI events et cetera.

565

566
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

567
00:30:01,486 --> 00:30:03,356 A:middle
Now let's look at
a sample setup.

568
00:30:04,036 --> 00:30:06,416 A:middle
Suppose you have your
AVAudioEngine set

569
00:30:06,416 --> 00:30:09,766 A:middle
up with an instrument node
connected to a mixer node

570
00:30:10,036 --> 00:30:13,636 A:middle
and to the output node.

571
00:30:13,856 --> 00:30:16,586 A:middle
You can now create
an AVAudioSequencer

572
00:30:16,586 --> 00:30:19,056 A:middle
and associate it
with this engine.

573
00:30:19,616 --> 00:30:24,746 A:middle
And then, when you start your
sequencer and start your engine,

574
00:30:25,026 --> 00:30:29,626 A:middle
the sequencer will automatically
discover the first instrument

575
00:30:29,626 --> 00:30:32,816 A:middle
node in the engine and
start sending MIDI events

576
00:30:32,966 --> 00:30:34,846 A:middle
to that instrument node.

577
00:30:35,396 --> 00:30:39,586 A:middle
And in code, it looks like this.

578
00:30:40,426 --> 00:30:42,866 A:middle
So the first part is
your engine setup,

579
00:30:42,956 --> 00:30:44,596 A:middle
which is outside
of the sequencer.

580
00:30:45,576 --> 00:30:49,556 A:middle
So here we have an instrument
node that is a sampler,

581
00:30:50,176 --> 00:30:53,536 A:middle
so you make your required
connections in the engine,

582
00:30:54,686 --> 00:30:56,876 A:middle
and then you start your engine.

583
00:30:58,026 --> 00:31:01,126 A:middle
Now, at this point, there
will be no audio playback

584

585
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

586
00:30:58,026 --> 00:31:01,126 A:middle
Now, at this point, there
will be no audio playback

587
00:31:01,266 --> 00:31:02,876 A:middle
because there isn't anything

588
00:31:02,876 --> 00:31:05,146 A:middle
that is driving the
instrument node.

589
00:31:06,576 --> 00:31:10,736 A:middle
Then next you create your
sequencer and associate it

590
00:31:10,956 --> 00:31:12,946 A:middle
with the engine that
you just configured.

591
00:31:13,716 --> 00:31:17,666 A:middle
You load your MIDI file
onto the sequencer.

592
00:31:18,316 --> 00:31:21,176 A:middle
And then you can
start your sequencer.

593
00:31:21,666 --> 00:31:25,716 A:middle
So at this point, the sequencer
will implicitly discover your

594
00:31:25,716 --> 00:31:28,776 A:middle
sampler node that you have
attached in the engine

595
00:31:29,016 --> 00:31:31,896 A:middle
and start sending MIDI
events to the sampler node.

596
00:31:32,306 --> 00:31:35,706 A:middle
And hence, your audio
playback will start.

597
00:31:37,896 --> 00:31:41,606 A:middle
Now, suppose you had multiple
tracks in your MIDI file.

598
00:31:43,066 --> 00:31:45,996 A:middle
Now, the default behavior
of the sequencer is

599
00:31:45,996 --> 00:31:49,836 A:middle
to send all the tracks to
the first instrument node

600
00:31:50,006 --> 00:31:53,086 A:middle
that it finds in the engine.

601
00:31:53,226 --> 00:31:56,296 A:middle
But in case you wanted
to direct your tracks

602
00:31:56,566 --> 00:31:58,446 A:middle
to the individual
instrument nodes,

603
00:31:59,386 --> 00:32:02,446 A:middle
you can do that with
just a few lines of code.

604

605
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

606
00:31:59,386 --> 00:32:02,446 A:middle
you can do that with
just a few lines of code.

607
00:32:02,966 --> 00:32:06,996 A:middle
Now, the creation and
setting up of the engine

608
00:32:06,996 --> 00:32:09,346 A:middle
in the sequencer is
the same as earlier.

609
00:32:09,716 --> 00:32:13,166 A:middle
The only additional thing that
you need to do is you need

610
00:32:13,166 --> 00:32:15,156 A:middle
to get the tracks
from your sequencer

611
00:32:15,776 --> 00:32:18,746 A:middle
and set the destination
for each of your tracks

612
00:32:19,096 --> 00:32:21,606 A:middle
to the instrument
node that you want.

613
00:32:25,816 --> 00:32:27,826 A:middle
Final few words on
the sequencer.

614
00:32:28,636 --> 00:32:31,916 A:middle
The sequencer has its own
set of transport controls

615
00:32:32,226 --> 00:32:36,116 A:middle
for the MIDI events, unlike the
transport controls on the engine

616
00:32:36,266 --> 00:32:38,136 A:middle
that control the flow of audio.

617
00:32:39,246 --> 00:32:42,616 A:middle
So here you can prepare
the sequencer for playback,

618
00:32:42,756 --> 00:32:44,826 A:middle
which basically does prerolling.

619
00:32:45,626 --> 00:32:47,836 A:middle
You can start/stop
the MIDI events.

620
00:32:48,866 --> 00:32:51,676 A:middle
You can set the playback
position of the MIDI events

621
00:32:51,736 --> 00:32:53,656 A:middle
in terms of seconds or beats.

622
00:32:54,736 --> 00:32:56,976 A:middle
And also, you can
set the playback rate

623
00:32:57,276 --> 00:32:58,266 A:middle
of the MIDI events.

624

625
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

626
00:33:02,176 --> 00:33:06,036 A:middle
Okay. So with that, we
have seen the new features

627
00:33:06,036 --> 00:33:10,146 A:middle
in AVAudioEngine for this
year's iOS and OS X releases.

628
00:33:10,636 --> 00:33:12,966 A:middle
Now I would like to
show you a quick demo

629
00:33:13,236 --> 00:33:15,636 A:middle
to see these new
features in action.

630
00:33:16,236 --> 00:33:20,136 A:middle
And for that, I would like to
invite Torrey onto the stage

631
00:33:20,826 --> 00:33:23,466 A:middle
to help me with the demo.

632
00:33:24,516 --> 00:33:26,676 A:middle
[ Applause ]

633
00:33:27,176 --> 00:33:27,696 A:middle
Okay.

634
00:33:33,106 --> 00:33:35,566 A:middle
So in this demo, we
have an AVAudioEngine

635
00:33:35,596 --> 00:33:39,776 A:middle
and an AVAudioSequencer that
is associated with this engine.

636
00:33:41,116 --> 00:33:44,826 A:middle
So in the engine, we have an
instrument node that you can see

637
00:33:44,826 --> 00:33:50,666 A:middle
at the top whose output is split
into three different paths.

638
00:33:50,666 --> 00:33:54,216 A:middle
One of the paths is directly
connected to the main mixer node

639
00:33:54,366 --> 00:33:58,226 A:middle
in the engine, and two of
the other paths are connected

640
00:33:58,706 --> 00:34:04,446 A:middle
through two different effects,
and then to the main mixer.

641

642
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

643
00:33:58,706 --> 00:34:04,446 A:middle
through two different effects,
and then to the main mixer.

644
00:34:04,446 --> 00:34:07,146 A:middle
Now, using the AVAudioMixing
protocol properties we

645
00:34:07,146 --> 00:34:11,275 A:middle
discussed, there are
volume controls on each

646
00:34:11,275 --> 00:34:13,005 A:middle
of these mixer input buses.

647
00:34:13,786 --> 00:34:16,666 A:middle
So the slightest that you
see for distortion volume,

648
00:34:16,766 --> 00:34:20,735 A:middle
direct volume, and reverb
volume are the volume controls

649
00:34:20,956 --> 00:34:22,606 A:middle
and controls through
mixing protocol.

650
00:34:24,005 --> 00:34:28,226 A:middle
Now, at the top, in
the light gray box,

651
00:34:28,226 --> 00:34:31,666 A:middle
you can see this transport
controls for the sequencer.

652
00:34:32,436 --> 00:34:36,306 A:middle
You can see that we have a play
stop control on the sequencer

653
00:34:36,485 --> 00:34:40,186 A:middle
as well as sliders for
setting the playback position

654
00:34:40,585 --> 00:34:43,306 A:middle
and the playback
rate of the MIDIs.

655
00:34:44,545 --> 00:34:47,596 A:middle
There is also a master
volume on the main mixer

656
00:34:47,735 --> 00:34:52,036 A:middle
to control the volume
of your mix.

657
00:34:52,916 --> 00:34:57,986 A:middle
Now let's go ahead and
start the sequencer [music].

658
00:34:57,986 --> 00:35:01,786 A:middle
So at this point, the
MIDI events are being sent

659

660
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

661
00:34:57,986 --> 00:35:01,786 A:middle
So at this point, the
MIDI events are being sent

662
00:35:02,006 --> 00:35:06,126 A:middle
to the instrument node
that is in the engine.

663
00:35:06,126 --> 00:35:12,056 A:middle
You can dynamically change
the position of playback

664
00:35:14,086 --> 00:35:17,766 A:middle
of the MIDI events
and the playback rate.

665
00:35:17,836 --> 00:35:28,496 A:middle
Using the volume controls, you
can blend in the required amount

666
00:35:28,496 --> 00:35:30,736 A:middle
of effects that you
want in your mix.

667
00:35:30,736 --> 00:35:34,476 A:middle
You could increase
the distortion volume.

668
00:35:35,656 --> 00:35:41,296 A:middle
Or the reverb volume.

669
00:35:41,376 --> 00:35:49,896 A:middle
So effectively, you can play
around with these volumes

670
00:35:49,996 --> 00:35:52,586 A:middle
and create the mix
that you desire.

671
00:35:52,586 --> 00:35:58,066 A:middle
And finally, using the master
volume on the mixer node,

672
00:35:58,456 --> 00:36:08,856 A:middle
you could control the volume of
the overall mix [audio fading].

673

674
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

675
00:35:58,456 --> 00:36:08,856 A:middle
you could control the volume of
the overall mix [audio fading].

676
00:36:09,396 --> 00:36:12,456 A:middle
Okay. So that was a
demo of the new features

677
00:36:12,456 --> 00:36:13,976 A:middle
that we just discussed.

678
00:36:15,516 --> 00:36:20,546 A:middle
[ Applause ]

679
00:36:21,046 --> 00:36:24,126 A:middle
So the sample code for this demo
should be available sometime

680
00:36:24,126 --> 00:36:26,886 A:middle
later this year.

681
00:36:27,086 --> 00:36:31,276 A:middle
Now final words on what we
saw today in AVAudioEngine.

682
00:36:32,176 --> 00:36:37,046 A:middle
We saw a recap, and we reviewed
how to handle multichannel audio

683
00:36:37,046 --> 00:36:41,166 A:middle
with AVAudioEngine, and then
we saw three new features

684
00:36:41,326 --> 00:36:45,466 A:middle
for this year -- first,
splitting support; second,

685
00:36:45,586 --> 00:36:47,426 A:middle
audio format conversion support,

686
00:36:47,746 --> 00:36:53,016 A:middle
the main class being
AVAudioConverter; and finally,

687
00:36:53,016 --> 00:36:55,946 A:middle
we saw another new class
called AVAudioSequencer

688
00:36:56,196 --> 00:36:58,346 A:middle
that supports playback
of MIDI files.

689
00:36:59,726 --> 00:37:02,716 A:middle
I hope you will use these
new features in your apps

690

691
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

692
00:36:59,726 --> 00:37:02,716 A:middle
I hope you will use these
new features in your apps

693
00:37:03,196 --> 00:37:04,706 A:middle
and provide us feedback.

694
00:37:05,376 --> 00:37:05,726 A:middle
Thank you.

695
00:37:06,646 --> 00:37:08,646 A:middle
Over to Torrey to
take it from here.

696
00:37:08,836 --> 00:37:09,406 A:middle
Thanks, Torrey.

697
00:37:10,516 --> 00:37:18,546 A:middle
[ Applause ]

698
00:37:19,046 --> 00:37:19,756 A:middle
Thanks, Akshatha.

699
00:37:20,416 --> 00:37:21,356 A:middle
Good afternoon, everyone.

700
00:37:21,916 --> 00:37:24,106 A:middle
I'm Torrey, and let's
keep it rolling

701
00:37:24,106 --> 00:37:25,876 A:middle
with Inter-Device
Audio Mode for iOS.

702
00:37:26,966 --> 00:37:29,066 A:middle
It's no secret that
the iPad is one

703
00:37:29,066 --> 00:37:31,536 A:middle
of the most versatile musical
instruments on the planet,

704
00:37:31,536 --> 00:37:33,616 A:middle
and that's primarily
thanks to all of you-all,

705
00:37:34,256 --> 00:37:37,896 A:middle
with digital audio workstation
apps, synthesizer apps,

706
00:37:37,896 --> 00:37:39,956 A:middle
drum machine apps, sound toys.

707
00:37:39,956 --> 00:37:41,946 A:middle
There's an endless
amount of audio content

708
00:37:41,946 --> 00:37:43,566 A:middle
that you can generate
with the same device.

709
00:37:44,326 --> 00:37:47,376 A:middle
So how do you get that audio
content from your iOS device

710
00:37:47,446 --> 00:37:50,216 A:middle
into your project that you
are working on on your Mac?

711
00:37:51,036 --> 00:37:55,076 A:middle
Well, you could plug in a
cable into the headphone jack,

712
00:37:55,076 --> 00:37:57,596 A:middle
run that into an audio
breakout box that's connected

713
00:37:57,596 --> 00:38:00,166 A:middle
to your Mac, but that
would be digital to analog

714

715
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

716
00:37:57,596 --> 00:38:00,166 A:middle
to your Mac, but that
would be digital to analog

717
00:38:00,166 --> 00:38:01,506 A:middle
and back again to digital.

718
00:38:01,506 --> 00:38:03,866 A:middle
I am sure that we can all
agree that's less than ideal.

719
00:38:04,426 --> 00:38:07,536 A:middle
So to record audio
digitally from an iOS device,

720
00:38:08,676 --> 00:38:11,466 A:middle
we attach a lightning-to-USB
adapter.

721
00:38:11,936 --> 00:38:15,546 A:middle
We attach a USB audio
class-compliant interface that's

722
00:38:15,546 --> 00:38:19,406 A:middle
capable of doing digital audio
output; a digital audio cable;

723
00:38:19,796 --> 00:38:21,616 A:middle
another interface that's capable

724
00:38:21,616 --> 00:38:23,456 A:middle
of receiving digital
audio input;

725
00:38:23,456 --> 00:38:25,316 A:middle
and we attach that to the Mac.

726
00:38:26,116 --> 00:38:28,456 A:middle
It works. But it's
a lot of hardware.

727
00:38:29,506 --> 00:38:31,546 A:middle
There's also third-party
software that attempts

728
00:38:31,546 --> 00:38:36,006 A:middle
to solve this same problem,
which is great if your app uses

729
00:38:36,006 --> 00:38:38,756 A:middle
that or if your favorite
app uses that.

730
00:38:39,516 --> 00:38:41,636 A:middle
But wouldn't it be
great if you didn't have

731
00:38:41,666 --> 00:38:45,686 A:middle
to use any extra hardware or
install any extra software

732
00:38:45,686 --> 00:38:49,306 A:middle
and you could just record audio
digitally through the darn cable

733
00:38:49,306 --> 00:38:52,596 A:middle
that came with the darn thing?

734
00:38:53,136 --> 00:38:54,316 A:middle
Well, drumroll, please.

735
00:38:55,906 --> 00:39:00,406 A:middle
Oh, great latency
on that [laughter].

736

737
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

738
00:38:55,906 --> 00:39:00,406 A:middle
Oh, great latency
on that [laughter].

739
00:39:01,176 --> 00:39:04,126 A:middle
Introducing Inter-Device
Audio Mode,

740
00:39:04,806 --> 00:39:07,566 A:middle
or as we like to call
it internally, IDAM.

741
00:39:07,916 --> 00:39:12,686 A:middle
IDAM allows you to record
audio digitally through the USB

742
00:39:12,686 --> 00:39:15,356 A:middle
to lightning cable that
came with your device.

743
00:39:16,076 --> 00:39:19,336 A:middle
It records at a hardware
audio stream format

744
00:39:19,336 --> 00:39:22,976 A:middle
of two channel 24-bit at
48 kilohertz sample rate,

745
00:39:23,396 --> 00:39:27,716 A:middle
and it is a USB 2.0 audio
class-compliant implementation

746
00:39:27,716 --> 00:39:28,456 A:middle
from end to end.

747
00:39:29,186 --> 00:39:31,536 A:middle
What that means is
on the Mac side,

748
00:39:31,816 --> 00:39:34,876 A:middle
you are using the class
Mac USB audio driver.

749
00:39:35,086 --> 00:39:37,986 A:middle
You will get the same great
performance and low latency

750
00:39:37,986 --> 00:39:41,566 A:middle
that class-compliant USB
audio devices currently get.

751
00:39:41,886 --> 00:39:43,966 A:middle
Also, on the iOS side,

752
00:39:44,176 --> 00:39:48,136 A:middle
the implementation is
USBISOCHRONOUS audio.

753
00:39:48,446 --> 00:39:50,826 A:middle
That means your bandwidth
is reserved.

754
00:39:51,286 --> 00:39:55,126 A:middle
If you want to backup
120 gigabytes of data

755
00:39:55,406 --> 00:39:57,896 A:middle
to your Mac while you are
tapping out a drum beat

756
00:39:57,896 --> 00:39:59,996 A:middle
and recording it,
you can rest assured

757
00:39:59,996 --> 00:40:03,436 A:middle
that your audio is not
going to have any artifacts.

758

759
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

760
00:39:59,996 --> 00:40:03,436 A:middle
that your audio is not
going to have any artifacts.

761
00:40:04,796 --> 00:40:07,006 A:middle
Next, my no slide.

762
00:40:07,646 --> 00:40:09,466 A:middle
No additional hardware required.

763
00:40:09,616 --> 00:40:11,416 A:middle
There's no additional
software required.

764
00:40:11,416 --> 00:40:13,926 A:middle
You don't need to modify
your OS X application

765
00:40:14,196 --> 00:40:15,836 A:middle
to take advantage
of this feature.

766
00:40:16,076 --> 00:40:19,386 A:middle
If your iOS application
already properly adapts

767
00:40:19,386 --> 00:40:23,646 A:middle
to a two-channel 24-bit
48-kilohertz audio stream

768
00:40:23,646 --> 00:40:26,346 A:middle
format, you don't have to
modify your iOS application.

769
00:40:27,126 --> 00:40:29,736 A:middle
And if you get a calendar alert
while you are in the middle

770
00:40:29,736 --> 00:40:31,376 A:middle
of jamming out a
sample baseline,

771
00:40:31,506 --> 00:40:33,496 A:middle
that alert is not going
to go out over the USB.

772
00:40:33,546 --> 00:40:36,606 A:middle
It goes out over the speaker
like it's supposed to.

773
00:40:37,516 --> 00:40:41,636 A:middle
[ Applause ]

774
00:40:42,136 --> 00:40:45,556 A:middle
Okay. So Inter-Device Audio
Mode, your device can charge

775
00:40:45,556 --> 00:40:49,316 A:middle
and sync in this mode; however,
photo import, tethering,

776
00:40:49,356 --> 00:40:52,046 A:middle
and QuickTime screen capture
will be temporarily disabled.

777
00:40:52,426 --> 00:40:54,316 A:middle
You want those back,
click a button

778
00:40:54,406 --> 00:40:55,776 A:middle
or just unplug the device.

779
00:40:56,666 --> 00:40:58,736 A:middle
Torrey, how do I
use it, you may ask?

780
00:40:59,466 --> 00:41:03,056 A:middle
So we built support directly
into audio MIDI setup.

781

782
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

783
00:40:59,466 --> 00:41:03,056 A:middle
So we built support directly
into audio MIDI setup.

784
00:41:03,216 --> 00:41:06,036 A:middle
If you look under the window
menu, you will see a new option,

785
00:41:06,776 --> 00:41:10,086 A:middle
show iOS device browser,
and if you click that,

786
00:41:10,086 --> 00:41:11,656 A:middle
you get this fancy-pants view.

787
00:41:12,206 --> 00:41:14,596 A:middle
It shows you all your
connected iOS devices.

788
00:41:15,086 --> 00:41:18,166 A:middle
You want to enter or exit
the IDAM configuration,

789
00:41:18,286 --> 00:41:19,266 A:middle
you click the button.

790
00:41:20,036 --> 00:41:24,086 A:middle
Now, you can actually embed this
view into your OS X application

791
00:41:24,086 --> 00:41:26,736 A:middle
if you choose to do so, and I
am going to show you some code

792
00:41:26,736 --> 00:41:29,376 A:middle
for how to do that,
but before that,

793
00:41:29,376 --> 00:41:31,106 A:middle
you've guessed it,
it's demo time.

794
00:41:36,136 --> 00:41:39,236 A:middle
I've got one of these
fancy iPads up here.

795
00:41:39,436 --> 00:41:40,126 A:middle
All right.

796
00:41:41,616 --> 00:41:45,956 A:middle
Here on this iPad, I am running
a synthesizer application

797
00:41:45,956 --> 00:41:46,766 A:middle
called Nave.

798
00:41:47,066 --> 00:41:48,576 A:middle
I like this application
because some

799
00:41:48,576 --> 00:41:52,446 A:middle
of the patches you can actually
get a nice touch interface

800
00:41:52,566 --> 00:41:53,006 A:middle
for it.

801
00:41:53,626 --> 00:41:55,296 A:middle
You can potentially
do aftertouch with it,

802
00:41:55,296 --> 00:41:57,306 A:middle
which is something that's
not on every MIDI controller

803
00:41:57,306 --> 00:41:58,216 A:middle
that you buy on the market.

804
00:41:58,526 --> 00:42:01,626 A:middle
It's one reason why iPads are
such great musical instruments.

805

806
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

807
00:41:58,526 --> 00:42:01,626 A:middle
It's one reason why iPads are
such great musical instruments.

808
00:42:02,316 --> 00:42:04,926 A:middle
So I selected a patch here
that sounds like this.

809
00:42:05,516 --> 00:42:11,556 A:middle
[ Music ]

810
00:42:12,056 --> 00:42:13,516 A:middle
I like those sounds, so
I want to record them

811
00:42:13,516 --> 00:42:16,356 A:middle
into a hip hop project that
I am working on on the Mac.

812
00:42:16,906 --> 00:42:22,026 A:middle
So let's move over to the Mac,

813
00:42:26,346 --> 00:42:29,646 A:middle
okay here on the Mac I already
have audio MIDI setup running.

814
00:42:29,646 --> 00:42:35,536 A:middle
I am going to go to the window
menu, show iOS device browser,

815
00:42:35,536 --> 00:42:39,136 A:middle
and I can see I currently
have no connected iOS devices.

816
00:42:39,596 --> 00:42:42,066 A:middle
So I will plug in my iPad.

817
00:42:43,766 --> 00:42:45,286 A:middle
It shows up immediately.

818
00:42:46,046 --> 00:42:48,016 A:middle
Blink and you miss
it, but click Enable,

819
00:42:48,916 --> 00:42:52,826 A:middle
and now you've got an extra
audio device right here.

820
00:42:53,206 --> 00:42:54,986 A:middle
Yes, Logic, we will
get to you shortly.

821
00:42:55,816 --> 00:42:58,556 A:middle
You can see there's a
two-channel input audio device

822
00:42:58,616 --> 00:42:59,526 A:middle
that's been added here.

823
00:42:59,576 --> 00:43:02,746 A:middle
And we do want to use this in
my Logic project, so I am going

824

825
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

826
00:42:59,576 --> 00:43:02,746 A:middle
And we do want to use this in
my Logic project, so I am going

827
00:43:02,746 --> 00:43:04,126 A:middle
to go ahead and say Use Here.

828
00:43:08,516 --> 00:43:10,066 A:middle
Let's bring Logic back up.

829
00:43:10,896 --> 00:43:11,956 A:middle
All right.

830
00:43:12,236 --> 00:43:13,636 A:middle
Here is the beat I
have been working on.

831
00:43:14,516 --> 00:43:20,706 A:middle
[ Music ]

832
00:43:21,206 --> 00:43:25,396 A:middle
And I want to record in an
audio track here, so I am going

833
00:43:25,396 --> 00:43:27,666 A:middle
to create a new audio track.

834
00:43:28,836 --> 00:43:31,746 A:middle
Record monitor that
and record enable.

835
00:43:32,766 --> 00:43:38,346 A:middle
Bring the volume down a little
bit because it will be at unity.

836
00:43:38,346 --> 00:43:42,346 A:middle
And now [music] I can hear that
coming directly into my track.

837
00:43:42,436 --> 00:43:43,976 A:middle
So let's record a piece.

838
00:43:44,516 --> 00:44:01,946 A:middle
[ Music ]

839

840
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

841
00:43:44,516 --> 00:44:01,946 A:middle
[ Music ]

842
00:44:02,446 --> 00:44:07,166 A:middle
And if I play back my
performance [music] the audio's

843
00:44:07,196 --> 00:44:08,966 A:middle
captured exactly like I expect.

844
00:44:15,046 --> 00:44:16,036 A:middle
Sick beat, Bro.

845
00:44:17,516 --> 00:44:23,826 A:middle
[ Applause ]

846
00:44:24,326 --> 00:44:27,046 A:middle
Now, that concludes my demo,
but I am not a professional.

847
00:44:27,076 --> 00:44:28,346 A:middle
Please try this at home.

848
00:44:28,346 --> 00:44:29,766 A:middle
It's in your betas right now.

849
00:44:29,946 --> 00:44:32,026 A:middle
If you find any bugs
with it whatsoever,

850
00:44:32,026 --> 00:44:35,906 A:middle
just go to bugreport.apple.com,
and file that bug for us.

851
00:44:36,606 --> 00:44:39,346 A:middle
Okay. So a few last
words about IDAM.

852
00:44:39,646 --> 00:44:43,026 A:middle
It requires OS X El
Capitan and iOS 9.

853
00:44:43,646 --> 00:44:45,926 A:middle
It will work on all iPhones
with a lightning connector.

854
00:44:45,996 --> 00:44:47,496 A:middle
It works on all iPads

855
00:44:47,496 --> 00:44:51,016 A:middle
with a lightning connector
except our very first iPad mini.

856
00:44:51,636 --> 00:44:55,816 A:middle
And if you've got a home iPhone,
a work iPhone, a home iPad,

857
00:44:55,816 --> 00:44:59,156 A:middle
a work iPad, and an iPad for
the kids and the power hubs

858
00:44:59,156 --> 00:45:02,286 A:middle
to support it, you can plug all
of those in at the same time,

859

860
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

861
00:44:59,156 --> 00:45:02,286 A:middle
to support it, you can plug all
of those in at the same time,

862
00:45:02,546 --> 00:45:05,476 A:middle
aggregate them together as a
massive ten-channel input device

863
00:45:05,476 --> 00:45:06,636 A:middle
if you want to, and record it.

864
00:45:06,636 --> 00:45:09,916 A:middle
And if you've got USB
ports left over after that,

865
00:45:09,956 --> 00:45:13,496 A:middle
please point your Safari browser
at store.apple.com [laughter].

866
00:45:15,516 --> 00:45:20,566 A:middle
[ Applause ]

867
00:45:21,066 --> 00:45:22,966 A:middle
Okay. I said earlier
that I would tell you how

868
00:45:23,036 --> 00:45:25,616 A:middle
to embed the view controller
into your OS X application

869
00:45:25,616 --> 00:45:27,156 A:middle
if you choose to do
that, and I am going

870
00:45:27,156 --> 00:45:28,436 A:middle
to show you the code
for that now.

871
00:45:32,376 --> 00:45:35,616 A:middle
This code is pretty boilerplate,
so I took the liberty

872
00:45:35,616 --> 00:45:36,886 A:middle
of highlighting the
important part,

873
00:45:36,946 --> 00:45:39,606 A:middle
if you will let your eyes
slide down to the yellow text,

874
00:45:39,906 --> 00:45:42,646 A:middle
and you will see CA Inter-
Device Audio View Controller.

875
00:45:43,076 --> 00:45:46,276 A:middle
You just want to create one of
those and then add the subview

876
00:45:46,276 --> 00:45:47,396 A:middle
to your view container.

877
00:45:47,996 --> 00:45:51,936 A:middle
As long as I am talking about
new view controllers that are

878
00:45:51,936 --> 00:45:53,796 A:middle
in CoreAudioKit, I
also wanted to tell you

879
00:45:53,796 --> 00:45:56,656 A:middle
about a couple more you
might be interested in.

880
00:45:56,956 --> 00:46:00,776 A:middle
We've also added
CABTLEMIDI window controller.

881

882
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

883
00:45:56,956 --> 00:46:00,776 A:middle
We've also added
CABTLEMIDI window controller.

884
00:46:01,436 --> 00:46:05,056 A:middle
This is the UI for configuring
your Bluetooth Low Energy MIDI

885
00:46:05,056 --> 00:46:07,686 A:middle
devices, it's a feature
that we debuted last year.

886
00:46:08,166 --> 00:46:11,216 A:middle
It's an NS window controller
subclass, and that view looks

887
00:46:11,216 --> 00:46:13,956 A:middle
like this, so you can
now embed this directly

888
00:46:13,956 --> 00:46:18,166 A:middle
into your OS X application
if you choose to do so.

889
00:46:18,426 --> 00:46:19,306 A:middle
One more for you.

890
00:46:19,826 --> 00:46:22,716 A:middle
We also have CA Network
Browser Window Controller.

891
00:46:22,876 --> 00:46:26,866 A:middle
This is the UI for configuring
your Audio Video Bridge

892
00:46:26,916 --> 00:46:27,696 A:middle
audio devices.

893
00:46:28,166 --> 00:46:30,106 A:middle
Also an NS window
controller subclass,

894
00:46:30,106 --> 00:46:36,876 A:middle
and that view looks like this.

895
00:46:37,086 --> 00:46:40,996 A:middle
Okay. Let's push in the clutch
and switch gears as we talk

896
00:46:40,996 --> 00:46:43,166 A:middle
about what's new
in AVAudioSession.

897
00:46:43,716 --> 00:46:46,496 A:middle
So how many of you listen
to podcasts and audio books?

898
00:46:47,596 --> 00:46:47,956 A:middle
All right.

899
00:46:47,956 --> 00:46:48,436 A:middle
A lot of you.

900
00:46:48,746 --> 00:46:50,546 A:middle
How many of you also
use your iPhone

901
00:46:50,546 --> 00:46:52,026 A:middle
as your primary navigation
device?

902
00:46:53,046 --> 00:46:55,076 A:middle
A lot of you too.

903
00:46:55,346 --> 00:46:57,366 A:middle
Okay. So you may have
seen this problem before.

904
00:46:57,636 --> 00:46:59,636 A:middle
Let's say you are going
to a soul food restaurant

905
00:46:59,636 --> 00:47:00,576 A:middle
that you've never been to.

906

907
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

908
00:46:59,636 --> 00:47:00,576 A:middle
that you've never been to.

909
00:47:01,096 --> 00:47:02,036 A:middle
You are navigating.

910
00:47:02,036 --> 00:47:03,566 A:middle
Then you are listening
to a podcast.

911
00:47:03,896 --> 00:47:06,906 A:middle
This podcast is hosted
by podcast personality X,

912
00:47:07,456 --> 00:47:11,406 A:middle
and they are interviewing your
favorite currently relevant

913
00:47:11,406 --> 00:47:14,786 A:middle
celebrity Y, and in the
middle of this interview,

914
00:47:14,986 --> 00:47:17,146 A:middle
the conversation is
getting really juicy

915
00:47:17,246 --> 00:47:20,766 A:middle
when your navigation pipes
up and says in 500 feet,

916
00:47:20,876 --> 00:47:23,056 A:middle
keep to the right, followed
by a -- keep to the right.

917
00:47:24,286 --> 00:47:26,316 A:middle
Then after that you
hear raucous laughter.

918
00:47:26,316 --> 00:47:28,556 A:middle
Some great joke happened,
and you just missed it.

919
00:47:28,646 --> 00:47:31,776 A:middle
So you back up the audio, and
you start playing it again,

920
00:47:31,776 --> 00:47:34,156 A:middle
and just as you get to the
joke, "keep to the right."

921
00:47:34,816 --> 00:47:41,116 A:middle
You pump your fist and say "I am
having a bad user experience."

922
00:47:42,186 --> 00:47:45,806 A:middle
Okay. So we have a solution
for that [laughter].

923
00:47:45,956 --> 00:47:47,366 A:middle
I took some liberties
with that one.

924
00:47:49,056 --> 00:47:51,246 A:middle
We have a solution for
that for you in iOS 9.

925
00:47:51,526 --> 00:47:54,236 A:middle
So now podcasts and audio
book apps can use a new

926
00:47:54,236 --> 00:47:57,546 A:middle
AVAudioSession mode called
AVAudioSession mode spoken

927
00:47:57,546 --> 00:48:01,026 A:middle
audio, and for navigation
and fitness apps or apps

928

929
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

930
00:47:57,546 --> 00:48:01,026 A:middle
audio, and for navigation
and fitness apps or apps

931
00:48:01,096 --> 00:48:02,336 A:middle
that issue vocal prompts

932
00:48:02,336 --> 00:48:04,286 A:middle
that interrupt other
applications' audio,

933
00:48:04,686 --> 00:48:08,396 A:middle
there's a new AVAudioSession
category option called Interrupt

934
00:48:08,396 --> 00:48:10,146 A:middle
Spoken Audio and
Mix with Others.

935
00:48:10,696 --> 00:48:13,386 A:middle
Now, Maps already uses
Interrupt Spoken Audio and Mix

936
00:48:13,386 --> 00:48:15,306 A:middle
with Others, and podcasts

937
00:48:15,356 --> 00:48:17,756 A:middle
and iBooks are already
using AVAudioSession mode

938
00:48:17,816 --> 00:48:18,586 A:middle
spoken audio.

939
00:48:19,176 --> 00:48:21,136 A:middle
How can you use these
in your application?

940
00:48:21,696 --> 00:48:23,046 A:middle
Well, let's look at some code.

941
00:48:23,426 --> 00:48:26,576 A:middle
I am just going to go through
these pieces of code line

942
00:48:26,576 --> 00:48:28,206 A:middle
by line so you can
see what we are doing.

943
00:48:28,436 --> 00:48:30,746 A:middle
First we will start with
your audio session setup.

944
00:48:30,976 --> 00:48:33,156 A:middle
You will get the shared
instance of the audio session,

945
00:48:33,606 --> 00:48:37,896 A:middle
set your category to
playback, and for your options,

946
00:48:37,896 --> 00:48:39,656 A:middle
you will use the
option duck others.

947
00:48:39,766 --> 00:48:42,416 A:middle
Now we are going to use
something new in Swift 2,

948
00:48:42,986 --> 00:48:44,576 A:middle
this new if # available.

949
00:48:44,796 --> 00:48:47,966 A:middle
If will allow you to deploy
the same code in iOS 9

950
00:48:48,106 --> 00:48:50,106 A:middle
that you can deploy
to earlier iOS's.

951
00:48:50,856 --> 00:48:54,406 A:middle
So only if you are on
iOS 9 or greater, you can

952
00:48:54,406 --> 00:48:56,246 A:middle
or in this extra option,

953
00:48:56,286 --> 00:48:58,356 A:middle
Interrupt Spoken Audio
and Mix with Others.

954
00:48:59,046 --> 00:49:00,936 A:middle
Then you will set your
audio session category.

955

956
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

957
00:48:59,046 --> 00:49:00,936 A:middle
Then you will set your
audio session category.

958
00:49:01,516 --> 00:49:04,346 A:middle
Okay. Let's actually
look at the nav prompt.

959
00:49:05,086 --> 00:49:07,266 A:middle
Now you are going to play
your navigation prompt

960
00:49:07,396 --> 00:49:08,246 A:middle
that looks like this.

961
00:49:08,856 --> 00:49:11,206 A:middle
First get the shared
instance of the audio session.

962
00:49:11,366 --> 00:49:14,646 A:middle
You will create an AV audio
player using the URL that's

963
00:49:14,696 --> 00:49:16,376 A:middle
supplied in the function
prototype.

964
00:49:17,326 --> 00:49:19,186 A:middle
You set the player's
delegate to self.

965
00:49:19,726 --> 00:49:22,906 A:middle
What this will do for you is it
will allow the delegate method

966
00:49:22,906 --> 00:49:24,576 A:middle
to be called on your behalf

967
00:49:24,576 --> 00:49:26,716 A:middle
when your audio prompt
is finished playing.

968
00:49:27,246 --> 00:49:30,056 A:middle
Set your audio session
to active,

969
00:49:30,196 --> 00:49:31,616 A:middle
and then play on, player.

970
00:49:32,306 --> 00:49:35,166 A:middle
Now, here we go.

971
00:49:35,166 --> 00:49:37,176 A:middle
Now we are -- your
audio is done playing,

972
00:49:37,216 --> 00:49:38,966 A:middle
so your delegate
method is being called.

973
00:49:38,966 --> 00:49:40,576 A:middle
Audio player did finish playing.

974
00:49:40,996 --> 00:49:41,976 A:middle
The code looks like this.

975
00:49:42,566 --> 00:49:44,416 A:middle
Get the shared instance
of the audio session.

976
00:49:45,186 --> 00:49:47,496 A:middle
Set your audio session
to be inactive.

977
00:49:47,916 --> 00:49:51,566 A:middle
And use the option, option
notify others on deactivation.

978
00:49:52,396 --> 00:49:55,316 A:middle
This means any other audio
that was playing before you

979
00:49:55,316 --> 00:49:57,386 A:middle
from another process
can get notified

980
00:49:57,386 --> 00:49:59,846 A:middle
that you are done
interrupting them.

981

982
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

983
00:50:00,046 --> 00:50:01,256 A:middle
Now let's look at
the other side.

984
00:50:01,256 --> 00:50:05,526 A:middle
Let's go to the podcast or
spoken audio application.

985
00:50:06,256 --> 00:50:08,576 A:middle
Here's the audio
session setup for that.

986
00:50:08,766 --> 00:50:10,516 A:middle
Get the shared instance
of the audio session,

987
00:50:11,026 --> 00:50:12,736 A:middle
set your category to playback.

988
00:50:12,986 --> 00:50:16,936 A:middle
You let the mode be default for
now, but if you were running

989
00:50:16,936 --> 00:50:19,966 A:middle
in iOS 9 or later, you
can use this new mode,

990
00:50:20,056 --> 00:50:22,156 A:middle
AVAudioSession mode
spoken audio,

991
00:50:22,766 --> 00:50:24,306 A:middle
then set your category
and your mode.

992
00:50:25,566 --> 00:50:27,596 A:middle
The next thing you're
going to want to do is

993
00:50:27,596 --> 00:50:28,756 A:middle
to add an interruption handler.

994
00:50:28,996 --> 00:50:32,836 A:middle
We are going add an interruption
handler called handle

995
00:50:32,836 --> 00:50:35,886 A:middle
interruption and we want
it to be called in response

996
00:50:36,046 --> 00:50:39,196 A:middle
to AVAudioSession
interruption notification.

997
00:50:40,716 --> 00:50:43,706 A:middle
This is also a good time to
register for other notifications

998
00:50:43,706 --> 00:50:46,546 A:middle
of interest; for example, if the
media server died and you want

999
00:50:46,546 --> 00:50:49,026 A:middle
to be notified about that so
you can reset your audio state.

1000
00:50:49,536 --> 00:50:52,686 A:middle
Okay. So now let's look at
the interruption handler.

1001
00:50:54,196 --> 00:50:56,196 A:middle
The first thing we'll do here
is we will get the user info

1002
00:50:56,196 --> 00:50:58,576 A:middle
dictionary from the NS
notification object that's

1003
00:50:58,576 --> 00:51:01,496 A:middle
supplied in the function
prototype and from

1004

1005
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1006
00:50:58,576 --> 00:51:01,496 A:middle
supplied in the function
prototype and from

1007
00:51:01,496 --> 00:51:03,276 A:middle
that user info dictionary
we will look

1008
00:51:03,276 --> 00:51:06,276 A:middle
at the key AVAudioSession
interruption type key.

1009
00:51:06,846 --> 00:51:09,346 A:middle
Now we are going to
switch on that type.

1010
00:51:09,876 --> 00:51:12,286 A:middle
The first part of this is
going to be what happens

1011
00:51:12,736 --> 00:51:15,556 A:middle
when your audio session is
beginning to be interrupted,

1012
00:51:15,946 --> 00:51:17,736 A:middle
and then the second part
will be on the next slide,

1013
00:51:17,736 --> 00:51:18,556 A:middle
and that's for the end.

1014
00:51:18,656 --> 00:51:21,276 A:middle
So if this is a begin
interruption,

1015
00:51:21,566 --> 00:51:23,656 A:middle
the first thing you will
want to do is update your UI

1016
00:51:23,656 --> 00:51:25,656 A:middle
to indicate your playback
has already been stopped.

1017
00:51:26,316 --> 00:51:29,756 A:middle
Then if your internal state
dictated that you were playing,

1018
00:51:29,886 --> 00:51:31,606 A:middle
then you will set
was playing to true.

1019
00:51:31,606 --> 00:51:35,216 A:middle
That will let you know later
on when this interruption is

1020
00:51:35,216 --> 00:51:39,336 A:middle
over that you are okay to resume
audio, if that's appropriate.

1021
00:51:39,686 --> 00:51:42,706 A:middle
Then, of course, update
your internal state.

1022
00:51:44,016 --> 00:51:46,006 A:middle
So now this is the
end interruption,

1023
00:51:46,186 --> 00:51:48,396 A:middle
so in case this is
the end interruption,

1024
00:51:48,706 --> 00:51:50,996 A:middle
you'll get the flag from
the user info dictionary

1025
00:51:50,996 --> 00:51:53,456 A:middle
at AVAudioSession
interruption option key,

1026
00:51:54,076 --> 00:51:57,146 A:middle
and if that flag is
option should resume

1027
00:51:57,196 --> 00:51:59,536 A:middle
and you were playing before
when you were interrupted,

1028

1029
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1030
00:52:00,006 --> 00:52:02,146 A:middle
rewind the audio
just a little bit

1031
00:52:02,146 --> 00:52:04,456 A:middle
because your audio was
ducked before it was stopped,

1032
00:52:04,686 --> 00:52:06,236 A:middle
and then you can play
your player again,

1033
00:52:06,806 --> 00:52:09,896 A:middle
update your internal state, and
then update the UI to reflect

1034
00:52:09,896 --> 00:52:11,206 A:middle
that the playback has resumed.

1035
00:52:11,786 --> 00:52:14,166 A:middle
And that's all the
code I have for you.

1036
00:52:15,376 --> 00:52:16,446 A:middle
Quick recap.

1037
00:52:16,446 --> 00:52:17,446 A:middle
Today we have told you

1038
00:52:17,446 --> 00:52:20,286 A:middle
about some exciting new
enhancements in AVAudioEngine.

1039
00:52:20,586 --> 00:52:23,016 A:middle
We have introduced
Inter-Device Audio Mode.

1040
00:52:23,756 --> 00:52:26,126 A:middle
We've told you about some new
CoreAudioKit view controllers

1041
00:52:26,126 --> 00:52:28,096 A:middle
that you can embed into
your OS X applications

1042
00:52:28,476 --> 00:52:31,686 A:middle
for Inter-Device Audio Mode,
Bluetooth Low Energy, MIDI,

1043
00:52:31,686 --> 00:52:32,896 A:middle
and Audio Video Bridge.

1044
00:52:33,776 --> 00:52:36,846 A:middle
And we've also introduced
AVAudioSession mode spoken audio

1045
00:52:37,296 --> 00:52:40,536 A:middle
and the new AVAudioSession
category option Interrupt Spoken

1046
00:52:40,536 --> 00:52:41,886 A:middle
Audio and Mix with Others.

1047
00:52:42,666 --> 00:52:43,746 A:middle
But that's not all.

1048
00:52:44,046 --> 00:52:47,436 A:middle
We have another session
coming up tomorrow at 11 a.m.

1049
00:52:47,696 --> 00:52:51,186 A:middle
on all the exciting changes
to Audio Unit Extensions,

1050
00:52:51,186 --> 00:52:52,326 A:middle
so we hope to see you all there.

1051
00:52:53,126 --> 00:52:55,886 A:middle
Also some related sessions
that happened earlier today,

1052
00:52:55,886 --> 00:52:57,706 A:middle
if you want to go
back and look at them,

1053
00:52:57,706 --> 00:53:00,976 A:middle
especially if you are coming
in from the game audio side.

1054

1055
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1056
00:52:57,706 --> 00:53:00,976 A:middle
especially if you are coming
in from the game audio side.

1057
00:53:02,136 --> 00:53:04,576 A:middle
If we are not able to answer
all your questions at the labs,

1058
00:53:04,766 --> 00:53:08,606 A:middle
these are some very useful
websites that you can go to,

1059
00:53:08,686 --> 00:53:12,566 A:middle
and any general inquiries can
be directed to Craig Keithley,

1060
00:53:12,566 --> 00:53:17,296 A:middle
whose contact information is
at the bottom, and we out.

1061
00:53:18,516 --> 00:53:31,780 A:middle
[ Applause ]

1062
