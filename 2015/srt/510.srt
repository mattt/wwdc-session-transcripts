X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:24,031 --> 00:00:26,031 A:middle
[ Applause ]

2
00:00:26,046 --> 00:00:26,586 A:middle
>> DAVID HAYWARD: Good
morning, everyone,

3
00:00:26,586 --> 00:00:29,416 A:middle
my name is David Hayward, and
it's my privilege today to talk

4
00:00:29,416 --> 00:00:32,415 A:middle
about what's new in
Core Image on iOS 9

5
00:00:32,576 --> 00:00:34,496 A:middle
and Mac OS X El Capitan.

6
00:00:35,136 --> 00:00:38,166 A:middle
So to start off, we will be
covering several things today.

7
00:00:38,276 --> 00:00:40,576 A:middle
First off I will give a brief
introduction to Core Image

8
00:00:40,676 --> 00:00:42,736 A:middle
for those new to the subject.

9
00:00:42,866 --> 00:00:44,356 A:middle
I recommend that you go back

10
00:00:44,356 --> 00:00:46,236 A:middle
and see our presentations
from last year.

11
00:00:46,316 --> 00:00:48,196 A:middle
In particular, there was
a great discussion on how

12
00:00:48,196 --> 00:00:49,926 A:middle
to write kernels in Core Image.

13
00:00:50,686 --> 00:00:52,936 A:middle
Next, we'll be talking
about what's new

14
00:00:52,936 --> 00:00:53,876 A:middle
in Core Image this year.

15
00:00:53,926 --> 00:00:55,456 A:middle
We have a lot of stuff
to talk about here.

16
00:00:55,876 --> 00:00:58,736 A:middle
And the other third of our
discussion today will be talking

17
00:00:58,736 --> 00:01:00,786 A:middle
about using Core
Image and bridging it

18

19
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

20
00:00:58,736 --> 00:01:00,786 A:middle
about using Core
Image and bridging it

21
00:01:00,786 --> 00:01:04,855 A:middle
with other graphics
frameworks on our platforms.

22
00:01:05,476 --> 00:01:08,956 A:middle
First, an introduction
to Core Image.

23
00:01:09,456 --> 00:01:13,306 A:middle
In concept, the idea of Core
Image is you can apply filters

24
00:01:13,306 --> 00:01:13,906 A:middle
to images.

25
00:01:14,436 --> 00:01:17,086 A:middle
In a simple example, you can
start with an input image

26
00:01:17,086 --> 00:01:19,996 A:middle
and apply a filter to do a
color effect such as sepia tone,

27
00:01:20,726 --> 00:01:21,756 A:middle
but if you don't like the color

28
00:01:21,756 --> 00:01:24,666 A:middle
of sepia tone you can
apply another color effect

29
00:01:24,766 --> 00:01:27,256 A:middle
to change the hue to make it
more of a blue-toned image.

30
00:01:27,816 --> 00:01:29,996 A:middle
You can also use Core
Image to apply effects

31
00:01:29,996 --> 00:01:32,166 A:middle
such as geometry-distorting
events.

32
00:01:32,436 --> 00:01:36,416 A:middle
In this example, we are just
using a simple transform to zoom

33
00:01:36,416 --> 00:01:37,576 A:middle
in on a portion of the image.

34
00:01:38,466 --> 00:01:40,716 A:middle
You can think of there
being an intermediate image

35
00:01:40,806 --> 00:01:41,796 A:middle
between every filter.

36
00:01:42,416 --> 00:01:45,396 A:middle
However, the way we
implement filters,

37
00:01:45,396 --> 00:01:47,056 A:middle
they are actually very
lightweight objects

38
00:01:47,056 --> 00:01:48,876 A:middle
that take very little
time to create,

39
00:01:49,336 --> 00:01:51,366 A:middle
and there are not necessarily
intermediate buffers

40
00:01:51,366 --> 00:01:52,706 A:middle
in between them.

41
00:01:52,786 --> 00:01:54,956 A:middle
Another important
concept is that associated

42
00:01:54,956 --> 00:01:57,216 A:middle
with each filter is
one or more kernels.

43
00:01:57,636 --> 00:02:01,306 A:middle
CI kernels are small subroutines
that apply the effect

44

45
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

46
00:01:57,636 --> 00:02:01,306 A:middle
CI kernels are small subroutines
that apply the effect

47
00:02:01,306 --> 00:02:03,106 A:middle
that that kernel is
trying to achieve.

48
00:02:04,586 --> 00:02:05,576 A:middle
One of the other key features

49
00:02:05,576 --> 00:02:12,116 A:middle
of Core Image is we concatenate
these kernels into a program

50
00:02:12,456 --> 00:02:15,576 A:middle
as much as possible to minimize
the use of intermediate buffers

51
00:02:15,576 --> 00:02:18,706 A:middle
and improve performance.

52
00:02:19,786 --> 00:02:22,696 A:middle
Another key feature in Core
Image is what we call region

53
00:02:22,696 --> 00:02:23,586 A:middle
of interest support.

54
00:02:24,146 --> 00:02:26,746 A:middle
The idea is that if you are only
rendering a portion of an image,

55
00:02:27,376 --> 00:02:29,286 A:middle
either because you are
zoomed in on a large image

56
00:02:29,286 --> 00:02:31,466 A:middle
or because it's being
rendered out in tiles,

57
00:02:32,556 --> 00:02:35,666 A:middle
we can ask each filter
that's been rendered how much

58
00:02:35,666 --> 00:02:38,896 A:middle
of the input image it needs, and
from that we can calculate back

59
00:02:38,896 --> 00:02:41,316 A:middle
to the source image the
exact region that's needed

60
00:02:41,546 --> 00:02:45,136 A:middle
of that image in order to
produce the desired output.

61
00:02:45,286 --> 00:02:48,876 A:middle
This is another great feature
of Core Image that allows us

62
00:02:48,876 --> 00:02:50,336 A:middle
to get good performance
especially

63
00:02:50,336 --> 00:02:51,686 A:middle
when working on large images.

64
00:02:53,136 --> 00:02:56,046 A:middle
There are four main
classes you need to be aware

65
00:02:56,046 --> 00:02:57,326 A:middle
of when you are using
Core Image.

66
00:02:57,716 --> 00:02:59,066 A:middle
The first is the CI kernel.

67
00:02:59,066 --> 00:03:00,646 A:middle
I mentioned this earlier.

68

69
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

70
00:02:59,066 --> 00:03:00,646 A:middle
I mentioned this earlier.

71
00:03:01,046 --> 00:03:03,366 A:middle
This represents the
program or routine written

72
00:03:03,366 --> 00:03:05,486 A:middle
in Core Image's kernel language.

73
00:03:05,996 --> 00:03:09,456 A:middle
The second key class is
the filter, the CI filter.

74
00:03:09,816 --> 00:03:13,326 A:middle
This is a mutable object, and
it can have multiple inputs,

75
00:03:13,366 --> 00:03:16,596 A:middle
and these input parameters
can be either numbers

76
00:03:16,596 --> 00:03:18,046 A:middle
or vectors or other images.

77
00:03:19,416 --> 00:03:23,106 A:middle
The filter uses one or
more kernels in order

78
00:03:23,106 --> 00:03:26,156 A:middle
to create an output image
based on the current state

79
00:03:26,156 --> 00:03:27,236 A:middle
of the input parameters.

80
00:03:27,916 --> 00:03:30,346 A:middle
A CI image is an
immutable object

81
00:03:30,746 --> 00:03:33,696 A:middle
that represents the recipe
to produce that image based

82
00:03:33,696 --> 00:03:35,946 A:middle
on the previous kernels
that have been applied.

83
00:03:37,446 --> 00:03:40,126 A:middle
And lastly, there is
the CIContext object.

84
00:03:40,356 --> 00:03:41,826 A:middle
And this is a more
heavyweight object.

85
00:03:41,826 --> 00:03:44,436 A:middle
This is the object through
which Core Image will render.

86
00:03:44,936 --> 00:03:48,376 A:middle
You want to avoid creating these
too often in your application,

87
00:03:48,416 --> 00:03:50,356 A:middle
so if you are doing
fast animation you want

88
00:03:50,356 --> 00:03:51,226 A:middle
to do this just once.

89
00:03:51,836 --> 00:03:52,436 A:middle
And the great thing

90
00:03:52,436 --> 00:03:54,546 A:middle
about CIContext is
they can be implemented

91
00:03:54,546 --> 00:03:57,736 A:middle
on various different back-end
renderers in our system.

92
00:03:58,326 --> 00:04:02,786 A:middle
So the next thing I would
like to talk about now

93

94
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

95
00:03:58,326 --> 00:04:02,786 A:middle
So the next thing I would
like to talk about now

96
00:04:02,786 --> 00:04:04,516 A:middle
that the introduction
is behind us is to talk

97
00:04:04,516 --> 00:04:06,456 A:middle
about what's new this
year in Core Image.

98
00:04:07,716 --> 00:04:09,536 A:middle
We have several things
to talk about today.

99
00:04:10,136 --> 00:04:13,786 A:middle
We will be talking about Metal,
talking about new filters,

100
00:04:14,276 --> 00:04:18,375 A:middle
new detector, color management
support, and some improvements

101
00:04:18,375 --> 00:04:20,836 A:middle
to the kernel classes
and languages.

102
00:04:21,815 --> 00:04:24,576 A:middle
And most important thing I want
to talk about is that we now

103
00:04:24,936 --> 00:04:28,096 A:middle
in Core Image have a unified
implementation across both

104
00:04:28,096 --> 00:04:32,136 A:middle
of our platforms, so for the
most part unless we mention

105
00:04:32,136 --> 00:04:34,786 A:middle
otherwise the behavior of Core
Image is completely consistent

106
00:04:35,036 --> 00:04:37,296 A:middle
and equivalent between
iOS and OS X.

107
00:04:37,296 --> 00:04:41,036 A:middle
And this is a great feature for
developers to be able to rely

108
00:04:41,036 --> 00:04:42,166 A:middle
on this consistent behavior.

109
00:04:43,036 --> 00:04:46,126 A:middle
This can be little
things such as the fact

110
00:04:46,126 --> 00:04:47,876 A:middle
that when you include
the Core Image header,

111
00:04:48,166 --> 00:04:50,616 A:middle
you can include Core
Image, Core Image.H,

112
00:04:50,816 --> 00:04:52,276 A:middle
regardless what platform
you are.

113
00:04:52,336 --> 00:04:53,326 A:middle
So it makes it a lot easier

114
00:04:53,326 --> 00:04:56,266 A:middle
if you're doing cross-platform
code.

115
00:04:56,626 --> 00:05:03,976 A:middle
We have now got API parity
between the two platforms.

116

117
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

118
00:04:56,626 --> 00:05:03,976 A:middle
We have now got API parity
between the two platforms.

119
00:05:03,976 --> 00:05:07,316 A:middle
So one of the major
things we want to talk

120
00:05:07,316 --> 00:05:09,686 A:middle
about today is Core
Image support for Metal.

121
00:05:09,746 --> 00:05:12,526 A:middle
And we will be talking this
in much more detail later

122
00:05:12,526 --> 00:05:13,506 A:middle
on in the presentation,

123
00:05:13,836 --> 00:05:15,346 A:middle
but I want to give you
the highlights right now.

124
00:05:15,886 --> 00:05:17,446 A:middle
The key things to think of is

125
00:05:17,446 --> 00:05:21,256 A:middle
that Metal Textures can now be
given as an input to Core Image,

126
00:05:21,806 --> 00:05:24,126 A:middle
and also Metal Textures can
be the output of Core Image.

127
00:05:25,146 --> 00:05:28,146 A:middle
And internally, Core
Image context will be able

128
00:05:28,146 --> 00:05:30,426 A:middle
to use Metal as their
internal renderer.

129
00:05:31,226 --> 00:05:32,986 A:middle
What that means is if
you have written a kernel

130
00:05:32,986 --> 00:05:35,966 A:middle
in CI's kernel language, it
will be automatically translated

131
00:05:36,406 --> 00:05:38,336 A:middle
on the fly to Metal language.

132
00:05:40,256 --> 00:05:42,696 A:middle
Another thing to keep in mind
is some of our built-in filters,

133
00:05:42,696 --> 00:05:46,706 A:middle
notably Gaussian and convolution
filters, are now built on top

134
00:05:46,706 --> 00:05:48,126 A:middle
of Metal performance
shaders in order

135
00:05:48,126 --> 00:05:50,496 A:middle
to get the best possible
performance on the diversity

136
00:05:50,496 --> 00:05:51,726 A:middle
of platforms that are supported.

137
00:05:53,636 --> 00:05:56,606 A:middle
A little bit about filters.

138
00:05:57,396 --> 00:05:58,796 A:middle
Again, as I mentioned before,

139
00:05:58,796 --> 00:06:01,016 A:middle
we now have a unified
implementation of Core Image.

140

141
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

142
00:05:58,796 --> 00:06:01,016 A:middle
we now have a unified
implementation of Core Image.

143
00:06:01,016 --> 00:06:04,366 A:middle
This means we have 200 buil-
in filters on both platforms.

144
00:06:04,906 --> 00:06:07,876 A:middle
That means we have
brought a lot of filters

145
00:06:08,096 --> 00:06:10,736 A:middle
to the iOS implementation
of Core Image.

146
00:06:10,886 --> 00:06:12,736 A:middle
Over 40 have been
added in this release.

147
00:06:13,126 --> 00:06:14,846 A:middle
These fall into different
categories.

148
00:06:14,846 --> 00:06:18,406 A:middle
There are fun filters like
comic effect, and CMYK Halftone,

149
00:06:18,406 --> 00:06:20,346 A:middle
and Droste, and Page Curl.

150
00:06:20,346 --> 00:06:22,846 A:middle
There are also some convolutions
filters that are useful,

151
00:06:22,846 --> 00:06:27,336 A:middle
such as median filters, edge
detection, and noise reduction.

152
00:06:27,916 --> 00:06:31,866 A:middle
Also we have reduction
filters, which are useful

153
00:06:31,866 --> 00:06:34,586 A:middle
for image analysis
such as Area Maximum

154
00:06:34,586 --> 00:06:36,106 A:middle
or Column Averaging an image.

155
00:06:37,476 --> 00:06:40,056 A:middle
In order to give you a
little taste of this,

156
00:06:40,056 --> 00:06:42,576 A:middle
I want to show you the
latest version of one

157
00:06:42,576 --> 00:06:44,916 A:middle
of our sample applications
called Core Image FunHouse,

158
00:06:45,596 --> 00:06:48,336 A:middle
and we try to update
this every year.

159
00:06:49,266 --> 00:06:52,336 A:middle
One of the things we have now
is now that we have 200 filters,

160
00:06:52,926 --> 00:06:55,936 A:middle
when you bring up the Filters
pop-up in this application,

161
00:06:55,936 --> 00:06:58,156 A:middle
we have now broken them
up into categories.

162
00:06:58,556 --> 00:07:00,246 A:middle
You can also see
highlighted in red all

163

164
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

165
00:06:58,556 --> 00:07:00,246 A:middle
You can also see
highlighted in red all

166
00:07:00,246 --> 00:07:03,306 A:middle
of the new filters we have
added, and there is now an API

167
00:07:03,306 --> 00:07:05,966 A:middle
for you to determine
what release a filter was

168
00:07:05,966 --> 00:07:06,486 A:middle
included in.

169
00:07:07,816 --> 00:07:11,396 A:middle
And this is, of course, showing
the CMYK Halftone effect getting

170
00:07:11,396 --> 00:07:14,626 A:middle
good performance on an
iPad at Retina resolution.

171
00:07:14,936 --> 00:07:22,366 A:middle
There are two new filters
we have added to Core Image

172
00:07:22,366 --> 00:07:24,236 A:middle
on both platforms
by popular request.

173
00:07:24,586 --> 00:07:27,756 A:middle
These are filters for
generating bar codes.

174
00:07:27,876 --> 00:07:31,226 A:middle
So the input in this case
to a filter is not a number

175
00:07:31,226 --> 00:07:33,246 A:middle
or another image,
but a text string.

176
00:07:34,006 --> 00:07:38,296 A:middle
And we have added these two
for generating PDF417 bar codes

177
00:07:38,336 --> 00:07:42,176 A:middle
and code 128 bar codes.

178
00:07:43,606 --> 00:07:46,526 A:middle
Another feature of Core
Image is what we call our CI

179
00:07:46,606 --> 00:07:47,616 A:middle
detector classes.

180
00:07:47,876 --> 00:07:49,906 A:middle
These are our classes we
have released in the past

181
00:07:49,906 --> 00:07:52,926 A:middle
for doing things like
detecting faces in an image,

182
00:07:53,416 --> 00:07:55,346 A:middle
detecting QR codes in an image,

183
00:07:55,796 --> 00:07:57,386 A:middle
or detecting rectangles
in an image.

184
00:07:57,656 --> 00:07:58,846 A:middle
And we have a new one this year,

185
00:07:58,846 --> 00:08:01,596 A:middle
which is for detecting
areas of text in an image.

186

187
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

188
00:07:58,846 --> 00:08:01,596 A:middle
which is for detecting
areas of text in an image.

189
00:08:02,036 --> 00:08:05,006 A:middle
The idea in the filter is to
locate areas that are likely

190
00:08:05,006 --> 00:08:06,876 A:middle
to contain upright text.

191
00:08:07,636 --> 00:08:10,666 A:middle
So let me give a brief demo
of this running on an iPad.

192
00:08:11,006 --> 00:08:13,756 A:middle
We have hooked this up to the
Core Image FunHouse application.

193
00:08:14,186 --> 00:08:17,786 A:middle
So we have an old box that was
on my shelf, and if we turn

194
00:08:17,786 --> 00:08:20,756 A:middle
on the text detector it's
locating the upright text,

195
00:08:21,236 --> 00:08:24,236 A:middle
both the runs of text and
the individual characters.

196
00:08:24,776 --> 00:08:27,786 A:middle
And as we zoom in and
rotate the camera,

197
00:08:28,146 --> 00:08:30,786 A:middle
the upright text will
detect some of the text

198
00:08:30,786 --> 00:08:33,395 A:middle
that was at an angle as well.

199
00:08:34,426 --> 00:08:36,236 A:middle
So that's our new text
detector so I'm excited

200
00:08:36,236 --> 00:08:39,385 A:middle
to see what developers
come up with to use that.

201
00:08:42,196 --> 00:08:43,736 A:middle
Another thing we
have brought now

202
00:08:43,736 --> 00:08:46,216 A:middle
with our unified implementation
of Core Image is now

203
00:08:46,216 --> 00:08:48,436 A:middle
on iOS we have the
great functionality

204
00:08:48,436 --> 00:08:49,876 A:middle
of automatic color management.

205
00:08:50,146 --> 00:08:53,256 A:middle
This has been available on
OS X ever since the beginning

206
00:08:53,256 --> 00:08:56,476 A:middle
of Core Image, but now we
have this on iOS as well.

207
00:08:57,096 --> 00:09:01,266 A:middle
What this means is that Core
Image now supports ICC-based

208

209
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

210
00:08:57,096 --> 00:09:01,266 A:middle
What this means is that Core
Image now supports ICC-based

211
00:09:02,396 --> 00:09:04,936 A:middle
CGColorSpaceRefs fully.

212
00:09:05,846 --> 00:09:09,236 A:middle
And these can be used on input
images or output images or even

213
00:09:09,236 --> 00:09:10,656 A:middle
as a working space
in Core Image.

214
00:09:11,856 --> 00:09:14,056 A:middle
This is through great
work that's been done

215
00:09:14,356 --> 00:09:19,466 A:middle
to support ColorSync
on iOS as well.

216
00:09:21,066 --> 00:09:22,176 A:middle
What this means to users is

217
00:09:22,176 --> 00:09:25,406 A:middle
that automatically you will
get correct rendering of TIFFs

218
00:09:25,406 --> 00:09:27,756 A:middle
or JPGs that are tagged
with color spaces.

219
00:09:28,426 --> 00:09:29,826 A:middle
Many images are tagged with sRGB

220
00:09:29,826 --> 00:09:34,086 A:middle
and those have been rendered
correctly on previous versions

221
00:09:34,126 --> 00:09:38,976 A:middle
of iOS, but now if you have an
image tagged with a color space

222
00:09:39,156 --> 00:09:41,126 A:middle
that is not sRGB, you
get the correct behavior.

223
00:09:41,526 --> 00:09:43,766 A:middle
Here is an example
of an image tagged

224
00:09:43,766 --> 00:09:45,076 A:middle
with the Pro Photo color space.

225
00:09:45,076 --> 00:09:48,586 A:middle
The red bench in the
background is desaturated,

226
00:09:48,586 --> 00:09:50,186 A:middle
and skin tones look poor.

227
00:09:50,686 --> 00:09:56,296 A:middle
When you correctly see the
embedded ICC profile on this,

228
00:09:56,456 --> 00:09:57,686 A:middle
the image is rendered correctly.

229
00:09:58,856 --> 00:10:03,936 A:middle
And this you get
automatically in Core Image.

230

231
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

232
00:09:58,856 --> 00:10:03,936 A:middle
And this you get
automatically in Core Image.

233
00:10:04,086 --> 00:10:07,766 A:middle
We also have some new
support for CI kernel classes

234
00:10:07,766 --> 00:10:09,406 A:middle
that is now available on OS X

235
00:10:09,406 --> 00:10:11,146 A:middle
like it has been
on iOS in the past.

236
00:10:11,196 --> 00:10:13,446 A:middle
This is another benefit of
our unified implementation.

237
00:10:14,626 --> 00:10:17,866 A:middle
For example, we have two
classes called CI color kernel

238
00:10:17,866 --> 00:10:19,026 A:middle
and CI warp kernels.

239
00:10:19,336 --> 00:10:22,096 A:middle
The idea behind these classes is
to make it much easier for you

240
00:10:22,096 --> 00:10:23,956 A:middle
to write the most
common basic filters.

241
00:10:24,806 --> 00:10:26,526 A:middle
Traditionally on
OS X, if you wanted

242
00:10:26,526 --> 00:10:27,916 A:middle
to write a simple blend filter

243
00:10:27,986 --> 00:10:32,306 A:middle
to blend three images given
a mask, you would have

244
00:10:32,786 --> 00:10:34,466 A:middle
to write several lines
of code to sample

245
00:10:34,826 --> 00:10:37,966 A:middle
from the sampler correctly,
and then you would do the math

246
00:10:38,576 --> 00:10:39,796 A:middle
to combine the three images.

247
00:10:40,736 --> 00:10:42,606 A:middle
If you use CI color
kernel classes,

248
00:10:43,006 --> 00:10:44,246 A:middle
the code becomes much simpler.

249
00:10:44,786 --> 00:10:48,386 A:middle
So now the input to the kernel
is a sampler, underscore,

250
00:10:48,386 --> 00:10:51,306 A:middle
underscore sample
parameter, and the code

251
00:10:51,306 --> 00:10:54,266 A:middle
for the kernel is just the math
for mixing the three results.

252
00:10:54,806 --> 00:10:56,766 A:middle
So this is a great
thing for developers.

253
00:10:56,766 --> 00:10:57,456 A:middle
It makes it easier.

254
00:10:57,456 --> 00:11:01,336 A:middle
It also makes the job for
Core Image easier to simplify

255

256
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

257
00:10:57,456 --> 00:11:01,336 A:middle
It also makes the job for
Core Image easier to simplify

258
00:11:01,906 --> 00:11:04,036 A:middle
and concatenate programs.

259
00:11:07,146 --> 00:11:09,096 A:middle
We also have a lot
of improvements

260
00:11:09,096 --> 00:11:12,006 A:middle
to the CI kernel language
are available on OS X.

261
00:11:12,596 --> 00:11:16,086 A:middle
Our unified implementation when
we compile CI kernel language

262
00:11:16,086 --> 00:11:18,976 A:middle
into the destination
context language,

263
00:11:19,916 --> 00:11:22,356 A:middle
we do that using LLVM
technology at Apple.

264
00:11:22,406 --> 00:11:26,776 A:middle
And what this this has given us
is new features in our language,

265
00:11:27,376 --> 00:11:30,226 A:middle
such as If, For, and While, that
were not previously available.

266
00:11:31,456 --> 00:11:33,696 A:middle
CI kernels in existing
apps should work fine.

267
00:11:34,096 --> 00:11:36,616 A:middle
However, with the new compiler
we have stricter warnings

268
00:11:36,616 --> 00:11:39,596 A:middle
so if your app is linked
against El Capitan or later,

269
00:11:40,396 --> 00:11:42,306 A:middle
keep a look out for
any compiler warnings.

270
00:11:42,966 --> 00:11:47,256 A:middle
As an example of this, here is
a simple example of a kernel

271
00:11:47,256 --> 00:11:51,406 A:middle
that wasn't possible before,
on OS X using kernel language,

272
00:11:51,766 --> 00:11:54,536 A:middle
and that's because this
particular filter has an input

273
00:11:54,536 --> 00:11:55,926 A:middle
parameter, which is a count.

274
00:11:56,566 --> 00:11:58,646 A:middle
And we want to have a For
loop inside this kernel

275
00:11:58,946 --> 00:12:00,676 A:middle
that loops based on
that count variable.

276

277
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

278
00:11:58,946 --> 00:12:00,676 A:middle
that loops based on
that count variable.

279
00:12:01,466 --> 00:12:03,546 A:middle
In this particular
example, we're trying

280
00:12:03,546 --> 00:12:06,026 A:middle
to do a motion blur along
a vector for n points.

281
00:12:06,636 --> 00:12:08,526 A:middle
And this is now a
trivial kernel to write.

282
00:12:09,446 --> 00:12:12,336 A:middle
You can get fancier,
and you can have a

283
00:12:12,336 --> 00:12:13,766 A:middle
For loop with an early exit.

284
00:12:14,596 --> 00:12:17,346 A:middle
In this case, we are sampling
from that image until we get

285
00:12:17,346 --> 00:12:21,566 A:middle
to an area of the image that is
not opaque, and then we break

286
00:12:21,566 --> 00:12:24,756 A:middle
out of the For loop and
return the average color

287
00:12:24,756 --> 00:12:29,756 A:middle
of only the colors
that are in the image.

288
00:12:29,916 --> 00:12:32,306 A:middle
So one thing to keep in mind is

289
00:12:32,306 --> 00:12:34,256 A:middle
with our kernel language is
what are our overall goals

290
00:12:34,256 --> 00:12:35,046 A:middle
of this language are.

291
00:12:35,476 --> 00:12:38,566 A:middle
What we want to do is enable
you to write kernels once

292
00:12:38,566 --> 00:12:42,766 A:middle
and have them run
regardless of the device

293
00:12:42,766 --> 00:12:44,046 A:middle
that your kernels
are running on.

294
00:12:44,546 --> 00:12:46,866 A:middle
So it will run independent of
what system you are running on,

295
00:12:46,866 --> 00:12:50,836 A:middle
whether iOS or OS X, what
size your input image is.

296
00:12:51,156 --> 00:12:54,916 A:middle
The CI kernel language has
support for destination core

297
00:12:54,916 --> 00:12:57,536 A:middle
to sampler transforms so we
can support automatic tiling

298
00:12:57,536 --> 00:12:58,086 A:middle
of images.

299
00:12:58,696 --> 00:13:02,136 A:middle
And the CI kernel
language works independent

300

301
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

302
00:12:58,696 --> 00:13:02,136 A:middle
And the CI kernel
language works independent

303
00:13:02,186 --> 00:13:03,656 A:middle
of what our back-end
renderer is,

304
00:13:03,906 --> 00:13:07,176 A:middle
so whether we are using
Metal, or OpenCL, or OpenGL,

305
00:13:07,176 --> 00:13:10,436 A:middle
or OpenGL ES, you can
write your algorithms

306
00:13:10,606 --> 00:13:11,986 A:middle
in the CI kernel language once.

307
00:13:16,056 --> 00:13:18,066 A:middle
So that's the highlights
of what's new

308
00:13:18,066 --> 00:13:19,366 A:middle
in Core Image this year.

309
00:13:20,056 --> 00:13:22,096 A:middle
The next subject we would
like to talk about is how

310
00:13:22,096 --> 00:13:23,856 A:middle
to bridge Core Image
with other frameworks.

311
00:13:24,056 --> 00:13:26,016 A:middle
Specifically, some of the wealth

312
00:13:26,016 --> 00:13:28,086 A:middle
of other great graphics
frameworks available

313
00:13:28,086 --> 00:13:28,746 A:middle
on our platform.

314
00:13:30,406 --> 00:13:35,236 A:middle
We have great imaging
frameworks on our platform

315
00:13:35,236 --> 00:13:39,276 A:middle
such as Core Animation,
SceneKit, SpriteKit, Metal,

316
00:13:39,746 --> 00:13:43,816 A:middle
AV Foundation, IOSurfaces,
and various View classes.

317
00:13:44,306 --> 00:13:46,046 A:middle
We spent a lot of
time this year trying

318
00:13:46,046 --> 00:13:49,656 A:middle
to make these work right
together with Core Image.

319
00:13:49,996 --> 00:13:51,806 A:middle
So to start that discussion,

320
00:13:51,926 --> 00:13:55,126 A:middle
I would like to introduce
Tony Chu, who will be talking

321
00:13:55,126 --> 00:13:56,916 A:middle
about Core Image and
Metal in more detail.

322
00:13:58,516 --> 00:14:04,606 A:middle
[ Applause ]

323

324
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

325
00:13:58,516 --> 00:14:04,606 A:middle
[ Applause ]

326
00:14:05,106 --> 00:14:05,726 A:middle
>> TONY CHU: Thank you, David.

327
00:14:06,106 --> 00:14:08,756 A:middle
Good morning, my name
is Tony and I would

328
00:14:08,756 --> 00:14:10,866 A:middle
like to first tell you
about a little bit more

329
00:14:10,866 --> 00:14:12,176 A:middle
about Core Image and Metal.

330
00:14:12,176 --> 00:14:17,156 A:middle
So as David mentioned earlier,
this year we have added support

331
00:14:17,156 --> 00:14:18,886 A:middle
for rendering with
Metal in Core Image,

332
00:14:19,386 --> 00:14:21,906 A:middle
and one of the reasons
we did that is to add

333
00:14:21,906 --> 00:14:24,266 A:middle
to our extensive suite
of supported image types

334
00:14:24,746 --> 00:14:28,446 A:middle
such as IOSurface and CGImag,e
all of which can be used

335
00:14:28,446 --> 00:14:32,226 A:middle
as inputs or outputs to a CI
filter regardless of the type

336
00:14:32,226 --> 00:14:33,246 A:middle
of CIContext you have.

337
00:14:34,116 --> 00:14:37,746 A:middle
But if you have an OpenGL-based
CIContext, you can also render

338
00:14:37,746 --> 00:14:39,646 A:middle
to and from OpenGL textures.

339
00:14:40,986 --> 00:14:43,636 A:middle
And now this year if you
have a Metal-based CIContext,

340
00:14:43,876 --> 00:14:45,916 A:middle
you can also render to
and from Metal Textures.

341
00:14:46,656 --> 00:14:48,996 A:middle
Previously, without this
support you would have had

342
00:14:48,996 --> 00:14:51,696 A:middle
to convert a Metal Texture to
one of the existing image types,

343
00:14:52,166 --> 00:14:55,366 A:middle
which would have likely
incurred an expensive data copy

344
00:14:55,366 --> 00:14:56,906 A:middle
between the CPU and GPU.

345
00:14:57,556 --> 00:14:59,496 A:middle
With proper support
we can render to

346
00:14:59,496 --> 00:15:01,276 A:middle
and from these resources
very efficiently.

347

348
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

349
00:14:59,496 --> 00:15:01,276 A:middle
and from these resources
very efficiently.

350
00:15:01,786 --> 00:15:06,246 A:middle
Let's take a look at some of
the new APIs we have available

351
00:15:06,246 --> 00:15:08,176 A:middle
for Metal support in Core Image.

352
00:15:09,016 --> 00:15:12,546 A:middle
The first is an API that allows
you to initialize a CI image

353
00:15:12,916 --> 00:15:18,126 A:middle
with an input Metal Texture as
well as an optional dictionary

354
00:15:18,126 --> 00:15:20,546 A:middle
where you can specify things
such as the color space

355
00:15:21,116 --> 00:15:22,576 A:middle
that that texture
it tagged with.

356
00:15:23,216 --> 00:15:25,096 A:middle
That's an example of
one of the advantages

357
00:15:25,096 --> 00:15:27,426 A:middle
of using a higher-level
framework, such as Core Image,

358
00:15:27,826 --> 00:15:29,226 A:middle
is that it will take
care of details

359
00:15:29,226 --> 00:15:32,016 A:middle
such as color management
automatically for you.

360
00:15:33,936 --> 00:15:35,706 A:middle
Then, in order to do rendering

361
00:15:35,706 --> 00:15:37,986 A:middle
with these Metal-based
resources, you will want

362
00:15:37,986 --> 00:15:41,836 A:middle
to create a new CIContext that
is a Metal-based CIContext

363
00:15:42,166 --> 00:15:45,066 A:middle
by giving it the Metal device
your application is using.

364
00:15:45,066 --> 00:15:49,286 A:middle
And, again, you can specify an
options dictionary for things

365
00:15:49,286 --> 00:15:52,896 A:middle
such as working color
space or working floor mat

366
00:15:52,896 --> 00:15:56,886 A:middle
for intermediate buffers or
even, you can even declare

367
00:15:56,886 --> 00:16:03,336 A:middle
that you want to use
a low-priority GPU.

368

369
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

370
00:15:56,886 --> 00:16:03,336 A:middle
that you want to use
a low-priority GPU.

371
00:16:03,546 --> 00:16:06,636 A:middle
In any case, with this
new Metal-based CIContext,

372
00:16:06,816 --> 00:16:09,736 A:middle
we have the new render
API that allows you

373
00:16:09,736 --> 00:16:12,966 A:middle
to render any CI image to
an output Metal Texture.

374
00:16:14,006 --> 00:16:15,786 A:middle
And one of the nice
features I want to call

375
00:16:15,786 --> 00:16:17,826 A:middle
out about this API
is the ability

376
00:16:17,826 --> 00:16:19,586 A:middle
to specify optional
command buffer.

377
00:16:21,126 --> 00:16:23,816 A:middle
If you want things nice and
simple, you can specify nil

378
00:16:23,816 --> 00:16:26,736 A:middle
and in that case Core Image
will create one internally

379
00:16:27,286 --> 00:16:29,126 A:middle
and code all the
necessary commands to it

380
00:16:29,126 --> 00:16:31,076 A:middle
and then commit it
before returning,

381
00:16:31,666 --> 00:16:33,056 A:middle
which will then effectively
schedule

382
00:16:33,056 --> 00:16:34,646 A:middle
that render call on the GPU.

383
00:16:35,166 --> 00:16:39,266 A:middle
But you can also provide a
command buffer to that call,

384
00:16:39,266 --> 00:16:42,596 A:middle
and in that case Core Image will
merely encode commands to it

385
00:16:42,916 --> 00:16:44,876 A:middle
and return without
committing it.

386
00:16:45,366 --> 00:16:48,406 A:middle
What that gives you is full
control on how you want

387
00:16:48,406 --> 00:16:53,486 A:middle
to schedule your command buffer
for rendering on the GPU as well

388
00:16:53,486 --> 00:16:56,486 A:middle
as the flexibility to
insert CI filters anywhere

389
00:16:56,486 --> 00:16:57,446 A:middle
into a command buffer.

390
00:16:57,586 --> 00:17:00,886 A:middle
So let me explain that in
a little bit more detail.

391

392
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

393
00:16:57,586 --> 00:17:00,886 A:middle
So let me explain that in
a little bit more detail.

394
00:17:00,886 --> 00:17:03,376 A:middle
For those who are new to Metal,

395
00:17:03,376 --> 00:17:05,976 A:middle
rendering with Metal basically
involves encoding a series

396
00:17:05,976 --> 00:17:07,726 A:middle
of render commands
to a command buffer.

397
00:17:08,576 --> 00:17:10,715 A:middle
In this case, we have
two sets of commands.

398
00:17:10,715 --> 00:17:16,185 A:middle
And with that new API that we
just saw, you can now insert

399
00:17:16,185 --> 00:17:19,736 A:middle
that CI filter anywhere into
this command buffer such as

400
00:17:19,736 --> 00:17:23,886 A:middle
at the very beginning or at
the very end, or even right

401
00:17:24,106 --> 00:17:26,156 A:middle
in the very middle between
these two render commands.

402
00:17:26,856 --> 00:17:29,156 A:middle
So you can imagine this might
be a situation where you want

403
00:17:29,156 --> 00:17:32,206 A:middle
to do some draw, cause,
and render to some texture

404
00:17:32,206 --> 00:17:35,656 A:middle
and then feed the texture
into a series of CI filters,

405
00:17:36,696 --> 00:17:38,176 A:middle
generate some output
texture from that,

406
00:17:38,176 --> 00:17:40,106 A:middle
and do more rendering with it.

407
00:17:42,016 --> 00:17:46,116 A:middle
And internally, Core Image will
then encode all the commands

408
00:17:46,256 --> 00:17:48,466 A:middle
for each filter you may
have in your image graph.

409
00:17:49,046 --> 00:17:52,306 A:middle
And in fact, as David
mentioned earlier,

410
00:17:52,796 --> 00:17:55,096 A:middle
some of our built-in filters
will use Metal performance

411
00:17:55,096 --> 00:17:56,586 A:middle
shaders to take advantage

412
00:17:56,586 --> 00:17:59,516 A:middle
of these highly optimized
shaders specifically tuned

413
00:17:59,516 --> 00:18:00,766 A:middle
for Metal-capable devices.

414

415
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

416
00:17:59,516 --> 00:18:00,766 A:middle
for Metal-capable devices.

417
00:18:01,436 --> 00:18:06,346 A:middle
And lastly, I want to
mention that this type

418
00:18:06,346 --> 00:18:09,116 A:middle
of calling convention lends
itself perfectly to be able

419
00:18:09,116 --> 00:18:12,006 A:middle
to use CI to render
directly to a MetalKit view.

420
00:18:12,566 --> 00:18:15,176 A:middle
So to explain that further,

421
00:18:15,176 --> 00:18:16,616 A:middle
I would like to show
you sample code.

422
00:18:17,926 --> 00:18:20,656 A:middle
So this is sample code that you
would have to write if you were

423
00:18:20,656 --> 00:18:23,256 A:middle
to create a new application
based

424
00:18:23,256 --> 00:18:25,406 A:middle
on the new MetalKit framework.

425
00:18:26,216 --> 00:18:28,746 A:middle
The first thing you need to
do is to do a couple of things

426
00:18:28,906 --> 00:18:30,646 A:middle
in this when you want
to set up the view.

427
00:18:31,516 --> 00:18:32,866 A:middle
The first key thing is

428
00:18:33,296 --> 00:18:37,136 A:middle
to specify the Frame Buffer Only
property on that view to False,

429
00:18:37,646 --> 00:18:40,146 A:middle
which will allow Core Image
to use Metal compute shaders

430
00:18:40,176 --> 00:18:42,316 A:middle
to render to that
view's output texture.

431
00:18:42,746 --> 00:18:47,476 A:middle
The next thing you want to do
is initialize the CIContext

432
00:18:47,476 --> 00:18:48,196 A:middle
with a Metal device.

433
00:18:48,806 --> 00:18:51,656 A:middle
You want to do that here because
initializing a CIContext is

434
00:18:51,656 --> 00:18:53,936 A:middle
something you only want to
do once in an application.

435
00:18:56,616 --> 00:18:59,436 A:middle
Then, in the Draw and
View Delegate function,

436
00:18:59,946 --> 00:19:01,936 A:middle
this is the code you would
need to write in order

437

438
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

439
00:18:59,946 --> 00:19:01,936 A:middle
this is the code you would
need to write in order

440
00:19:01,936 --> 00:19:03,546 A:middle
to render some CI
filters through that view.

441
00:19:03,796 --> 00:19:05,716 A:middle
So let me step you
through this line by line.

442
00:19:06,706 --> 00:19:08,686 A:middle
First thing is, you
create a command buffer

443
00:19:08,686 --> 00:19:11,446 A:middle
that will eventually be used
to present the drawable with.

444
00:19:11,446 --> 00:19:16,196 A:middle
Then we are going to
initialize a CI image

445
00:19:16,286 --> 00:19:18,336 A:middle
with some given input
Metal Texture.

446
00:19:18,656 --> 00:19:22,686 A:middle
Now, this CI image could come
by other means, for example,

447
00:19:22,686 --> 00:19:25,116 A:middle
some of the other image types
we have, like a CGImage.

448
00:19:25,116 --> 00:19:28,956 A:middle
But in this case we will just
show you how to use our new API.

449
00:19:28,956 --> 00:19:32,096 A:middle
But then once you
have a CI image,

450
00:19:32,206 --> 00:19:36,276 A:middle
you can chain together a
series of CI filters to it.

451
00:19:36,276 --> 00:19:39,456 A:middle
In this case, we will apply
a CI Gaussian Blur filter.

452
00:19:41,856 --> 00:19:44,986 A:middle
Then, once you have your CI
image that you want to render,

453
00:19:45,496 --> 00:19:48,596 A:middle
you want to grab the
texture currently bound

454
00:19:48,636 --> 00:19:52,666 A:middle
to that view's current
drawable and render the CI image

455
00:19:52,746 --> 00:19:56,226 A:middle
to that texture with the command
buffer we want to use here.

456
00:19:57,856 --> 00:20:00,236 A:middle
Then finally, once we have
encoded the render commands

457

458
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

459
00:19:57,856 --> 00:20:00,236 A:middle
Then finally, once we have
encoded the render commands

460
00:20:00,236 --> 00:20:02,716 A:middle
there is one more Metal
command that you need to insert

461
00:20:02,716 --> 00:20:03,496 A:middle
at the command buffer,

462
00:20:03,756 --> 00:20:05,826 A:middle
and that's to present the
view's current drawable.

463
00:20:05,826 --> 00:20:08,326 A:middle
And then you just call
Commit on that buffer.

464
00:20:09,676 --> 00:20:11,096 A:middle
That is how easy it is

465
00:20:11,096 --> 00:20:13,076 A:middle
to integrate some
Core Image filters

466
00:20:13,226 --> 00:20:14,816 A:middle
into a MetalKit application.

467
00:20:14,816 --> 00:20:19,996 A:middle
So next I would like to talk

468
00:20:19,996 --> 00:20:22,286 A:middle
about bridging Core
Image and AV Foundation.

469
00:20:22,906 --> 00:20:26,946 A:middle
So with the latest changes
we have this year in both

470
00:20:26,946 --> 00:20:30,666 A:middle
of these frameworks, it is now
easy to add Core Image filters

471
00:20:30,666 --> 00:20:31,876 A:middle
to your AV Foundation app,

472
00:20:32,936 --> 00:20:35,836 A:middle
and that's because Core Image
is now conveniently integrated

473
00:20:36,036 --> 00:20:38,106 A:middle
with the AVVideoComposition
class.

474
00:20:38,786 --> 00:20:42,276 A:middle
And by default you would get
automatic color management,

475
00:20:42,276 --> 00:20:44,926 A:middle
but if you don't need
it, you can disable it.

476
00:20:46,036 --> 00:20:48,716 A:middle
So we will take a look at
a couple of examples on how

477
00:20:48,716 --> 00:20:50,346 A:middle
to apply CI filters to videos.

478
00:20:50,916 --> 00:20:52,706 A:middle
First in the context
of exporting the video

479
00:20:52,776 --> 00:20:54,846 A:middle
and next during live
playback of a video.

480
00:20:55,426 --> 00:20:59,916 A:middle
So for the purpose of
demonstrating these examples,

481

482
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

483
00:21:00,096 --> 00:21:01,366 A:middle
we are going to use a filter

484
00:21:01,366 --> 00:21:03,566 A:middle
that we showed you a
couple of years ago at WWDC.

485
00:21:03,566 --> 00:21:08,066 A:middle
And this is a filter where for
every frame of the video image,

486
00:21:08,066 --> 00:21:12,866 A:middle
we are going to first apply a
sepia tone filter to it along

487
00:21:12,866 --> 00:21:19,126 A:middle
with some random noise, and then
finally some vertical scratches

488
00:21:19,126 --> 00:21:21,906 A:middle
overlaid on top of it.

489
00:21:21,906 --> 00:21:27,756 A:middle
For those who may recall,
this is the old film filter

490
00:21:28,346 --> 00:21:31,586 A:middle
that we showed you from a
couple of years ago at WWDC.

491
00:21:31,736 --> 00:21:34,186 A:middle
This filter is very
straightforward,

492
00:21:34,186 --> 00:21:37,746 A:middle
all it takes is a single
input image as well

493
00:21:37,746 --> 00:21:39,866 A:middle
as an input time parameter,
which will allow you

494
00:21:39,866 --> 00:21:42,656 A:middle
to apply the effect to the
video in a repeatable way

495
00:21:42,946 --> 00:21:44,166 A:middle
with deterministic results.

496
00:21:44,886 --> 00:21:49,896 A:middle
So let's get back to how we
would apply this filter during

497
00:21:49,896 --> 00:21:50,876 A:middle
exporting of that video.

498
00:21:52,266 --> 00:21:55,246 A:middle
What you need to do first is
create a filtered composition,

499
00:21:55,866 --> 00:21:59,796 A:middle
giving it the AV asset that
you want to export as well

500
00:21:59,796 --> 00:22:04,666 A:middle
as a callback block in which
you can specify a filter recipe

501

502
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

503
00:21:59,796 --> 00:22:04,666 A:middle
as a callback block in which
you can specify a filter recipe

504
00:22:05,196 --> 00:22:09,586 A:middle
to be applied as each frame of
the video is being rendered.

505
00:22:10,486 --> 00:22:13,246 A:middle
And from this callback block,
we will get a request object

506
00:22:13,246 --> 00:22:16,326 A:middle
as an input parameter from which
you can get the composition time

507
00:22:16,696 --> 00:22:18,076 A:middle
as well as the source image

508
00:22:18,306 --> 00:22:20,396 A:middle
for chaining together
your CI filters.

509
00:22:21,036 --> 00:22:26,006 A:middle
And then once you have
your filtered CI image,

510
00:22:26,396 --> 00:22:28,836 A:middle
you then call Finish With
Image on the request object.

511
00:22:29,456 --> 00:22:31,816 A:middle
You can pass in a nil
context to that call,

512
00:22:32,186 --> 00:22:36,646 A:middle
and the AVVideoComposition would
create a CIContext by default,

513
00:22:37,326 --> 00:22:38,476 A:middle
which, as I mentioned earlier,

514
00:22:38,476 --> 00:22:40,016 A:middle
will get automatic
color management.

515
00:22:41,006 --> 00:22:42,776 A:middle
If you want to disable
that, all you need

516
00:22:42,776 --> 00:22:44,736 A:middle
to do is create a
CIContext on your own

517
00:22:44,736 --> 00:22:48,746 A:middle
and specify a null color
working space and pass that into

518
00:22:48,746 --> 00:22:50,446 A:middle
that Finish With Image call.

519
00:22:50,986 --> 00:22:57,106 A:middle
Now, that filter we just showed
you is a pretty simple filter

520
00:22:57,676 --> 00:23:00,446 A:middle
that has no convolution
filters involved.

521

522
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

523
00:22:57,676 --> 00:23:00,446 A:middle
that has no convolution
filters involved.

524
00:23:00,996 --> 00:23:03,226 A:middle
But in the case where you
do have convolution filters,

525
00:23:03,546 --> 00:23:07,456 A:middle
one thing you want to watch out
for is an undesirable result

526
00:23:08,006 --> 00:23:11,056 A:middle
where you get clear
pixels bleeding

527
00:23:11,056 --> 00:23:12,806 A:middle
into the edges of that image.

528
00:23:13,816 --> 00:23:17,346 A:middle
To fix that, we have a pretty
simple recipe that we use

529
00:23:17,576 --> 00:23:19,436 A:middle
in a lot of cases
such as that one.

530
00:23:20,396 --> 00:23:23,486 A:middle
The first thing you want to
do is with the source image

531
00:23:23,486 --> 00:23:26,026 A:middle
that you have, that you want
to apply the convolution filter

532
00:23:26,026 --> 00:23:28,676 A:middle
to it, you want to call
image by clamping to extent.

533
00:23:28,676 --> 00:23:32,926 A:middle
It will edge replicate all
of the pixels along the edge

534
00:23:32,926 --> 00:23:34,306 A:middle
of that image to infinity.

535
00:23:34,306 --> 00:23:37,726 A:middle
And by doing that, you will
no longer have the problem

536
00:23:37,726 --> 00:23:42,056 A:middle
of clear pixels bleeding
into the image

537
00:23:42,056 --> 00:23:44,446 A:middle
as you are applying the filter.

538
00:23:44,586 --> 00:23:47,436 A:middle
Because by doing that you end
up with an infinite image,

539
00:23:47,806 --> 00:23:51,486 A:middle
at the very end of applying the
filter you want to add image

540
00:23:51,486 --> 00:23:54,176 A:middle
by cropping the rect in
order to crop that image back

541
00:23:54,176 --> 00:23:55,636 A:middle
into the source image's extent.

542
00:23:57,256 --> 00:24:01,626 A:middle
By applying that simple recipe,
you will get a much cleaner look

543

544
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

545
00:23:57,256 --> 00:24:01,626 A:middle
By applying that simple recipe,
you will get a much cleaner look

546
00:24:02,056 --> 00:24:08,556 A:middle
with nice, crisp, sharp
borders on the edge.

547
00:24:08,766 --> 00:24:11,126 A:middle
So once we have that
AVVideoComposition,

548
00:24:12,106 --> 00:24:15,636 A:middle
if we want to create an
export session in order

549
00:24:15,636 --> 00:24:17,996 A:middle
to export a video, and you do

550
00:24:17,996 --> 00:24:19,916 A:middle
that by creating this
AV export session

551
00:24:19,946 --> 00:24:23,746 A:middle
and specify an output URL
location to which you want

552
00:24:23,746 --> 00:24:26,266 A:middle
to export as well as
the video composition

553
00:24:26,266 --> 00:24:27,106 A:middle
that we just created.

554
00:24:28,156 --> 00:24:30,316 A:middle
And one thing to keep in
mind is you might want to --

555
00:24:31,016 --> 00:24:34,286 A:middle
you want to call Remove Item
at URL to remove any item

556
00:24:34,286 --> 00:24:36,366 A:middle
that might already exist
at that output location.

557
00:24:37,226 --> 00:24:38,156 A:middle
Once you have done that,

558
00:24:38,156 --> 00:24:40,426 A:middle
then you can call
Export Asynchronously

559
00:24:40,426 --> 00:24:43,486 A:middle
on that export session, which
will then kick off a process

560
00:24:44,216 --> 00:24:47,976 A:middle
to export that video and
apply all of the CI filters

561
00:24:48,016 --> 00:24:49,486 A:middle
to every single frame
of your video.

562
00:24:50,376 --> 00:24:53,376 A:middle
If you wanted to update
some progress on your UI

563
00:24:53,376 --> 00:24:56,296 A:middle
to show the progress
of that export,

564
00:24:56,516 --> 00:24:59,876 A:middle
you can use the Composition Time
parameter in your callback block

565

566
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

567
00:25:00,016 --> 00:25:01,936 A:middle
to update such a UI element.

568
00:25:06,046 --> 00:25:07,836 A:middle
So now that was exporting.

569
00:25:08,156 --> 00:25:11,116 A:middle
For playing back an AV asset,
the code that you would need

570
00:25:11,116 --> 00:25:12,886 A:middle
to write is actually
very similar.

571
00:25:13,316 --> 00:25:16,126 A:middle
Creating the video composition
is exactly the same code we

572
00:25:16,126 --> 00:25:16,736 A:middle
saw earlier.

573
00:25:17,466 --> 00:25:19,976 A:middle
The only difference
now is instead

574
00:25:20,016 --> 00:25:21,296 A:middle
of creating an export session,

575
00:25:21,726 --> 00:25:23,376 A:middle
you need to create
an AVPlayerItem

576
00:25:23,456 --> 00:25:25,316 A:middle
with that AV asset along

577
00:25:25,316 --> 00:25:27,476 A:middle
with the video composition
we just created

578
00:25:28,396 --> 00:25:30,866 A:middle
and then create an AVPlayer
with that player item

579
00:25:30,866 --> 00:25:33,116 A:middle
and then call Play
on your player.

580
00:25:33,726 --> 00:25:39,716 A:middle
So I'm going to now show you
a video of how we are applying

581
00:25:39,716 --> 00:25:44,386 A:middle
that old film filter to an
AV asset during playback.

582
00:25:48,146 --> 00:25:50,006 A:middle
So one thing to notice here is

583
00:25:50,006 --> 00:25:51,706 A:middle
as you are scrubbing
back this video,

584
00:25:51,986 --> 00:25:53,986 A:middle
you can see the same
effect being applied

585
00:25:53,986 --> 00:25:56,996 A:middle
in a repeatable way with
deterministic results.

586
00:25:58,016 --> 00:25:59,466 A:middle
So that is Core Image

587
00:25:59,466 --> 00:26:02,726 A:middle
and AV Foundation interoperating
together very efficiently.

588

589
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

590
00:25:59,466 --> 00:26:02,726 A:middle
and AV Foundation interoperating
together very efficiently.

591
00:26:03,216 --> 00:26:07,256 A:middle
Next, I would like
to call up Alex

592
00:26:07,256 --> 00:26:09,266 A:middle
to tell you a little bit more
about Core Image providers.

593
00:26:09,896 --> 00:26:10,126 A:middle
Thank you.

594
00:26:11,516 --> 00:26:14,996 A:middle
[ Applause ]

595
00:26:15,496 --> 00:26:15,916 A:middle
>> ALEXANDRE NAAMAN:
Thank you, Tony.

596
00:26:17,236 --> 00:26:19,906 A:middle
My name is Alexandre
Naaman and I will talk

597
00:26:19,906 --> 00:26:21,446 A:middle
about Core Image providers
and then we will talk

598
00:26:21,446 --> 00:26:24,136 A:middle
about more APIs we have
on the system and STKs

599
00:26:24,136 --> 00:26:26,116 A:middle
and how they can
work with Core Image

600
00:26:26,366 --> 00:26:27,796 A:middle
to create interesting
applications.

601
00:26:29,486 --> 00:26:31,286 A:middle
Let's start with
CIImageProvider,

602
00:26:31,626 --> 00:26:33,706 A:middle
which is a category
we had on CI image

603
00:26:33,706 --> 00:26:37,616 A:middle
that existed previously just on
OS X but now exists also on iOS

604
00:26:37,686 --> 00:26:39,896 A:middle
as part of our unified
implementation.

605
00:26:40,406 --> 00:26:44,246 A:middle
It's a great way for you
to bring input images

606
00:26:44,246 --> 00:26:48,186 A:middle
into your system that wouldn't
be able to be done otherwise.

607
00:26:48,186 --> 00:26:50,996 A:middle
So, for example, if
you had a file format

608
00:26:50,996 --> 00:26:52,256 A:middle
that wasn't supported
and you wanted

609
00:26:52,256 --> 00:26:55,006 A:middle
to somehow create a CI image
that was based on that,

610
00:26:55,676 --> 00:26:58,546 A:middle
or if you had data that was
streaming from some site

611
00:26:58,546 --> 00:27:01,006 A:middle
and you wanted to
create a CI image,

612

613
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

614
00:26:58,546 --> 00:27:01,006 A:middle
and you wanted to
create a CI image,

615
00:27:01,006 --> 00:27:02,206 A:middle
you could use a CIImageProvider.

616
00:27:03,336 --> 00:27:05,286 A:middle
They are implemented
via callbacks.

617
00:27:06,176 --> 00:27:10,336 A:middle
It's all done lazily, and we
will call you and tell you

618
00:27:10,336 --> 00:27:13,486 A:middle
when we need to fill in the data
and you get automatic tiling

619
00:27:13,486 --> 00:27:15,956 A:middle
and we handle the purgability
and caching for you.

620
00:27:16,706 --> 00:27:19,416 A:middle
Let's take a look
at how this is done.

621
00:27:19,416 --> 00:27:20,976 A:middle
First things first, you
will create your own class.

622
00:27:20,976 --> 00:27:23,516 A:middle
In this case, we will create
one called tile provider.

623
00:27:24,686 --> 00:27:27,456 A:middle
And then we create a CI image
with that tile provider,

624
00:27:27,926 --> 00:27:30,446 A:middle
and in addition to that,
we give it the size

625
00:27:30,666 --> 00:27:33,466 A:middle
of the image we are trying to
create, whatever format we would

626
00:27:33,466 --> 00:27:37,066 A:middle
like to use to create for this
image, a color space optionally,

627
00:27:37,346 --> 00:27:40,226 A:middle
and in this case we
will give the tile size

628
00:27:40,226 --> 00:27:42,786 A:middle
in the options dictionary.

629
00:27:44,466 --> 00:27:45,866 A:middle
Now, in order to use this,

630
00:27:46,846 --> 00:27:50,016 A:middle
all we have to do is implement
a method called Provide Image

631
00:27:50,016 --> 00:27:52,476 A:middle
Data, and Core Image
will call you and ask you

632
00:27:52,476 --> 00:27:53,846 A:middle
to fill in this information.

633
00:27:55,066 --> 00:27:56,976 A:middle
And you have to fill
in that data pointer

634
00:27:57,216 --> 00:28:01,616 A:middle
with a given row bytes value,
a certain location in X and Y,

635

636
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

637
00:27:57,216 --> 00:28:01,616 A:middle
with a given row bytes value,
a certain location in X and Y,

638
00:28:01,726 --> 00:28:04,216 A:middle
width and height, and you
can tag some user info

639
00:28:04,216 --> 00:28:04,896 A:middle
if you would like as well.

640
00:28:05,346 --> 00:28:06,926 A:middle
That's all you need
to do in order

641
00:28:06,926 --> 00:28:09,926 A:middle
to implement your
own image providers.

642
00:28:09,926 --> 00:28:15,446 A:middle
Now, let's talk about
the various view classes

643
00:28:15,516 --> 00:28:17,036 A:middle
that we have that you can use

644
00:28:17,036 --> 00:28:19,016 A:middle
with Core Image on
both iOS and OS X.

645
00:28:20,206 --> 00:28:23,316 A:middle
So we have a broad spectrum
of support for rendering

646
00:28:23,316 --> 00:28:25,086 A:middle
with Core Image on
a system ranging

647
00:28:25,086 --> 00:28:29,166 A:middle
from the very high level,
such as UIImageView,

648
00:28:29,476 --> 00:28:30,686 A:middle
which makes it very easy

649
00:28:30,996 --> 00:28:32,766 A:middle
to render an image
that's been applied

650
00:28:32,766 --> 00:28:33,636 A:middle
with a Core Image effect.

651
00:28:34,076 --> 00:28:36,096 A:middle
And going to the
much more low-level

652
00:28:36,556 --> 00:28:40,826 A:middle
and potentially higher
performance APIs such as GLKView

653
00:28:40,826 --> 00:28:45,406 A:middle
or MTK view, which give
you more fine-grain control

654
00:28:45,406 --> 00:28:50,036 A:middle
over what you are doing.

655
00:28:50,206 --> 00:28:51,886 A:middle
So let's take a look
at UIImageView.

656
00:28:53,256 --> 00:28:55,376 A:middle
UIImageView is probably
the simplest way

657
00:28:55,376 --> 00:28:59,616 A:middle
to display a CI image on iOS,
and all you have to do is

658
00:28:59,916 --> 00:29:03,386 A:middle
on your UIImageView, set the
Image property to a UI image --

659

660
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

661
00:28:59,916 --> 00:29:03,386 A:middle
on your UIImageView, set the
Image property to a UI image --

662
00:29:03,936 --> 00:29:06,226 A:middle
in this case, one
based on a CI image.

663
00:29:07,196 --> 00:29:10,196 A:middle
The problem is, although
this is very easy to use,

664
00:29:10,826 --> 00:29:12,826 A:middle
it's not the most
high-performance method

665
00:29:12,826 --> 00:29:13,386 A:middle
of doing so.

666
00:29:13,976 --> 00:29:18,826 A:middle
So what ends up happening is
we have to render that back

667
00:29:18,826 --> 00:29:21,206 A:middle
onto the CPU and send
it back up to the GPU,

668
00:29:21,206 --> 00:29:22,836 A:middle
so it's not as efficient
as possible.

669
00:29:22,836 --> 00:29:24,776 A:middle
And if we take a look
at a simple example,

670
00:29:24,776 --> 00:29:27,996 A:middle
in this case we will run
a pixelate filter using

671
00:29:28,116 --> 00:29:29,536 A:middle
a UIImageView.

672
00:29:29,976 --> 00:29:32,976 A:middle
We see that we get about
20 frames per second

673
00:29:32,976 --> 00:29:38,166 A:middle
on a Retina-sized image with
this effect being applied.

674
00:29:40,016 --> 00:29:44,966 A:middle
Now, if we switch to
an OpenGL ES-based view

675
00:29:45,726 --> 00:29:48,246 A:middle
and apply the same filter,

676
00:29:49,266 --> 00:29:52,426 A:middle
we can see that now we
get 48 frames per second.

677
00:29:53,096 --> 00:29:58,656 A:middle
And if we go one step further
and do a Metal-based view,

678

679
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

680
00:30:00,026 --> 00:30:02,966 A:middle
we get slight improvement here.

681
00:30:02,966 --> 00:30:04,316 A:middle
We get 52 frames per second.

682
00:30:04,686 --> 00:30:07,436 A:middle
And although this isn't great
we are only applying one filter,

683
00:30:07,436 --> 00:30:11,086 A:middle
and so the advantages that
we get aren't as noticeable

684
00:30:11,086 --> 00:30:14,126 A:middle
as we would get if we had
many filters being applied

685
00:30:14,776 --> 00:30:17,106 A:middle
or if we had a bunch
of smaller renders.

686
00:30:18,196 --> 00:30:19,276 A:middle
But the basic idea is there.

687
00:30:20,936 --> 00:30:23,786 A:middle
So now, let's take a look at
Core Image and Core Animation

688
00:30:23,786 --> 00:30:25,436 A:middle
and how we can make
those work well together.

689
00:30:27,116 --> 00:30:28,766 A:middle
This is one of the few instances

690
00:30:28,766 --> 00:30:31,536 A:middle
where we do have differences
between iOS and OS X.

691
00:30:31,666 --> 00:30:36,126 A:middle
On OS X, we can just apply,
we just have to do two things

692
00:30:36,576 --> 00:30:39,266 A:middle
in order to use Core Image
and Core Animation together.

693
00:30:39,676 --> 00:30:43,646 A:middle
First things first, on
your NSview, all you need

694
00:30:43,646 --> 00:30:48,296 A:middle
to do is say view.layer uses
Core Image filters and set

695
00:30:48,296 --> 00:30:51,666 A:middle
that to True and then
optionally specify an array

696
00:30:51,666 --> 00:30:53,246 A:middle
of filters you would
like to be applied

697
00:30:53,386 --> 00:30:55,106 A:middle
to whatever layer you have.

698
00:30:55,156 --> 00:30:58,956 A:middle
And that's really
all you need to do.

699
00:30:59,886 --> 00:31:03,396 A:middle
On iOS, we don't
have that support,

700

701
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

702
00:30:59,886 --> 00:31:03,396 A:middle
On iOS, we don't
have that support,

703
00:31:03,396 --> 00:31:06,126 A:middle
so instead what you could
do is OpenGL directly.

704
00:31:07,646 --> 00:31:10,726 A:middle
You can do that either
by deriving from GLKView

705
00:31:11,126 --> 00:31:14,346 A:middle
or by creating a
UIView and ensuring

706
00:31:14,346 --> 00:31:17,026 A:middle
that you override the
layer class method

707
00:31:17,246 --> 00:31:19,346 A:middle
and returning CA
Eagle layer.self.

708
00:31:19,346 --> 00:31:24,346 A:middle
And when you do that, then
you get a GL ES-based object

709
00:31:24,346 --> 00:31:26,306 A:middle
that you can use to
create your CIContext.

710
00:31:26,376 --> 00:31:28,416 A:middle
And that will ensure that
you get optimal performance.

711
00:31:28,906 --> 00:31:31,446 A:middle
All of that is great, but
one thing you need to keep

712
00:31:31,446 --> 00:31:33,996 A:middle
into mind is that if you want
to get great performance,

713
00:31:33,996 --> 00:31:35,676 A:middle
it's not just a question
of using the best API,

714
00:31:35,736 --> 00:31:37,086 A:middle
but using it efficiently.

715
00:31:37,316 --> 00:31:39,876 A:middle
And in this case, the number one
thing you have to remember is

716
00:31:39,916 --> 00:31:42,076 A:middle
to only create your
CIContext once because that's

717
00:31:42,076 --> 00:31:46,146 A:middle
where the caching takes place
and a bunch of state is held.

718
00:31:46,696 --> 00:31:51,126 A:middle
So keep that in mind when you're
using the lower-level APIs.

719
00:31:51,126 --> 00:31:56,736 A:middle
Now, I would like to talk
about Core Image on IOSurface.

720
00:31:57,976 --> 00:32:01,736 A:middle
Internally, within the
Core Image implementation,

721

722
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

723
00:31:57,976 --> 00:32:01,736 A:middle
Internally, within the
Core Image implementation,

724
00:32:01,736 --> 00:32:03,216 A:middle
we use IOSurface extensively.

725
00:32:03,716 --> 00:32:06,236 A:middle
We love it as an API because
it provides us with a bunch

726
00:32:06,236 --> 00:32:07,546 A:middle
of functionality
that doesn't exist

727
00:32:07,546 --> 00:32:10,986 A:middle
with any other API
on the system.

728
00:32:10,986 --> 00:32:13,416 A:middle
So mainly we have
great purgability,

729
00:32:13,756 --> 00:32:15,906 A:middle
some locking semantics so
we can get data in and out

730
00:32:15,906 --> 00:32:19,306 A:middle
of IOSurfaces, and it's a great
way to move data between CPU

731
00:32:19,306 --> 00:32:20,566 A:middle
and GPU and vice versa.

732
00:32:21,406 --> 00:32:24,266 A:middle
We have an incredibly
broad spectrum of support

733
00:32:24,266 --> 00:32:26,456 A:middle
for different formats,
we think probably some

734
00:32:26,456 --> 00:32:27,636 A:middle
of the best on the
entire system.

735
00:32:27,636 --> 00:32:31,756 A:middle
For example, we have 420, 444,

736
00:32:31,756 --> 00:32:34,296 A:middle
RGBA half float,
and many others.

737
00:32:34,296 --> 00:32:37,396 A:middle
Now, on iOS, as a
developer it's difficult

738
00:32:37,396 --> 00:32:40,806 A:middle
to use IOSurface directly,
but you can inform Core Image

739
00:32:40,806 --> 00:32:42,336 A:middle
that you would like
to use IOSurface

740
00:32:42,966 --> 00:32:44,396 A:middle
by creating Pixel Buffers

741
00:32:45,756 --> 00:32:49,036 A:middle
that have the KCV pixel
buffer IOSurface property

742
00:32:49,036 --> 00:32:49,966 A:middle
key specified.

743
00:32:50,846 --> 00:32:52,986 A:middle
When you do that, so if
you create a CV Image

744
00:32:53,276 --> 00:32:55,796 A:middle
from a CV Pixel Buffer
that has this key,

745
00:32:56,706 --> 00:32:58,036 A:middle
what ends up happening
internally is

746
00:32:58,316 --> 00:33:02,166 A:middle
that Core Image knows that it's
an IOSurface-backed CV Pixel

747

748
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

749
00:32:58,316 --> 00:33:02,166 A:middle
that Core Image knows that it's
an IOSurface-backed CV Pixel

750
00:33:02,166 --> 00:33:04,256 A:middle
Buffer and we can render
as efficiently as possible.

751
00:33:04,936 --> 00:33:06,646 A:middle
So, this is something to
keep in mind if you want

752
00:33:06,646 --> 00:33:08,336 A:middle
to get all the benefits
of IOSurface on iOS.

753
00:33:08,336 --> 00:33:13,066 A:middle
Next I'd like to talk
about a few other APIs.

754
00:33:13,066 --> 00:33:16,236 A:middle
We will go over examples of how
we can actually use Core Image

755
00:33:16,616 --> 00:33:21,236 A:middle
and STKs together to create
sample applications very simply.

756
00:33:21,236 --> 00:33:23,356 A:middle
So we are going to start
off with SpriteKit.

757
00:33:24,436 --> 00:33:29,796 A:middle
If we start in XCode and
create a new application,

758
00:33:30,176 --> 00:33:34,266 A:middle
we choose Game, and
then we will choose

759
00:33:34,266 --> 00:33:36,526 A:middle
as a game technology SpriteKit.

760
00:33:36,966 --> 00:33:41,996 A:middle
And we just build and run,
we will get this application,

761
00:33:41,996 --> 00:33:46,406 A:middle
which as you tap on the screen
you get new ships showing up,

762
00:33:46,796 --> 00:33:51,706 A:middle
and you can see here we are
getting 60 frames a second.

763
00:33:51,706 --> 00:33:54,626 A:middle
We can now with a
very small amount

764
00:33:54,626 --> 00:33:58,306 A:middle
of code add Core Image
to this application.

765
00:33:58,646 --> 00:33:59,716 A:middle
So in this case, we will go

766
00:33:59,716 --> 00:34:01,986 A:middle
and modify the Touches
Began method inside

767

768
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

769
00:33:59,716 --> 00:34:01,986 A:middle
and modify the Touches
Began method inside

770
00:34:01,986 --> 00:34:06,086 A:middle
of GameScene.swift, and
initially what was happening was

771
00:34:06,386 --> 00:34:09,676 A:middle
for every tap it was adding
that sprite to the root node.

772
00:34:09,676 --> 00:34:15,565 A:middle
We will modify that a bit, and
we will use an SK effect node.

773
00:34:15,565 --> 00:34:18,856 A:middle
An SK effect node renders the
entire contexts into a buffer,

774
00:34:19,396 --> 00:34:21,826 A:middle
which you can then apply
a series of filters to.

775
00:34:23,226 --> 00:34:24,716 A:middle
So we put an SK effect node.

776
00:34:25,065 --> 00:34:27,286 A:middle
Instead of adding our sprite
that we had earlier to the root,

777
00:34:27,286 --> 00:34:28,676 A:middle
we will add it to the effect.

778
00:34:29,726 --> 00:34:33,556 A:middle
We will say we want to enable
some effects, we are going

779
00:34:33,556 --> 00:34:35,536 A:middle
to create a filter, in
this case we are going

780
00:34:35,536 --> 00:34:36,565 A:middle
to use a pixelate filter,

781
00:34:37,315 --> 00:34:39,025 A:middle
which is the same one
we were viewing earlier.

782
00:34:39,826 --> 00:34:43,716 A:middle
And then we will add
that effect to the root.

783
00:34:43,716 --> 00:34:44,786 A:middle
That is all we need to do.

784
00:34:45,266 --> 00:34:47,255 A:middle
This is the exact code you
would write if you wanted

785
00:34:47,255 --> 00:34:51,505 A:middle
to add Core Image to a
SpriteKit application.

786
00:34:51,856 --> 00:34:54,226 A:middle
And if we now run that exact
same sample that we had

787
00:34:54,866 --> 00:34:59,706 A:middle
and start tapping away, we get
beautifully pixelated sprites

788
00:34:59,856 --> 00:35:01,846 A:middle
in our application and running

789

790
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

791
00:34:59,856 --> 00:35:01,846 A:middle
in our application and running

792
00:35:01,846 --> 00:35:03,536 A:middle
at pretty much the
same frame rate.

793
00:35:03,536 --> 00:35:08,296 A:middle
Now, let's talk a little
bit about SceneKit.

794
00:35:08,906 --> 00:35:09,686 A:middle
Same idea.

795
00:35:10,556 --> 00:35:13,636 A:middle
We will create an
application from Start,

796
00:35:13,636 --> 00:35:16,486 A:middle
and we will choose SceneKit
as a game technology.

797
00:35:16,926 --> 00:35:20,716 A:middle
If we just build and run this
app, we get this spaceship

798
00:35:20,716 --> 00:35:24,556 A:middle
that just rotates around
at interactive rates.

799
00:35:24,976 --> 00:35:29,176 A:middle
Now, if we want to add Core
Image to this application,

800
00:35:29,176 --> 00:35:31,826 A:middle
all we have to do is go to
the View Did Load method

801
00:35:31,876 --> 00:35:35,806 A:middle
in GameViewController.swift,
find the ship,

802
00:35:36,566 --> 00:35:40,546 A:middle
which is aligned
in the sample code.

803
00:35:41,916 --> 00:35:44,646 A:middle
We then create, once
again, the pixelated filter,

804
00:35:45,606 --> 00:35:48,556 A:middle
and we specify an optional
array of filters to the ship.

805
00:35:49,476 --> 00:35:54,766 A:middle
If we do that and run, we get
a beautifully pixelated ship.

806
00:35:55,616 --> 00:35:59,396 A:middle
So you can apply this to any
node in your scene, and, again,

807
00:35:59,396 --> 00:36:01,956 A:middle
we get great frame rate.

808

809
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

810
00:35:59,396 --> 00:36:01,956 A:middle
we get great frame rate.

811
00:36:02,086 --> 00:36:03,156 A:middle
One of the big advantages

812
00:36:03,526 --> 00:36:08,496 A:middle
of using SceneKit alongside
Core Image is you can animate

813
00:36:08,496 --> 00:36:10,176 A:middle
properties with Core Animation.

814
00:36:11,496 --> 00:36:13,176 A:middle
So in this case,
we are just going

815
00:36:13,176 --> 00:36:15,806 A:middle
to create a CA basic
animation, and we are going

816
00:36:15,806 --> 00:36:17,526 A:middle
to animate the input
scale, so we are going

817
00:36:17,526 --> 00:36:21,676 A:middle
to get a varying scale pixelate
effect that will be applied

818
00:36:21,676 --> 00:36:23,926 A:middle
over time going from
a value of 0 to 50.

819
00:36:24,586 --> 00:36:28,106 A:middle
It will ease in and ease out
over the course of two seconds.

820
00:36:28,666 --> 00:36:33,506 A:middle
If we add this code,
we then get our ship

821
00:36:34,756 --> 00:36:40,826 A:middle
with a beautifully
animated pixelate effect.

822
00:36:41,576 --> 00:36:44,526 A:middle
And, again, great frame rates.

823
00:36:45,176 --> 00:36:49,876 A:middle
Now, this doesn't necessarily
have to be applied to one node.

824
00:36:49,876 --> 00:36:51,806 A:middle
You can apply it to
your entire scene.

825
00:36:51,806 --> 00:36:53,116 A:middle
Here we have a sample
that we shipped

826
00:36:53,186 --> 00:36:55,726 A:middle
that you can download
called Bananas,

827
00:36:56,466 --> 00:36:59,006 A:middle
where we have applied the same
effect along with animation

828
00:36:59,986 --> 00:37:04,066 A:middle
and we are changing the pixelate
scale in real time here.

829

830
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

831
00:36:59,986 --> 00:37:04,066 A:middle
and we are changing the pixelate
scale in real time here.

832
00:37:04,916 --> 00:37:07,396 A:middle
I was surprised that I
could play this game better

833
00:37:07,396 --> 00:37:12,226 A:middle
when it was pixelated
than when it was full-res.

834
00:37:12,396 --> 00:37:15,116 A:middle
But you could use this
not just to create games

835
00:37:15,116 --> 00:37:18,336 A:middle
but to also apply an effect
at the end of the game,

836
00:37:18,336 --> 00:37:23,356 A:middle
for example, or if you wanted
to have different versions

837
00:37:23,356 --> 00:37:24,466 A:middle
of your assets rendered

838
00:37:24,836 --> 00:37:26,316 A:middle
with different image
processing effects,

839
00:37:26,316 --> 00:37:28,376 A:middle
you could use Core Image

840
00:37:28,376 --> 00:37:31,856 A:middle
with these APIs together
and it works great.

841
00:37:32,446 --> 00:37:36,796 A:middle
So, so far today we have seen
a bunch of stuff about how

842
00:37:36,796 --> 00:37:39,476 A:middle
to use Core Image with
Metal, AV Foundation,

843
00:37:40,406 --> 00:37:42,496 A:middle
why IOSurface is
so important to us.

844
00:37:42,496 --> 00:37:45,056 A:middle
The easy way to use UIImageView

845
00:37:45,056 --> 00:37:47,736 A:middle
if you are only creating
an image once

846
00:37:47,736 --> 00:37:49,576 A:middle
and don't need to
constantly update.

847
00:37:49,576 --> 00:37:51,876 A:middle
It's a great way to
apply an effect once.

848
00:37:52,876 --> 00:37:55,736 A:middle
We showed you how to use Core
Animation as well, how to bring

849
00:37:55,736 --> 00:37:57,766 A:middle
in custom data with
CIImageProvider,

850
00:37:57,766 --> 00:38:01,826 A:middle
and how to use it in the context
of games or other applications

851

852
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

853
00:37:57,766 --> 00:38:01,826 A:middle
and how to use it in the context
of games or other applications

854
00:38:02,106 --> 00:38:08,786 A:middle
that you can create very simply
with SceneKit or SpriteKit.

855
00:38:09,216 --> 00:38:10,966 A:middle
For additional information,
we have a bunch

856
00:38:10,966 --> 00:38:14,276 A:middle
of resources available online
at developer.apple.com,

857
00:38:15,126 --> 00:38:18,436 A:middle
and for any additional inquiries
you can contact Stephen Chick

858
00:38:18,436 --> 00:38:20,796 A:middle
at chick@apple.com.

859
00:38:22,036 --> 00:38:25,696 A:middle
There are other sessions you
may be interested in going to,

860
00:38:25,696 --> 00:38:27,876 A:middle
including the Editing
Movies in AV Foundation

861
00:38:28,346 --> 00:38:31,996 A:middle
which took place a few days
ago but you can look at online

862
00:38:31,996 --> 00:38:35,466 A:middle
and What's New in Metal Part 2
that also took place yesterday.

863
00:38:36,336 --> 00:38:40,456 A:middle
And on that note, I would like
to thank you all for coming

864
00:38:40,526 --> 00:38:43,116 A:middle
and I hope you enjoy using Core
Image in your applications,

865
00:38:43,176 --> 00:38:44,596 A:middle
and I hope you enjoy the
rest of the conference.

866
00:38:44,596 --> 00:38:45,256 A:middle
Thank you very much!

867
00:38:47,516 --> 00:38:58,360 A:middle
[ Applause ]

868
