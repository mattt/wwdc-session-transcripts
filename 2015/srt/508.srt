X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:24,516 --> 00:00:26,746 A:middle
[Applause]

2
00:00:27,246 --> 00:00:27,796 A:middle
>> DOUG WYATT: Good morning.

3
00:00:29,706 --> 00:00:32,686 A:middle
I'm Doug Wyatt from the
Core Audio team and I would

4
00:00:32,686 --> 00:00:34,516 A:middle
like to show you something
new we have been working

5
00:00:34,516 --> 00:00:36,986 A:middle
on called Audio Unit Extensions.

6
00:00:37,386 --> 00:00:42,416 A:middle
This is a new technology in
iOS 9 and OS X El Capitan.

7
00:00:43,946 --> 00:00:46,786 A:middle
About Audio Units: we've
had had this technology

8
00:00:46,786 --> 00:00:51,316 A:middle
in our operating systems since
the beginning OS X and iOS.

9
00:00:52,096 --> 00:00:54,436 A:middle
The operating system
includes a great number

10
00:00:54,436 --> 00:00:57,756 A:middle
of built-in units ranging
from I/O units and mixers,

11
00:00:58,116 --> 00:01:02,386 A:middle
a lot of different effects
ranging to software sampler.

12

13
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

14
00:00:58,116 --> 00:01:02,386 A:middle
a lot of different effects
ranging to software sampler.

15
00:01:04,086 --> 00:01:06,436 A:middle
We use these internal
Audio Units in many

16
00:01:06,436 --> 00:01:09,166 A:middle
of our higher-level
APIs, for example,

17
00:01:09,356 --> 00:01:10,736 A:middle
the media playback stack.

18
00:01:12,076 --> 00:01:15,756 A:middle
But Audio Units are also a
widely adopted third-party

19
00:01:15,876 --> 00:01:17,806 A:middle
plug-in format on OS X.

20
00:01:18,216 --> 00:01:21,056 A:middle
There are literally thousands
of third-party Audio Units

21
00:01:21,056 --> 00:01:23,616 A:middle
in the market out there.

22
00:01:24,246 --> 00:01:25,916 A:middle
Now, Audio Unit extensions

23
00:01:25,916 --> 00:01:28,936 A:middle
for the first time bring
us a full plug-in model

24
00:01:29,426 --> 00:01:31,736 A:middle
on both OS X and iOS.

25
00:01:32,016 --> 00:01:35,266 A:middle
It is built on top of the
app extension technology,

26
00:01:35,746 --> 00:01:39,006 A:middle
which means if you are writing
plug-ins you can package them

27
00:01:39,006 --> 00:01:42,646 A:middle
into apps, and those apps can
be sold on the App Stores.

28
00:01:43,516 --> 00:01:49,186 A:middle
[Applause]

29
00:01:49,686 --> 00:01:53,256 A:middle
As part of this technology,
we have modernized the API and

30
00:01:53,736 --> 00:01:56,616 A:middle
yet at the same time
maintained compatibility,

31
00:01:57,116 --> 00:02:00,236 A:middle
and in this session I will go
through details of this new API,

32

33
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

34
00:01:57,116 --> 00:02:00,236 A:middle
and in this session I will go
through details of this new API,

35
00:02:01,216 --> 00:02:05,096 A:middle
which we are calling the
version 3 Audio Unit API.

36
00:02:05,916 --> 00:02:10,175 A:middle
It's based on an Objective-C
class called AUAudioUnit that's

37
00:02:10,175 --> 00:02:11,626 A:middle
in the Audio Unit framework.

38
00:02:12,036 --> 00:02:15,766 A:middle
And as an Objective-C class,
of course, it plays nicely

39
00:02:15,766 --> 00:02:19,256 A:middle
with Swift, as we will see.

40
00:02:19,946 --> 00:02:21,966 A:middle
In this session, we are also
going to look at a number

41
00:02:21,966 --> 00:02:24,516 A:middle
of classes in the
AVFoundation framework.

42
00:02:25,146 --> 00:02:28,996 A:middle
We have AV Audio Unit
component manager

43
00:02:29,616 --> 00:02:31,456 A:middle
and AV Audio Unit component.

44
00:02:32,146 --> 00:02:35,656 A:middle
These are used to located the
audio components on the system.

45
00:02:36,376 --> 00:02:38,666 A:middle
Those appear for the
first time in iOS 9.

46
00:02:39,296 --> 00:02:40,936 A:middle
They also exist on Yosemite.

47
00:02:41,736 --> 00:02:45,296 A:middle
And we will also be using
AVAudioEngine in some

48
00:02:45,296 --> 00:02:47,366 A:middle
of our example code we
will be showing today,

49
00:02:48,206 --> 00:02:50,806 A:middle
in particular the
AVAudioUnit class

50
00:02:50,806 --> 00:02:52,796 A:middle
and AVAudioUnitEffect class.

51
00:02:53,216 --> 00:02:56,276 A:middle
Those have been available
since last year's OS releases.

52
00:02:58,536 --> 00:03:00,306 A:middle
So about compatibility now.

53

54
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

55
00:02:58,536 --> 00:03:00,306 A:middle
So about compatibility now.

56
00:03:00,306 --> 00:03:02,666 A:middle
This is how things
look now in OS X.

57
00:03:03,036 --> 00:03:05,646 A:middle
We have our existing
version 2 Audio Unit hosts

58
00:03:06,056 --> 00:03:09,246 A:middle
and existing version 2
Audio Unit implementations.

59
00:03:09,616 --> 00:03:12,036 A:middle
The hosts start their
communication

60
00:03:12,036 --> 00:03:13,866 A:middle
with audio component
instance new,

61
00:03:14,526 --> 00:03:16,696 A:middle
and our implementations
are built

62
00:03:16,696 --> 00:03:18,986 A:middle
on audio component
factory functions.

63
00:03:21,436 --> 00:03:23,676 A:middle
We have a new set of APIs here,

64
00:03:24,036 --> 00:03:26,826 A:middle
so we will have new hosts
using those new APIs.

65
00:03:26,826 --> 00:03:31,556 A:middle
And new Audio Units implemented
using those new APIs.

66
00:03:32,296 --> 00:03:35,566 A:middle
Hosts will communicate with
the class AU Audio Unit.

67
00:03:35,996 --> 00:03:40,066 A:middle
New version 3 Audio Units
will subclass AU Audio Unit.

68
00:03:40,866 --> 00:03:42,916 A:middle
So that's two separate APIs.

69
00:03:42,916 --> 00:03:44,876 A:middle
What are we going to
do to be compatible?

70
00:03:44,926 --> 00:03:48,626 A:middle
We have built bridges
between these two APIs.

71
00:03:49,996 --> 00:03:52,606 A:middle
So thanks to these
bridges, we will find

72
00:03:52,606 --> 00:03:57,236 A:middle
that new version 3 hosts should
be almost completely compatible

73
00:03:57,236 --> 00:03:59,536 A:middle
with existing version
2 Audio Units.

74

75
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

76
00:04:00,286 --> 00:04:04,606 A:middle
And conversely, existing version
2 hosts would only need minor

77
00:04:04,606 --> 00:04:08,476 A:middle
source changes to work with
new version 3 Audio Units.

78
00:04:08,806 --> 00:04:12,266 A:middle
And I will detail those API
changes in a little bit.

79
00:04:15,456 --> 00:04:17,646 A:middle
So now I would like
to give you a demo

80
00:04:17,646 --> 00:04:19,796 A:middle
of a new Audio Unit working

81
00:04:19,796 --> 00:04:22,906 A:middle
in an only slightly modified
version of Logic Pro.

82
00:04:23,016 --> 00:04:29,356 A:middle
I have a little session here,
it has a drum loop built in.

83
00:04:29,606 --> 00:04:34,536 A:middle
And here I'm going to apply
an Audio Unit to this track.

84
00:04:35,946 --> 00:04:38,626 A:middle
So here are all of the
Apple built-in Audio Units.

85
00:04:40,146 --> 00:04:45,406 A:middle
And here I have a new demo
Audio Unit called v3 Distortion.

86
00:04:46,696 --> 00:04:48,376 A:middle
So I can open this Audio Unit.

87
00:04:49,376 --> 00:04:55,246 A:middle
I can find the preset I like,
and we can hear Logic playing

88
00:04:55,246 --> 00:04:55,976 A:middle
through this Audio Unit.

89
00:04:56,516 --> 00:05:01,576 A:middle
[Music]

90

91
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

92
00:04:56,516 --> 00:05:01,576 A:middle
[Music]

93
00:05:02,076 --> 00:05:04,646 A:middle
There it's dry.

94
00:05:04,986 --> 00:05:05,816 A:middle
Completely distorted.

95
00:05:06,816 --> 00:05:09,306 A:middle
Now, if I go to activity
monitor here,

96
00:05:10,096 --> 00:05:13,296 A:middle
we can see that this
distortion Audio Unit is running

97
00:05:13,486 --> 00:05:17,306 A:middle
in a separate process,
AU v3 distortion.

98
00:05:17,706 --> 00:05:19,806 A:middle
It's consuming a
little bit of CPU.

99
00:05:20,326 --> 00:05:21,896 A:middle
It has some threads running.

100
00:05:23,086 --> 00:05:27,976 A:middle
Now, suppose this Audio Unit
has a bug in it, and it crashes.

101
00:05:27,976 --> 00:05:30,366 A:middle
Well, I can simulate that
here in activity monitor.

102
00:05:31,016 --> 00:05:32,886 A:middle
I can force quit it.

103
00:05:33,116 --> 00:05:36,476 A:middle
And notice in Logic,
the view went blank

104
00:05:36,886 --> 00:05:38,196 A:middle
but the music kept playing.

105
00:05:39,516 --> 00:05:48,676 A:middle
[Applause]

106
00:05:49,176 --> 00:05:51,546 A:middle
So here is a diagram of what
we were just looking at.

107
00:05:52,036 --> 00:05:54,966 A:middle
That's a slightly modified
version of Logic Pro,

108
00:05:55,746 --> 00:05:58,606 A:middle
but it's still basically
communicating using the existing

109
00:05:58,606 --> 00:06:03,846 A:middle
version 2 API, which is bridged
to AU Audio Unit and in turn,

110

111
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

112
00:05:58,606 --> 00:06:03,846 A:middle
version 2 API, which is bridged
to AU Audio Unit and in turn,

113
00:06:04,116 --> 00:06:06,526 A:middle
in that separate
extension service process,

114
00:06:06,916 --> 00:06:10,616 A:middle
we saw the distortion units
AU Audio Unit subclass running

115
00:06:11,296 --> 00:06:13,036 A:middle
along with its custom
View Controller.

116
00:06:13,606 --> 00:06:16,216 A:middle
In the Logic process, there
is also a View Controller,

117
00:06:16,796 --> 00:06:18,626 A:middle
and you see how these
are bridged

118
00:06:19,206 --> 00:06:21,286 A:middle
across the process boundary.

119
00:06:24,906 --> 00:06:27,596 A:middle
Now, I'd like to talk
about hosting Audio Units

120
00:06:28,256 --> 00:06:32,046 A:middle
and I will show you an example
that uses the version 3 APIs.

121
00:06:32,156 --> 00:06:35,286 A:middle
We have sample code called
Audio Unit v3 Example.

122
00:06:35,716 --> 00:06:38,236 A:middle
I checked a couple of hours
ago, but it hadn't appeared yet.

123
00:06:38,566 --> 00:06:42,616 A:middle
I hope it comes out today.

124
00:06:42,916 --> 00:06:45,336 A:middle
In this sample code project,
you will see there are a number

125
00:06:45,336 --> 00:06:48,186 A:middle
of targets and one of
them is called AU Host.

126
00:06:49,006 --> 00:06:51,876 A:middle
Now, this application is fairly
simple and straightforward,

127
00:06:52,276 --> 00:06:55,586 A:middle
but it shows how to find and
open Audio Units that are

128
00:06:55,586 --> 00:06:58,486 A:middle
on the system, how to
connect them together

129
00:06:58,826 --> 00:07:02,316 A:middle
into a rendering chain, how
to select Audio Unit presets,

130

131
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

132
00:06:58,826 --> 00:07:02,316 A:middle
into a rendering chain, how
to select Audio Unit presets,

133
00:07:02,766 --> 00:07:05,656 A:middle
and how to open an Audio
Unit's custom view.

134
00:07:07,496 --> 00:07:11,066 A:middle
So in the AU host app, we have
something called simple play

135
00:07:11,066 --> 00:07:14,946 A:middle
engine, which is a Swift
class that uses AVAudioEngine.

136
00:07:14,986 --> 00:07:19,146 A:middle
It uses an AV audio
player node connected

137
00:07:19,146 --> 00:07:20,426 A:middle
to an AV Audio Unit effect.

138
00:07:20,426 --> 00:07:23,266 A:middle
That AV Audio Unit effect

139
00:07:23,266 --> 00:07:26,556 A:middle
in turn exposed an
underlying AU Audio Unit,

140
00:07:27,146 --> 00:07:30,776 A:middle
which is the maiden class of
the version 3 Audio Unit API.

141
00:07:31,756 --> 00:07:33,546 A:middle
We have the player
to the effect,

142
00:07:33,546 --> 00:07:34,986 A:middle
to the mixer, to the output.

143
00:07:35,246 --> 00:07:37,416 A:middle
That's how the simple
play engine makes sound.

144
00:07:38,316 --> 00:07:42,966 A:middle
We will also see how to use the
AV Audio Unit component manager

145
00:07:42,996 --> 00:07:46,476 A:middle
class to select from the
AV Audio Unit components

146
00:07:46,476 --> 00:07:50,146 A:middle
on the system and use
that to control what kind

147
00:07:50,146 --> 00:07:52,596 A:middle
of AV Audio Unit
effect gets selected.

148
00:07:52,596 --> 00:07:56,466 A:middle
So let's get into a
little bit of code,

149
00:07:56,466 --> 00:07:59,746 A:middle
but first there is a very
fundamental data structure here

150
00:07:59,746 --> 00:08:01,276 A:middle
when working with Audio Units.

151

152
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

153
00:07:59,746 --> 00:08:01,276 A:middle
when working with Audio Units.

154
00:08:01,866 --> 00:08:03,796 A:middle
We have the audio
component description

155
00:08:04,296 --> 00:08:07,596 A:middle
and its first three fields:
the component type, type,

156
00:08:07,736 --> 00:08:10,386 A:middle
subtype, and manufacturer.

157
00:08:10,816 --> 00:08:14,626 A:middle
That tuple uniquely identifies
an Audio Unit in the system.

158
00:08:15,236 --> 00:08:16,756 A:middle
The flags are also important.

159
00:08:16,756 --> 00:08:19,556 A:middle
They are partially populated
by the audio component,

160
00:08:19,946 --> 00:08:23,356 A:middle
and there are new ones
populated by the system.

161
00:08:23,356 --> 00:08:25,686 A:middle
We will describe some
of those as we go along.

162
00:08:26,136 --> 00:08:28,336 A:middle
The important thing
here is this is the key

163
00:08:28,336 --> 00:08:29,956 A:middle
that identifies the plug-in.

164
00:08:31,776 --> 00:08:34,946 A:middle
So to find Audio Unit
components on the system,

165
00:08:35,836 --> 00:08:38,926 A:middle
the first thing we do is create
an audio component description

166
00:08:39,666 --> 00:08:41,316 A:middle
that contains a wildcard.

167
00:08:41,666 --> 00:08:43,726 A:middle
Here we say the component
type is effect.

168
00:08:43,836 --> 00:08:46,706 A:middle
That's not a wildcard, but
we have component subtype

169
00:08:46,706 --> 00:08:48,456 A:middle
and manufacturer of zero.

170
00:08:48,806 --> 00:08:51,786 A:middle
Those are wildcards, so we have
built a component description

171
00:08:51,786 --> 00:08:54,056 A:middle
here that identifies any effect.

172
00:08:55,536 --> 00:09:00,606 A:middle
And then we can take that any
effect component description

173

174
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

175
00:08:55,536 --> 00:09:00,606 A:middle
And then we can take that any
effect component description

176
00:09:00,606 --> 00:09:03,496 A:middle
and pass it to AV Audio
Unit component manager,

177
00:09:04,106 --> 00:09:06,106 A:middle
and it will give us
back all of the effects

178
00:09:06,106 --> 00:09:08,736 A:middle
on the system matching
that wildcard.

179
00:09:09,626 --> 00:09:13,366 A:middle
So here we get an array of AV
Audio Unit component objects,

180
00:09:13,976 --> 00:09:18,396 A:middle
and those contain things
like the name, tags,

181
00:09:18,866 --> 00:09:23,366 A:middle
also the audio component
description of that unit.

182
00:09:25,336 --> 00:09:27,486 A:middle
So here we have got an
array of components.

183
00:09:27,486 --> 00:09:28,876 A:middle
We can pass that back to the UI,

184
00:09:28,876 --> 00:09:34,146 A:middle
and in turn the UI can call this
method in the simple play engine

185
00:09:34,526 --> 00:09:37,946 A:middle
to select one of these
previously vended

186
00:09:38,656 --> 00:09:39,776 A:middle
effect components.

187
00:09:40,136 --> 00:09:41,706 A:middle
So here it gives us a component.

188
00:09:42,176 --> 00:09:44,586 A:middle
We are going to fetch the
audio component description

189
00:09:44,586 --> 00:09:50,196 A:middle
out of that, pass it to an
internal method, and the guts

190
00:09:50,196 --> 00:09:51,806 A:middle
of that internal method is here.

191
00:09:52,286 --> 00:09:56,436 A:middle
We are going to call a new
class method of AV Audio Unit.

192
00:09:57,296 --> 00:10:01,026 A:middle
And this method asks it to
create an instance based

193

194
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

195
00:09:57,296 --> 00:10:01,026 A:middle
And this method asks it to
create an instance based

196
00:10:01,026 --> 00:10:03,106 A:middle
on the component
description we have here.

197
00:10:04,136 --> 00:10:07,316 A:middle
Now, this is an asynchronous
function, meaning it's going

198
00:10:07,316 --> 00:10:09,316 A:middle
to go off and start
instantiating it,

199
00:10:09,756 --> 00:10:11,846 A:middle
and then it's going
to call this closure

200
00:10:12,846 --> 00:10:18,046 A:middle
when it actually has
instantiated the Audio Unit

201
00:10:18,046 --> 00:10:20,556 A:middle
and we are ready to use it.

202
00:10:21,486 --> 00:10:22,986 A:middle
So here we are in our callback.

203
00:10:22,986 --> 00:10:24,796 A:middle
This is Swift closure syntax.

204
00:10:25,396 --> 00:10:27,646 A:middle
We have our AV Audio Unit.

205
00:10:29,306 --> 00:10:32,996 A:middle
And then we can attach
it to our engine.

206
00:10:33,476 --> 00:10:36,286 A:middle
We have stored it into a
member variable, the effect.

207
00:10:37,606 --> 00:10:43,806 A:middle
And now we have an AV Audio
Unit know that's the effect.

208
00:10:43,806 --> 00:10:45,576 A:middle
We are going to patch
that into the engine.

209
00:10:46,156 --> 00:10:48,506 A:middle
We will disconnect the
effect from the main mixer,

210
00:10:49,206 --> 00:10:51,586 A:middle
then connect from the
player to the effect.

211
00:10:52,896 --> 00:10:55,896 A:middle
And then from the effect
to the main mixer node.

212
00:10:57,446 --> 00:10:59,576 A:middle
So now we have got an
effect in our play engine.

213

214
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

215
00:11:01,426 --> 00:11:05,626 A:middle
And now we can store the
actual AU Audio Unit.

216
00:11:06,066 --> 00:11:08,346 A:middle
That's the plug-in, and
here we can do all kinds

217
00:11:08,346 --> 00:11:09,246 A:middle
of interesting things

218
00:11:09,246 --> 00:11:13,626 A:middle
like manipulate the component's
effect, presets, and parameters.

219
00:11:14,936 --> 00:11:18,946 A:middle
For instance, here, we will just
get the list of factory presets.

220
00:11:20,586 --> 00:11:23,476 A:middle
And this too can
populate a field

221
00:11:23,476 --> 00:11:25,426 A:middle
in the table view --
rather, in the UI.

222
00:11:27,236 --> 00:11:29,356 A:middle
So the user can choose
the factory preset.

223
00:11:31,236 --> 00:11:34,106 A:middle
And finally, I would
like to show you how

224
00:11:34,316 --> 00:11:35,876 A:middle
in the app I will
show you in a minute,

225
00:11:36,446 --> 00:11:39,146 A:middle
we can get the Audio Unit's
custom view and embed it

226
00:11:39,196 --> 00:11:40,966 A:middle
into the host application's
view.

227
00:11:41,546 --> 00:11:43,906 A:middle
Here we are in the View
Controller of the host,

228
00:11:43,906 --> 00:11:47,476 A:middle
so we are going to ask the play
engine, give me your Audio Unit,

229
00:11:47,866 --> 00:11:49,816 A:middle
and then we are going
to ask the Audio Unit

230
00:11:49,896 --> 00:11:50,896 A:middle
for a View Controller.

231
00:11:51,216 --> 00:11:52,916 A:middle
When it's done with that,
it will call us back

232
00:11:52,916 --> 00:11:56,486 A:middle
with a View Controller that we
can embed in the host's view.

233
00:11:58,266 --> 00:12:00,826 A:middle
Okay. I would like to bring up
my colleague Michael Hopkins now

234

235
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

236
00:11:58,266 --> 00:12:00,826 A:middle
Okay. I would like to bring up
my colleague Michael Hopkins now

237
00:12:01,266 --> 00:12:03,396 A:middle
to show you this app
actually running now.

238
00:12:06,516 --> 00:12:12,216 A:middle
[Applause]

239
00:12:12,716 --> 00:12:13,856 A:middle
>> MICHAEL HOPKINS: Thank
you very much, Doug.

240
00:12:14,176 --> 00:12:16,446 A:middle
I'm delighted to have
this opportunity today

241
00:12:16,446 --> 00:12:21,316 A:middle
to show you this
AVAudioEngine-based v3 host

242
00:12:21,316 --> 00:12:23,356 A:middle
application running
on an iPad here.

243
00:12:24,156 --> 00:12:25,766 A:middle
As you can see, I'm
going to launch

244
00:12:25,766 --> 00:12:28,146 A:middle
that by tapping the
icon for the host.

245
00:12:29,126 --> 00:12:31,936 A:middle
And on the left-hand side of
the screen we have a list of all

246
00:12:31,936 --> 00:12:35,106 A:middle
of the effects Audio Units
that are present on the system.

247
00:12:35,486 --> 00:12:38,196 A:middle
And this includes both
the built-in Apple audio

248
00:12:38,196 --> 00:12:40,486 A:middle
component-based effects as well

249
00:12:40,486 --> 00:12:43,566 A:middle
as several new extension-based
v3 Audio Units I

250
00:12:43,566 --> 00:12:44,566 A:middle
installed myself.

251
00:12:45,776 --> 00:12:48,956 A:middle
At the top of the screen, I have
a Play button that I can tap

252
00:12:49,056 --> 00:12:51,656 A:middle
to toggle the playback
of a drum loop.

253
00:12:52,736 --> 00:12:56,006 A:middle
Now, let's see how I can
apply some effect nodes

254
00:12:56,216 --> 00:12:57,386 A:middle
and add them to the graph.

255
00:12:57,956 --> 00:12:59,596 A:middle
First, I will play
this with no effect

256
00:12:59,596 --> 00:13:01,436 A:middle
and then I will add
a couple effects

257

258
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

259
00:12:59,596 --> 00:13:01,436 A:middle
and then I will add
a couple effects

260
00:13:01,436 --> 00:13:02,666 A:middle
so you can hear that working.

261
00:13:03,516 --> 00:13:08,626 A:middle
[Music]

262
00:13:09,126 --> 00:13:12,896 A:middle
With the high pass filter,
it's filtering out almost all

263
00:13:12,896 --> 00:13:16,186 A:middle
of the sounds of the cymbals
and other higher frequencies.

264
00:13:17,046 --> 00:13:21,916 A:middle
A delay, which is a little
bit hard to hear in this room.

265
00:13:22,366 --> 00:13:24,476 A:middle
And I'm going to go
ahead and stop that.

266
00:13:24,876 --> 00:13:26,096 A:middle
So now I would like to show you

267
00:13:26,096 --> 00:13:29,556 A:middle
for the first time an
extension-based Audio Unit

268
00:13:29,556 --> 00:13:31,006 A:middle
running on this iPad.

269
00:13:31,006 --> 00:13:33,896 A:middle
That is the distortion demo.

270
00:13:34,696 --> 00:13:37,576 A:middle
When I select that, now
you can see the list of all

271
00:13:37,576 --> 00:13:40,436 A:middle
of the factory presets that
the Audio Unit is publishing.

272
00:13:41,246 --> 00:13:43,816 A:middle
These include some
drum-specific ones as well

273
00:13:43,816 --> 00:13:47,156 A:middle
as some really crazy, wild
effects like alien chatter.

274
00:13:48,466 --> 00:13:49,666 A:middle
Now, as Doug mentioned ,

275
00:13:49,816 --> 00:13:53,916 A:middle
v3 Audio Unit can have
a custom view on iOS.

276
00:13:54,566 --> 00:13:56,156 A:middle
And I'm going to show you that.

277
00:13:56,156 --> 00:13:57,906 A:middle
I'm going to go ahead
and tap the View button.

278
00:13:58,396 --> 00:14:02,506 A:middle
And what we have done is we
have loaded that View Controller

279

280
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

281
00:13:58,396 --> 00:14:02,506 A:middle
And what we have done is we
have loaded that View Controller

282
00:14:02,506 --> 00:14:04,486 A:middle
from the Audio Unit
and I have installed it

283
00:14:04,486 --> 00:14:08,426 A:middle
as a child View Controller
within our application context.

284
00:14:08,426 --> 00:14:11,846 A:middle
So for the first time, we
have a built in Audio Unit

285
00:14:11,846 --> 00:14:13,936 A:middle
with a UI running in our host.

286
00:14:15,096 --> 00:14:20,176 A:middle
We have a large slider, excuse
me, a large knob that I can use

287
00:14:20,176 --> 00:14:21,806 A:middle
to control the amount
of distortion.

288
00:14:22,876 --> 00:14:24,566 A:middle
And let me go ahead
and play that for you

289
00:14:24,566 --> 00:14:25,916 A:middle
so you can hear that in action.

290
00:14:27,516 --> 00:14:43,546 A:middle
[Music]

291
00:14:44,046 --> 00:14:45,416 A:middle
It's really a lot of fun.

292
00:14:45,416 --> 00:14:47,896 A:middle
It's an amazing experience
to be able to have

293
00:14:47,896 --> 00:14:52,366 A:middle
that Multi-Touch UI working
fluidly in a host application

294
00:14:52,366 --> 00:14:55,316 A:middle
without having to go through
all of the hassle of switching

295
00:14:55,316 --> 00:14:57,676 A:middle
out to another application,
doing some tweaks,

296
00:14:57,676 --> 00:14:59,036 A:middle
switching back to your host,

297
00:14:59,366 --> 00:15:01,306 A:middle
starting recording,
switching back.

298

299
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

300
00:14:59,366 --> 00:15:01,306 A:middle
starting recording,
switching back.

301
00:15:01,306 --> 00:15:03,046 A:middle
Now, you won't have
to do that ever again.

302
00:15:04,516 --> 00:15:08,586 A:middle
[Applause]

303
00:15:09,086 --> 00:15:09,516 A:middle
Thank you.

304
00:15:10,746 --> 00:15:12,456 A:middle
And I'd also like
to point out further

305
00:15:12,456 --> 00:15:15,876 A:middle
that this is the same Audio Unit
that you saw running in Logic

306
00:15:15,876 --> 00:15:17,566 A:middle
in Doug's earlier demo.

307
00:15:17,956 --> 00:15:21,056 A:middle
In fact, the source code for
the Audio Unit is identical.

308
00:15:21,056 --> 00:15:22,336 A:middle
No changes were required.

309
00:15:22,906 --> 00:15:26,666 A:middle
The drawing code is also
very similar because I chose

310
00:15:26,666 --> 00:15:28,526 A:middle
to write this using
Core Animation

311
00:15:28,526 --> 00:15:30,826 A:middle
so that API is almost
fully portable.

312
00:15:31,486 --> 00:15:33,316 A:middle
The only changes
that were necessary

313
00:15:33,316 --> 00:15:36,936 A:middle
to bring this Audio Unit to
iOS are in the event model,

314
00:15:36,936 --> 00:15:39,486 A:middle
whereas we have had to use
the touch events in UIKit

315
00:15:39,546 --> 00:15:45,086 A:middle
versus the AppKit mouse
events on the desktop.

316
00:15:45,496 --> 00:15:47,666 A:middle
So really you guys
have an opportunity

317
00:15:47,666 --> 00:15:52,486 A:middle
to with only a few changes
to publish an Audio Unit both

318
00:15:52,486 --> 00:15:54,216 A:middle
on the desktop and on iOS.

319
00:15:54,696 --> 00:15:55,976 A:middle
Thank you very much.

320
00:15:56,016 --> 00:15:57,256 A:middle
[Applause]

321
00:15:57,256 --> 00:15:57,846 A:middle
Back to you, Doug.

322

323
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

324
00:16:00,236 --> 00:16:02,056 A:middle
>> DOUG WYATT: Thank
you, Michael.

325
00:16:05,656 --> 00:16:08,806 A:middle
So I would like to talk
about using Audio Units

326
00:16:09,176 --> 00:16:11,626 A:middle
in your host applications
in situations

327
00:16:11,626 --> 00:16:13,626 A:middle
where you are not
using AVAudioEngine.

328
00:16:14,446 --> 00:16:18,026 A:middle
We have a similar method
on the AU Audio Unit class

329
00:16:18,546 --> 00:16:20,706 A:middle
to asynchronously
create an instance

330
00:16:20,706 --> 00:16:21,986 A:middle
of the component description.

331
00:16:21,986 --> 00:16:22,736 A:middle
You see that there.

332
00:16:23,566 --> 00:16:26,726 A:middle
We also, for those of you
with existing version 2 hosts,

333
00:16:27,066 --> 00:16:29,886 A:middle
a minimal translation path is

334
00:16:29,946 --> 00:16:32,406 A:middle
to start using audio
component instantiate.

335
00:16:32,796 --> 00:16:35,916 A:middle
We will talk about that
in detail in a bit.

336
00:16:37,626 --> 00:16:39,556 A:middle
Now, I would like to
talk about the subject

337
00:16:39,556 --> 00:16:42,116 A:middle
of extension service processes

338
00:16:42,116 --> 00:16:45,306 A:middle
versus plug-ins loaded
into host processes.

339
00:16:47,066 --> 00:16:50,356 A:middle
Now, as anybody who has worked
with Audio Units is aware,

340
00:16:50,356 --> 00:16:52,306 A:middle
of course, with our
existing plug-in model,

341
00:16:52,636 --> 00:16:55,456 A:middle
the plug-ins are always loaded
into the host's progress,

342
00:16:55,876 --> 00:16:59,566 A:middle
and this remains true
for version 3 hosts.

343
00:16:59,796 --> 00:17:03,336 A:middle
If it's a version 2 existing
plug-in, and that might be one

344

345
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

346
00:16:59,796 --> 00:17:03,336 A:middle
If it's a version 2 existing
plug-in, and that might be one

347
00:17:03,336 --> 00:17:05,616 A:middle
of the Apple built-in
ones on iOS

348
00:17:05,616 --> 00:17:09,136 A:middle
or it could be a third-party
one on OS X, but in any case

349
00:17:09,796 --> 00:17:13,465 A:middle
if it's a version 2 Audio Unit,
regardless of any other factor,

350
00:17:13,465 --> 00:17:15,376 A:middle
it's always in the
host's process.

351
00:17:17,016 --> 00:17:20,346 A:middle
Now, version 3 Audio Units have
a slightly more complicated

352
00:17:20,346 --> 00:17:21,016 A:middle
story here.

353
00:17:21,665 --> 00:17:25,415 A:middle
By default, version 3
Audio Units are loaded

354
00:17:25,415 --> 00:17:28,096 A:middle
into a separate extension
service process.

355
00:17:28,435 --> 00:17:31,186 A:middle
And this is the diagram
we saw before with Logic.

356
00:17:32,306 --> 00:17:35,766 A:middle
This is true, again,
whether it's a version 2 host

357
00:17:35,766 --> 00:17:36,976 A:middle
or a version 3 host.

358
00:17:38,086 --> 00:17:43,326 A:middle
Now, on OS X only it is
possible for the plug-in

359
00:17:43,326 --> 00:17:46,096 A:middle
to be loaded directly
into the host's process.

360
00:17:46,616 --> 00:17:50,096 A:middle
Now, for this to happen,
both parties have to opt in.

361
00:17:50,626 --> 00:17:54,136 A:middle
The host when instantiating
the Audio Unit has

362
00:17:54,136 --> 00:17:55,836 A:middle
to pass this option to any

363
00:17:55,836 --> 00:17:58,806 A:middle
of the asynchronous
creation methods we just saw,

364
00:17:59,996 --> 00:18:02,696 A:middle
and you see the name of that
new flag there called Load

365

366
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

367
00:17:59,996 --> 00:18:02,696 A:middle
and you see the name of that
new flag there called Load

368
00:18:02,696 --> 00:18:03,526 A:middle
in Process.

369
00:18:04,066 --> 00:18:07,556 A:middle
And the Audio Unit also has
to be packaged specially

370
00:18:07,886 --> 00:18:12,216 A:middle
and consent to this with
a plist entry called Audio

371
00:18:12,216 --> 00:18:13,176 A:middle
Component Bundle.

372
00:18:13,856 --> 00:18:15,866 A:middle
So if both parties do opt in,

373
00:18:16,246 --> 00:18:19,776 A:middle
then the framework will
actually load the plug-in

374
00:18:19,836 --> 00:18:21,256 A:middle
into the host's process.

375
00:18:21,416 --> 00:18:23,586 A:middle
So the host will be
communicating directly

376
00:18:23,586 --> 00:18:27,466 A:middle
with the plug-in's AU
Audio Unit subclass.

377
00:18:30,016 --> 00:18:33,036 A:middle
Now, as a host author, why
would you want to do this?

378
00:18:33,556 --> 00:18:35,986 A:middle
There is a tradeoff
here between safety

379
00:18:35,986 --> 00:18:37,396 A:middle
and performance is the reason.

380
00:18:37,896 --> 00:18:41,326 A:middle
Of course, it's a security risk
to be loading third-party code

381
00:18:41,326 --> 00:18:46,056 A:middle
into your app, and if it
crashes inside your app,

382
00:18:46,406 --> 00:18:48,796 A:middle
then users might
blame you instead

383
00:18:48,796 --> 00:18:50,076 A:middle
of the misbehaving plug-in.

384
00:18:51,516 --> 00:18:54,316 A:middle
But on the other hand, we
have performance reasons

385
00:18:54,316 --> 00:18:57,836 A:middle
where you may want to load
plug-ins into your process

386
00:18:57,836 --> 00:19:00,656 A:middle
if you are a host, because
there is some overhead

387

388
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

389
00:18:57,836 --> 00:19:00,656 A:middle
if you are a host, because
there is some overhead

390
00:19:00,766 --> 00:19:03,176 A:middle
to communicating with
that separate extension

391
00:19:03,176 --> 00:19:04,256 A:middle
service process.

392
00:19:04,856 --> 00:19:07,056 A:middle
And we have measured that
as being on the order

393
00:19:07,056 --> 00:19:09,326 A:middle
of 40 seconds microseconds
per render cycle ,

394
00:19:09,326 --> 00:19:13,146 A:middle
o you can do the math to figure
out how significant that is

395
00:19:13,146 --> 00:19:14,796 A:middle
in the context of your host.

396
00:19:15,356 --> 00:19:16,446 A:middle
You have some number

397
00:19:16,446 --> 00:19:19,526 A:middle
of out-of-process plug-ins you
might be communicating with,

398
00:19:20,066 --> 00:19:21,676 A:middle
so you have to add that up.

399
00:19:22,236 --> 00:19:23,626 A:middle
And there is also the factor

400
00:19:23,626 --> 00:19:26,856 A:middle
of how much audio you are
asking them to render.

401
00:19:27,656 --> 00:19:30,436 A:middle
For example, if you are
rendering at a very low latency

402
00:19:30,436 --> 00:19:33,676 A:middle
of 32 frames, that's a 1
millisecond render interval,

403
00:19:34,016 --> 00:19:37,196 A:middle
so overhead of 40 microseconds
could be significant

404
00:19:37,196 --> 00:19:38,496 A:middle
at 5.5 percent.

405
00:19:39,096 --> 00:19:43,226 A:middle
So that's your tradeoff
if you are a host author.

406
00:19:44,996 --> 00:19:45,896 A:middle
I mentioned earlier

407
00:19:45,896 --> 00:19:49,486 A:middle
that existing version 2 Audio
Unit hosts need a few changes

408
00:19:49,856 --> 00:19:52,146 A:middle
to work with version
3 Audio Units,

409
00:19:52,146 --> 00:19:53,986 A:middle
and here is what has to change.

410
00:19:55,226 --> 00:19:58,556 A:middle
I mentioned the audio
component description flags,

411
00:19:59,166 --> 00:20:01,186 A:middle
and in there, the
component flags.

412

413
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

414
00:19:59,166 --> 00:20:01,186 A:middle
and in there, the
component flags.

415
00:20:01,186 --> 00:20:04,646 A:middle
There is a new flag called
Requires Async Instantiation.

416
00:20:05,236 --> 00:20:09,566 A:middle
That's set for most if not
all new version 3 Audio Units,

417
00:20:10,006 --> 00:20:12,916 A:middle
so if you see that flag set
in the component description,

418
00:20:12,916 --> 00:20:16,556 A:middle
you have to use the new Audio
Component Instantiate method

419
00:20:16,936 --> 00:20:19,006 A:middle
instead of Audio
Component Instance New.

420
00:20:21,026 --> 00:20:23,746 A:middle
Now, similarly in an
existing v ersion 2 host,

421
00:20:24,386 --> 00:20:27,356 A:middle
if you want to access an
Audio Unit's View Controller,

422
00:20:28,146 --> 00:20:31,686 A:middle
then you also need to use a new
asynchronous method to do that.

423
00:20:32,096 --> 00:20:34,806 A:middle
There is a new property,
Request View Controller.

424
00:20:35,266 --> 00:20:36,546 A:middle
It is also asynchronous.

425
00:20:36,546 --> 00:20:38,906 A:middle
You can read about
the details of that

426
00:20:39,116 --> 00:20:41,226 A:middle
in Audio Unit properties.h.

427
00:20:43,606 --> 00:20:46,186 A:middle
So about these asynchronous
methods.

428
00:20:46,566 --> 00:20:49,886 A:middle
You can use the new methods
with version 2 units,

429
00:20:49,996 --> 00:20:53,616 A:middle
but you must use them
with version 3 units

430
00:20:53,616 --> 00:20:56,196 A:middle
when the flags are set.

431
00:20:56,196 --> 00:20:58,836 A:middle
And the reasoning here,
well, the big sort

432
00:20:58,836 --> 00:21:01,926 A:middle
of externally facing reason is
that it helps responsiveness.

433

434
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

435
00:20:58,836 --> 00:21:01,926 A:middle
of externally facing reason is
that it helps responsiveness.

436
00:21:02,236 --> 00:21:04,986 A:middle
If it's going to take half
a second to instantiate

437
00:21:04,986 --> 00:21:08,576 A:middle
that Audio Unit, well, if
you unblock the main thread,

438
00:21:09,186 --> 00:21:10,986 A:middle
your host applications, meters,

439
00:21:10,986 --> 00:21:13,306 A:middle
or other animations will
keep drawing smoothly.

440
00:21:14,446 --> 00:21:16,976 A:middle
Now, especially when
updating existing code --

441
00:21:16,976 --> 00:21:18,336 A:middle
and this was the
first thing I did

442
00:21:18,336 --> 00:21:23,506 A:middle
when testing internal test code
-- it's tempting to sit there

443
00:21:23,506 --> 00:21:24,756 A:middle
and wait on the main thread

444
00:21:24,756 --> 00:21:27,056 A:middle
for the asynchronous
operation to complete.

445
00:21:27,736 --> 00:21:31,906 A:middle
Well, don't do that, because not
only will you block any graphics

446
00:21:31,906 --> 00:21:35,786 A:middle
you are doing, but you will also
block some underlying operations

447
00:21:35,786 --> 00:21:38,226 A:middle
in the framework that
are actually required

448
00:21:38,226 --> 00:21:40,956 A:middle
for the Audio Unit
to be instantiated.

449
00:21:41,376 --> 00:21:43,756 A:middle
So you will deadlock if you
block on the main thread.

450
00:21:43,966 --> 00:21:47,546 A:middle
Don't do that.

451
00:21:47,546 --> 00:21:49,476 A:middle
Now, I would like to
switch gears from talking

452
00:21:49,476 --> 00:21:53,006 A:middle
about hosting Audio Units
to creating Audio Units

453
00:21:53,006 --> 00:21:54,976 A:middle
with the new version 3 API.

454
00:21:57,316 --> 00:21:59,776 A:middle
First, a few words
about app extensions

455
00:21:59,826 --> 00:22:04,246 A:middle
since the new Audio Unit model
is based on app extensions.

456

457
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

458
00:21:59,826 --> 00:22:04,246 A:middle
since the new Audio Unit model
is based on app extensions.

459
00:22:05,466 --> 00:22:09,986 A:middle
App extensions are bundles with
a file type extension of .appex.

460
00:22:10,366 --> 00:22:13,606 A:middle
Xcode will build them into
an app's plug-ins directory,

461
00:22:14,026 --> 00:22:18,496 A:middle
and we saw how they get
loaded by the system

462
00:22:18,896 --> 00:22:21,526 A:middle
into separate extension
service processes.

463
00:22:22,206 --> 00:22:26,326 A:middle
You can read all about the nuts
and bolts of app extensions

464
00:22:26,586 --> 00:22:28,476 A:middle
in the app extension
programming guide.

465
00:22:31,206 --> 00:22:35,496 A:middle
Now, our new sample code
project, Audio Unit v3 Example,

466
00:22:35,956 --> 00:22:39,206 A:middle
contains a sample Audio
Unit implementation called

467
00:22:39,206 --> 00:22:39,916 A:middle
Filter Demo.

468
00:22:42,656 --> 00:22:44,106 A:middle
Filter Demo, when you look

469
00:22:44,106 --> 00:22:46,816 A:middle
at that sample project,
has three targets.

470
00:22:47,306 --> 00:22:49,316 A:middle
It has what we call
the containing app,

471
00:22:50,076 --> 00:22:54,556 A:middle
and what it contains is the app
extension as well as a framework

472
00:22:55,136 --> 00:22:58,506 A:middle
where a lot of its
common code exists.

473
00:22:58,616 --> 00:23:01,806 A:middle
Both the app and the extension
link against this framework.

474

475
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

476
00:22:58,616 --> 00:23:01,806 A:middle
Both the app and the extension
link against this framework.

477
00:23:03,486 --> 00:23:06,756 A:middle
Now, inside this framework,
we have two main classes.

478
00:23:07,126 --> 00:23:08,866 A:middle
There is AU v3 Filter Demo,

479
00:23:08,866 --> 00:23:11,436 A:middle
that's the AU Audio
Unit subclass,

480
00:23:11,706 --> 00:23:13,936 A:middle
and the Filter Demo
View Controller

481
00:23:14,766 --> 00:23:20,076 A:middle
that controls the custom
view of the Audio Unit.

482
00:23:20,486 --> 00:23:23,276 A:middle
Now, what's cool about
doing things this way is

483
00:23:23,336 --> 00:23:26,916 A:middle
that while we are developing our
signal processing and view code,

484
00:23:27,356 --> 00:23:30,016 A:middle
we can do this all in the
context of our own app

485
00:23:30,816 --> 00:23:34,676 A:middle
so we are debugging not in a
separate SPC service process,

486
00:23:35,116 --> 00:23:35,996 A:middle
but we are debugging

487
00:23:35,996 --> 00:23:38,466 A:middle
and developing our code
right there interactively

488
00:23:38,726 --> 00:23:39,456 A:middle
in our own app.

489
00:23:40,536 --> 00:23:43,516 A:middle
We also let our app
look like something

490
00:23:43,516 --> 00:23:44,666 A:middle
when the user opens it.

491
00:23:44,666 --> 00:23:46,636 A:middle
It's not just a plug-in
for somebody else.

492
00:23:47,136 --> 00:23:49,976 A:middle
And we are not duplicating
any code

493
00:23:49,976 --> 00:23:51,286 A:middle
to be able to accomplish that.

494
00:23:52,446 --> 00:23:57,246 A:middle
There is one extra bonus here
that on OS X, if we want to,

495
00:23:57,786 --> 00:24:00,516 A:middle
we can designate this
framework as being the bundle

496

497
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

498
00:23:57,786 --> 00:24:00,516 A:middle
we can designate this
framework as being the bundle

499
00:24:00,716 --> 00:24:03,326 A:middle
that a host process
can load into itself.

500
00:24:03,946 --> 00:24:09,146 A:middle
So let's look at
the app extension.

501
00:24:09,146 --> 00:24:11,936 A:middle
It has an info plist
with important entries.

502
00:24:12,336 --> 00:24:15,516 A:middle
The NSExtensionPointIdentifier
tells the system what kind

503
00:24:15,516 --> 00:24:18,986 A:middle
of extension it is, the main
storyboard tells the system,

504
00:24:19,396 --> 00:24:22,276 A:middle
when you launch my
extension service process,

505
00:24:22,716 --> 00:24:23,946 A:middle
open the storyboard.

506
00:24:25,206 --> 00:24:28,086 A:middle
And finally, there is an
Audio Components array

507
00:24:28,396 --> 00:24:32,136 A:middle
that tells the system, here are
the audio component descriptions

508
00:24:32,656 --> 00:24:33,716 A:middle
that I am registering.

509
00:24:37,306 --> 00:24:40,626 A:middle
Just a quick reminder here, in
your storyboard, you will want

510
00:24:40,666 --> 00:24:44,506 A:middle
to be sure to specify
your custom class.

511
00:24:44,666 --> 00:24:47,496 A:middle
You may need to specify the
module if you are building it

512
00:24:47,496 --> 00:24:49,336 A:middle
into a separate framework
like we are here.

513
00:24:50,476 --> 00:24:53,326 A:middle
Then the extension actually
has no code in it other

514
00:24:53,326 --> 00:24:54,676 A:middle
than this little
bit of dummy code

515
00:24:54,676 --> 00:24:56,186 A:middle
to keep it from being empty.

516
00:24:56,876 --> 00:24:59,076 A:middle
We have to link against
the Filter Demo framework.

517
00:24:59,176 --> 00:25:00,366 A:middle
All of the good stuff
is in there,

518

519
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

520
00:24:59,176 --> 00:25:00,366 A:middle
All of the good stuff
is in there,

521
00:25:00,906 --> 00:25:05,656 A:middle
and here we just have a global
variable referring to it.

522
00:25:06,386 --> 00:25:07,936 A:middle
Let's move onto the
framework now.

523
00:25:09,366 --> 00:25:10,666 A:middle
So the main class

524
00:25:10,666 --> 00:25:13,306 A:middle
in the framework is the
Filter Demo View Controller.

525
00:25:13,826 --> 00:25:15,436 A:middle
In extension terminology,

526
00:25:15,436 --> 00:25:17,316 A:middle
this is the extension's
principal class.

527
00:25:17,736 --> 00:25:20,526 A:middle
Whenever the extension
is created or loaded,

528
00:25:20,926 --> 00:25:22,896 A:middle
the system will create
an instance

529
00:25:22,896 --> 00:25:24,586 A:middle
of that principal class.

530
00:25:25,136 --> 00:25:26,596 A:middle
And it's got two main jobs.

531
00:25:26,886 --> 00:25:30,796 A:middle
It in turn creates the AU
Audio Unit subclass and,

532
00:25:30,876 --> 00:25:33,526 A:middle
as a View Controller as you
would expect, it creates

533
00:25:33,526 --> 00:25:36,296 A:middle
and manages the plug-ins
custom view.

534
00:25:38,436 --> 00:25:39,896 A:middle
Here is the class declaration

535
00:25:39,896 --> 00:25:41,526 A:middle
for the Filter Demo
View Controller.

536
00:25:42,226 --> 00:25:44,886 A:middle
It derives from AU
View Controller,

537
00:25:45,566 --> 00:25:48,656 A:middle
which is either an NS or UI
View Controller basically,

538
00:25:49,386 --> 00:25:52,396 A:middle
and it also implements a
protocol called AU Audio

539
00:25:52,396 --> 00:25:53,426 A:middle
Unit factory.

540
00:25:53,916 --> 00:25:57,516 A:middle
That's a simple protocol and
implements exactly one method,

541
00:25:59,056 --> 00:26:01,236 A:middle
Create Audio Unit with
Component Description.

542

543
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

544
00:25:59,056 --> 00:26:01,236 A:middle
Create Audio Unit with
Component Description.

545
00:26:02,546 --> 00:26:04,756 A:middle
And the job of this method is

546
00:26:04,756 --> 00:26:07,266 A:middle
to create the AU
Audio Unit subclass.

547
00:26:08,706 --> 00:26:12,466 A:middle
And here it is, the
AU v3 Filter Demo.

548
00:26:14,606 --> 00:26:17,566 A:middle
Now, let's look at that
AU Audio Unit subclass.

549
00:26:18,236 --> 00:26:22,486 A:middle
So for reasons we will
get into in a bit,

550
00:26:22,946 --> 00:26:27,946 A:middle
these are actually embedded
C++ classes or objects.

551
00:26:28,006 --> 00:26:31,396 A:middle
The filter DSP kernel is
where all of the math happens.

552
00:26:33,256 --> 00:26:34,186 A:middle
We will listen to it later.

553
00:26:34,186 --> 00:26:37,836 A:middle
It's a little more interesting
than looking at its code.

554
00:26:37,936 --> 00:26:42,806 A:middle
We have some code here
dealing with the buses.

555
00:26:43,136 --> 00:26:43,896 A:middle
This is an effect.

556
00:26:43,896 --> 00:26:47,656 A:middle
It has one input and one output,
and our base class is going

557
00:26:47,656 --> 00:26:51,006 A:middle
to want us to provide
arrays of buses

558
00:26:51,126 --> 00:26:52,736 A:middle
so we have numbers
to support that.

559
00:26:53,176 --> 00:26:55,446 A:middle
And we have something
called a parameter tree.

560
00:26:55,516 --> 00:26:57,916 A:middle
We will see what that
is in just a second.

561
00:26:58,476 --> 00:26:59,496 A:middle
Here is the initializer.

562

563
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

564
00:27:00,586 --> 00:27:03,196 A:middle
So the first thing we do
is initialize our input

565
00:27:03,196 --> 00:27:07,606 A:middle
and output buses, and then
we wrap them in bus arrays.

566
00:27:09,086 --> 00:27:12,136 A:middle
And these arrays each
contain a single bus.

567
00:27:16,346 --> 00:27:18,346 A:middle
And now we are looking
at parameters.

568
00:27:18,946 --> 00:27:23,446 A:middle
So every parameter is an object,
and you can think of this object

569
00:27:23,446 --> 00:27:26,356 A:middle
as kind of the bridge
between your implementation

570
00:27:26,716 --> 00:27:27,436 A:middle
and the host.

571
00:27:27,436 --> 00:27:30,516 A:middle
In the middle, there is
the parameter object.

572
00:27:30,896 --> 00:27:32,486 A:middle
This is a simple
low-pass filter,

573
00:27:32,486 --> 00:27:34,096 A:middle
so it's only got two parameters,

574
00:27:34,356 --> 00:27:36,086 A:middle
a cutoff frequency
and residence.

575
00:27:36,936 --> 00:27:39,146 A:middle
Every parameter has
an identifier,

576
00:27:39,426 --> 00:27:41,176 A:middle
so here we are saying
it's cutoff.

577
00:27:41,176 --> 00:27:42,886 A:middle
It has a localizalbe name.

578
00:27:42,886 --> 00:27:44,806 A:middle
We are being bad and
not localizing it here.

579
00:27:45,616 --> 00:27:47,006 A:middle
It has an address.

580
00:27:47,006 --> 00:27:48,326 A:middle
We will talk about
that in a bit.

581
00:27:48,926 --> 00:27:52,906 A:middle
Arrange, and some units, and
flags which you will recognize

582
00:27:52,906 --> 00:27:55,066 A:middle
as being almost identical
to what we do

583
00:27:55,066 --> 00:27:56,596 A:middle
with version 2 Audio Units.

584
00:27:57,366 --> 00:27:59,366 A:middle
So here we have created
our first parameter.

585
00:27:59,366 --> 00:28:02,726 A:middle
We will create our second
one almost identically.

586

587
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

588
00:27:59,366 --> 00:28:02,726 A:middle
We will create our second
one almost identically.

589
00:28:03,736 --> 00:28:06,656 A:middle
And then finally we can
create our parameter tree,

590
00:28:07,206 --> 00:28:09,736 A:middle
passing an array of
those two parameters.

591
00:28:11,126 --> 00:28:14,976 A:middle
Now, we have our parameter tree,
and we want to wire it up so

592
00:28:14,976 --> 00:28:17,276 A:middle
that it's connected
to our DSP code.

593
00:28:19,126 --> 00:28:21,536 A:middle
And the way we do this
is install a block

594
00:28:21,796 --> 00:28:25,556 A:middle
into the parameter tree called
the Implementer Value Observer.

595
00:28:26,866 --> 00:28:30,276 A:middle
So this block will get
called any time somebody,

596
00:28:30,276 --> 00:28:33,866 A:middle
whether it's the host or our
own view, changes a parameter,

597
00:28:34,556 --> 00:28:37,696 A:middle
And so in response to that
change, we will simply set

598
00:28:37,756 --> 00:28:40,466 A:middle
that new value on
our filter DSP kernel

599
00:28:40,996 --> 00:28:43,286 A:middle
so that it takes
immediate audible effect.

600
00:28:45,576 --> 00:28:47,726 A:middle
Now, in the other
direction, there are times

601
00:28:47,726 --> 00:28:51,536 A:middle
when the tree needs to refresh
its value based on what we have

602
00:28:51,536 --> 00:28:52,756 A:middle
in our signal processing.

603
00:28:53,326 --> 00:28:55,066 A:middle
That's what this block does.

604
00:28:55,636 --> 00:28:59,146 A:middle
It fetches the current
value from the DSP

605
00:28:59,146 --> 00:29:00,766 A:middle
and returns it to the tree.

606

607
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

608
00:28:59,146 --> 00:29:00,766 A:middle
and returns it to the tree.

609
00:29:04,086 --> 00:29:07,066 A:middle
Next, this is an
important override method.

610
00:29:07,586 --> 00:29:09,926 A:middle
If you're familiar with the
version 2 Audio Unit API,

611
00:29:10,136 --> 00:29:12,746 A:middle
this was called Audio
Unit Initialize,

612
00:29:13,866 --> 00:29:17,196 A:middle
which is not a good name choice
in the Objective-C world.

613
00:29:17,676 --> 00:29:19,996 A:middle
So we decided to make
it very specific.

614
00:29:20,946 --> 00:29:25,116 A:middle
What was initialize time
is really prepare to render

615
00:29:25,456 --> 00:29:28,666 A:middle
and allocate the resources that
are associated with rendering.

616
00:29:29,936 --> 00:29:33,636 A:middle
So there are things like
buffers, DSP state, and so on.

617
00:29:34,546 --> 00:29:37,636 A:middle
So the first thing we do here
is called the base class method.

618
00:29:39,126 --> 00:29:42,596 A:middle
Then we can ask our input
bus to allocate some memory

619
00:29:42,786 --> 00:29:44,646 A:middle
for audio input to the plug-in,

620
00:29:45,776 --> 00:29:50,806 A:middle
and we can initialize our signal
processing code here based

621
00:29:50,806 --> 00:29:55,636 A:middle
on the current channel count and
sample rate of the output bus.

622
00:29:58,456 --> 00:30:01,276 A:middle
So entirely parallel, we
have a method that's called

623

624
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

625
00:29:58,456 --> 00:30:01,276 A:middle
So entirely parallel, we
have a method that's called

626
00:30:01,566 --> 00:30:03,496 A:middle
to deallocate render resources.

627
00:30:03,886 --> 00:30:05,746 A:middle
And here, too, we
call the base class

628
00:30:06,106 --> 00:30:09,526 A:middle
and basically undo whatever
we did when allocating.

629
00:30:12,536 --> 00:30:15,886 A:middle
So the process of rendering
works through a block

630
00:30:16,886 --> 00:30:21,406 A:middle
that gets called every render
cycle, but we are asked

631
00:30:21,506 --> 00:30:24,436 A:middle
to provide this block
before starting to render.

632
00:30:25,806 --> 00:30:30,366 A:middle
Here we are going to
capture our C++ members

633
00:30:30,366 --> 00:30:32,586 A:middle
into local variables
that are pointers.

634
00:30:33,236 --> 00:30:37,856 A:middle
Now, the reason for this
is that we are going

635
00:30:38,196 --> 00:30:41,816 A:middle
to be running our block for
rendering in a real-time context

636
00:30:42,296 --> 00:30:46,136 A:middle
where it's not safe to access
any Objective-C objects

637
00:30:46,476 --> 00:30:49,296 A:middle
because the runtime could block
and cause an audio glitch.

638
00:30:50,076 --> 00:30:51,906 A:middle
So, again, we are just going

639
00:30:51,906 --> 00:30:54,696 A:middle
to capture our C++
member variables.

640
00:30:57,406 --> 00:30:58,846 A:middle
And then we can return
the block.

641
00:30:59,936 --> 00:31:02,036 A:middle
It returns AU Audio Unit status.

642

643
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

644
00:30:59,936 --> 00:31:02,036 A:middle
It returns AU Audio Unit status.

645
00:31:03,086 --> 00:31:05,436 A:middle
And if you are familiar
with the version 2 API,

646
00:31:05,606 --> 00:31:07,466 A:middle
the parameters are
largely the same.

647
00:31:07,846 --> 00:31:10,456 A:middle
There is a time stamp, a
number of sample frames,

648
00:31:11,016 --> 00:31:12,486 A:middle
an output audio buffer list,

649
00:31:13,046 --> 00:31:15,906 A:middle
and here is something new called
the real-time event list head.

650
00:31:16,886 --> 00:31:19,786 A:middle
I will talk about that
in detail, but it relates

651
00:31:19,786 --> 00:31:22,576 A:middle
to scheduled parameters
and MIDI events.

652
00:31:25,536 --> 00:31:27,356 A:middle
And finally, the
Pull Input block.

653
00:31:27,896 --> 00:31:31,076 A:middle
This is how the host
tells us, the implementer

654
00:31:31,076 --> 00:31:33,926 A:middle
of the Audio Unit,
where to get input from.

655
00:31:35,596 --> 00:31:37,106 A:middle
So in the guts of
the input block,

656
00:31:37,416 --> 00:31:40,876 A:middle
the first thing we will do
is pass that Pull Input block

657
00:31:41,146 --> 00:31:46,096 A:middle
to our input C++ object
and ask that input object

658
00:31:46,336 --> 00:31:49,476 A:middle
to fetch the audio input
for this render cycle.

659
00:31:51,056 --> 00:31:53,316 A:middle
Then we are going to do some
housekeeping with buffers.

660
00:31:53,316 --> 00:31:58,546 A:middle
We will send them down to
the DSP state, and finally,

661
00:31:59,046 --> 00:32:03,336 A:middle
we ask the DSP state to process
the audio for this render cycle.

662

663
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

664
00:31:59,046 --> 00:32:03,336 A:middle
we ask the DSP state to process
the audio for this render cycle.

665
00:32:04,376 --> 00:32:06,806 A:middle
It's already been
informed of the buffers,

666
00:32:06,896 --> 00:32:09,966 A:middle
and we are just going to give it
a time stamp, the frame count,

667
00:32:10,176 --> 00:32:12,426 A:middle
and the linked list
of real-time events.

668
00:32:12,896 --> 00:32:15,636 A:middle
So that's the guts
of this Audio Unit,

669
00:32:15,636 --> 00:32:16,636 A:middle
there is not a whole
lot of code.

670
00:32:16,636 --> 00:32:18,006 A:middle
There is a lot more code

671
00:32:18,006 --> 00:32:19,766 A:middle
that does the actual
signal processing,

672
00:32:20,366 --> 00:32:23,046 A:middle
but as I mentioned before,
it's better to listen

673
00:32:23,046 --> 00:32:24,076 A:middle
to that than to look at it.

674
00:32:24,076 --> 00:32:25,736 A:middle
So I would like to bring
Michael Hopkins back

675
00:32:25,736 --> 00:32:29,326 A:middle
up to show us the
AU v3 Filter Demo.

676
00:32:31,316 --> 00:32:32,906 A:middle
>> MICHAEL HOPKINS:
Thank you, Doug.

677
00:32:33,516 --> 00:32:39,836 A:middle
[Applause]

678
00:32:40,336 --> 00:32:44,316 A:middle
I'm going to go ahead and
start with the app container

679
00:32:44,316 --> 00:32:46,056 A:middle
that contains the extension.

680
00:32:46,906 --> 00:32:49,686 A:middle
You will see first on the screen

681
00:32:49,686 --> 00:32:51,916 A:middle
in the left-hand side
is our Filter Demo,

682
00:32:52,286 --> 00:32:54,156 A:middle
which we have distributed
as sample code.

683
00:32:54,676 --> 00:32:58,166 A:middle
To the right of it is the
distortion demo application

684
00:32:58,166 --> 00:32:59,296 A:middle
that I showed you earlier.

685
00:32:59,896 --> 00:33:02,026 A:middle
I will go ahead and
launch the Filter Demo.

686

687
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

688
00:32:59,896 --> 00:33:02,026 A:middle
I will go ahead and
launch the Filter Demo.

689
00:33:03,236 --> 00:33:04,966 A:middle
Now, at the top of the screen,

690
00:33:04,966 --> 00:33:06,416 A:middle
you will notice the
two parameters

691
00:33:06,416 --> 00:33:07,656 A:middle
that Doug talked about.

692
00:33:08,116 --> 00:33:10,406 A:middle
We have the cutoff in
the residence parameter,

693
00:33:10,866 --> 00:33:12,766 A:middle
and these are represented
in our UI

694
00:33:12,766 --> 00:33:14,836 A:middle
with a slider and a text field.

695
00:33:15,326 --> 00:33:18,406 A:middle
And this portion of the
UI is actually contained

696
00:33:18,406 --> 00:33:22,686 A:middle
in the application, whereas the
larger area in the main screen

697
00:33:22,686 --> 00:33:26,146 A:middle
with the graph is
actually our embedded view

698
00:33:26,546 --> 00:33:28,636 A:middle
from the Audio Unit.

699
00:33:29,066 --> 00:33:32,816 A:middle
I can go ahead and change
the value of the parameters

700
00:33:32,816 --> 00:33:34,186 A:middle
by dragging the slider.

701
00:33:35,006 --> 00:33:38,596 A:middle
And what's happening here is
the application is changing the

702
00:33:38,596 --> 00:33:39,936 A:middle
value of that parameter.

703
00:33:40,446 --> 00:33:43,866 A:middle
And the view is listening for
changes to that parameter,

704
00:33:43,866 --> 00:33:44,866 A:middle
and then it's updating.

705
00:33:45,586 --> 00:33:47,856 A:middle
As you will see,
that update is live.

706
00:33:48,536 --> 00:33:50,866 A:middle
Conversely, I can
interact directly

707
00:33:50,866 --> 00:33:54,386 A:middle
with our embedded Audio
Unit view by tapping

708
00:33:54,386 --> 00:33:55,726 A:middle
in the graph and dragging.

709
00:33:56,046 --> 00:33:58,746 A:middle
And you will notice that as
I drag that with my finger,

710
00:33:58,746 --> 00:34:01,206 A:middle
the application is
receiving notifications

711

712
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

713
00:33:58,746 --> 00:34:01,206 A:middle
the application is
receiving notifications

714
00:34:01,206 --> 00:34:04,496 A:middle
that the parameters have changed
and it's updating in turn.

715
00:34:04,856 --> 00:34:08,396 A:middle
But that's kind of a boring
demo without any audio going

716
00:34:08,396 --> 00:34:09,286 A:middle
through it, wouldn't you say?

717
00:34:09,976 --> 00:34:12,286 A:middle
Let's go ahead and
take a listen to that.

718
00:34:14,516 --> 00:34:29,746 A:middle
[Music]

719
00:34:30,246 --> 00:34:31,976 A:middle
I could do this all day.

720
00:34:32,085 --> 00:34:32,735 A:middle
You got time?

721
00:34:34,996 --> 00:34:40,085 A:middle
Now, it's really, really
cool to just, the fluidity.

722
00:34:40,545 --> 00:34:41,146 A:middle
Thank you.

723
00:34:41,255 --> 00:34:44,596 A:middle
Just how fun it is to use your
fingers to just be able to play

724
00:34:44,596 --> 00:34:45,956 A:middle
with that in a Multi-Touch UI.

725
00:34:46,446 --> 00:34:47,616 A:middle
It's phenomenal.

726
00:34:47,696 --> 00:34:51,545 A:middle
Another thing that's
cool about this is

727
00:34:51,545 --> 00:34:55,766 A:middle
because we have designed the
user interface in such a way

728
00:34:55,766 --> 00:35:00,006 A:middle
that it can adapt to any
size that it's embedded in,

729

730
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

731
00:34:55,766 --> 00:35:00,006 A:middle
that it can adapt to any
size that it's embedded in,

732
00:35:00,466 --> 00:35:04,586 A:middle
we can actually take this iPad
and we can rotate it sideways,

733
00:35:04,586 --> 00:35:07,616 A:middle
and you can see that now the
user interface is updated.

734
00:35:07,956 --> 00:35:12,366 A:middle
And from a portrait view to a
landscape view, and vice versa.

735
00:35:14,566 --> 00:35:17,886 A:middle
Now, we are doing that because
we are supporting Auto Layout

736
00:35:17,886 --> 00:35:20,866 A:middle
and we are looking at size
classes, so that's really great.

737
00:35:20,866 --> 00:35:23,806 A:middle
But what happens when we go
and we take this and we put it

738
00:35:23,806 --> 00:35:26,156 A:middle
into our host app, which
has a much smaller amount

739
00:35:26,156 --> 00:35:29,236 A:middle
of screen real estate
dedicated to plug-ins?

740
00:35:30,076 --> 00:35:33,246 A:middle
So I will go ahead and
switch back, and we are going

741
00:35:33,246 --> 00:35:34,396 A:middle
to open the host there.

742
00:35:34,536 --> 00:35:37,416 A:middle
I'm going to get rid of the
beautiful distortion demo

743
00:35:37,516 --> 00:35:40,436 A:middle
and embed our Filter Demo view.

744
00:35:40,466 --> 00:35:41,846 A:middle
Tap on View to load that.

745
00:35:42,276 --> 00:35:43,986 A:middle
And now you can see
that that's being loaded

746
00:35:43,986 --> 00:35:50,096 A:middle
in a constrained vertical space
and a very wide horizontal space

747
00:35:50,636 --> 00:35:52,586 A:middle
yet it still works
as you would expect,

748
00:35:52,586 --> 00:35:55,806 A:middle
and none of the labels overlap.

749
00:35:56,176 --> 00:36:00,606 A:middle
It still works exactly
as we would expect.

750

751
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

752
00:35:56,176 --> 00:36:00,606 A:middle
It still works exactly
as we would expect.

753
00:36:02,156 --> 00:36:04,186 A:middle
So this is a fantastic
new technology,

754
00:36:04,186 --> 00:36:06,926 A:middle
and we are so excited to be able
to finally bring it to you guys

755
00:36:07,216 --> 00:36:10,996 A:middle
and I can't wait to see what
do in your own iOS apps.

756
00:36:11,676 --> 00:36:11,976 A:middle
Thank you.

757
00:36:12,516 --> 00:36:15,616 A:middle
[Applause]

758
00:36:16,116 --> 00:36:17,356 A:middle
>> DOUG WYATT: Thank
you, Michael.

759
00:36:18,926 --> 00:36:24,126 A:middle
Just a few words now about
the containing app in general.

760
00:36:24,746 --> 00:36:27,146 A:middle
It is a vehicle for your
plug-in and helps you

761
00:36:27,146 --> 00:36:30,826 A:middle
with rapid iteration and
development, but you can think

762
00:36:30,826 --> 00:36:33,556 A:middle
about putting some extra
things in that containing app.

763
00:36:34,076 --> 00:36:36,886 A:middle
We saw with the Filter Demo that
it has the simple play engine,

764
00:36:37,376 --> 00:36:40,526 A:middle
you may for whatever reason
want a more complex play engine

765
00:36:40,526 --> 00:36:41,146 A:middle
of some sort.

766
00:36:41,496 --> 00:36:44,396 A:middle
This is also a good
place, the containing app,

767
00:36:44,466 --> 00:36:47,556 A:middle
to try putting creative
touch controller.

768
00:36:47,826 --> 00:36:49,736 A:middle
There may not be room
in a plug-in view

769
00:36:50,036 --> 00:36:51,286 A:middle
for your full touch controller.

770
00:36:51,356 --> 00:36:54,936 A:middle
Maybe there is, but you might
think about having extra,

771
00:36:55,336 --> 00:36:56,866 A:middle
an extra-large version
or something

772
00:36:56,866 --> 00:36:57,906 A:middle
in your containing app.

773
00:36:58,786 --> 00:37:02,186 A:middle
The app is also a good place
for any documentation or help

774

775
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

776
00:36:58,786 --> 00:37:02,186 A:middle
The app is also a good place
for any documentation or help

777
00:37:02,726 --> 00:37:07,466 A:middle
that would make the
plug-in view a little dense.

778
00:37:08,266 --> 00:37:11,246 A:middle
A few final words about
creating an app extension here.

779
00:37:11,856 --> 00:37:14,696 A:middle
So if you are going to build
a framework to be loaded

780
00:37:14,696 --> 00:37:18,926 A:middle
in process on OS X, despite what
we are doing here with Swift,

781
00:37:19,796 --> 00:37:22,676 A:middle
we can't recommend that
you do this on OS X

782
00:37:22,676 --> 00:37:26,136 A:middle
because the Swift API
is subject to change.

783
00:37:26,486 --> 00:37:29,776 A:middle
If you build your plug-in
against one version

784
00:37:29,776 --> 00:37:32,946 A:middle
of the Swift runtime and you are
loaded into a host that happens

785
00:37:32,946 --> 00:37:35,736 A:middle
to be using another version,
there could be collisions,

786
00:37:35,736 --> 00:37:37,716 A:middle
and that would be bad.

787
00:37:38,536 --> 00:37:43,116 A:middle
We realize when you look at the
sample code here and you try

788
00:37:43,116 --> 00:37:45,926 A:middle
to build your own plug-ins,
there is a lot, you know,

789
00:37:45,926 --> 00:37:48,906 A:middle
there is three related targets
that have to be built properly.

790
00:37:48,906 --> 00:37:50,416 A:middle
It's a little bit complicated.

791
00:37:50,726 --> 00:37:52,746 A:middle
We do plan in Xcode's template,

792
00:37:53,166 --> 00:37:56,056 A:middle
but for now you can copy
liberally from the Filter Demo.

793
00:37:59,026 --> 00:38:02,126 A:middle
Okay. Now I would like
to talk in general

794

795
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

796
00:37:59,026 --> 00:38:02,126 A:middle
Okay. Now I would like
to talk in general

797
00:38:02,126 --> 00:38:07,126 A:middle
about the modernized AU Audio
Unit API from both the host

798
00:38:07,326 --> 00:38:09,556 A:middle
and the implementation sides.

799
00:38:09,556 --> 00:38:15,556 A:middle
I would like to compare the
way that properties are handled

800
00:38:15,556 --> 00:38:17,986 A:middle
in version 2 versus version 3.

801
00:38:18,616 --> 00:38:22,126 A:middle
In version 2 Audio Unit
API, we have scope-

802
00:38:22,126 --> 00:38:23,716 A:middle
and element-based properties.

803
00:38:24,196 --> 00:38:26,996 A:middle
A large number of properties
are in the global scope

804
00:38:26,996 --> 00:38:29,006 A:middle
so you have a bunch of
code where you type.

805
00:38:29,306 --> 00:38:32,266 A:middle
K Audio Unit scope
global, element 0.

806
00:38:34,256 --> 00:38:37,146 A:middle
And it's painful,
especially from Swift,

807
00:38:37,776 --> 00:38:41,376 A:middle
where we have property values
that are void pointers.

808
00:38:41,916 --> 00:38:44,996 A:middle
You end up typing unsafe mutable
pointer all over the place,

809
00:38:44,996 --> 00:38:46,566 A:middle
and that makes my head hurt.

810
00:38:47,316 --> 00:38:50,736 A:middle
We have these functions
with long argument lists.

811
00:38:52,486 --> 00:38:55,806 A:middle
And by comparison in
the version 3 API, well,

812
00:38:55,806 --> 00:38:57,116 A:middle
properties are properties.

813
00:38:57,926 --> 00:39:00,796 A:middle
We use a dot syntax in
Objective-C and Swift,

814

815
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

816
00:38:57,926 --> 00:39:00,796 A:middle
We use a dot syntax in
Objective-C and Swift,

817
00:39:00,796 --> 00:39:04,166 A:middle
so you can write
AU.maximum frames to render.

818
00:39:05,106 --> 00:39:09,656 A:middle
We also implement our
classes to be key-value coding

819
00:39:09,656 --> 00:39:12,966 A:middle
and key-value observing
compliant so you can use value

820
00:39:12,966 --> 00:39:15,796 A:middle
for key, and add
observer for key path.

821
00:39:16,806 --> 00:39:20,306 A:middle
We also added a special KVO
method to the bus array,

822
00:39:20,656 --> 00:39:23,116 A:middle
add observer to all
buses, so you don't have

823
00:39:23,116 --> 00:39:27,056 A:middle
to simultaneously be watching
for buses to come and go just

824
00:39:27,056 --> 00:39:30,076 A:middle
so that you can add
KVO observers on them.

825
00:39:30,556 --> 00:39:34,176 A:middle
That can be a painful
cycle to chase.

826
00:39:35,756 --> 00:39:38,626 A:middle
Speaking of buses, they
are full-fledged objects

827
00:39:38,626 --> 00:39:40,036 A:middle
in the new API.

828
00:39:40,036 --> 00:39:42,706 A:middle
We have the AU Audio
Unit bus array.

829
00:39:42,786 --> 00:39:46,186 A:middle
The AU Audio Unit has
an array of input buses,

830
00:39:46,186 --> 00:39:47,516 A:middle
an array of output buses.

831
00:39:48,686 --> 00:39:51,296 A:middle
And the buses have
two major properties.

832
00:39:51,706 --> 00:39:54,016 A:middle
They have a format and a name.

833
00:39:54,526 --> 00:39:58,286 A:middle
The format is manipulated
by the host.

834
00:39:58,666 --> 00:40:01,436 A:middle
We are able to reject
formats that we don't like.

835

836
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

837
00:39:58,666 --> 00:40:01,436 A:middle
We are able to reject
formats that we don't like.

838
00:40:01,436 --> 00:40:02,786 A:middle
We use the same formats

839
00:40:02,786 --> 00:40:04,906 A:middle
in version 3 Audio
Units as version 2.

840
00:40:08,296 --> 00:40:09,486 A:middle
Let's look at parameters.

841
00:40:09,486 --> 00:40:11,286 A:middle
We have some of the
same problems here

842
00:40:11,396 --> 00:40:14,116 A:middle
in the version 2
API with parameters

843
00:40:14,116 --> 00:40:15,346 A:middle
as we did with properties.

844
00:40:15,836 --> 00:40:18,846 A:middle
We have these unwieldy
scope element ID tuples.

845
00:40:18,846 --> 00:40:22,886 A:middle
And furthermore, in some very
complex AUs we just didn't have

846
00:40:22,886 --> 00:40:23,626 A:middle
enough bits.

847
00:40:24,536 --> 00:40:27,466 A:middle
We have these functions with
long argument lists again,

848
00:40:27,866 --> 00:40:30,666 A:middle
and we also have a complicated
AU event listener API.

849
00:40:33,566 --> 00:40:36,506 A:middle
In the version 3 API, I
hinted at this earlier

850
00:40:38,056 --> 00:40:40,326 A:middle
with the parameter tree
and the Filter Demo.

851
00:40:40,696 --> 00:40:42,146 A:middle
Well, it is a full tree.

852
00:40:42,246 --> 00:40:45,776 A:middle
Parameters can be grouped,
and here we have an example

853
00:40:45,776 --> 00:40:48,576 A:middle
of a simple analog
synthesizer emulation.

854
00:40:48,916 --> 00:40:51,436 A:middle
It has groups for oscillator,
filter, and amplifier.

855
00:40:51,916 --> 00:40:55,566 A:middle
The filter and amplifier have
envelope groups beneath them.

856
00:40:55,866 --> 00:40:58,896 A:middle
And the most brightly
colored boxes beneath are

857
00:40:58,896 --> 00:40:59,716 A:middle
the parameters.

858

859
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

860
00:41:00,266 --> 00:41:03,326 A:middle
So the waveform octave,
filter cutoff and resonance,

861
00:41:03,326 --> 00:41:06,266 A:middle
and the envelope attack,
sustain, and release.

862
00:41:07,226 --> 00:41:10,606 A:middle
So these boxes are all nodes,
whether they are groups

863
00:41:10,606 --> 00:41:12,896 A:middle
or parameters, and every node

864
00:41:12,896 --> 00:41:17,136 A:middle
in the parameter tree has
a unique and permanent ID.

865
00:41:17,136 --> 00:41:19,816 A:middle
This is like a C identifier.

866
00:41:21,436 --> 00:41:25,496 A:middle
So using these unique
IDs, we can use KVC to go

867
00:41:25,496 --> 00:41:27,456 A:middle
and find a parameter
we are looking for,

868
00:41:27,796 --> 00:41:32,176 A:middle
such as oscillator.wave
or filter.envelope.attack.

869
00:41:32,586 --> 00:41:34,816 A:middle
And this would be
a lot more flexible

870
00:41:34,816 --> 00:41:37,096 A:middle
for these very complex
audio units

871
00:41:37,096 --> 00:41:39,506 A:middle
that have very large
parameter trees.

872
00:41:40,526 --> 00:41:41,626 A:middle
Now, you will notice

873
00:41:41,676 --> 00:41:44,146 A:middle
that parameters have
numeric addresses

874
00:41:44,266 --> 00:41:48,296 A:middle
and that they are 64 bits,
but we do have to treat them

875
00:41:48,296 --> 00:41:53,306 A:middle
as transient in any situation
where we aren't the one who made

876
00:41:53,306 --> 00:41:54,586 A:middle
up that addressing scheme.

877
00:41:56,946 --> 00:42:00,156 A:middle
So that means if I'm a
host application and I want

878

879
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

880
00:41:56,946 --> 00:42:00,156 A:middle
So that means if I'm a
host application and I want

881
00:42:00,156 --> 00:42:03,196 A:middle
to record some parameter
automation, I should record

882
00:42:03,196 --> 00:42:06,556 A:middle
that automation using
the key value path --

883
00:42:07,106 --> 00:42:10,656 A:middle
I'm sorry, the key path of that
parameter and not its address.

884
00:42:11,236 --> 00:42:15,086 A:middle
I alluded to this earlier.

885
00:42:15,796 --> 00:42:20,256 A:middle
The AU parameter object is
the focus of communication

886
00:42:20,326 --> 00:42:24,116 A:middle
for parameter values
between hosts and views,

887
00:42:24,416 --> 00:42:27,166 A:middle
and on the other side, the
Audio Unit implementations.

888
00:42:29,766 --> 00:42:31,866 A:middle
Now, from the host's
point of view,

889
00:42:32,176 --> 00:42:36,306 A:middle
the parameter object has
properties like its value,

890
00:42:36,306 --> 00:42:38,686 A:middle
also a minimum and
maximum value, and so on.

891
00:42:39,476 --> 00:42:44,126 A:middle
So we can set and get parameter
values using dot notation

892
00:42:44,126 --> 00:42:44,926 A:middle
as you would expect.

893
00:42:45,836 --> 00:42:48,366 A:middle
Now, we can also set
values in such a way

894
00:42:48,366 --> 00:42:52,416 A:middle
to prevent a feedback
loop, which is useful both

895
00:42:52,446 --> 00:42:56,256 A:middle
for performance and for
keeping the UI smooth.

896
00:42:56,396 --> 00:42:58,536 A:middle
We don't want to be
getting notifications

897
00:42:58,536 --> 00:42:59,556 A:middle
that are slightly different

898
00:42:59,626 --> 00:43:02,196 A:middle
from what we are doing
as we move a slider.

899

900
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

901
00:42:59,626 --> 00:43:02,196 A:middle
from what we are doing
as we move a slider.

902
00:43:02,646 --> 00:43:06,486 A:middle
So the set value method
accomplishes that.

903
00:43:07,396 --> 00:43:12,686 A:middle
And that token is obtained from
a method to add an observer

904
00:43:12,686 --> 00:43:15,856 A:middle
to a parameter, or its tree,
or a group in the tree.

905
00:43:16,866 --> 00:43:19,056 A:middle
And when we do that, then
we can get called back

906
00:43:19,056 --> 00:43:19,936 A:middle
from the parameter.

907
00:43:19,936 --> 00:43:21,326 A:middle
That's what we see
at the bottom there.

908
00:43:21,836 --> 00:43:24,386 A:middle
There is the block called
the AU parameter observer,

909
00:43:24,866 --> 00:43:27,996 A:middle
and it passes us the
address and the new value

910
00:43:27,996 --> 00:43:29,316 A:middle
of the parameter that changed.

911
00:43:29,876 --> 00:43:35,586 A:middle
As for the implementation, we
saw this in the Filter Demo.

912
00:43:36,046 --> 00:43:38,176 A:middle
It has the implementer
value observer

913
00:43:38,416 --> 00:43:40,106 A:middle
and value provider blocks.

914
00:43:40,736 --> 00:43:42,256 A:middle
Now, in Filter Demo,

915
00:43:42,256 --> 00:43:44,356 A:middle
it installed these
blocks on the tree.

916
00:43:44,516 --> 00:43:48,046 A:middle
It's also possible to install
them at any level of the tree,

917
00:43:48,466 --> 00:43:50,096 A:middle
even on individual parameters.

918
00:43:50,926 --> 00:43:56,776 A:middle
I would also like to show
off what we have done

919
00:43:56,776 --> 00:43:57,996 A:middle
with parameter scheduling

920
00:43:57,996 --> 00:43:59,816 A:middle
because I think this
is a big improvement

921

922
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

923
00:44:00,186 --> 00:44:02,346 A:middle
over the version 2
API in this area.

924
00:44:03,726 --> 00:44:06,696 A:middle
We have the host and the
implementation dealing

925
00:44:06,696 --> 00:44:08,226 A:middle
with things somewhat separately,

926
00:44:08,776 --> 00:44:13,406 A:middle
but here we have the AU Audio
Unit base class doing some help,

927
00:44:13,486 --> 00:44:15,246 A:middle
it's helping us implement this.

928
00:44:15,536 --> 00:44:20,456 A:middle
So the host can obtain from the
AU Audio Unit a block called the

929
00:44:20,456 --> 00:44:21,776 A:middle
schedule parameter block.

930
00:44:22,496 --> 00:44:26,696 A:middle
And at render time, it can call
this block to change parameters

931
00:44:26,736 --> 00:44:28,786 A:middle
in sample-accurate way.

932
00:44:29,856 --> 00:44:32,726 A:middle
So the first argument to do
schedule is a sample time,

933
00:44:33,446 --> 00:44:35,556 A:middle
the parameter value
can ramp over time

934
00:44:35,556 --> 00:44:38,756 A:middle
if the Audio Unit has
advertised it as being rampable.

935
00:44:39,346 --> 00:44:43,516 A:middle
For example, the
Apple Mixer does this.

936
00:44:44,266 --> 00:44:46,436 A:middle
And the last two
parameters, of course,

937
00:44:46,846 --> 00:44:50,066 A:middle
are function parameters -- are
the address of the parameter

938
00:44:50,066 --> 00:44:52,656 A:middle
to be changed and the
new parameter value.

939
00:44:54,226 --> 00:44:55,706 A:middle
Now, things are a
little bit different

940
00:44:55,706 --> 00:44:57,066 A:middle
on the implementation side.

941
00:44:57,066 --> 00:45:00,096 A:middle
We don't just get a
pass-through call from the host.

942

943
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

944
00:44:57,066 --> 00:45:00,096 A:middle
We don't just get a
pass-through call from the host.

945
00:45:00,946 --> 00:45:03,196 A:middle
Instead, the base class is going

946
00:45:03,196 --> 00:45:05,546 A:middle
to fetch the internal
render block, which we saw

947
00:45:05,546 --> 00:45:08,516 A:middle
in the Filter Demo,
and it's going to pass

948
00:45:08,566 --> 00:45:11,516 A:middle
that render block
the real-time events

949
00:45:12,166 --> 00:45:14,796 A:middle
that pertain only to
that render cycle.

950
00:45:15,136 --> 00:45:19,086 A:middle
So the base class is maintaining
the full schedule of all

951
00:45:19,086 --> 00:45:21,866 A:middle
of the pending scheduled
parameter changes

952
00:45:22,236 --> 00:45:25,146 A:middle
and just parceling out
the relevant pieces of it

953
00:45:25,146 --> 00:45:27,496 A:middle
to the Audio Unit
at rendering time.

954
00:45:29,886 --> 00:45:31,376 A:middle
So that's parameter scheduling,

955
00:45:31,376 --> 00:45:34,186 A:middle
and we have done the exact
same thing with MIDI events.

956
00:45:35,086 --> 00:45:36,416 A:middle
The host fetches a block

957
00:45:36,926 --> 00:45:39,166 A:middle
from the Audio Unit
before starting to render.

958
00:45:40,006 --> 00:45:42,496 A:middle
It calls that block
at render time.

959
00:45:43,376 --> 00:45:47,466 A:middle
Now, you will notice here we
have added a function argument

960
00:45:47,506 --> 00:45:50,286 A:middle
called cable where,

961
00:45:50,286 --> 00:45:54,036 A:middle
in the version 2 Audio Unit API
there is only one MIDI cable

962
00:45:54,036 --> 00:45:59,076 A:middle
with 16 channels, now we
have 256 virtual MIDI cables.

963
00:45:59,536 --> 00:46:00,816 A:middle
So if you have an Audio Unit

964

965
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

966
00:45:59,536 --> 00:46:00,816 A:middle
So if you have an Audio Unit

967
00:46:01,386 --> 00:46:04,476 A:middle
that wants huge sample
banks, you can do that.

968
00:46:04,476 --> 00:46:07,346 A:middle
You can address them all
on virtual MIDI cables.

969
00:46:09,186 --> 00:46:11,226 A:middle
On the implementation
side for MIDI events,

970
00:46:11,276 --> 00:46:14,346 A:middle
this is exactly the same as
for scheduled parameters.

971
00:46:15,126 --> 00:46:19,006 A:middle
The base class AU Audio Unit is
maintaining internal schedule

972
00:46:19,806 --> 00:46:23,076 A:middle
and passing events to
the internal render block

973
00:46:23,606 --> 00:46:28,246 A:middle
through the real-time event list
only during the render cycle

974
00:46:28,246 --> 00:46:30,196 A:middle
during which they are
supposed to take effect.

975
00:46:32,016 --> 00:46:34,836 A:middle
So we think this is
a big improvement.

976
00:46:34,836 --> 00:46:36,596 A:middle
It saves the implementer
a lot of work.

977
00:46:39,086 --> 00:46:43,456 A:middle
Now, about rendering in general,
we are still using a pull model,

978
00:46:43,456 --> 00:46:47,826 A:middle
meaning that an output unit
pulls a mixer, pulls an effect,

979
00:46:47,996 --> 00:46:49,746 A:middle
pulls another effect,
pulls the player.

980
00:46:49,746 --> 00:46:51,776 A:middle
Audio flows back down
through the chain.

981
00:46:52,736 --> 00:46:55,236 A:middle
One difference here is
in the version 2 API,

982
00:46:55,236 --> 00:46:58,206 A:middle
the Audio Unit needs
to maintain some state.

983
00:46:58,206 --> 00:47:02,426 A:middle
It needs to have a notion of
whether it's getting its input

984

985
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

986
00:46:58,206 --> 00:47:02,426 A:middle
It needs to have a notion of
whether it's getting its input

987
00:47:02,426 --> 00:47:05,976 A:middle
from another Audio Unit
upstream or a function callback.

988
00:47:06,606 --> 00:47:09,776 A:middle
Now, in the version 3
API, it's much simpler,

989
00:47:09,776 --> 00:47:12,436 A:middle
the AU doesn't have to
maintain that state.

990
00:47:12,916 --> 00:47:15,306 A:middle
This callback, as we
saw in the Filter Demo,

991
00:47:15,736 --> 00:47:19,216 A:middle
comes from the host, and
it is passed during every

992
00:47:19,216 --> 00:47:20,026 A:middle
render cycle.

993
00:47:21,536 --> 00:47:24,936 A:middle
But otherwise, the APIs are
pretty much functionally

994
00:47:24,936 --> 00:47:28,126 A:middle
identical, and this lets
us bridge very efficiently

995
00:47:28,126 --> 00:47:28,776 A:middle
between them.

996
00:47:32,586 --> 00:47:37,396 A:middle
Now, if your host is calling AU
Audio Unit directly to render

997
00:47:37,706 --> 00:47:40,656 A:middle
as opposed to using AU
graph or AVAudioEngine,

998
00:47:41,616 --> 00:47:45,906 A:middle
here you will want to call
allocate render resources

999
00:47:45,906 --> 00:47:49,066 A:middle
as usual and then hold
onto the render block.

1000
00:47:50,076 --> 00:47:51,656 A:middle
You can call the
render block to render.

1001
00:47:52,496 --> 00:47:54,876 A:middle
It looks very similar to
the internal render block.

1002
00:47:55,716 --> 00:47:59,656 A:middle
It's worth reviewing
here some rules

1003
00:47:59,656 --> 00:48:03,296 A:middle
about the audio buffer lists
that appear at render time.

1004

1005
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1006
00:47:59,656 --> 00:48:03,296 A:middle
about the audio buffer lists
that appear at render time.

1007
00:48:03,946 --> 00:48:06,826 A:middle
Now, the host provides an
output audio buffer list,

1008
00:48:07,366 --> 00:48:11,296 A:middle
and in that audio buffer list
the M data pointer can be null.

1009
00:48:12,286 --> 00:48:15,696 A:middle
The Audio Unit must replace this
with an internally owned buffer

1010
00:48:15,876 --> 00:48:19,516 A:middle
and at the same time,
the AU has to promise

1011
00:48:19,566 --> 00:48:21,346 A:middle
that that buffer
will remain valid

1012
00:48:21,346 --> 00:48:22,706 A:middle
until the next render cycle.

1013
00:48:23,266 --> 00:48:25,066 A:middle
This is all, by the
way, exactly the same

1014
00:48:25,066 --> 00:48:27,856 A:middle
as with version 2 Audio Units,
I'm just reemphasizing it

1015
00:48:28,496 --> 00:48:29,406 A:middle
because it's important.

1016
00:48:31,456 --> 00:48:35,816 A:middle
Now, in the render block, we
have some rules, similar rules

1017
00:48:35,816 --> 00:48:37,706 A:middle
but not the same,
about input buffers.

1018
00:48:38,146 --> 00:48:41,256 A:middle
The host provides that
input block, the AU calls it

1019
00:48:41,256 --> 00:48:45,116 A:middle
for input, and when the AU
calls that block for input,

1020
00:48:45,526 --> 00:48:48,456 A:middle
it has to supply valid
audio buffer lists

1021
00:48:48,646 --> 00:48:52,016 A:middle
with non-null M data
pointers to that block.

1022
00:48:52,846 --> 00:48:56,966 A:middle
Now, the host is allowed to
replace those pointers to memory

1023
00:48:56,966 --> 00:49:00,736 A:middle
that it owns and can
promise to keep valid

1024

1025
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1026
00:48:56,966 --> 00:49:00,736 A:middle
that it owns and can
promise to keep valid

1027
00:49:00,736 --> 00:49:04,476 A:middle
until the next render cycle or
deallocate render resources,

1028
00:49:05,166 --> 00:49:08,446 A:middle
and all of this accomplishes
an important goal,

1029
00:49:08,446 --> 00:49:11,266 A:middle
which is to absolutely
minimize copying.

1030
00:49:12,076 --> 00:49:17,526 A:middle
Okay. Here is the scary
slide for those of you

1031
00:49:18,596 --> 00:49:23,276 A:middle
who are writing code to
run in rendering context.

1032
00:49:23,696 --> 00:49:26,786 A:middle
So audio rendering
almost always happens

1033
00:49:26,786 --> 00:49:28,656 A:middle
in a real-time thread context.

1034
00:49:28,966 --> 00:49:30,956 A:middle
And this is a restrictive
environment

1035
00:49:31,096 --> 00:49:32,966 A:middle
because we can't
allocate memory,

1036
00:49:33,546 --> 00:49:36,386 A:middle
which means that we really
shouldn't even be calling

1037
00:49:36,386 --> 00:49:38,066 A:middle
dispatch async, for instance.

1038
00:49:38,346 --> 00:49:42,046 A:middle
And in fact we can't make any
call at all which might block,

1039
00:49:42,636 --> 00:49:47,046 A:middle
for example, taking a mutex
or waiting on a semaphore.

1040
00:49:47,436 --> 00:49:51,846 A:middle
The reason is if we do block and
we block for any length of time,

1041
00:49:52,276 --> 00:49:53,866 A:middle
then the audio rendering thread

1042
00:49:53,866 --> 00:49:55,686 A:middle
in the system will
miss its deadline,

1043
00:49:56,186 --> 00:49:59,316 A:middle
and the user will
experience that as a glitch.

1044

1045
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1046
00:50:00,526 --> 00:50:05,426 A:middle
So we have to be very careful
when both using and calling or,

1047
00:50:05,426 --> 00:50:06,316 A:middle
I'm sorry, both using

1048
00:50:06,316 --> 00:50:08,536 A:middle
and implementing
these render blocks.

1049
00:50:10,286 --> 00:50:14,096 A:middle
So you will see in the Filter
Demo how we went to some lengths

1050
00:50:14,266 --> 00:50:17,366 A:middle
to not capture our Self object

1051
00:50:17,366 --> 00:50:20,256 A:middle
or any other Objective-C
object for that matter.

1052
00:50:21,276 --> 00:50:24,346 A:middle
In that block, we avoid
the Objective-C runtime

1053
00:50:24,346 --> 00:50:27,716 A:middle
because it's inherently unsafe.

1054
00:50:27,716 --> 00:50:28,756 A:middle
It can take blocks.

1055
00:50:29,426 --> 00:50:31,756 A:middle
Unfortunately, the Swift
run-time is exactly the

1056
00:50:31,756 --> 00:50:31,936 A:middle
same way.

1057
00:50:32,396 --> 00:50:37,556 A:middle
So this is why in the Filter
Demo you'll see we have C++

1058
00:50:37,556 --> 00:50:41,776 A:middle
objects and we capture
pointers to those C++ objects.

1059
00:50:42,246 --> 00:50:44,106 A:middle
Now, if you are allergic
to C++, you are free

1060
00:50:44,106 --> 00:50:47,026 A:middle
to do the same thing
in plain vanilla C,

1061
00:50:47,026 --> 00:50:51,276 A:middle
although I'm not sure why
you would want to do that.

1062
00:50:51,276 --> 00:50:52,276 A:middle
Enough scary stuff.

1063
00:50:52,276 --> 00:50:54,046 A:middle
I would like to bring
up Alec Little now

1064
00:50:54,156 --> 00:50:57,926 A:middle
to show Audio Unit extensions
in Apple Music creation apps.

1065
00:50:58,516 --> 00:51:03,916 A:middle
[Applause]

1066

1067
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1068
00:50:58,516 --> 00:51:03,916 A:middle
[Applause]

1069
00:51:04,416 --> 00:51:04,856 A:middle
>> ALEC LITTLE: Thanks, Doug.

1070
00:51:05,106 --> 00:51:09,446 A:middle
I'm Alec. I work on the music
creation applications for Apple,

1071
00:51:09,446 --> 00:51:10,846 A:middle
things like GarageBand
and Logic.

1072
00:51:11,276 --> 00:51:14,826 A:middle
We are excited about the
new Audio Unit extensions.

1073
00:51:14,826 --> 00:51:18,086 A:middle
We think they will add real
power and creative possibilities

1074
00:51:18,086 --> 00:51:19,836 A:middle
for developers and users.

1075
00:51:19,836 --> 00:51:21,556 A:middle
So I wanted to talk a little bit

1076
00:51:21,556 --> 00:51:23,566 A:middle
about what some of
our plans are.

1077
00:51:23,666 --> 00:51:25,396 A:middle
So first of all, we plan

1078
00:51:25,396 --> 00:51:27,586 A:middle
to support the Audio Unit
extension, of course,

1079
00:51:27,586 --> 00:51:29,686 A:middle
in all of our main applications.

1080
00:51:29,686 --> 00:51:34,466 A:middle
So that's GarageBand iOS,
GarageBand Mac, Logic Pro X,

1081
00:51:34,466 --> 00:51:35,906 A:middle
Logic Pro 10, and Mainstage.

1082
00:51:37,326 --> 00:51:42,836 A:middle
So what I thought we would do
today is look at some examples,

1083
00:51:42,836 --> 00:51:46,286 A:middle
some pretty pictures, if you
will, from GarageBand iOS.

1084
00:51:46,286 --> 00:51:47,966 A:middle
And this is just
preliminary stuff,

1085
00:51:47,966 --> 00:51:49,616 A:middle
but I think it will
give you an idea of kind

1086
00:51:49,616 --> 00:51:51,976 A:middle
of what we are planning
to do as a host

1087
00:51:52,286 --> 00:51:53,786 A:middle
to support Audio
Unit extensions.

1088
00:51:55,136 --> 00:51:58,926 A:middle
So first of all, we are going
to be supporting AU instruments.

1089
00:51:59,206 --> 00:52:02,126 A:middle
So the example I'm going to be
giving is about how we're going

1090

1091
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1092
00:51:59,206 --> 00:52:02,126 A:middle
So the example I'm going to be
giving is about how we're going

1093
00:52:02,126 --> 00:52:03,626 A:middle
to implement those
AU instruments.

1094
00:52:04,796 --> 00:52:07,136 A:middle
So first of all, just a
little graphic to explain

1095
00:52:07,136 --> 00:52:08,936 A:middle
about what we are going to
do, something simple here,

1096
00:52:08,936 --> 00:52:10,786 A:middle
but GarageBand is
going to request

1097
00:52:10,786 --> 00:52:14,756 A:middle
from the View Controller
a custom UI dimension

1098
00:52:14,756 --> 00:52:15,976 A:middle
that we will talk
about in a second.

1099
00:52:16,556 --> 00:52:18,526 A:middle
Pass MIDI events over to
the Audio Unit and then

1100
00:52:18,526 --> 00:52:22,316 A:middle
of course receive audio
back over the audio bus.

1101
00:52:22,876 --> 00:52:26,276 A:middle
On to the promised pictures.

1102
00:52:27,236 --> 00:52:31,286 A:middle
So GarageBand, our main
launch screen launches

1103
00:52:31,286 --> 00:52:35,836 A:middle
into what we call our
touch instrument carousel.

1104
00:52:35,836 --> 00:52:38,556 A:middle
We have all of our touch
instruments here: keyboards,

1105
00:52:38,556 --> 00:52:40,936 A:middle
drums, smart guitars,
all of those things.

1106
00:52:41,966 --> 00:52:44,956 A:middle
Then if you see on the left
there is this container,

1107
00:52:44,956 --> 00:52:47,426 A:middle
and if GarageBand is seeing

1108
00:52:47,426 --> 00:52:49,556 A:middle
that there are Audio Unit
instruments installed

1109
00:52:49,556 --> 00:52:51,596 A:middle
on the device, we will
show that container.

1110
00:52:51,596 --> 00:52:53,686 A:middle
I can swipe over
to that container,

1111
00:52:54,276 --> 00:52:55,826 A:middle
and that's where my
Audio Units live.

1112
00:52:55,826 --> 00:53:00,786 A:middle
If I tap on it, then
we will see all

1113

1114
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1115
00:52:55,826 --> 00:53:00,786 A:middle
If I tap on it, then
we will see all

1116
00:53:00,786 --> 00:53:04,656 A:middle
of the Audio Unit instruments
installed on the device.

1117
00:53:04,656 --> 00:53:07,066 A:middle
Now, if I tap on one
of those instruments,

1118
00:53:07,826 --> 00:53:10,196 A:middle
we will show a big gray
box and a keyboard -- no.

1119
00:53:10,706 --> 00:53:13,876 A:middle
We will show your
custom UI up there

1120
00:53:14,336 --> 00:53:17,416 A:middle
in that nice embedded
view inside GarageBand,

1121
00:53:17,416 --> 00:53:19,546 A:middle
and I think that's the coolest
part of this whole thing is

1122
00:53:19,586 --> 00:53:22,596 A:middle
that we get to show
the actual identity

1123
00:53:22,596 --> 00:53:25,606 A:middle
of your Audio Unit
inside our host there.

1124
00:53:25,606 --> 00:53:28,846 A:middle
And we will be providing our
standard GarageBand keyboard

1125
00:53:28,846 --> 00:53:30,966 A:middle
for you to be able to play that.

1126
00:53:31,416 --> 00:53:35,326 A:middle
We will be recording the MIDI
and receiving the audio back.

1127
00:53:35,466 --> 00:53:38,926 A:middle
So that just kind of brings
up a pretty obvious point.

1128
00:53:39,316 --> 00:53:41,516 A:middle
When you are providing
these custom UIs,

1129
00:53:41,516 --> 00:53:44,936 A:middle
make sure you are not putting
any sort of custom, you know,

1130
00:53:45,086 --> 00:53:47,136 A:middle
MIDI controller-type
device there

1131
00:53:47,136 --> 00:53:49,426 A:middle
because we won't be capturing
your MIDI in GarageBand.

1132
00:53:51,236 --> 00:53:54,456 A:middle
Just a quick look what we
plan to do on the phone.

1133
00:53:55,406 --> 00:53:59,196 A:middle
Is, again, we have a lot more
limited screen real estate

1134
00:53:59,196 --> 00:54:01,646 A:middle
there, so there is a button
in the top-right corner,

1135

1136
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1137
00:53:59,196 --> 00:54:01,646 A:middle
there, so there is a button
in the top-right corner,

1138
00:54:01,736 --> 00:54:03,326 A:middle
which pulls up the
controls view,

1139
00:54:04,056 --> 00:54:06,096 A:middle
and there is the custom UI.

1140
00:54:06,416 --> 00:54:08,586 A:middle
So all of the control there,
and a little bit of room

1141
00:54:08,586 --> 00:54:10,856 A:middle
for the user to still play on
the keyboard down at the bottom.

1142
00:54:10,986 --> 00:54:14,746 A:middle
So here is the most important
slide probably from me today,

1143
00:54:14,746 --> 00:54:17,656 A:middle
and this is the dimensions
we will be requesting

1144
00:54:17,876 --> 00:54:19,986 A:middle
from the View Controller.

1145
00:54:20,806 --> 00:54:23,806 A:middle
So you want to have your
stuff look good in GarageBand,

1146
00:54:24,306 --> 00:54:25,666 A:middle
pay attention to
those dimensions,

1147
00:54:25,666 --> 00:54:29,726 A:middle
and we will do something
pretty cool together.

1148
00:54:30,376 --> 00:54:32,936 A:middle
So, again, we think it's going
to be really exciting to be able

1149
00:54:32,936 --> 00:54:35,636 A:middle
to see and have the
users be able to play

1150
00:54:35,636 --> 00:54:37,556 A:middle
with the actual interface

1151
00:54:37,556 --> 00:54:39,936 A:middle
of your Audio Units
right inside GarageBand,

1152
00:54:39,936 --> 00:54:42,316 A:middle
and we are really excited to
work with you guys to come

1153
00:54:42,316 --> 00:54:43,246 A:middle
up with really cool stuff!

1154
00:54:44,516 --> 00:54:51,816 A:middle
[Applause]

1155
00:54:52,316 --> 00:54:52,916 A:middle
>> DOUG WYATT: Thanks, Alec.

1156
00:54:54,416 --> 00:54:57,516 A:middle
So I imagine you may have
questions at this point.

1157
00:54:57,966 --> 00:55:01,306 A:middle
I would like to try to
anticipate a few of them.

1158

1159
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1160
00:54:57,966 --> 00:55:01,306 A:middle
I would like to try to
anticipate a few of them.

1161
00:55:01,956 --> 00:55:04,836 A:middle
What about inter-app
audio on iOS?

1162
00:55:05,656 --> 00:55:07,226 A:middle
This is a couple
of years old now.

1163
00:55:08,236 --> 00:55:10,596 A:middle
And there is a number of
apps that have supported it.

1164
00:55:11,116 --> 00:55:13,876 A:middle
Well, from our point of view,
this uses a small subset

1165
00:55:13,876 --> 00:55:17,406 A:middle
of the version 2 API, and it
doesn't support a bunch of thing

1166
00:55:17,406 --> 00:55:18,746 A:middle
that people have asked us for,

1167
00:55:18,746 --> 00:55:21,446 A:middle
like parameter support,
presets, and so on.

1168
00:55:22,096 --> 00:55:25,106 A:middle
And we get these requests
and I think, well,

1169
00:55:25,106 --> 00:55:26,976 A:middle
we should have a
full plug-in model,

1170
00:55:27,386 --> 00:55:29,606 A:middle
which is what we have now.

1171
00:55:29,816 --> 00:55:32,296 A:middle
So while we are not
deprecating inter-app audio,

1172
00:55:32,296 --> 00:55:36,436 A:middle
we do see the way forward to add
all of these missing features is

1173
00:55:36,436 --> 00:55:38,746 A:middle
through Audio Unit extensions.

1174
00:55:39,466 --> 00:55:43,206 A:middle
Now on OS X, you
may be wondering

1175
00:55:43,206 --> 00:55:44,996 A:middle
about the compatibility story

1176
00:55:45,356 --> 00:55:47,546 A:middle
if you have existing
hosts and Audio Units.

1177
00:55:48,256 --> 00:55:51,156 A:middle
The bridges should save
you from a lot of pain.

1178
00:55:51,156 --> 00:55:54,066 A:middle
They are compatible, and we
have gone to a lot of work

1179
00:55:54,256 --> 00:55:57,406 A:middle
to make things work
as well as we can.

1180
00:55:58,096 --> 00:56:01,726 A:middle
So I would recommend that you
update to version 3 when you can

1181

1182
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1183
00:55:58,096 --> 00:56:01,726 A:middle
So I would recommend that you
update to version 3 when you can

1184
00:56:01,906 --> 00:56:03,846 A:middle
or need to for some feature.

1185
00:56:03,846 --> 00:56:06,746 A:middle
Maybe you want to redo the
way you handle MIDI events

1186
00:56:06,746 --> 00:56:08,456 A:middle
or scheduled parameters,
for example.

1187
00:56:09,736 --> 00:56:12,316 A:middle
We do have a shortcut
for porting.

1188
00:56:12,316 --> 00:56:15,056 A:middle
It's called AU Audio
Unit v2 Bridge.

1189
00:56:15,056 --> 00:56:18,546 A:middle
This is an AU Audio Unit
subclass that is implemented

1190
00:56:18,546 --> 00:56:21,876 A:middle
on top of a version 2 AU, so you
might be able to start with that

1191
00:56:21,916 --> 00:56:25,736 A:middle
and evolve to a more fully
native implementation.

1192
00:56:26,326 --> 00:56:30,356 A:middle
And as Michael mentioned
earlier,

1193
00:56:31,216 --> 00:56:34,176 A:middle
version 3 Audio Units are
largely cross-platform

1194
00:56:34,176 --> 00:56:36,536 A:middle
between iOS and OS X.

1195
00:56:36,716 --> 00:56:38,076 A:middle
The signal processing code

1196
00:56:38,076 --> 00:56:41,556 A:middle
in AU Audio Unit should be
absolutely fully portable

1197
00:56:41,556 --> 00:56:43,786 A:middle
because there are no
UI implementations,

1198
00:56:44,216 --> 00:56:45,526 A:middle
or dependencies, rather.

1199
00:56:46,196 --> 00:56:51,136 A:middle
AU View Controller derives from
either UI or NSViewController

1200
00:56:51,136 --> 00:56:54,126 A:middle
so you get a little bit of
insulation, but you will

1201
00:56:54,126 --> 00:56:56,126 A:middle
at some point run into
platform-specific UI.

1202
00:56:56,126 --> 00:57:00,576 A:middle
We are running out of
time, and there is way more

1203

1204
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1205
00:56:56,126 --> 00:57:00,576 A:middle
We are running out of
time, and there is way more

1206
00:57:00,576 --> 00:57:03,406 A:middle
than I could possibly go
through in an hour here.

1207
00:57:03,546 --> 00:57:06,876 A:middle
At this point I would like to
refer you to your header files

1208
00:57:06,876 --> 00:57:08,856 A:middle
in the Audio Unit framework.

1209
00:57:09,006 --> 00:57:13,216 A:middle
You do need to link AudioToolbox
for historical reasons.

1210
00:57:13,556 --> 00:57:16,806 A:middle
The main header file is AU Audio
Unit.h but there are others,

1211
00:57:17,306 --> 00:57:20,356 A:middle
AU View Controllers in the
Core Audio kit framework,

1212
00:57:20,906 --> 00:57:24,436 A:middle
and as we mentioned, there
is the AVFoundation framework

1213
00:57:24,436 --> 00:57:28,796 A:middle
with AU Audio Unit component.h.
We have good HeaderDoc in all

1214
00:57:28,796 --> 00:57:32,276 A:middle
of these, so I would like to
urge you to check them out.

1215
00:57:34,376 --> 00:57:38,216 A:middle
Finally, if you would like to
use our Audio Unit's logo --

1216
00:57:38,306 --> 00:57:39,546 A:middle
there is a white version, too --

1217
00:57:39,546 --> 00:57:43,266 A:middle
you can go check out
this link for a license.

1218
00:57:44,616 --> 00:57:46,086 A:middle
And that brings us to the end.

1219
00:57:46,466 --> 00:57:48,426 A:middle
So we have seen how we now have

1220
00:57:48,426 --> 00:57:52,736 A:middle
for the first time a full
plug-in model for audio on iOS,

1221
00:57:52,866 --> 00:57:54,356 A:middle
and it's the same on OS X.

1222
00:57:55,056 --> 00:57:58,446 A:middle
And, again, it lets you sell
Audio Units in both the iOS

1223
00:57:58,666 --> 00:58:02,566 A:middle
and OS X App Stores by
packaging your Audio Units

1224

1225
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1226
00:57:58,666 --> 00:58:02,566 A:middle
and OS X App Stores by
packaging your Audio Units

1227
00:58:02,566 --> 00:58:03,716 A:middle
as app extensions.

1228
00:58:04,606 --> 00:58:08,416 A:middle
We looked at the simple host
applications that are possible

1229
00:58:08,416 --> 00:58:12,316 A:middle
with AVAudioEngine, and that's
illustrated in our new sample,

1230
00:58:12,706 --> 00:58:14,126 A:middle
Audio Unit v3 Example.

1231
00:58:14,876 --> 00:58:17,346 A:middle
So I would like to encourage
you to write bugs as you work

1232
00:58:17,346 --> 00:58:19,526 A:middle
through the sample code,
read the documentation,

1233
00:58:20,036 --> 00:58:23,156 A:middle
and work on the great AU hosts

1234
00:58:23,156 --> 00:58:25,616 A:middle
and implementations
that I know you will.

1235
00:58:26,236 --> 00:58:34,026 A:middle
So for more information, this
was our session yesterday,

1236
00:58:34,756 --> 00:58:35,676 A:middle
so thank you very much!

1237
00:58:36,516 --> 00:58:39,500 A:middle
[Applause]

1238
