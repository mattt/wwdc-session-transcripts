X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

1
00:00:25,516 --> 00:00:32,766 A:middle
[Applause]

2
00:00:33,266 --> 00:00:36,246 A:middle
>> Good morning, and welcome to
Optimizing Swift Performance.

3
00:00:36,546 --> 00:00:39,676 A:middle
My name is Nadav, and together
with my colleagues, Michael

4
00:00:39,836 --> 00:00:41,836 A:middle
and Joe, I am going
to show you how

5
00:00:41,836 --> 00:00:43,456 A:middle
to optimize your Swift programs.

6
00:00:44,356 --> 00:00:48,626 A:middle
Now, we, the engineers on the
Compiler Team, are passionate

7
00:00:48,626 --> 00:00:49,936 A:middle
about making code run fast.

8
00:00:50,296 --> 00:00:52,636 A:middle
We believe that you can
build amazing things

9
00:00:52,636 --> 00:00:54,136 A:middle
when your apps are
highly optimized.

10
00:00:54,406 --> 00:01:00,736 A:middle
And if you feel the same way,
then this talk is for you.

11

12
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

13
00:00:54,406 --> 00:01:00,736 A:middle
And if you feel the same way,
then this talk is for you.

14
00:01:01,916 --> 00:01:04,075 A:middle
Today I'll start by
telling you about some

15
00:01:04,075 --> 00:01:05,716 A:middle
of the new compiler
optimizations

16
00:01:05,836 --> 00:01:07,316 A:middle
that we have added
over the last year.

17
00:01:07,996 --> 00:01:11,756 A:middle
Later, Michael will describe
the underlying implementation

18
00:01:11,756 --> 00:01:13,506 A:middle
of Swift and give
you some advice

19
00:01:13,736 --> 00:01:15,436 A:middle
on writing high-performance
Swift code.

20
00:01:15,956 --> 00:01:18,446 A:middle
And finally, Joe
will demonstrate how

21
00:01:18,446 --> 00:01:20,556 A:middle
to use instruments to identify

22
00:01:20,936 --> 00:01:25,786 A:middle
and analyze performance
bottlenecks in your Swift code.

23
00:01:26,736 --> 00:01:32,106 A:middle
So Swift is a flexible and safe
programming language with lots

24
00:01:32,106 --> 00:01:36,786 A:middle
of great features, like closures
and protocols and generics and,

25
00:01:36,786 --> 00:01:38,526 A:middle
of course, automatic
reference counting.

26
00:01:38,986 --> 00:01:42,606 A:middle
Now, some of you may associate
these features with slowness

27
00:01:42,826 --> 00:01:45,236 A:middle
because the program
has to do more work

28
00:01:45,356 --> 00:01:46,896 A:middle
to implement these
high-level features.

29
00:01:47,616 --> 00:01:50,806 A:middle
But Swift is a very fast
programming language that's

30
00:01:50,856 --> 00:01:53,086 A:middle
compiled to highly
optimized native code.

31
00:01:54,096 --> 00:01:56,206 A:middle
So how did we make Swift fast?

32
00:01:57,226 --> 00:01:59,756 A:middle
Well, we made Swift fast

33

34
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

35
00:02:00,066 --> 00:02:04,016 A:middle
by implementing compiler
optimizations that target all

36
00:02:04,016 --> 00:02:05,396 A:middle
of these high-level features.

37
00:02:05,866 --> 00:02:09,265 A:middle
These compiler optimizations
make sure that the overhead

38
00:02:09,596 --> 00:02:12,496 A:middle
of the high-level
features is minimal.

39
00:02:14,476 --> 00:02:16,916 A:middle
Now, we have lots of
compiler optimizations,

40
00:02:16,916 --> 00:02:19,376 A:middle
and we don't have enough
time to go over all of them,

41
00:02:19,676 --> 00:02:22,056 A:middle
so I decided to bring
you one example

42
00:02:22,136 --> 00:02:23,556 A:middle
of one compiler optimization.

43
00:02:24,126 --> 00:02:26,986 A:middle
This optimization is called
bounds checks elimination.

44
00:02:29,636 --> 00:02:31,926 A:middle
On the screen, you can
see a very simple loop.

45
00:02:32,186 --> 00:02:34,076 A:middle
This loop encrypts the
content of the array

46
00:02:34,346 --> 00:02:37,646 A:middle
by X-raying all the elements in
the array with the number 13.

47
00:02:37,906 --> 00:02:39,056 A:middle
It's not a very good encryption.

48
00:02:39,846 --> 00:02:43,116 A:middle
The reading and writing
outside of the bounds

49
00:02:43,116 --> 00:02:45,046 A:middle
of the array is a serious bug

50
00:02:45,506 --> 00:02:47,386 A:middle
and can also have
security implications,

51
00:02:48,086 --> 00:02:52,456 A:middle
and Swift is protecting you
by adding a little bit of code

52
00:02:52,546 --> 00:02:54,596 A:middle
that checks that you don't
read or write outside

53
00:02:54,596 --> 00:02:55,426 A:middle
of the bounds of the array.

54
00:02:56,106 --> 00:03:00,056 A:middle
Now, the problem is that this
check slows your code down.

55

56
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

57
00:02:56,106 --> 00:03:00,056 A:middle
Now, the problem is that this
check slows your code down.

58
00:03:02,186 --> 00:03:05,366 A:middle
Another problem is that it
blocks other optimizations.

59
00:03:05,366 --> 00:03:07,976 A:middle
For example, we cannot
vectorize this code

60
00:03:08,396 --> 00:03:09,316 A:middle
with this check in place.

61
00:03:10,536 --> 00:03:13,186 A:middle
So we've implemented a
compiler optimization

62
00:03:13,616 --> 00:03:17,046 A:middle
for hoisting this check outside
of the loop, making the cost

63
00:03:17,046 --> 00:03:19,976 A:middle
of the check negligible,
because instead of checking

64
00:03:20,056 --> 00:03:21,476 A:middle
on each iteration of the loop

65
00:03:21,796 --> 00:03:24,046 A:middle
that we are hitting inside
the bounds of the array,

66
00:03:24,266 --> 00:03:26,676 A:middle
we are only checking once
when we enter the array.

67
00:03:27,186 --> 00:03:28,936 A:middle
So this is a very
powerful optimization

68
00:03:29,456 --> 00:03:32,966 A:middle
that makes numeric
code run faster.

69
00:03:33,076 --> 00:03:36,316 A:middle
Okay. So this was one
example of one optimization,

70
00:03:36,616 --> 00:03:38,626 A:middle
and we have lots
of optimizations.

71
00:03:39,316 --> 00:03:41,016 A:middle
And we know that these
optimizations work

72
00:03:41,206 --> 00:03:44,866 A:middle
and that they are very effective
because we are tracking hundreds

73
00:03:44,866 --> 00:03:47,586 A:middle
of programs and benchmarks,
and over the last year,

74
00:03:47,836 --> 00:03:50,926 A:middle
we noticed that these programs
became significantly faster.

75
00:03:51,386 --> 00:03:53,556 A:middle
Every time we added
a new optimization,

76
00:03:53,926 --> 00:03:55,536 A:middle
every time we made
an improvement

77
00:03:55,776 --> 00:03:57,186 A:middle
to existing optimizations,

78
00:03:57,456 --> 00:03:59,656 A:middle
we noticed that these
programs became faster.

79

80
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

81
00:04:00,786 --> 00:04:03,546 A:middle
Now, it's not going to be very
interesting for you to see all

82
00:04:03,546 --> 00:04:06,956 A:middle
of these programs, so I decided
to bring you five programs.

83
00:04:08,116 --> 00:04:09,096 A:middle
The programs that you see

84
00:04:09,096 --> 00:04:11,406 A:middle
on the screen behind me
right now are programs

85
00:04:11,406 --> 00:04:12,356 A:middle
from multiple domains.

86
00:04:13,286 --> 00:04:15,966 A:middle
One is an object-oriented
program.

87
00:04:16,055 --> 00:04:17,305 A:middle
Another one is numeric.

88
00:04:17,466 --> 00:04:19,146 A:middle
Another one is functional.

89
00:04:20,456 --> 00:04:22,786 A:middle
And I believe that these
programs represent the kind

90
00:04:22,786 --> 00:04:25,406 A:middle
of code that users
write today in Swift.

91
00:04:26,346 --> 00:04:27,996 A:middle
And as you can see,
over the last year,

92
00:04:28,566 --> 00:04:30,346 A:middle
these programs became
significantly faster,

93
00:04:30,346 --> 00:04:33,046 A:middle
between two to eight times
faster, which is great.

94
00:04:33,506 --> 00:04:36,306 A:middle
Now, these programs are
optimized in release mode.

95
00:04:37,226 --> 00:04:39,766 A:middle
But I know that you also
care about the performance

96
00:04:39,766 --> 00:04:42,826 A:middle
of unoptimized programs
because you are spending a lot

97
00:04:42,826 --> 00:04:45,646 A:middle
of time writing your code and
debugging it and running it

98
00:04:45,646 --> 00:04:46,816 A:middle
in simulator, so you care

99
00:04:46,816 --> 00:04:48,396 A:middle
about the performance
of unoptimized code.

100
00:04:49,486 --> 00:04:51,416 A:middle
So, these are the
same five programs,

101
00:04:51,986 --> 00:04:54,046 A:middle
this time in debug mode.

102
00:04:54,516 --> 00:04:55,316 A:middle
They are unoptimized.

103
00:04:55,996 --> 00:04:58,626 A:middle
So you are probably
asking yourself, wait,

104
00:04:58,716 --> 00:04:59,946 A:middle
how can improvements

105
00:04:59,946 --> 00:05:04,306 A:middle
to the optimizer improve the
performance of unoptimized code.

106

107
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

108
00:04:59,946 --> 00:05:04,306 A:middle
to the optimizer improve the
performance of unoptimized code.

109
00:05:04,626 --> 00:05:08,146 A:middle
Right? Well, we made
unoptimized code run faster

110
00:05:08,146 --> 00:05:09,046 A:middle
by doing two things.

111
00:05:09,406 --> 00:05:12,526 A:middle
First of all, we improved
the Swift runtime component.

112
00:05:12,806 --> 00:05:17,096 A:middle
The runtime is responsible
for allocating memory,

113
00:05:17,096 --> 00:05:19,426 A:middle
accessing metadata,
things like that.

114
00:05:19,506 --> 00:05:20,426 A:middle
So we optimized that.

115
00:05:20,946 --> 00:05:24,436 A:middle
And the second thing that we
did is that now we are able

116
00:05:24,436 --> 00:05:26,926 A:middle
to optimize the Swift
Standard Library better.

117
00:05:27,076 --> 00:05:28,406 A:middle
The Standard Library
is the component

118
00:05:28,406 --> 00:05:31,966 A:middle
that has the implementation of
array and dictionary and set.

119
00:05:32,286 --> 00:05:35,756 A:middle
So by optimizing the
Standard Library better,

120
00:05:36,056 --> 00:05:38,206 A:middle
we are able to accelerate
the performance

121
00:05:38,206 --> 00:05:41,016 A:middle
of unoptimized programs.

122
00:05:41,396 --> 00:05:43,656 A:middle
We know that over the
last year, the performance

123
00:05:43,656 --> 00:05:45,156 A:middle
of both optimized

124
00:05:45,476 --> 00:05:48,866 A:middle
and unoptimized programs
became significantly better.

125
00:05:49,436 --> 00:05:50,616 A:middle
But to get the full picture,

126
00:05:50,616 --> 00:05:53,986 A:middle
I want to show you a
comparison to Objective-C.

127
00:05:54,536 --> 00:05:58,706 A:middle
So on the screen you can see
two very well-known benchmarks.

128
00:05:59,116 --> 00:06:01,176 A:middle
It's Richards and
DeltaBlue, both written

129

130
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

131
00:05:59,116 --> 00:06:01,176 A:middle
It's Richards and
DeltaBlue, both written

132
00:06:01,176 --> 00:06:02,686 A:middle
in object-oriented style.

133
00:06:03,216 --> 00:06:04,266 A:middle
And on these benchmarks,

134
00:06:04,516 --> 00:06:06,796 A:middle
Swift is a lot faster
than Objective-C.

135
00:06:07,476 --> 00:06:09,646 A:middle
At this point in the
talk, I am not going

136
00:06:09,646 --> 00:06:12,226 A:middle
to tell you why Swift is
faster than Objective-C,

137
00:06:12,686 --> 00:06:14,856 A:middle
but I promise you that we
will get back to this slide

138
00:06:15,256 --> 00:06:18,466 A:middle
and we will talk about
why Swift is faster.

139
00:06:19,416 --> 00:06:22,556 A:middle
Okay. Now I am going to talk
about something different.

140
00:06:22,856 --> 00:06:25,816 A:middle
I want to talk about a new
compiler optimization mode

141
00:06:25,946 --> 00:06:28,116 A:middle
that's called "Whole
Module Optimization"

142
00:06:28,376 --> 00:06:30,696 A:middle
that can make your programs
run significantly faster.

143
00:06:31,526 --> 00:06:33,466 A:middle
But before I do that,
I would like to talk

144
00:06:33,466 --> 00:06:36,526 A:middle
about the way Xcode
compiles files.

145
00:06:37,496 --> 00:06:41,436 A:middle
So Xcode compiles your
files individually.

146
00:06:42,156 --> 00:06:45,236 A:middle
And this is a good idea because
it can compile many files

147
00:06:45,236 --> 00:06:47,656 A:middle
in parallel on multiple
cores in your machine.

148
00:06:48,156 --> 00:06:48,636 A:middle
That's good.

149
00:06:49,046 --> 00:06:52,856 A:middle
It can also recompile only
files that need to be updated.

150
00:06:53,366 --> 00:06:53,916 A:middle
So that's good.

151
00:06:54,536 --> 00:06:56,956 A:middle
But the problem is that
the optimizer is limited

152
00:06:56,956 --> 00:06:59,006 A:middle
to the scope of one file.

153
00:06:59,826 --> 00:07:05,156 A:middle
With Whole Module Optimization,
the compiler is able

154

155
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

156
00:06:59,826 --> 00:07:05,156 A:middle
With Whole Module Optimization,
the compiler is able

157
00:07:05,156 --> 00:07:09,016 A:middle
to optimize the entire module
at once, which is great

158
00:07:09,126 --> 00:07:10,786 A:middle
because it can analyze
everything

159
00:07:10,786 --> 00:07:12,936 A:middle
and make aggressive
optimizations.

160
00:07:13,566 --> 00:07:17,266 A:middle
Now, naturally, Whole Module
Optimization builds take longer.

161
00:07:19,106 --> 00:07:22,226 A:middle
But the generated binaries
usually run faster.

162
00:07:24,636 --> 00:07:27,236 A:middle
In Swift 2, we made
two major improvements

163
00:07:27,286 --> 00:07:28,506 A:middle
to Whole Module Optimizations.

164
00:07:28,586 --> 00:07:33,016 A:middle
So first, we added new
optimizations that rely

165
00:07:33,506 --> 00:07:35,086 A:middle
on Whole Module Optimization
mode.

166
00:07:36,016 --> 00:07:38,266 A:middle
So your programs are
likely to run faster.

167
00:07:38,976 --> 00:07:43,166 A:middle
And second, we were able
to parallelize some parts

168
00:07:43,166 --> 00:07:44,316 A:middle
of the compilation pipeline.

169
00:07:44,816 --> 00:07:48,546 A:middle
So compiling projects in Whole
Module Optimization mode should

170
00:07:48,576 --> 00:07:49,846 A:middle
take less time.

171
00:07:50,446 --> 00:07:55,206 A:middle
On the screen behind me,
you can see two programs

172
00:07:55,206 --> 00:07:57,926 A:middle
that became significantly faster
with Whole Module Optimization

173
00:07:58,046 --> 00:08:01,036 A:middle
because the compiler was able
to make better decisions,

174

175
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

176
00:07:58,046 --> 00:08:01,036 A:middle
because the compiler was able
to make better decisions,

177
00:08:01,076 --> 00:08:03,366 A:middle
it was able to analyze
the entire module

178
00:08:03,726 --> 00:08:05,726 A:middle
and make more aggressive
optimizations

179
00:08:06,106 --> 00:08:09,006 A:middle
with the information
that it had.

180
00:08:10,126 --> 00:08:12,316 A:middle
In Xcode 7, we've
made some changes

181
00:08:12,316 --> 00:08:13,706 A:middle
to the optimization level menu,

182
00:08:14,206 --> 00:08:16,896 A:middle
and now Whole Module
Optimization is one

183
00:08:16,896 --> 00:08:18,656 A:middle
of the options that
you can select.

184
00:08:19,226 --> 00:08:21,436 A:middle
And I encourage you to try
Whole Module Optimization

185
00:08:21,796 --> 00:08:22,456 A:middle
on your programs.

186
00:08:23,006 --> 00:08:25,896 A:middle
At this point, I would like
to invite Michael on stage

187
00:08:25,946 --> 00:08:28,666 A:middle
to tell you about the underlying
implementation of Swift

188
00:08:28,666 --> 00:08:30,196 A:middle
and give you some advice

189
00:08:30,196 --> 00:08:32,176 A:middle
on writing high-performance
Swift code.

190
00:08:32,655 --> 00:08:32,905 A:middle
Thank you.

191
00:08:33,515 --> 00:08:43,706 A:middle
[Applause]

192
00:08:44,206 --> 00:08:45,596 A:middle
>> MICHAEL GOTTESMAN:
Thanks, Nadav.

193
00:08:46,186 --> 00:08:47,846 A:middle
Today I would like
to speak to you

194
00:08:48,186 --> 00:08:51,466 A:middle
about three different aspects of
the Swift programming language

195
00:08:51,536 --> 00:08:53,146 A:middle
and their performance
characteristics.

196
00:08:53,736 --> 00:08:57,266 A:middle
For each I will give specific
techniques that you can use

197
00:08:57,416 --> 00:08:59,766 A:middle
to improve the performance
of your app today.

198

199
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

200
00:09:00,506 --> 00:09:04,126 A:middle
Let's begin by talking
about reference counting.

201
00:09:04,756 --> 00:09:07,956 A:middle
In general, the compiler
can eliminate most reference

202
00:09:07,956 --> 00:09:09,626 A:middle
counting overhead
without any help.

203
00:09:10,436 --> 00:09:13,686 A:middle
But sometimes you may still
find slowdowns in your code due

204
00:09:13,686 --> 00:09:14,996 A:middle
to reference counting overhead.

205
00:09:15,946 --> 00:09:19,586 A:middle
Today I'm going to present two
techniques that you can use

206
00:09:19,856 --> 00:09:22,096 A:middle
to reduce or even
eliminate this overhead.

207
00:09:23,516 --> 00:09:26,026 A:middle
Let's begin by looking at the
basics of reference counting

208
00:09:26,356 --> 00:09:28,166 A:middle
by looking at how
reference counting

209
00:09:28,166 --> 00:09:29,176 A:middle
and classes go together.

210
00:09:30,656 --> 00:09:32,866 A:middle
So here I have a block of code.

211
00:09:33,106 --> 00:09:36,266 A:middle
It consists of a class C,
a function foo that takes

212
00:09:36,266 --> 00:09:39,146 A:middle
in an optional C, and a couple
of variable definitions.

213
00:09:39,606 --> 00:09:41,926 A:middle
Let's walk through the code's
execution line by line.

214
00:09:43,656 --> 00:09:46,766 A:middle
First we begin by allocating
new instance of class C

215
00:09:46,766 --> 00:09:48,816 A:middle
and assign it to the variable X.

216
00:09:49,776 --> 00:09:52,546 A:middle
Notice how at the top of the
class instance, there is a box

217
00:09:52,546 --> 00:09:53,376 A:middle
with the number 1 in it.

218
00:09:53,546 --> 00:09:56,226 A:middle
This represents the reference
count of the class instance.

219
00:09:56,996 --> 00:09:59,446 A:middle
Of course, it's 1 because
there's only one reference

220
00:09:59,486 --> 00:10:01,426 A:middle
to the class instance
currently, namely x.

221

222
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

223
00:09:59,486 --> 00:10:01,426 A:middle
to the class instance
currently, namely x.

224
00:10:02,896 --> 00:10:05,856 A:middle
Then we assign x
to the variable y.

225
00:10:06,016 --> 00:10:08,036 A:middle
This creates a new reference
to the class instance,

226
00:10:08,326 --> 00:10:10,406 A:middle
causing us to increment
the reference count

227
00:10:10,406 --> 00:10:13,606 A:middle
of the class instance, giving
us a reference count of 2.

228
00:10:14,856 --> 00:10:16,636 A:middle
Then we pass off y to foo,

229
00:10:16,636 --> 00:10:18,776 A:middle
but we don't actually
pass off y itself.

230
00:10:18,856 --> 00:10:24,686 A:middle
Instead, we create a temporary
C, and then we assign y to C.

231
00:10:25,176 --> 00:10:29,266 A:middle
This then acts as a third
reference to the class instance,

232
00:10:29,526 --> 00:10:31,586 A:middle
which then causes us to
increment the reference count

233
00:10:31,586 --> 00:10:32,816 A:middle
of the class instance once more.

234
00:10:33,916 --> 00:10:37,326 A:middle
Then when foo exits, C is
destroyed, which then causes us

235
00:10:37,326 --> 00:10:39,476 A:middle
to decrement the reference
count of the class instance,

236
00:10:39,716 --> 00:10:42,106 A:middle
bringing us to a
reference count of 2.

237
00:10:42,356 --> 00:10:45,436 A:middle
Then finally, we assign
nil to y and nil to x,

238
00:10:45,856 --> 00:10:48,166 A:middle
bringing the reference count
of our class instance to 0,

239
00:10:48,166 --> 00:10:49,896 A:middle
and then it's deallocated.

240
00:10:51,656 --> 00:10:55,266 A:middle
Notice how every time
we made an assignment,

241
00:10:55,556 --> 00:10:58,066 A:middle
we had to perform a
reference counting operation

242
00:10:58,226 --> 00:11:00,346 A:middle
to maintain the reference
count of the class instance.

243

244
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

245
00:10:58,226 --> 00:11:00,346 A:middle
to maintain the reference
count of the class instance.

246
00:11:01,246 --> 00:11:02,836 A:middle
This is important
since we always have

247
00:11:02,836 --> 00:11:05,766 A:middle
to maintain memory safety.

248
00:11:05,876 --> 00:11:09,296 A:middle
Now, for those of you who are
familiar with Objective-C,

249
00:11:09,296 --> 00:11:11,856 A:middle
of course, nothing new is
happening here with, of course,

250
00:11:12,296 --> 00:11:17,016 A:middle
increment and decrement
being respectfully retained

251
00:11:17,676 --> 00:11:18,316 A:middle
and released.

252
00:11:19,246 --> 00:11:21,216 A:middle
But now I'd like to talk to you

253
00:11:21,216 --> 00:11:23,496 A:middle
about something that's
perhaps a bit more exotic,

254
00:11:23,496 --> 00:11:24,436 A:middle
more unfamiliar.

255
00:11:24,856 --> 00:11:28,086 A:middle
Namely, how structs interact
with reference counting.

256
00:11:29,356 --> 00:11:33,426 A:middle
I'll begin -- let's begin this
discussion by looking at a class

257
00:11:33,546 --> 00:11:35,176 A:middle
that doesn't contain
any references.

258
00:11:36,686 --> 00:11:37,836 A:middle
Here I have a class, Point.

259
00:11:37,836 --> 00:11:40,016 A:middle
Of course, it doesn't
contain any references,

260
00:11:40,446 --> 00:11:41,936 A:middle
but it does have two
properties in it,

261
00:11:41,936 --> 00:11:43,776 A:middle
x and y, that are both floats.

262
00:11:44,716 --> 00:11:47,036 A:middle
If I store one of these
points in an array,

263
00:11:47,466 --> 00:11:48,786 A:middle
because it's a class, of course,

264
00:11:48,786 --> 00:11:50,716 A:middle
I don't store it
directly in the array.

265
00:11:51,006 --> 00:11:53,706 A:middle
Instead, I store reference
to the points in the array.

266
00:11:54,636 --> 00:11:56,906 A:middle
So when I iterate
over the array,

267
00:11:56,906 --> 00:12:01,346 A:middle
when I initialize
the loop variable p,

268

269
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

270
00:11:56,906 --> 00:12:01,346 A:middle
when I initialize
the loop variable p,

271
00:12:01,346 --> 00:12:04,876 A:middle
I am actually creating a new
reference to the class instance,

272
00:12:05,296 --> 00:12:07,926 A:middle
meaning that I have to perform
a reference count increment.

273
00:12:08,946 --> 00:12:11,786 A:middle
Then, when p is destroyed at
the end of the loop iteration,

274
00:12:11,836 --> 00:12:14,166 A:middle
I then have to decrement
that reference count.

275
00:12:15,296 --> 00:12:17,806 A:middle
In Objective-C, one
would oftentimes have

276
00:12:17,956 --> 00:12:20,536 A:middle
to make simple data
structures, like Point,

277
00:12:20,536 --> 00:12:22,716 A:middle
a class so you could
use data structures

278
00:12:22,716 --> 00:12:24,226 A:middle
from Foundation like NSRA.

279
00:12:24,986 --> 00:12:27,606 A:middle
Then whenever you manipulated
the simple data structure,

280
00:12:27,786 --> 00:12:29,716 A:middle
you would have the
overhead of having a class.

281
00:12:30,676 --> 00:12:32,936 A:middle
In Swift, we can use structs --

282
00:12:33,176 --> 00:12:36,056 A:middle
in Swift, we can work around
this issue by using a struct

283
00:12:36,056 --> 00:12:37,396 A:middle
in this case instead of a class.

284
00:12:38,516 --> 00:12:41,056 A:middle
So let's make Point a struct.

285
00:12:41,566 --> 00:12:44,926 A:middle
Immediately, we can store each
Point in the array directly,

286
00:12:44,926 --> 00:12:47,206 A:middle
since Swift arrays can
store structs directly.

287
00:12:47,206 --> 00:12:51,156 A:middle
But more importantly, since
a struct does not inherently

288
00:12:51,156 --> 00:12:54,176 A:middle
require reference counting
and both properties

289
00:12:54,496 --> 00:12:57,136 A:middle
of the struct also don't
require reference counting,

290
00:12:57,366 --> 00:13:00,636 A:middle
we can immediately eliminate all
the reference counting overhead

291

292
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

293
00:12:57,366 --> 00:13:00,636 A:middle
we can immediately eliminate all
the reference counting overhead

294
00:13:00,636 --> 00:13:02,846 A:middle
from the loop.

295
00:13:03,106 --> 00:13:06,416 A:middle
Let's now consider a slightly
more elaborate example of this

296
00:13:06,416 --> 00:13:12,806 A:middle
by considering a struct with
a reference inside of it.

297
00:13:13,086 --> 00:13:15,956 A:middle
While a struct itself does not
inherently require reference

298
00:13:15,956 --> 00:13:17,556 A:middle
counting modifications
on assignment,

299
00:13:17,556 --> 00:13:21,026 A:middle
like I mentioned before, it
does require such modifications

300
00:13:21,076 --> 00:13:22,836 A:middle
if the struct contains
a reference.

301
00:13:23,836 --> 00:13:26,866 A:middle
This is because assigning
a struct is equivalent

302
00:13:27,016 --> 00:13:28,026 A:middle
to assigning each one

303
00:13:28,026 --> 00:13:30,166 A:middle
of its properties
independently of each other.

304
00:13:31,266 --> 00:13:33,606 A:middle
So consider that the struct
Point that we saw previously,

305
00:13:35,096 --> 00:13:36,426 A:middle
it is copied efficiently,

306
00:13:36,426 --> 00:13:38,736 A:middle
there are no reference counting
needed when we assign it.

307
00:13:39,166 --> 00:13:42,766 A:middle
But let's say that one
day I'm working on my app

308
00:13:42,766 --> 00:13:44,776 A:middle
and I decide that, well, I
would like to make each one

309
00:13:44,776 --> 00:13:47,476 A:middle
of my Points to be
drawn a different color.

310
00:13:47,576 --> 00:13:51,586 A:middle
So I add a UIColor
property to my struct.

311
00:13:52,086 --> 00:13:53,486 A:middle
Of course, UIColor
being a class,

312
00:13:53,486 --> 00:13:56,366 A:middle
this is actually adding
a reference to my struct.

313
00:13:56,986 --> 00:14:00,906 A:middle
Now, this means that every
time I assign this struct,

314

315
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

316
00:13:56,986 --> 00:14:00,906 A:middle
Now, this means that every
time I assign this struct,

317
00:14:01,326 --> 00:14:03,926 A:middle
it's equivalent to assigning
this UIColor independently

318
00:14:03,926 --> 00:14:05,896 A:middle
of the struct, which
means that I have

319
00:14:05,896 --> 00:14:08,896 A:middle
to perform a reference
counting modification.

320
00:14:10,326 --> 00:14:14,626 A:middle
Now, while having a struct with
one reference count in it is not

321
00:14:14,626 --> 00:14:17,756 A:middle
that expensive, I mean, we
work with classes all the time,

322
00:14:17,756 --> 00:14:19,356 A:middle
and classes have
the same property.

323
00:14:19,896 --> 00:14:23,746 A:middle
I would now like to present
to you a more extreme example,

324
00:14:24,296 --> 00:14:27,496 A:middle
namely, a struct with many
reference counted fields.

325
00:14:29,066 --> 00:14:32,436 A:middle
Here I have a struct user, and
I am using it to model users

326
00:14:32,436 --> 00:14:33,356 A:middle
in an app I am writing.

327
00:14:33,706 --> 00:14:37,056 A:middle
And each user instance has some
data associated with it, namely,

328
00:14:37,136 --> 00:14:40,916 A:middle
three strings -- one for
the first name of the user,

329
00:14:41,366 --> 00:14:43,536 A:middle
one for the last
name of the user,

330
00:14:43,576 --> 00:14:45,766 A:middle
and one for the user's address.

331
00:14:46,876 --> 00:14:49,706 A:middle
I also have a field for
an array and a dictionary

332
00:14:49,706 --> 00:14:52,766 A:middle
that stores app-specific
data about the user.

333
00:14:54,376 --> 00:14:57,706 A:middle
Even though all of these
properties are value types,

334
00:14:58,606 --> 00:15:02,006 A:middle
internally, they contain
a class which is used

335

336
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

337
00:14:58,606 --> 00:15:02,006 A:middle
internally, they contain
a class which is used

338
00:15:02,416 --> 00:15:05,756 A:middle
to manage the lifetime
of their internal data.

339
00:15:06,966 --> 00:15:10,086 A:middle
So this means that every time
I assign one of these structs,

340
00:15:11,396 --> 00:15:14,366 A:middle
every time I pass it off to
a function, I actually have

341
00:15:14,366 --> 00:15:17,796 A:middle
to perform five reference
counting modifications.

342
00:15:19,226 --> 00:15:22,056 A:middle
Well, we can work around this
by using a wrapper class.

343
00:15:23,416 --> 00:15:26,206 A:middle
Here again, I have my user
struct, but this time,

344
00:15:26,206 --> 00:15:28,606 A:middle
instead of standing on
its own, it's contained

345
00:15:28,606 --> 00:15:29,476 A:middle
within a wrapper class.

346
00:15:30,126 --> 00:15:32,816 A:middle
I can still manipulate the
struct using the class reference

347
00:15:32,816 --> 00:15:36,296 A:middle
and, more importantly, if I pass
off this reference to a function

348
00:15:36,506 --> 00:15:38,296 A:middle
or I declare -- or I sign --

349
00:15:38,296 --> 00:15:39,766 A:middle
initialize a variable
with the reference,

350
00:15:39,826 --> 00:15:43,156 A:middle
I am only performing one
reference count increment.

351
00:15:44,466 --> 00:15:46,836 A:middle
Now, it's important to note

352
00:15:47,476 --> 00:15:49,686 A:middle
that there's been a
change in semantics here.

353
00:15:50,366 --> 00:15:54,386 A:middle
We've changed from using
something with value semantics

354
00:15:54,866 --> 00:15:56,996 A:middle
to something with
reference semantics.

355
00:15:58,356 --> 00:16:02,346 A:middle
This may cause unexpected
data sharing that may lead

356

357
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

358
00:15:58,356 --> 00:16:02,346 A:middle
This may cause unexpected
data sharing that may lead

359
00:16:02,346 --> 00:16:04,676 A:middle
to weird results or things
that you may not expect.

360
00:16:06,086 --> 00:16:08,506 A:middle
But turns out there is a way

361
00:16:08,506 --> 00:16:12,566 A:middle
that you can have value
semantics and benefit

362
00:16:12,566 --> 00:16:13,586 A:middle
from this optimization.

363
00:16:14,616 --> 00:16:15,976 A:middle
If you'd like to
learn more about this,

364
00:16:16,126 --> 00:16:20,256 A:middle
please go to the Building Better
Apps with Value Types talk

365
00:16:20,256 --> 00:16:22,366 A:middle
in Swift tomorrow in Mission

366
00:16:22,366 --> 00:16:24,686 A:middle
at 2:30 p.m. It's going
to be a great talk.

367
00:16:24,686 --> 00:16:29,686 A:middle
I really suggest that you go.

368
00:16:29,686 --> 00:16:32,106 A:middle
Now that we've talked
about reference counting,

369
00:16:32,876 --> 00:16:36,426 A:middle
I'd like to continue by talking
a little bit about generics.

370
00:16:39,736 --> 00:16:41,796 A:middle
Here I have a generic
function min.

371
00:16:41,956 --> 00:16:44,276 A:middle
It's generic over
type T that conforms

372
00:16:44,276 --> 00:16:47,276 A:middle
to the comparable protocol from
the Swift Standard Library.

373
00:16:47,766 --> 00:16:49,476 A:middle
From a source code perspective,

374
00:16:49,756 --> 00:16:51,116 A:middle
this doesn't really
look that big.

375
00:16:51,116 --> 00:16:52,396 A:middle
I mean, it's just three lines.

376
00:16:53,136 --> 00:16:55,426 A:middle
But in reality, a
lot more is going

377
00:16:55,426 --> 00:16:57,366 A:middle
on behind the scenes
than one might think.

378
00:16:57,916 --> 00:17:00,896 A:middle
For instance, the code
that's actually emitted --

379

380
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

381
00:16:57,916 --> 00:17:00,896 A:middle
For instance, the code
that's actually emitted --

382
00:17:00,896 --> 00:17:02,686 A:middle
here, again I am
using a pseudo-Swift

383
00:17:02,686 --> 00:17:04,195 A:middle
to represent the code
the compiler emits --

384
00:17:04,195 --> 00:17:07,175 A:middle
the code the compiler emits
is not these three lines.

385
00:17:07,266 --> 00:17:09,965 A:middle
Instead, it's this.

386
00:17:10,695 --> 00:17:13,656 A:middle
First notice that the
compiler is using indirection

387
00:17:13,656 --> 00:17:15,056 A:middle
to compare both x and y.

388
00:17:15,506 --> 00:17:18,136 A:middle
This is because we could
be passing in two integers

389
00:17:18,136 --> 00:17:22,116 A:middle
to the min function, or we
could be passing in two floats

390
00:17:22,116 --> 00:17:24,685 A:middle
or two strings, or we could be
passing in any comparable type.

391
00:17:24,685 --> 00:17:28,016 A:middle
So the compiler must be
correct in all cases and be able

392
00:17:28,016 --> 00:17:29,796 A:middle
to handle any of them.

393
00:17:30,116 --> 00:17:32,796 A:middle
Additionally, because
the compiler can't know

394
00:17:32,976 --> 00:17:35,696 A:middle
if T requires reference
counting modifications or not,

395
00:17:35,926 --> 00:17:37,786 A:middle
it must insert additional
indirection

396
00:17:38,076 --> 00:17:41,586 A:middle
so the min T function
can handle both types T

397
00:17:41,586 --> 00:17:45,936 A:middle
that require reference counting
and those types T that do not.

398
00:17:46,116 --> 00:17:47,876 A:middle
In the case of an
integer, for instance,

399
00:17:48,166 --> 00:17:51,116 A:middle
these are just no-up calls
into the Swift runtime.

400
00:17:52,716 --> 00:17:55,896 A:middle
In both of these cases, the
compiler is being conservative

401
00:17:56,126 --> 00:17:59,986 A:middle
since it must be able to
handle any type T in this case.

402

403
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

404
00:18:01,536 --> 00:18:03,796 A:middle
Luckily, there is a
compiler optimization

405
00:18:03,796 --> 00:18:06,036 A:middle
that can help us here, that
can remove this overhead.

406
00:18:06,736 --> 00:18:09,796 A:middle
This compiler optimization is
called generic specialization.

407
00:18:10,906 --> 00:18:13,816 A:middle
Here I have a function
foo, it passes two integers

408
00:18:13,816 --> 00:18:15,216 A:middle
to the generic min-T function.

409
00:18:15,986 --> 00:18:18,746 A:middle
When the compiler performs
generic specialization,

410
00:18:19,056 --> 00:18:21,696 A:middle
first it looks at the call
to min and foo and sees, oh,

411
00:18:22,326 --> 00:18:23,726 A:middle
there are two integers
being passed

412
00:18:23,926 --> 00:18:25,396 A:middle
to the generic min-T
function here.

413
00:18:26,276 --> 00:18:30,666 A:middle
Then since the compiler
can see the definition

414
00:18:30,666 --> 00:18:34,386 A:middle
of the generic min-T
function, it can clone min-T

415
00:18:34,386 --> 00:18:36,286 A:middle
and specialize this
clone function

416
00:18:36,286 --> 00:18:41,416 A:middle
by replacing the generic type T
with the specialized type Int.

417
00:18:42,596 --> 00:18:45,156 A:middle
Then the specialized
function is optimized for Int,

418
00:18:45,676 --> 00:18:49,136 A:middle
and all the overhead associated
with this function is removed,

419
00:18:49,136 --> 00:18:50,276 A:middle
so all the reference count --

420
00:18:50,276 --> 00:18:52,546 A:middle
the unnecessary reference
counting calls are removed,

421
00:18:52,546 --> 00:18:54,866 A:middle
and we can compare the
two integers directly.

422
00:18:56,356 --> 00:18:58,556 A:middle
Finally, the compiler
replaces the call

423
00:18:58,556 --> 00:19:01,126 A:middle
to the generic min-T
function with a call

424

425
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

426
00:18:58,556 --> 00:19:01,126 A:middle
to the generic min-T
function with a call

427
00:19:01,126 --> 00:19:04,066 A:middle
to the specialized
min Int function,

428
00:19:04,306 --> 00:19:06,046 A:middle
enabling further optimizations.

429
00:19:07,756 --> 00:19:11,756 A:middle
While generic specialization is
a very powerful optimization,

430
00:19:12,466 --> 00:19:15,986 A:middle
it does have one
limitation; namely, that --

431
00:19:15,986 --> 00:19:18,386 A:middle
namely, the visibility of
the generic definition.

432
00:19:18,596 --> 00:19:20,616 A:middle
For instance, this case,
the generic definition

433
00:19:20,616 --> 00:19:21,626 A:middle
of the min-T function.

434
00:19:22,956 --> 00:19:24,426 A:middle
Here we have a function compute

435
00:19:24,956 --> 00:19:27,176 A:middle
which calls a generic min-T
function with two integers.

436
00:19:27,906 --> 00:19:31,776 A:middle
In this case, can we perform
generic specialization?

437
00:19:32,566 --> 00:19:34,476 A:middle
Well, even though
the compiler can see

438
00:19:34,476 --> 00:19:36,096 A:middle
that two integers
are being passed

439
00:19:36,096 --> 00:19:37,516 A:middle
to the generic min-T function,

440
00:19:38,336 --> 00:19:40,426 A:middle
because we are compiling
file 1.Swift

441
00:19:41,046 --> 00:19:44,756 A:middle
and file 2.Swift separately,
the definition of functions

442
00:19:44,756 --> 00:19:47,506 A:middle
from file 2 are not
visible to the compiler

443
00:19:47,676 --> 00:19:49,946 A:middle
when the compiler
is compiling file 1.

444
00:19:50,116 --> 00:19:54,186 A:middle
So in this case, the compiler
cannot see the definition

445
00:19:54,366 --> 00:19:57,536 A:middle
of the generic min-T function
when it's compiling file 1,

446
00:19:57,536 --> 00:20:01,206 A:middle
and so we must call the
generic min-T function.

447

448
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

449
00:19:57,536 --> 00:20:01,206 A:middle
and so we must call the
generic min-T function.

450
00:20:02,576 --> 00:20:06,466 A:middle
But what if we have Whole
Module Optimization enabled?

451
00:20:07,856 --> 00:20:10,876 A:middle
Well, if we have Whole
Module Optimization enabled,

452
00:20:11,216 --> 00:20:15,536 A:middle
both file 1.Swift and file
2.Swift are compiled together.

453
00:20:16,046 --> 00:20:17,976 A:middle
This means that definitions
from file 1

454
00:20:17,976 --> 00:20:19,976 A:middle
and file 2 are both visible

455
00:20:19,976 --> 00:20:22,656 A:middle
when you are compiling
file 1 or file 2 together.

456
00:20:22,656 --> 00:20:26,656 A:middle
So basically, this means that
the generic min-T function,

457
00:20:26,656 --> 00:20:28,046 A:middle
even though it's in file 2,

458
00:20:29,046 --> 00:20:32,606 A:middle
can be seen when we
are compiling file 1.

459
00:20:33,726 --> 00:20:36,706 A:middle
Thus, we are able to specialize
the generic min-T function

460
00:20:36,736 --> 00:20:41,246 A:middle
into min int and replace the
call to min-T with min Int.

461
00:20:42,396 --> 00:20:44,716 A:middle
This is but one case
where the power

462
00:20:44,716 --> 00:20:46,466 A:middle
of whole module optimization
is apparent.

463
00:20:47,166 --> 00:20:50,326 A:middle
The only reason the compiler can
perform generic specification

464
00:20:50,326 --> 00:20:54,186 A:middle
in this case is because of the
extra information provided to it

465
00:20:54,266 --> 00:20:56,866 A:middle
by having Whole Module
Optimization being enabled.

466

467
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

468
00:21:00,876 --> 00:21:05,466 A:middle
Now that I have spoken about
generics, I'd like to conclude

469
00:21:05,896 --> 00:21:08,656 A:middle
by talking about
dynamic dispatch.

470
00:21:11,236 --> 00:21:14,166 A:middle
Here I have a class
hierarchy for the class Pet.

471
00:21:15,196 --> 00:21:19,716 A:middle
Notice that Pet has a method
noise, a property name,

472
00:21:20,126 --> 00:21:22,656 A:middle
and a method noiseimpl,
which is used

473
00:21:22,656 --> 00:21:23,816 A:middle
to implement the method nose.

474
00:21:24,686 --> 00:21:27,026 A:middle
Also notice it has a subclass

475
00:21:27,026 --> 00:21:29,596 A:middle
of Pet called Dog
that overrides noise.

476
00:21:30,186 --> 00:21:32,526 A:middle
Now consider the
function make noise.

477
00:21:33,136 --> 00:21:34,526 A:middle
It's a very simple function,

478
00:21:34,656 --> 00:21:38,476 A:middle
it takes an argument p that's
an instance of class Pet.

479
00:21:38,886 --> 00:21:42,016 A:middle
Even though this block of code
only involves a small amount

480
00:21:42,016 --> 00:21:45,806 A:middle
of source again, a lot more is
occurring here behind the scenes

481
00:21:45,806 --> 00:21:46,566 A:middle
than one might think.

482
00:21:46,866 --> 00:21:50,056 A:middle
For instance, the following
pseudo-Swift code is not what is

483
00:21:50,056 --> 00:21:51,476 A:middle
actually emitted
by the compiler.

484
00:21:51,846 --> 00:21:53,796 A:middle
Name and noise are
not called directly.

485
00:21:53,876 --> 00:21:56,466 A:middle
Instead, the compiler
emits this code.

486
00:21:57,176 --> 00:21:58,956 A:middle
Notice the indirection
here that's used

487
00:21:58,956 --> 00:22:02,266 A:middle
to call names getter
or the method noise.

488

489
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

490
00:21:58,956 --> 00:22:02,266 A:middle
to call names getter
or the method noise.

491
00:22:02,436 --> 00:22:04,516 A:middle
The compiler must
insert this indirection

492
00:22:04,826 --> 00:22:08,076 A:middle
because it cannot know given the
current class hierarchy whether

493
00:22:08,076 --> 00:22:11,846 A:middle
or not the property name or
the method noise are meant

494
00:22:11,846 --> 00:22:13,476 A:middle
to be overridden by subclasses.

495
00:22:14,606 --> 00:22:17,316 A:middle
The compiler in this
case can only emit --

496
00:22:17,876 --> 00:22:21,356 A:middle
can only emit direct
calls if it can prove

497
00:22:21,856 --> 00:22:24,536 A:middle
that there are no
possible overrides

498
00:22:24,756 --> 00:22:27,546 A:middle
by any subclasses
of name or noise.

499
00:22:28,766 --> 00:22:32,056 A:middle
In the case of noise, this
is exactly what we want.

500
00:22:32,456 --> 00:22:34,446 A:middle
We want noise to be
able to be overridden

501
00:22:34,446 --> 00:22:35,746 A:middle
by subclasses in this API.

502
00:22:36,396 --> 00:22:38,296 A:middle
We want to make it so
that if I have an instance

503
00:22:38,296 --> 00:22:42,636 A:middle
of Pet that's really a dog, the
dog barks when I call noise.

504
00:22:42,636 --> 00:22:45,916 A:middle
And if I have an instance of
Pet that's actually a class,

505
00:22:46,246 --> 00:22:47,986 A:middle
that when I call
noise, we have a meow.

506
00:22:48,246 --> 00:22:49,266 A:middle
That makes perfect sense.

507
00:22:50,626 --> 00:22:54,626 A:middle
But in the case of name,
this is actually undesirable.

508
00:22:55,326 --> 00:22:56,586 A:middle
This is because in this API,

509
00:22:57,226 --> 00:23:01,006 A:middle
name is not -- is
never overridden.

510

511
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

512
00:22:57,226 --> 00:23:01,006 A:middle
name is not -- is
never overridden.

513
00:23:01,006 --> 00:23:02,696 A:middle
It's not necessary
to override name.

514
00:23:03,226 --> 00:23:04,106 A:middle
We can model this

515
00:23:04,606 --> 00:23:06,766 A:middle
by constraining this
API's class hierarchy.

516
00:23:08,186 --> 00:23:10,086 A:middle
There are two Swift language
features that I am going

517
00:23:10,086 --> 00:23:11,686 A:middle
to show you today
that you can use

518
00:23:11,716 --> 00:23:13,616 A:middle
to constrain your
API's class hierarchy.

519
00:23:14,066 --> 00:23:15,706 A:middle
The first are constraints
on inheritance,

520
00:23:16,176 --> 00:23:19,536 A:middle
and the second are constrains
on access via access control.

521
00:23:19,616 --> 00:23:23,586 A:middle
Let's begin by talking about
inheritance constraints,

522
00:23:23,646 --> 00:23:25,136 A:middle
namely, the final keyword.

523
00:23:25,646 --> 00:23:29,496 A:middle
When an API contains
a declaration

524
00:23:29,496 --> 00:23:32,556 A:middle
with the final keyword attached,
the API is communicating

525
00:23:32,556 --> 00:23:35,746 A:middle
that this declaration will never
be overridden by a subclass.

526
00:23:36,846 --> 00:23:38,476 A:middle
Consider again the
make noise example.

527
00:23:38,986 --> 00:23:42,006 A:middle
By default, the compiler
must use indirection

528
00:23:42,446 --> 00:23:44,196 A:middle
to call the getter for name.

529
00:23:44,576 --> 00:23:49,096 A:middle
This is because without more
information, it can't know

530
00:23:49,326 --> 00:23:51,226 A:middle
if name is overridden
by a subclass.

531
00:23:51,626 --> 00:23:56,096 A:middle
But we know that in this API,
name is never overridden,

532
00:23:56,096 --> 00:24:00,236 A:middle
and we know that in this API,
it's not intended for name

533

534
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

535
00:23:56,096 --> 00:24:00,236 A:middle
and we know that in this API,
it's not intended for name

536
00:24:00,236 --> 00:24:02,056 A:middle
to be able to be overridden.

537
00:24:02,226 --> 00:24:04,956 A:middle
So we can enforce this
and communicate this

538
00:24:05,026 --> 00:24:07,516 A:middle
by attaching the
final keyword to name.

539
00:24:08,956 --> 00:24:12,586 A:middle
Then the compiler can look
at name and realize, oh,

540
00:24:12,586 --> 00:24:14,256 A:middle
this will never be
overridden by a subclass,

541
00:24:14,256 --> 00:24:17,696 A:middle
and the dynamic dispatch, the
indirection, can be eliminated.

542
00:24:17,696 --> 00:24:22,866 A:middle
Now that we've talked about
final inheritance constraints,

543
00:24:22,936 --> 00:24:25,086 A:middle
I'd like to talk a little
bit about access control.

544
00:24:26,296 --> 00:24:30,776 A:middle
Turns out in this API, pet and
dog are both in separate files,

545
00:24:31,086 --> 00:24:35,056 A:middle
pet.Swift and dog.Swift, but are
in the same module, module A.

546
00:24:35,526 --> 00:24:39,046 A:middle
Additionally, there is another
subclass of pet called Cat

547
00:24:39,376 --> 00:24:42,446 A:middle
in a different module but
in the file cat.Swift.

548
00:24:42,596 --> 00:24:44,036 A:middle
The question I'd like to ask is,

549
00:24:44,116 --> 00:24:47,476 A:middle
can the compiler emit a
direct call to noiseimpl?

550
00:24:49,036 --> 00:24:50,466 A:middle
By default, it cannot.

551
00:24:51,146 --> 00:24:53,536 A:middle
This is because by default,
the compiler must assume

552
00:24:53,536 --> 00:24:56,986 A:middle
that this API intended for
noiseimpl to be overridden

553
00:24:56,986 --> 00:24:58,896 A:middle
in subclasses like Cat and Dog.

554
00:24:59,916 --> 00:25:02,516 A:middle
But we know that
this is not true.

555

556
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

557
00:24:59,916 --> 00:25:02,516 A:middle
But we know that
this is not true.

558
00:25:02,806 --> 00:25:06,936 A:middle
We know that noiseimpl is a
private implementation detail

559
00:25:07,376 --> 00:25:11,026 A:middle
of pet.Swift and that it
shouldn't be visible outside

560
00:25:11,026 --> 00:25:11,746 A:middle
of pet.swift.

561
00:25:12,616 --> 00:25:16,036 A:middle
We can enforce this by
attaching the private keyword

562
00:25:16,266 --> 00:25:16,956 A:middle
to noiseimpl.

563
00:25:18,136 --> 00:25:20,186 A:middle
Once we attach the private
keyword to noiseimpl,

564
00:25:20,506 --> 00:25:23,566 A:middle
noiseimpl is no longer
visible outside of pet.Swift.

565
00:25:24,436 --> 00:25:26,756 A:middle
This means that the
compiler can immediately know

566
00:25:27,016 --> 00:25:30,486 A:middle
that there cannot be any
overrides of noiseimpl in cat

567
00:25:30,486 --> 00:25:33,016 A:middle
or dog because, well,
they are not in pet.Swift,

568
00:25:33,016 --> 00:25:36,066 A:middle
and since there is only
one class in pet.Swift

569
00:25:36,566 --> 00:25:39,256 A:middle
that implements noiseimpl,
namely Pet,

570
00:25:39,416 --> 00:25:43,186 A:middle
the compiler can emit a direct
call to noiseimpl in this case.

571
00:25:44,546 --> 00:25:47,376 A:middle
Now that we've spoken about
private, I would like to talk

572
00:25:47,376 --> 00:25:50,156 A:middle
about the interaction between
Whole Module Optimization

573
00:25:50,156 --> 00:25:50,976 A:middle
and access control.

574
00:25:51,516 --> 00:25:54,246 A:middle
We have been talking a lot

575
00:25:54,246 --> 00:25:56,966 A:middle
about the class Pet,
but what about Dog?

576
00:25:58,036 --> 00:26:00,906 A:middle
Remember that Dog
is a subclass of Pet

577

578
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

579
00:25:58,036 --> 00:26:00,906 A:middle
Remember that Dog
is a subclass of Pet

580
00:26:00,906 --> 00:26:05,086 A:middle
that has internal access
instead of public access.

581
00:26:05,956 --> 00:26:08,356 A:middle
If we call noise on an
instance of class Dog,

582
00:26:08,786 --> 00:26:12,096 A:middle
without more information, the
compiler must insert indirection

583
00:26:12,626 --> 00:26:15,176 A:middle
because it cannot know if
there is a subclass of Dog

584
00:26:15,176 --> 00:26:16,826 A:middle
in a different file of module A.

585
00:26:17,896 --> 00:26:20,306 A:middle
But when we have Whole
Module Optimization enabled,

586
00:26:21,006 --> 00:26:23,456 A:middle
the compiler has
module-wide visibility.

587
00:26:23,976 --> 00:26:26,436 A:middle
It can see all the files
in the module together.

588
00:26:27,016 --> 00:26:29,946 A:middle
And so the compiler is
able to see, well, no,

589
00:26:29,946 --> 00:26:31,426 A:middle
there are no subclasses of dog,

590
00:26:31,846 --> 00:26:35,036 A:middle
so the compiler can
call noise directly

591
00:26:35,036 --> 00:26:36,806 A:middle
on instances of class Dog.

592
00:26:37,086 --> 00:26:40,146 A:middle
The key thing to notice here
is that all I needed to do was

593
00:26:40,146 --> 00:26:42,026 A:middle
to turn on Whole
Module Optimization.

594
00:26:42,546 --> 00:26:44,926 A:middle
I didn't need to
change my code at all.

595
00:26:45,706 --> 00:26:47,846 A:middle
By giving the compiler
more information,

596
00:26:48,186 --> 00:26:50,886 A:middle
by allowing the compiler to
understand my class hierarchy,

597
00:26:51,186 --> 00:26:54,206 A:middle
with more information I was
able to get this optimization

598
00:26:54,426 --> 00:26:59,356 A:middle
for free without
any work on my part.

599
00:26:59,526 --> 00:27:01,496 A:middle
Now I'd like to bring
back that graph

600

601
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

602
00:26:59,526 --> 00:27:01,496 A:middle
Now I'd like to bring
back that graph

603
00:27:01,496 --> 00:27:02,676 A:middle
that Nadav introduced earlier.

604
00:27:03,506 --> 00:27:10,306 A:middle
Why Is Swift so much
faster than Objective-C

605
00:27:11,286 --> 00:27:14,206 A:middle
on these object-oriented
benchmarks?

606
00:27:16,596 --> 00:27:20,016 A:middle
The reason why is
that in Objective-C,

607
00:27:20,856 --> 00:27:23,856 A:middle
the compiler cannot
eliminate the dynamic dispatch

608
00:27:23,856 --> 00:27:24,886 A:middle
through Ob-C message send.

609
00:27:25,126 --> 00:27:26,316 A:middle
It can't inline through it.

610
00:27:26,316 --> 00:27:27,706 A:middle
It can't perform any analysis.

611
00:27:27,826 --> 00:27:30,216 A:middle
The compiler must assume
that there could be anything

612
00:27:30,336 --> 00:27:32,046 A:middle
on the other side of
an Ob-C message send.

613
00:27:32,886 --> 00:27:35,906 A:middle
But in Swift, the compiler
has more information.

614
00:27:36,236 --> 00:27:39,466 A:middle
It's able to see all the certain
things on the other side.

615
00:27:39,466 --> 00:27:42,146 A:middle
It's able to eliminate this
dynamic dispatch in many cases.

616
00:27:43,246 --> 00:27:44,996 A:middle
And in those cases
where it does,

617
00:27:45,396 --> 00:27:47,476 A:middle
a lot more performance results,

618
00:27:47,736 --> 00:27:51,426 A:middle
resulting in significantly
faster code.

619
00:27:51,646 --> 00:27:55,406 A:middle
So please, use the final
keyword in access control

620
00:27:55,406 --> 00:27:57,036 A:middle
to communicate your
API's intent.

621
00:27:57,686 --> 00:28:00,426 A:middle
This will help the compiler to
understand your class hierarchy,

622

623
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

624
00:27:57,686 --> 00:28:00,426 A:middle
This will help the compiler to
understand your class hierarchy,

625
00:28:01,306 --> 00:28:03,806 A:middle
which will enable
additional optimizations.

626
00:28:04,016 --> 00:28:07,906 A:middle
However, keep in mind that
existing clients may need

627
00:28:07,906 --> 00:28:10,006 A:middle
to be updated in
response to such changes.

628
00:28:10,576 --> 00:28:12,186 A:middle
And try out Whole
Module Optimization

629
00:28:12,186 --> 00:28:12,986 A:middle
in your release builds.

630
00:28:12,986 --> 00:28:16,366 A:middle
It will enable the compiler to
make further optimizations --

631
00:28:16,456 --> 00:28:18,466 A:middle
for instance, more
aggressive specialization --

632
00:28:18,736 --> 00:28:20,736 A:middle
and by allowing the compiler

633
00:28:20,736 --> 00:28:22,996 A:middle
to better understand your
API's class hierarchy,

634
00:28:23,316 --> 00:28:25,686 A:middle
without any work on your
part, you can benefit

635
00:28:25,686 --> 00:28:30,326 A:middle
from increased elimination
of dynamic dispatch.

636
00:28:30,426 --> 00:28:32,716 A:middle
Now I'd like to turn this
presentation over to Joe,

637
00:28:32,716 --> 00:28:35,206 A:middle
who will show you how you
can use these techniques

638
00:28:35,276 --> 00:28:37,396 A:middle
and instruments to
improve the performance

639
00:28:37,606 --> 00:28:39,386 A:middle
of your application today.

640
00:28:40,516 --> 00:28:46,366 A:middle
[Applause]

641
00:28:46,866 --> 00:28:48,356 A:middle
>> JOE GRZYWACZ:
Thank you, Michael.

642
00:28:48,766 --> 00:28:49,796 A:middle
My name is Joe Grzywacz.

643
00:28:49,796 --> 00:28:51,396 A:middle
I am an engineer on
the Instruments Team,

644
00:28:51,526 --> 00:28:52,256 A:middle
and today I want to take you

645
00:28:52,256 --> 00:28:54,806 A:middle
through a demo application
that's running a little slowly

646
00:28:54,806 --> 00:29:03,686 A:middle
right now, so let's get started.

647

648
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

649
00:28:54,806 --> 00:29:03,686 A:middle
right now, so let's get started.

650
00:29:03,766 --> 00:29:04,566 A:middle
All right.

651
00:29:08,596 --> 00:29:11,576 A:middle
So here we have my Swift
application that's running

652
00:29:11,576 --> 00:29:14,966 A:middle
slowly, so what I want to do
is go ahead and click and hold

653
00:29:14,966 --> 00:29:17,126 A:middle
on the Run button
and choose Profile.

654
00:29:17,126 --> 00:29:19,436 A:middle
That's going to build my
application in release mode

655
00:29:19,496 --> 00:29:21,316 A:middle
and then launch instruments
as template choosers

656
00:29:21,316 --> 00:29:23,066 A:middle
so we can decide how we
want to profile this.

657
00:29:23,376 --> 00:29:25,726 A:middle
Since it's running slowly,
a good place to start is

658
00:29:25,726 --> 00:29:27,076 A:middle
with the time profiler template.

659
00:29:28,256 --> 00:29:30,316 A:middle
From Instruments,
just press Record,

660
00:29:30,816 --> 00:29:33,736 A:middle
your application launches, and
Instruments is recording data

661
00:29:33,736 --> 00:29:35,086 A:middle
in the background
about what it's doing.

662
00:29:35,666 --> 00:29:36,546 A:middle
So here we can see
we are running

663
00:29:36,546 --> 00:29:38,596 A:middle
at 60 frames per second
before I've started anything,

664
00:29:38,926 --> 00:29:41,256 A:middle
which is my target performance.

665
00:29:41,636 --> 00:29:43,456 A:middle
But as soon as I add these
particles to the screen,

666
00:29:43,546 --> 00:29:45,136 A:middle
they are moving around and
avoiding each other just

667
00:29:45,136 --> 00:29:47,246 A:middle
like I wanted, but we
are running at only

668
00:29:47,246 --> 00:29:48,606 A:middle
about 38 frames per second.

669
00:29:48,646 --> 00:29:50,306 A:middle
We lost about a third
of our performance.

670
00:29:50,306 --> 00:29:52,226 A:middle
Now that we have
reproduced the problem,

671
00:29:52,666 --> 00:29:55,296 A:middle
we can quit our application
and come back to Instruments.

672
00:29:56,106 --> 00:29:57,136 A:middle
Let me make this a
little bit larger

673
00:29:57,136 --> 00:29:58,086 A:middle
so we can see what's going on.

674
00:29:58,846 --> 00:30:01,606 A:middle
You can just drag
this, drag that around.

675

676
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

677
00:29:58,846 --> 00:30:01,606 A:middle
You can just drag
this, drag that around.

678
00:30:01,816 --> 00:30:03,416 A:middle
View Snap Track to Fit is handy

679
00:30:03,416 --> 00:30:05,146 A:middle
to make your data fill
your horizontal time.

680
00:30:05,836 --> 00:30:06,796 A:middle
Now what are we looking at?

681
00:30:06,866 --> 00:30:09,356 A:middle
Here in the track view,
this is our CPU usage

682
00:30:09,356 --> 00:30:10,086 A:middle
of our application.

683
00:30:10,196 --> 00:30:13,366 A:middle
We can see on the left before I
did anything, CPU usage was low;

684
00:30:13,756 --> 00:30:16,256 A:middle
after I added those particles,
CPU usage became higher.

685
00:30:16,656 --> 00:30:18,726 A:middle
You can see what those values
are by moving your mouse

686
00:30:18,726 --> 00:30:20,816 A:middle
and hovering it inside
this ruler view.

687
00:30:21,226 --> 00:30:24,276 A:middle
You can see prior we were around
10% or so, not doing much.

688
00:30:24,656 --> 00:30:26,926 A:middle
Later on we moved around 100%.

689
00:30:26,926 --> 00:30:28,336 A:middle
So we saturated our CPU.

690
00:30:28,646 --> 00:30:30,606 A:middle
In order to increase
our performance,

691
00:30:30,836 --> 00:30:32,516 A:middle
we need to decrease how
much work we're doing.

692
00:30:33,166 --> 00:30:34,386 A:middle
So what work were we doing?

693
00:30:34,716 --> 00:30:37,236 A:middle
That's where this detail
pane down below comes in.

694
00:30:38,496 --> 00:30:39,846 A:middle
So here's all of our threads.

695
00:30:40,226 --> 00:30:41,606 A:middle
Go ahead and open
this up a little bit.

696
00:30:41,606 --> 00:30:43,576 A:middle
You are probably familiar
with this call stack

697
00:30:43,576 --> 00:30:46,056 A:middle
from seeing it inside of
Xcode in the debugger.

698
00:30:46,316 --> 00:30:49,346 A:middle
Start, calls main, calls NS
application main, et cetera.

699
00:30:49,346 --> 00:30:51,046 A:middle
But what Instruments
is also going

700
00:30:51,046 --> 00:30:53,636 A:middle
to tell you is how much time
you were spending inside

701
00:30:53,636 --> 00:30:55,446 A:middle
of that function,
including its children,

702
00:30:55,846 --> 00:30:57,466 A:middle
right here in this first
column Running Time.

703
00:30:57,546 --> 00:31:01,436 A:middle
We can see 11,220 milliseconds,
or 99% of our time,

704

705
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

706
00:30:57,546 --> 00:31:01,436 A:middle
We can see 11,220 milliseconds,
or 99% of our time,

707
00:31:01,796 --> 00:31:04,136 A:middle
was spent in NSApplication
Main or the things it called.

708
00:31:04,666 --> 00:31:05,776 A:middle
The second column, Self,

709
00:31:05,776 --> 00:31:07,516 A:middle
is how much time the
instrument sampled inside

710
00:31:07,516 --> 00:31:09,996 A:middle
that function itself, so
it excludes its children.

711
00:31:10,876 --> 00:31:11,996 A:middle
So what I want to
do is see where does

712
00:31:11,996 --> 00:31:13,766 A:middle
that self number get
larger, and that means

713
00:31:13,766 --> 00:31:15,586 A:middle
that function is actually
performing a lot of work.

714
00:31:16,096 --> 00:31:18,546 A:middle
You can continue opening these
up one by one, hunting around,

715
00:31:18,606 --> 00:31:19,686 A:middle
but that can take
a little while.

716
00:31:20,436 --> 00:31:22,616 A:middle
Instead we recommend you come
over here to the right side,

717
00:31:22,806 --> 00:31:24,046 A:middle
this extended detail view,

718
00:31:24,046 --> 00:31:26,886 A:middle
and Instruments will show you
the single heaviest stack trace

719
00:31:26,886 --> 00:31:27,596 A:middle
in your application.

720
00:31:27,596 --> 00:31:29,726 A:middle
That's where it sampled
the most number of times.

721
00:31:30,036 --> 00:31:31,396 A:middle
You can see again here
is our main thread,

722
00:31:31,396 --> 00:31:34,006 A:middle
it took 11,229 milliseconds.

723
00:31:34,236 --> 00:31:35,856 A:middle
It began in Start.

724
00:31:35,936 --> 00:31:37,986 A:middle
Symbols in gray are
system frameworks.

725
00:31:38,276 --> 00:31:40,616 A:middle
Symbols in black here,
like Main, are your code.

726
00:31:40,616 --> 00:31:42,966 A:middle
And what I'd like to do is just
look down this list and see

727
00:31:42,966 --> 00:31:43,926 A:middle
if it's kind of a big jump.

728
00:31:43,926 --> 00:31:46,626 A:middle
That means something interesting
happened around this time.

729
00:31:46,626 --> 00:31:47,496 A:middle
If I scan down this list,

730
00:31:47,496 --> 00:31:49,046 A:middle
the number is slowly
getting smaller,

731
00:31:49,046 --> 00:31:52,026 A:middle
but there's no big jumps going
on, until I get down here

732
00:31:52,106 --> 00:31:54,696 A:middle
where I see a jump from
about 9,000 to about 4,000.

733
00:31:54,696 --> 00:31:55,756 A:middle
So something happened there.

734
00:31:55,756 --> 00:31:57,536 A:middle
I am going to go ahead
and click on my code,

735
00:31:58,176 --> 00:32:00,246 A:middle
and Instruments has
automatically expanded the call

736

737
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

738
00:31:58,176 --> 00:32:00,246 A:middle
and Instruments has
automatically expanded the call

739
00:32:00,246 --> 00:32:02,336 A:middle
tree on the left side so you can
see what you just clicked on.

740
00:32:03,566 --> 00:32:04,796 A:middle
Let me frame this up.

741
00:32:06,226 --> 00:32:07,196 A:middle
And what's going on here?

742
00:32:07,816 --> 00:32:09,476 A:middle
Well, if I back up just a
little bit for a moment,

743
00:32:09,476 --> 00:32:12,616 A:middle
here is my NSFiretimer call,
what's driving my simulation,

744
00:32:12,616 --> 00:32:14,156 A:middle
trying to get at 60
frames per second.

745
00:32:14,736 --> 00:32:18,766 A:middle
Down here is my particle
Sim.app delegate.update routine,

746
00:32:19,106 --> 00:32:20,846 A:middle
that's my Swift routine
driving my simulation.

747
00:32:21,446 --> 00:32:25,006 A:middle
But in between is this weird
@objc thing sitting here.

748
00:32:25,586 --> 00:32:27,706 A:middle
I want to point out
that's just a thunk.

749
00:32:27,826 --> 00:32:30,856 A:middle
Basically, it's a compiler
inserted function that gets us

750
00:32:30,856 --> 00:32:34,026 A:middle
from the Objective-C
world here in NSFiretimer

751
00:32:34,466 --> 00:32:36,956 A:middle
down to the Swift world
down here inside of my code.

752
00:32:37,316 --> 00:32:37,916 A:middle
That's all it is.

753
00:32:37,916 --> 00:32:38,806 A:middle
Otherwise, we can ignore it.

754
00:32:39,566 --> 00:32:42,456 A:middle
Now, we can see my update
routine is taking 89%

755
00:32:42,456 --> 00:32:43,916 A:middle
of the time, so continuing

756
00:32:43,916 --> 00:32:45,656 A:middle
to optimize this
function is a good idea.

757
00:32:45,656 --> 00:32:48,056 A:middle
So everything else above it is
not really interesting to me.

758
00:32:48,146 --> 00:32:50,236 A:middle
I am going to go ahead
and hide it by focusing

759
00:32:50,236 --> 00:32:51,896 A:middle
in on just this update routine

760
00:32:51,896 --> 00:32:53,586 A:middle
by clicking this arrow
here on the right.

761
00:32:54,536 --> 00:32:56,106 A:middle
Everything else around
this has been hidden.

762
00:32:56,556 --> 00:32:59,406 A:middle
Running time has been
renormalized to 100%,

763
00:32:59,406 --> 00:33:02,356 A:middle
just to help you do a
little less mental math.

764

765
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

766
00:32:59,406 --> 00:33:02,356 A:middle
just to help you do a
little less mental math.

767
00:33:02,356 --> 00:33:04,126 A:middle
If we look in on what's
going on in this function,

768
00:33:04,166 --> 00:33:06,636 A:middle
Update Phase Avoid calls
Find Nearest Neighbor,

769
00:33:07,076 --> 00:33:09,416 A:middle
that calls down into something
really interesting here.

770
00:33:09,856 --> 00:33:12,956 A:middle
We see Swift release is
taking 40% of our time,

771
00:33:13,026 --> 00:33:15,996 A:middle
and Swift retain is taking
another 35% of our time.

772
00:33:16,106 --> 00:33:19,546 A:middle
So between just these two
functions, we are doing

773
00:33:19,546 --> 00:33:20,396 A:middle
about three-quarters

774
00:33:20,396 --> 00:33:22,876 A:middle
of our update routine is just
managing reference counts.

775
00:33:23,616 --> 00:33:24,526 A:middle
Far from ideal.

776
00:33:24,626 --> 00:33:26,046 A:middle
So what's going on here?

777
00:33:26,566 --> 00:33:28,676 A:middle
Well, if I double-click on my
Find Nearest Neighbor routine

778
00:33:29,686 --> 00:33:31,366 A:middle
that calls those
retains releases,

779
00:33:31,366 --> 00:33:32,776 A:middle
Instruments will show
you the source code.

780
00:33:33,256 --> 00:33:35,736 A:middle
However, Swift is an automatic
reference counted language,

781
00:33:35,736 --> 00:33:37,376 A:middle
so you are not going
to see the releases

782
00:33:37,376 --> 00:33:38,556 A:middle
and retains here directly.

783
00:33:39,206 --> 00:33:41,946 A:middle
But you can, if you go over
to the disassembly view,

784
00:33:42,636 --> 00:33:43,656 A:middle
click on that button there,

785
00:33:44,206 --> 00:33:46,336 A:middle
Instruments will show you what
the compiler actually generated.

786
00:33:46,856 --> 00:33:47,946 A:middle
And you can hunt around in here

787
00:33:47,946 --> 00:33:49,616 A:middle
and see there's a
bunch of calls here.

788
00:33:49,616 --> 00:33:52,426 A:middle
There's 23% of the
time on this release.

789
00:33:52,746 --> 00:33:54,646 A:middle
There's some more
retains and releases here.

790
00:33:54,646 --> 00:33:55,946 A:middle
There is another
release down here.

791
00:33:55,946 --> 00:33:57,076 A:middle
They are all over the place.

792
00:33:57,156 --> 00:33:58,686 A:middle
So what can we do about that?

793
00:33:59,846 --> 00:34:04,176 A:middle
Let's return to our code here
and go to my particle file.

794

795
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

796
00:33:59,846 --> 00:34:04,176 A:middle
Let's return to our code here
and go to my particle file.

797
00:34:04,316 --> 00:34:05,596 A:middle
Here is my class Particle,

798
00:34:05,636 --> 00:34:07,056 A:middle
so it's an internal
class by default.

799
00:34:07,056 --> 00:34:09,306 A:middle
And it adheres to some
collidable protocol.

800
00:34:09,686 --> 00:34:10,016 A:middle
All right.

801
00:34:11,106 --> 00:34:13,775 A:middle
Down below is -- this is the
Find Nearest Neighbor routine

802
00:34:13,775 --> 00:34:15,286 A:middle
that was taking all
of that time before.

803
00:34:15,956 --> 00:34:19,255 A:middle
Now, I know that when the update
timer fires, that code is going

804
00:34:19,255 --> 00:34:21,246 A:middle
to call Find Nearest Neighbor
on every single particle

805
00:34:21,246 --> 00:34:24,786 A:middle
on the screen, and then there's
this interfor loop that's going

806
00:34:24,786 --> 00:34:26,926 A:middle
to iterate over every single
particle on the screen.

807
00:34:27,076 --> 00:34:30,396 A:middle
We have an N-squared
algorithm here or effectively,

808
00:34:30,396 --> 00:34:32,146 A:middle
the stuff that happens
inside this for loop is going

809
00:34:32,146 --> 00:34:33,806 A:middle
to happen a really
large number of times.

810
00:34:34,436 --> 00:34:37,216 A:middle
Whatever we do to optimize this
thing should have big payoff.

811
00:34:37,815 --> 00:34:38,636 A:middle
So what is going on?

812
00:34:39,016 --> 00:34:40,466 A:middle
We have our for loop itself

813
00:34:40,466 --> 00:34:42,275 A:middle
where we access one
of those particles.

814
00:34:42,275 --> 00:34:43,735 A:middle
So there's some retain
release overhead.

815
00:34:44,416 --> 00:34:46,755 A:middle
There are property
getters being called here,

816
00:34:46,755 --> 00:34:47,896 A:middle
this dot ID property.

817
00:34:48,246 --> 00:34:49,426 A:middle
And as Michael was
talking about,

818
00:34:49,426 --> 00:34:50,755 A:middle
since this is an internal class,

819
00:34:50,786 --> 00:34:52,246 A:middle
there might be some other
Swift files somewhere

820
00:34:52,246 --> 00:34:54,866 A:middle
that overrides these property
getters, so we are going

821
00:34:54,866 --> 00:34:56,565 A:middle
to be performing
a dynamic dispatch

822
00:34:56,886 --> 00:34:57,916 A:middle
to these property getters,

823
00:34:57,916 --> 00:34:59,706 A:middle
which has retain/release
overhead as well.

824

825
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

826
00:35:00,976 --> 00:35:03,096 A:middle
Down here there is this
distance squared function call.

827
00:35:03,616 --> 00:35:06,596 A:middle
Despite the fact that it lives
literally a dozen source code

828
00:35:06,596 --> 00:35:08,426 A:middle
lines away, once
again, we are going

829
00:35:08,426 --> 00:35:11,306 A:middle
to be doing a dynamic dispatch
to this routine with all

830
00:35:11,306 --> 00:35:13,236 A:middle
of that overhead as well as
the retain release overhead.

831
00:35:13,676 --> 00:35:16,076 A:middle
So what can we do
about this code?

832
00:35:16,336 --> 00:35:18,006 A:middle
Well, this code is complete.

833
00:35:18,316 --> 00:35:20,096 A:middle
I wrote this application,
I am finished,

834
00:35:20,096 --> 00:35:21,576 A:middle
my particle class is complete,

835
00:35:21,716 --> 00:35:23,366 A:middle
and I have no need
to subclass it.

836
00:35:23,576 --> 00:35:25,586 A:middle
So what I should do is
communicate my intention

837
00:35:25,586 --> 00:35:28,186 A:middle
to the compiler by marking
this class as final.

838
00:35:28,226 --> 00:35:32,746 A:middle
So with that one little
change, let's go ahead

839
00:35:32,746 --> 00:35:35,066 A:middle
and profile application
again and see what happened.

840
00:35:36,516 --> 00:35:39,386 A:middle
This time, the compiler was
able to compile that file,

841
00:35:39,386 --> 00:35:41,856 A:middle
knowing that there are
no other subclasses

842
00:35:41,856 --> 00:35:44,456 A:middle
of that particle file --
particle class, excuse me --

843
00:35:44,876 --> 00:35:46,356 A:middle
and that means it's able

844
00:35:46,356 --> 00:35:48,606 A:middle
to perform additional
optimizations.

845
00:35:48,856 --> 00:35:50,536 A:middle
It can call those
functions directly,

846
00:35:50,536 --> 00:35:53,396 A:middle
maybe even inline them, or any
other number of optimizations

847
00:35:53,626 --> 00:35:55,796 A:middle
that can reduce the
overhead that we had before.

848
00:35:56,586 --> 00:36:00,276 A:middle
So if we record, this time
when I add the particles,

849

850
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

851
00:35:56,586 --> 00:36:00,276 A:middle
So if we record, this time
when I add the particles,

852
00:36:00,276 --> 00:36:01,926 A:middle
we can see they are
moving around and running

853
00:36:01,926 --> 00:36:03,586 A:middle
around at 60 frames per
second at this time,

854
00:36:03,586 --> 00:36:05,566 A:middle
so we got back 20 frames
per second with just

855
00:36:05,566 --> 00:36:06,666 A:middle
that one small change.

856
00:36:07,286 --> 00:36:08,246 A:middle
That's looking good.

857
00:36:08,456 --> 00:36:09,926 A:middle
However, as you may guess,

858
00:36:09,926 --> 00:36:12,136 A:middle
I have a second phase
here called collision

859
00:36:12,136 --> 00:36:13,586 A:middle
where we swap the algorithm

860
00:36:13,586 --> 00:36:14,936 A:middle
and now they are
bouncing off one another,

861
00:36:15,246 --> 00:36:17,776 A:middle
and again our frame rate
dropped by about 25 percent

862
00:36:17,776 --> 00:36:19,346 A:middle
down to 45 frames per second.

863
00:36:19,966 --> 00:36:23,096 A:middle
We reproduced the problem again,
let's return to Instruments

864
00:36:23,256 --> 00:36:24,746 A:middle
and see what's happening.

865
00:36:24,746 --> 00:36:28,496 A:middle
We will do what we do before,
make this a little bit larger,

866
00:36:29,036 --> 00:36:32,376 A:middle
Snap Track to Fit, and
now what do we see?

867
00:36:32,376 --> 00:36:35,466 A:middle
Over here on the left, this
was our avoidance phase.

868
00:36:35,566 --> 00:36:39,456 A:middle
Things are running much
better, around 30%, 40% or so,

869
00:36:39,456 --> 00:36:41,586 A:middle
so that's why we are hitting
our 60 frames per second.

870
00:36:42,376 --> 00:36:45,186 A:middle
But over here on the right,
this is our collision phase.

871
00:36:45,216 --> 00:36:48,486 A:middle
And now this is capping
out at 100% of our CPU,

872
00:36:48,746 --> 00:36:50,286 A:middle
and that's why our frame
rate is suffering again.

873
00:36:50,966 --> 00:36:54,996 A:middle
We did what we did a moment ago
right now, this call tree data

874
00:36:54,996 --> 00:36:57,656 A:middle
down here in the detail
pane is going to have data

875
00:36:57,656 --> 00:36:59,666 A:middle
from this avoidance phase,
which is running fine,

876
00:36:59,966 --> 00:37:02,516 A:middle
as well as this collision phase,
which is what I really want

877

878
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

879
00:36:59,966 --> 00:37:02,516 A:middle
as well as this collision phase,
which is what I really want

880
00:37:02,516 --> 00:37:04,216 A:middle
to actually be focusing on.

881
00:37:04,216 --> 00:37:06,956 A:middle
So that avoidance
sample over here is going

882
00:37:06,956 --> 00:37:08,156 A:middle
to water down our results.

883
00:37:08,516 --> 00:37:10,996 A:middle
Instead, I would like to set a
time filter so I am only looking

884
00:37:10,996 --> 00:37:11,926 A:middle
at my collision phase.

885
00:37:12,286 --> 00:37:13,376 A:middle
That's really simple to do.

886
00:37:13,376 --> 00:37:15,496 A:middle
Just click and drag
in the timeline view,

887
00:37:16,076 --> 00:37:17,596 A:middle
and now our detail
pane has been updated

888
00:37:17,596 --> 00:37:19,916 A:middle
to only consider the samples
from our collision phase.

889
00:37:20,856 --> 00:37:22,486 A:middle
Now we can do what
we did before,

890
00:37:22,486 --> 00:37:24,766 A:middle
head over to our
extended detail view.

891
00:37:25,696 --> 00:37:28,766 A:middle
Look down this list,
see where we see a jump,

892
00:37:28,766 --> 00:37:30,406 A:middle
and something interesting
happens here,

893
00:37:30,406 --> 00:37:32,646 A:middle
we went from about
8,000 milliseconds

894
00:37:32,646 --> 00:37:33,916 A:middle
to 2,000 milliseconds.

895
00:37:33,916 --> 00:37:36,616 A:middle
So I am going to click on my
collision detection class here.

896
00:37:37,696 --> 00:37:40,216 A:middle
Instruments once again
automatically expands this call

897
00:37:40,216 --> 00:37:40,896 A:middle
tree for us.

898
00:37:41,636 --> 00:37:43,386 A:middle
And if we just kind of look
at what's going on here,

899
00:37:43,536 --> 00:37:47,036 A:middle
88% of my time is spend inside
of this runtime step routine.

900
00:37:47,036 --> 00:37:48,356 A:middle
This is a good place to dig in.

901
00:37:48,936 --> 00:37:50,516 A:middle
I'll do what I did
before and click

902
00:37:50,516 --> 00:37:52,006 A:middle
on this Focus arrow
here on the right.

903
00:37:52,056 --> 00:37:54,576 A:middle
Now we are looking at just
our runtime step routine,

904
00:37:55,306 --> 00:37:56,416 A:middle
and let's see what it's doing.

905
00:37:57,286 --> 00:37:57,546 A:middle
All right.

906
00:37:57,546 --> 00:37:59,756 A:middle
Well, 25% of its time
is being spent inside

907
00:37:59,756 --> 00:38:02,286 A:middle
of Swift.array.underscore
getelement.

908

909
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

910
00:37:59,756 --> 00:38:02,286 A:middle
of Swift.array.underscore
getelement.

911
00:38:02,956 --> 00:38:05,726 A:middle
When you see this A
inside of angle brackets,

912
00:38:05,816 --> 00:38:07,706 A:middle
that means you are calling
into the generic form

913
00:38:07,706 --> 00:38:10,166 A:middle
of that function and all
the overhead that entails.

914
00:38:10,786 --> 00:38:12,976 A:middle
You will see this
again here inside

915
00:38:12,976 --> 00:38:15,416 A:middle
of Swift array is
valid subscript,

916
00:38:15,716 --> 00:38:17,646 A:middle
there's that A inside
of angle brackets.

917
00:38:18,036 --> 00:38:19,356 A:middle
It also happens when you have

918
00:38:19,356 --> 00:38:20,896 A:middle
that A inside of
square brackets.

919
00:38:20,896 --> 00:38:23,426 A:middle
So we are calling a generic
property getter here.

920
00:38:23,676 --> 00:38:26,276 A:middle
So just between these
three generic functions,

921
00:38:26,276 --> 00:38:31,006 A:middle
we are looking at about 50% of
our time is being spent inside

922
00:38:31,006 --> 00:38:32,126 A:middle
of these generic functions.

923
00:38:32,456 --> 00:38:34,726 A:middle
So what can we do about
getting rid of that overhead?

924
00:38:34,726 --> 00:38:37,226 A:middle
All right, back over to Xcode.

925
00:38:38,456 --> 00:38:40,326 A:middle
Here is my collision
detection file.

926
00:38:40,866 --> 00:38:43,006 A:middle
Here we can see that
collidable protocol

927
00:38:43,106 --> 00:38:44,586 A:middle
that my particle
was adhering to.

928
00:38:45,016 --> 00:38:47,356 A:middle
Here is that generic
class, class detection,

929
00:38:47,666 --> 00:38:50,226 A:middle
type T that adheres to
a collidable protocol.

930
00:38:50,776 --> 00:38:53,526 A:middle
What does it do, well it has
this collidables array here,

931
00:38:53,526 --> 00:38:54,816 A:middle
that's of generic type T.

932
00:38:55,446 --> 00:38:58,296 A:middle
And here down below is
our runtime step routine,

933
00:38:58,436 --> 00:39:00,566 A:middle
and that's where we were
spending all of our time.

934

935
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

936
00:38:58,436 --> 00:39:00,566 A:middle
and that's where we were
spending all of our time.

937
00:39:00,976 --> 00:39:02,286 A:middle
So what does this function do?

938
00:39:02,646 --> 00:39:05,796 A:middle
Well, it iterates over all
our collidables, accesses one

939
00:39:05,796 --> 00:39:08,306 A:middle
of the collidables from
that array, calls a bunch

940
00:39:08,306 --> 00:39:09,726 A:middle
of property getters here.

941
00:39:10,026 --> 00:39:10,726 A:middle
Here's some more.

942
00:39:11,056 --> 00:39:13,366 A:middle
There is an interfor
loop, where we do kind

943
00:39:13,366 --> 00:39:14,536 A:middle
of the same thing again, we pull

944
00:39:14,536 --> 00:39:16,426 A:middle
out another second
collidable from that array.

945
00:39:16,726 --> 00:39:18,406 A:middle
Then all sorts of property
getters down below.

946
00:39:18,566 --> 00:39:21,386 A:middle
We're doing a lot of generic
operations here, and we'd really

947
00:39:21,386 --> 00:39:22,856 A:middle
like to get rid of that.

948
00:39:22,856 --> 00:39:23,626 A:middle
How do we do that?

949
00:39:24,176 --> 00:39:28,406 A:middle
Well, this time you can see my
collision detection class is

950
00:39:28,406 --> 00:39:29,726 A:middle
here inside of this Swift file.

951
00:39:30,096 --> 00:39:33,996 A:middle
However, the users of this,

952
00:39:34,126 --> 00:39:36,196 A:middle
where I am using this class
is inside this app delegate

953
00:39:36,196 --> 00:39:38,746 A:middle
routine, this particle Swift
file, so it's in other parts

954
00:39:38,746 --> 00:39:40,676 A:middle
of this module, so we
are going to have to turn

955
00:39:40,676 --> 00:39:41,966 A:middle
to Whole Module Optimization.

956
00:39:42,716 --> 00:39:45,166 A:middle
Doing that's really easy,
just click on your project.

957
00:39:46,356 --> 00:39:48,206 A:middle
Go over here to build settings.

958
00:39:48,626 --> 00:39:50,436 A:middle
Make sure you are looking at
all of your build settings.

959
00:39:50,916 --> 00:39:52,906 A:middle
Then just do a search
for optimization.

960
00:39:54,046 --> 00:39:57,006 A:middle
And here is that setting that
Nadav showed you earlier.

961
00:39:57,106 --> 00:39:58,786 A:middle
You just want to switch
your release build

962
00:39:58,816 --> 00:40:00,376 A:middle
over to Whole Module
Optimization.

963

964
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

965
00:39:58,816 --> 00:40:00,376 A:middle
over to Whole Module
Optimization.

966
00:40:01,046 --> 00:40:03,406 A:middle
And now when we profile, the
compiler is going to look

967
00:40:03,406 --> 00:40:07,236 A:middle
at all those files together and
build a more optimized binary,

968
00:40:07,446 --> 00:40:08,606 A:middle
but let's check and
see what happened.

969
00:40:09,286 --> 00:40:11,306 A:middle
So we will launch time profiler
for the third time here,

970
00:40:12,006 --> 00:40:15,746 A:middle
start our recording, and
60 frames per second,

971
00:40:16,166 --> 00:40:18,566 A:middle
we add our particles, this
avoidance phase still running

972
00:40:18,566 --> 00:40:19,736 A:middle
at 60 frames per second.

973
00:40:19,876 --> 00:40:21,426 A:middle
Good, I expected
that not to change.

974
00:40:21,466 --> 00:40:22,426 A:middle
Always good to verify.

975
00:40:23,046 --> 00:40:24,906 A:middle
Then we move over to
our collision phase.

976
00:40:24,976 --> 00:40:27,666 A:middle
Now that is running at 60
frames per second as well.

977
00:40:28,076 --> 00:40:30,376 A:middle
All it took was a couple
minutes of analysis

978
00:40:30,376 --> 00:40:31,626 A:middle
and a few small tweaks,

979
00:40:31,726 --> 00:40:33,496 A:middle
and we made our application
a lot faster.

980
00:40:34,516 --> 00:40:41,696 A:middle
[Applause]

981
00:40:42,196 --> 00:40:42,846 A:middle
All right.

982
00:40:42,846 --> 00:40:44,166 A:middle
So to summarize what
we saw here today,

983
00:40:44,566 --> 00:40:47,006 A:middle
we know that Swift is a
flexible programming language

984
00:40:47,296 --> 00:40:48,686 A:middle
that uses -- that's safe

985
00:40:48,686 --> 00:40:50,236 A:middle
and uses automatic
reference counting

986
00:40:50,306 --> 00:40:51,656 A:middle
to perform its memory
management.

987
00:40:51,936 --> 00:40:53,916 A:middle
Now, those powerful features
are what make it a delight

988
00:40:53,916 --> 00:40:56,416 A:middle
to program in, but they
can come with a cost.

989
00:40:56,596 --> 00:40:59,446 A:middle
What we want you to do is focus
on your APIs and your code

990
00:40:59,446 --> 00:41:01,816 A:middle
that when you are writing them,
you keep performance in mind.

991

992
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00,000

993
00:40:59,446 --> 00:41:01,816 A:middle
that when you are writing them,
you keep performance in mind.

994
00:41:01,816 --> 00:41:04,316 A:middle
And how do you know what
costs you are paying for?

995
00:41:04,766 --> 00:41:06,596 A:middle
Profile your application
inside of Instruments,

996
00:41:06,596 --> 00:41:07,976 A:middle
and do it throughout
the lifetime

997
00:41:07,976 --> 00:41:10,756 A:middle
of your application development
so that when you find a problem,

998
00:41:10,786 --> 00:41:13,506 A:middle
you find it sooner and you
can react to that more easily,

999
00:41:13,506 --> 00:41:16,686 A:middle
especially if it involves
changing some of your APIs.

1000
00:41:17,456 --> 00:41:19,506 A:middle
There's documentation
online, of course.

1001
00:41:19,506 --> 00:41:22,146 A:middle
The Developer Forums where you
can go, and you will be able

1002
00:41:22,146 --> 00:41:23,876 A:middle
to ask questions about
Swift and get them answered,

1003
00:41:23,876 --> 00:41:25,086 A:middle
as well as Instruments.

1004
00:41:26,336 --> 00:41:28,356 A:middle
And speaking of Instruments,
there's a Profiling

1005
00:41:28,356 --> 00:41:30,586 A:middle
in Depth talk today
in Mission at 3:30.

1006
00:41:30,586 --> 00:41:33,056 A:middle
There is an entire session
devoted to Time Profiler

1007
00:41:33,056 --> 00:41:34,446 A:middle
and getting into even more depth

1008
00:41:34,506 --> 00:41:35,956 A:middle
than we're able to
get into today.

1009
00:41:36,386 --> 00:41:37,596 A:middle
And as Michael talked
about earlier,

1010
00:41:37,596 --> 00:41:40,106 A:middle
there is a Building Better
Apps with Value Types in Swift

1011
00:41:40,106 --> 00:41:42,086 A:middle
that will also build
upon what you saw today.

1012
00:41:42,086 --> 00:41:42,906 A:middle
So thank you very much.

1013
00:41:43,516 --> 00:41:47,500 A:middle
[Applause]

1014
